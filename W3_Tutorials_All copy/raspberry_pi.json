{
  "course_name": "Raspberry Pi",
  "description": "Node.js is a free, open source tool that lets you run JavaScript outside the web browser. With Node.js, you can build fast and scalable applications like web servers, APIs, tools, and more. Tip: Sign in to track your progress - it's free. Node.js uses an event-driven, non-blocking model. It can handle many connections at once without waiting for one to finish before starting another. This makes it great for real-time apps and high-traffic websites. Here are some examples of what you can build with Node.js: Save your code in a file, for example app.js, then run it in your terminal or command prompt with: This will start your Node.js program. REMOVE ADS Our \"Show Node.js\" tool makes it easy to learn Node.js, it shows both the code and the result. Click on the \"Run example\" button to see how it works. In this tutorial there will be some examples that are better explained by displaying the result in the command line interface.",
  "course_summary": [
    {
      "title": "Node.js Introduction",
      "summary": "What You'll Learn\nIn this tutorial, you'll learn:\nHow to install and run Node.js\nCore concepts like modules and the event loop\nHow to build web servers and APIs\nWorking with databases and files\nDeploying Node.js applications\nWhat is Node.js?\nNode.js is a free, open-source JavaScript runtime that runs on Windows, Mac, Linux, and more.\nIt lets you execute JavaScript code outside of a web browser, enabling server-side development with JavaScript.\nBuilt on Chrome's V8 JavaScript engine, Node.js is designed for building scalable network applications efficiently.\nExample: Print a MessageGet your own Node.js Server\nWhy Node.js?\nNode.js excels at handling many simultaneous connections with minimal overhead, making it perfect for:\nReal-time applications (chats, gaming, collaboration tools)\nAPIs and microservices\nData streaming applications\nCommand-line tools\nServer-side web applications\nIts non-blocking, event-driven architecture makes it highly efficient for I/O-heavy workloads.\nREMOVE ADS\nAsynchronous Programming\nNode.js uses asynchronous (non-blocking) programming.\nThis means it can keep working while waiting for tasks like reading files or talking to a database.\nWith asynchronous code, Node.js can handle many things at once—making it fast and efficient.\nExample: Read a File Asynchronously\nIn this example:\nWe load the built-in fs module\nWe call readFile to read a file\nNode.js continues to the next line while reading the file\nWhen the file is read, our callback function runs\nThis non-blocking behavior lets Node.js handle many requests efficiently.\nWhat Can Node.js Do?\nWeb Servers: Create fast, scalable network applications\nFile Operations: Read, write, and manage files on the server\nDatabase Interaction: Work with databases like MongoDB, MySQL, and more\nAPIs: Build RESTful services and GraphQL APIs\nReal-time: Handle WebSockets for live applications\nCLI Tools: Create command-line applications\nExample: Simple Web Server\nWhat is a Node.js File?\nNode.js files contain code that runs on the server. They usually have the .js extension and can be started with the node command.\nNode.js files run tasks when certain events happen (like a web request)\nThey must be started on the server to have any effect\nThey use JavaScript syntax\nExample: Running a Node.js File\nNode.js Versions & LTS:\nNode.js releases a new major version every six months.\nFor stability, use an LTS (Long Term Support) version for production projects.",
      "examples": [
        "console.log('Hello from Node.js!');",
        "// Load the filesystem module\nconst fs = require('fs');\n\n// Read file asynchronously\nfs.readFile('myfile.txt', 'utf8', (err, data) => {\nif (err) {\nconsole.error('Error reading file: ' + err);\nreturn;\n}\nconsole.log('File content: ' + data);\n});\n\nconsole.log('Reading file... (this runs first!)');",
        "const http = require('http');\nhttp.createServer((req, res) => {\nres.writeHead(200, {'Content-Type': 'text/plain'});\nres.end('Hello World!');\n}).listen(8080);",
        "node app.js",
        "fs",
        "readFile",
        ".js",
        "node"
      ]
    },
    {
      "title": "Node.js Get Started",
      "summary": "Download and Install Node.js\nGo to https://nodejs.org\nDownload the LTS (Long Term Support) version\nRun the installer and follow the instructions\nVerify Installation\nOpen your terminal/command prompt and type:\nYou should see version numbers for both Node.js and npm (Node Package Manager).\nTroubleshooting\nIf the commands don't work:\nRestart your terminal/command prompt\nMake sure Node.js was added to your system's PATH during installation\nOn Windows, you might need to restart your computer\nGetting Started\nOnce you have installed Node.js, let's create your first server that says \"Hello World!\" in a web browser.\nCreate a file called myfirst.js and add this code:\nmyfirst.js\nSave the file on your computer, for example: C:\\Users\\Your Name\\myfirst.js\nThis code creates a simple web server.\nWhen someone visits your computer on port 8080, it will show \"Hello World!\".\nCommand Line Interface\nNode.js files must be initiated in the \"Command Line Interface\" program of your computer.\nHow to open the command line interface on your computer depends on the operating system.\nFor Windows users, press the start button and look for \"Command Prompt\", or simply write \"cmd\" in the search field.\nNavigate to the folder that contains the file \"myfirst.js\", the command line interface window should look something like this:\nREMOVE ADS\nInitiate the Node.js File\nThe file you have just created must be initiated by Node.js before any action can take place.\nStart your command line interface, write node myfirst.js and hit enter:\nInitiate \"myfirst.js\":\nNow, your computer works as a server!\nIf anyone tries to access your computer on port 8080, they will get a \"Hello World!\" message in return!\nStart your internet browser, and type in the address: http://localhost:8080",
      "examples": [
        "node --version\nnpm --version",
        "let http = require('http');\nhttp.createServer(function (req, res) {\nres.writeHead(200, {'Content-Type': 'text/html'});\nres.end('Hello World!');\n}).listen(8080);",
        "C:\\Users\\Your Name>_",
        "C:\\Users\\Your Name>node myfirst.js",
        "myfirst.js",
        "C:\\Users\\Your Name\\myfirst.js",
        "node myfirst.js"
      ]
    },
    {
      "title": "Node.js JavaScript Requirements",
      "summary": "Quick Start\nIf you're new to JavaScript, don't worry!\nHere are the key concepts you need to know before diving into Node.js.\nWe'll cover the essentials with simple examples.\nTry It Yourself\nYou can run these examples directly in your browser's console or in a .js file using Node.js.\nJavaScript Fundamentals\nBefore starting with Node.js, you should be familiar with these JavaScript concepts:\nVariables\nFunctions\nObjects\nArrays\nAsynchronous programming (callbacks, promises, async/await)\nES6+ features\nThis page will give short examples of essential JavaScript concepts needed for Node.js development.\nFor a greater understanding for JavaScipt, visit our JavaScript Tutorial.\nVariables and FunctionsGet your own Node.js Server\nObjects and Arrays\nAsynchronous JavaScript\nDestructuring & Template Literals (ES6+)\nKey JavaScript Concepts\nVariables: let (mutable), const (immutable), var (legacy)\nFunctions: Regular, arrow functions, and methods\nObjects & Arrays: Data structures for organizing data\nModules: require() (CommonJS) and import/export (ES6)\nError Handling: try/catch blocks\nREMOVE ADS\nQuick Reference Table",
      "examples": [
        "// Variables (let, const, var)\nlet name = 'Node.js';\nconst version = 20;\n\n// Function declaration\nfunction greet(user) {\nreturn `Hello, ${user}!`; // Template literal (ES6)\n}\n\n// Arrow function (ES6+)\nconst add = (a, b) => a + b;\n\nconsole.log(greet('Developer')); // Hello, Developer!\nconsole.log(add(5, 3)); // 8",
        "// Object\nconst user = {\nname: 'Alice',\nage: 25,\ngreet() {\nconsole.log(`Hi, I'm ${this.name}`);\n}\n};\n\n// Array\nconst colors = ['red', 'green', 'blue'];\n\n// Array methods (ES6+)\ncolors.forEach(color => console.log(color));\nconst lengths = colors.map(color => color.length);",
        "// 1. Callbacks (traditional)\nfunction fetchData(callback) {\nsetTimeout(() => {\ncallback('Data received!');\n}, 1000);\n}\n\n// 2. Promises (ES6+)\nconst fetchDataPromise = () => {\nreturn new Promise((resolve) => {\nsetTimeout(() => resolve('Promise resolved!'), 1000);\n});\n};\n\n// 3. Async/Await (ES8+)\nasync function getData() {\nconst result = await fetchDataPromise();\nconsole.log(result);\n}\n\ngetData(); // Call the async function",
        "const { name } = user;\nconsole.log(`Hello, ${name}!`);",
        ".js",
        "let",
        "const",
        "var",
        "require()",
        "import/export",
        "try/catch"
      ]
    },
    {
      "title": "Node.js vs Browser",
      "summary": "Key Differences\nNode.js and browsers both run JavaScript, but they have different environments and capabilities.\nNode.js is designed for server-side development, while browsers are for client-side applications.\nAPIs: Node.js provides APIs for file system, networking, and OS, which browsers do not.\nBrowsers provide DOM, fetch, and UI APIs not available in Node.js.\nGlobal Objects: Node.js uses global; browsers use window or self.\nModules: Node.js uses CommonJS (require) and ES modules (import); browsers use ES modules or plain <script> tags.\nSecurity: Browsers run in a sandbox with limited access; Node.js has full access to the file system and network.\nEvent Loop: Both environments use an event loop, but Node.js has additional APIs for timers, process, etc.\nEnvironment Variables: Node.js can access environment variables (process.env); browsers cannot.\nPackage Management: Node.js uses npm/yarn; browsers use CDNs or bundlers.\nThis page explains the key differences, with examples for each environment.\nExamples\nGlobal ObjectsGet your own Node.js Server\nFile Access\nHTTP Requests\nModules\nREMOVE ADS\nComparison Table",
      "examples": [
        "// Node.js\nglobal.mylet = 42;\nconsole.log(global.mylet); // 42",
        "// Browser\nwindow.mylet = 42;\nconsole.log(window.mylet); // 42",
        "// Node.js\nconst fs = require('fs');\nfs.readFile('myfile.txt', 'utf8', (err, data) => {\nif (err) throw err;\nconsole.log(data);\n});",
        "// Browser\n// Not allowed for security reasons",
        "// Node.js\nconst https = require('https');\nhttps.get('https://example.com', res => {\nlet data = '';\nres.on('data', chunk => data += chunk);\nres.on('end', () => console.log(data));\n});",
        "// Browser\nfetch('https://example.com')\n.then(response => response.text())\n.then(console.log);",
        "// Node.js (CommonJS)\nconst fs = require('fs');",
        "// Node.js & Browser (ES Modules)\n// import fs from 'fs'; // Node.js only, not browser\n// import _ from 'https://cdn.jsdelivr.net/npm/lodash-es/lodash.js'; // Browser",
        "global",
        "window",
        "self",
        "require",
        "import",
        "<script>",
        "process.env"
      ]
    },
    {
      "title": "Node.js Command Line Usage",
      "summary": "Node.js provides a powerful command line interface (CLI) that allows you to run JavaScript files, manage packages, debug applications, and more.\nThis guide covers the essential commands and techniques every Node.js developer should know.\nNote: All commands should be run in a terminal or command prompt.\nOn Windows, you can use Command Prompt, PowerShell, or Windows Terminal.\nOn macOS/Linux, use Terminal.\nBasic Node.js Commands\nThese are the most common commands you'll use when working with Node.js applications:\nRun a JavaScript fileGet your own Node.js Server\nUsing the REPL\nThe Node.js REPL (Read-Eval-Print Loop) is an interactive shell for executing JavaScript code.\nThe REPL is started by running node in the terminal:\nUsing the REPL\nCommand Line Arguments\nAccess command line arguments using process.argv:\nCommand Line Arguments\nEnvironment Variables\nAccess and set environment variables:\nEnvironment Variables\nSet Environment Variables\nDebugging Node.js Applications\nNode.js includes a powerful debugging system that integrates with Chrome DevTools:\nBasic Debugging Commands\nUsing Chrome DevTools for Debugging\nStart your application with node --inspect app.js\nOpen Chrome and navigate to chrome://inspect\nClick on \"Open dedicated DevTools for Node\"\nSet breakpoints and debug your application\nCommon CLI Tools\nNode.js comes with several useful command-line tools:\nNode Version Manager (nvm)\nnpm (Node Package Manager)\nCommon Command Line Flags\nNode.js provides several command-line flags to control its behavior. Here are some of the most useful ones:\nBasic Flags\nRuntime Behavior\nPerformance and Optimization",
      "examples": [
        "# Run a JavaScript file\nnode app.js\n\n# Run with additional arguments\nnode app.js arg1 arg2\n\n# Run in watch mode (restarts on file changes)\nnode --watch app.js",
        "> const name = 'Node.js';\n> console.log(`Hello, ${name}!`);\n> .help // Show available commands\n> .exit // Exit REPL",
        "// args.js\nconsole.log('All arguments:', process.argv);\nconsole.log('First argument:', process.argv[2]);\nconsole.log('Second argument:', process.argv[3]);\n\n// Example usage:\n// node args.js hello world\n// Output:\n// All arguments: ['/path/to/node', '/path/to/args.js', 'hello', 'world']\n// First argument: hello\n// Second argument: world",
        "// env.js\nconsole.log('Environment:', process.env.NODE_ENV || 'development');\nconsole.log('Custom variable:', process.env.MY_VARIABLE);\nconsole.log('Database URL:', process.env.DATABASE_URL || 'Not set');\n\n// Example usage with environment variables:\n// NODE_ENV=production MY_VARIABLE=test node env.js",
        "# Set environment variables when running\nNODE_ENV=production MY_VARIABLE=test node env.js",
        "# Start with inspector (listens on default port 9229)\nnode --inspect app.js\n\n# Break on first line of application\nnode --inspect-brk app.js\n\n# Specify a custom port\nnode --inspect=9222 app.js\n\n# Enable remote debugging (be careful with this in production)\nnode --inspect=0.0.0.0:9229 app.js",
        "# Install and use different Node.js versions\nnvm install 18.16.0 # Install specific version\nnvm use 18.16.0 # Switch to version\nnvm ls # List installed versions",
        "# Common npm commands\nnpm init # Initialize a new project\nnpm install # Install dependencies\nnpm update # Update packages\nnpm audit # Check for vulnerabilities",
        "# Show Node.js version\nnode --version # or -v\n\n# Show V8 version\nnode --v8-options\n\n# Show command-line help\nnode --help",
        "# Check syntax without executing\nnode --check app.js\n\n# Show stack traces for warnings\nnode --trace-warnings app.js\n\n# Set max memory (in MB)\nnode --max-old-space-size=4096 app.js\n\n# Preload a module before execution\nnode --require dotenv/config app.js",
        "# Enable ES module loader\nnode --experimental-modules app.mjs\n\n# Enable experimental features\nnode --experimental-repl-await\n\n# Enable experimental worker threads\nnode --experimental-worker",
        "node",
        "process.argv",
        "node --inspect app.js",
        "chrome://inspect"
      ]
    },
    {
      "title": "Node.js V8 Engine",
      "summary": "What is the V8 Engine?\nThe V8 engine is Google's open-source JavaScript engine, used by Chrome and Node.js.\nIt compiles JavaScript to native machine code for fast execution.\nOrigin: Developed by Google for Chrome in 2008\nIntegration: Node.js uses V8 to provide JavaScript runtime on the server\nFeatures: Just-In-Time compilation, efficient garbage collection, ES6+ support\nWhy V8 Makes Node.js Fast\nJust-In-Time (JIT) Compilation: Converts JavaScript into optimized machine code instead of interpreting it\nHidden Classes: Optimizes property access on JavaScript objects\nEfficient Garbage Collection: Manages memory to prevent leaks and optimize performance\nInline Caching: Speeds up property access by remembering where to find object properties\nExample: Check V8 Version in Node.jsGet your own Node.js Server\nREMOVE ADS\nUnderstanding V8's Role in Node.js\nV8 provides the core JavaScript execution environment that Node.js is built upon.\nIt allows Node.js to:\nExecute JavaScript code outside the browser\nAccess operating system functionality (file system, networking, etc.)\nUse the same JavaScript engine that powers Chrome for consistency\nExample: V8 Memory Usage\nV8's Update Cycle\nV8 is constantly being improved with new JavaScript features and performance optimizations.\nNode.js regularly updates its V8 engine version\nNew Node.js versions often include newer versions of V8\nThis provides access to newer JavaScript features and better performance\nV8 implements the ECMAScript and WebAssembly standards.\nWhen a new JavaScript feature becomes part of the ECMAScript standard, V8 will eventually implement it, making it available in both Chrome and Node.js.",
      "examples": [
        "// Show the V8 engine version used by your Node.js installation\nconsole.log(`V8 version: ${process.versions.v8}`);",
        "// Get information about V8's heap memory usage\nconst v8 = require('v8');\nconst heapStats = v8.getHeapStatistics();\n\nconsole.log('Heap size limit:', (heapStats.heap_size_limit / 1024 / 1024).toFixed(2), 'MB');\nconsole.log('Total heap size:', (heapStats.total_heap_size / 1024 / 1024).toFixed(2), 'MB');\nconsole.log('Used heap size:', (heapStats.used_heap_size / 1024 / 1024).toFixed(2), 'MB');"
      ]
    },
    {
      "title": "Node.js Architecture",
      "summary": "What is Node.js Architecture?\nNode.js uses a single-threaded, event-driven architecture that is designed to handle many connections at once, efficiently and without blocking the main thread.\nThis makes Node.js ideal for building scalable network applications, real-time apps, and APIs.\nKey Characteristics: Non-blocking I/O, event-driven, single-threaded with event loop, asynchronous execution\nNode.js Architecture Diagram\nHere is a simple overview of how Node.js processes requests:\n1. Client Request Phase\nClients send requests to the Node.js server\nEach request is added to the Event Queue\n2. Event Loop Phase\nThe Event Loop continuously checks the Event Queue\nPicks up requests one by one in a loop\n3. Request Processing\nSimple (non-blocking) tasks are handled immediately by the main thread\nComplex/blocking tasks are offloaded to the Thread Pool\n4. Response Phase\nWhen blocking tasks complete, their callbacks are placed in the Callback Queue\nEvent Loop processes callbacks and sends responses\nNon-blocking Examples\nExample: Non-blocking File ReadGet your own Node.js Server\nNotice how \"After file read\" is printed before the file contents, showing that Node.js does not wait for the file operation to finish.\nExample: Blocking vs Non-blocking Code\nKey Difference: The first example blocks the entire process until the file is read, while the second example allows other operations to continue while the file is being read.\nREMOVE ADS\nWhen to Use Node.js\nNode.js is particularly well-suited for:\nI/O-bound applications - File operations, database queries, network requests\nReal-time applications - Chat apps, live notifications, collaboration tools\nAPIs - RESTful services, GraphQL APIs\nMicroservices - Small, independent services\nNote: Node.js may not be the best choice for CPU-intensive tasks as they can block the event loop. For such cases, consider:\nUsing worker threads\nCreating a microservice in a more suitable language\nUsing native add-ons\nSummary\nNode.js is fast and efficient because it uses a non-blocking event loop and delegates heavy work to the system.\nThis allows it to handle thousands of connections at the same time, with minimal resources.\nKey Benefits:\nHandles many concurrent connections efficiently\nGreat for I/O-bound applications\nUses JavaScript on both client and server\nLarge ecosystem of packages (npm)",
      "examples": [
        "const fs = require('fs');\nconsole.log('Before file read');\nfs.readFile('myfile.txt', 'utf8', (err, data) => {\nif (err) throw err;\nconsole.log('File contents:', data);\n});\nconsole.log('After file read');",
        "// Blocking code example\nconsole.log('Start of blocking code');\nconst data = fs.readFileSync('myfile.txt', 'utf8'); // Blocks here\nconsole.log('Blocking operation completed');\n\n// Non-blocking code example\nconsole.log('Start of non-blocking code');\nfs.readFile('myfile.txt', 'utf8', (err, data) => {\nif (err) throw err;\nconsole.log('Non-blocking operation completed');\n});\nconsole.log('This runs before the file is read');"
      ]
    },
    {
      "title": "Node.js Event Loop",
      "summary": "What is the Event Loop?\nThe event loop is what makes Node.js non-blocking and efficient.\nIt handles asynchronous operations by delegating tasks to the system and processing their results through callbacks, allowing Node.js to manage thousands of concurrent connections with a single thread.\nHow the Event Loop Works\nNode.js follows these steps to handle operations:\nExecute the main script (synchronous code)\nProcess any microtasks (Promises, process.nextTick)\nExecute timers (setTimeout, setInterval)\nRun I/O callbacks (file system, network operations)\nProcess setImmediate callbacks\nHandle close events (like socket.on('close'))\nExample: Event Loop OrderGet your own Node.js Server\nThis demonstrates the execution order:\nSync code runs first ('First', 'Fourth')\nMicrotasks (Promises) run before the next phase ('Second')\nTimers execute last ('Third')\nREMOVE ADS\nEvent Loop Phases\nThe event loop processes different types of callbacks in this order:\nTimers: setTimeout, setInterval\nI/O Callbacks: Completed I/O operations\nPoll: Retrieve new I/O events\nCheck: setImmediate callbacks\nClose: Cleanup callbacks (like socket.on('close'))\nNote: Between each phase, Node.js runs microtasks (Promises) and process.nextTick callbacks.\nExample: Event Loop Phases\nThe output will be:\nThis shows the priority order: sync code > nextTick > Promises > Timers > Check phase.\nWhy is the Event Loop Important?\nThe event loop enables Node.js to handle thousands of concurrent connections with a single thread, making it perfect for:\nReal-time applications\nAPIs and microservices\nData streaming\nChat applications\nSummary\nNode.js uses an event loop to handle async operations\nDifferent types of callbacks have different priorities\nMicrotasks (Promises) run before the next event loop phase\nThis non-blocking model enables high concurrency",
      "examples": [
        "console.log('First');\nsetTimeout(() => console.log('Third'), 0);\nPromise.resolve().then(() => console.log('Second'));\nconsole.log('Fourth');",
        "console.log('1. Start');\n\n// Next tick queue\nprocess.nextTick(() => console.log('2. Next tick'));\n\n// Microtask queue (Promise)\nPromise.resolve().then(() => console.log('3. Promise'));\n\n// Timer phase\nsetTimeout(() => console.log('4. Timeout'), 0);\n\n// Check phase\nsetImmediate(() => console.log('5. Immediate'));\n\nconsole.log('6. End');",
        "1. Start 6. End 2. Next tick 3. Promise 4. Timeout 5. Immediate",
        "setTimeout",
        "setInterval",
        "setImmediate",
        "socket.on('close')",
        "process.nextTick"
      ]
    },
    {
      "title": "Node.js Asynchronous Programming",
      "summary": "What is Asynchronous Programming?\nIn Node.js, asynchronous operations let your program do other work while waiting for tasks like file I/O or network requests to complete.\nThis non-blocking approach enables Node.js to handle thousands of concurrent connections efficiently.\nSync vs Async: Key Differences\nSynchronous\nBlocks execution until complete\nSimple to understand\nCan cause delays\nUses functions like readFileSync\nAsynchronous\nNon-blocking execution\nBetter performance\nMore complex to handle\nUses callbacks, promises, or async/await\nExample: Synchronous File ReadGet your own Node.js Server\nOutput will be in order: 1 → 2 → 3 (blocks between each step)\nExample: Asynchronous File Read\nOutput order: 1 → 3 → 2 (doesn't wait for file read to complete)\nREMOVE ADS\nAvoiding Callback Hell\nProblem: Nested Callbacks (Callback Hell)\nSolution: Use Promises\nEven Better: Async/Await\nModern Async Patterns\n1. Promises\n2. Async/Await (Recommended)\nBest Practices\nDo This\nNot This\nKey Takeaways\n✅ Use async/await for better readability\n✅ Always handle errors with try/catch\n✅ Run independent operations in parallel with Promise.all\n❌ Avoid mixing sync and async code patterns\n❌ Don't forget to await promises\nWhy Use Asynchronous Code?\nAsynchronous code lets Node.js handle many requests at once, without waiting for slow operations like file or database access.\nThis makes Node.js great for servers and real-time apps.\nSummary\nAsynchronous Programming in Node.js\nNode.js uses an event loop for non-blocking I/O\nModern async code uses async/await with Promises\nAlways handle errors in async operations\nUse Promise.all for parallel operations\nAvoid callback hell with proper async patterns",
      "examples": [
        "const fs = require('fs');\n\nconsole.log('1. Starting sync read...');\nconst data = fs.readFileSync('myfile.txt', 'utf8');\nconsole.log('2. File contents:', data);\nconsole.log('3. Done reading file');",
        "const fs = require('fs');\n\nconsole.log('1. Starting async read...');\nfs.readFile('myfile.txt', 'utf8', (err, data) => {\nif (err) throw err;\nconsole.log('2. File contents:', data);\n});\n\nconsole.log('3. Done starting read operation');",
        "getUser(userId, (err, user) => {\nif (err) return handleError(err);\ngetOrders(user.id, (err, orders) => {\nif (err) return handleError(err);\nprocessOrders(orders, (err) => {\nif (err) return handleError(err);\nconsole.log('All done!');\n});\n});\n});",
        "getUser(userId)\n.then(user => getOrders(user.id))\n.then(orders => processOrders(orders))\n.then(() => console.log('All done!'))\n.catch(handleError);",
        "async function processUser(userId) {\ntry {\nconst user = await getUser(userId);\nconst orders = await getOrders(user.id);\nawait processOrders(orders);\nconsole.log('All done!');\n} catch (err) {\nhandleError(err);\n}\n}",
        "const fs = require('fs').promises;\n\nconsole.log('1. Reading file...');\nfs.readFile('myfile.txt', 'utf8')\n.then(data => {\nconsole.log('3. File content:', data);\n})\n.catch(err => console.error('Error:', err));\n\nconsole.log('2. This runs before file is read!');",
        "async function readFiles() {\ntry {\nconsole.log('1. Starting to read files...');\nconst data1 = await fs.readFile('file1.txt', 'utf8');\nconst data2 = await fs.readFile('file2.txt', 'utf8');\nconsole.log('2. Files read successfully!');\nreturn { data1, data2 };\n} catch (error) {\nconsole.error('Error reading files:', error);\n}\n}",
        "// Use async/await for better readability\nasync function getUserData(userId) {\ntry {\nconst user = await User.findById(userId);\nconst orders = await Order.find({ userId });\nreturn { user, orders };\n} catch (error) {     console.error('Failed to fetch user data:', error);\nthrow error; // Re-throw or handle appropriately\n}\n}",
        "// Nested callbacks are hard to read and maintain\nUser.findById(userId, (err, user) => {\nif (err) return console.error(err);\nOrder.find({ userId }, (err, orders) => {\nif (err) return console.error(err);\n// Process orders...\n});\n});",
        "// Run multiple async operations in parallel\nasync function fetchAllData() {\ntry {\nconst [users, products, orders] = await Promise.all([\nUser.find(),\nProduct.find(),\nOrder.find()\n]);\nreturn { users, products, orders };\n} catch (error) {\nconsole.error('Error fetching data:', error);\nthrow error;\n}\n}",
        "readFileSync",
        "async/await",
        "try/catch",
        "Promise.all",
        "await"
      ]
    },
    {
      "title": "Node.js Promises",
      "summary": "Introduction to Promises\nPromises in Node.js provide a cleaner way to handle asynchronous operations compared to traditional callbacks.\nPromises represent the completion (or failure) of an asynchronous operation and its result.\nPromise States\nPending: Initial state, operation not completed\nFulfilled: Operation completed successfully\nRejected: Operation failed\nOnce a promise is settled (either fulfilled or rejected), its state cannot change.\nBenefits of Using Promises\nWith CallbacksGet your own Node.js Server\nWith Promises\nFlatter code structure (avoids callback hell)\nBetter error handling with single .catch()\nEasier to compose and chain operations\nBuilt-in support for parallel operations\nCallback Hell Example (Without Promises)\nCreating and Using Promises\nPromises can be created using the Promise constructor, which accepts an executor function with two parameters: resolve and reject.\nBasic Promise Creation\nExample: Reading a File with Promises\nREMOVE ADS\nPromise Chaining\nPromises can be chained to execute asynchronous operations in sequence, with each .then() receiving the result of the previous operation.\nExample: Promise Chaining\nPromise Methods\nthen(onFulfilled, onRejected)\nHandles fulfillment or rejection\ncatch(onRejected)\nHandles rejections\nfinally(onFinally)\nRuns after promise settles\nPromise.all(iterable)\nWaits for all promises to resolve\nPromise.race(iterable)\nWaits for first promise to settle\nPromise.allSettled(iterable)\nWaits for all to settle\nPromise.resolve(value)\nCreates a resolved promise\nPromise.reject(reason)\nCreates a rejected promise\nPromise.then()\nThe then() method takes up to two arguments. The arguments are callback functions for the success and failure cases for the Promise.\nPromise.catch()\nThe catch() method handles rejected promises and is equivalent to .then(null, errorHandler).\nPromise.finally()\nThe finally() method executes code regardless of whether the promise is fulfilled or rejected.\nPromise.all() for Parallel Execution\nPromise.all() is used to run multiple promises in parallel, and wait for ALL of them to complete. It fails fast if any promise rejects.\nExample: Running Multiple Promises in Parallel\nPromise.race() for First Result\nPromise.race() is useful when you need the result of the first settled promise, whether it's fulfilled or rejected.\nExample: Timeout Pattern with Promise.race()\nError Handling in Promises\nProper error handling is important.\nPromises provide several ways to handle errors:\nExample: Error Handling in Promise\nBest Practice: Always include error handling with promises using .catch() to prevent unhandled promise rejections, which can lead to silent failures and memory leaks.",
      "examples": [
        "getUser(id, (err, user) => {\nif (err) return handleError(err);\ngetOrders(user.id, (err, orders) => {\nif (err) return handleError(err);\n// Process orders...\n});\n});",
        "getUser(id)\n.then(user => getOrders(user.id))\n.then(orders => processOrders(orders))\n.catch(handleError);",
        "fs.readFile('file1.txt', (err, data1) => {\nif (err) throw err;\nfs.readFile('file2.txt', (err, data2) => {\nif (err) throw err;\nfs.readFile('file3.txt', (err, data3) => {\nif (err) throw err;\n// Use data1, data2, and data3\n});\n});\n});",
        "// Create a new Promise\nconst myPromise = new Promise((resolve, reject) => {\n// Simulate an async operation (e.g., API call, file read)\nsetTimeout(() => {\nconst success = Math.random() > 0.5;\n\nif (success) {\nresolve('Operation completed successfully');\n} else {\nreject(new Error('Operation failed'));\n}\n}, 1000); // Simulate delay\n});\n\n// Using the Promise\nmyPromise\n.then(result => console.log('Success:', result))\n.catch(error => console.error('Error:', error.message));",
        "const fs = require('fs').promises;\nconst promise1 = Promise.resolve('First result');\nconst promise2 = new Promise((resolve) => setTimeout(() => resolve('Second result'), 1000));\nconst promise3 = fs.readFile('myfile.txt', 'utf8'); // Read local file instead of fetch\n\nPromise.all([promise1, promise2, promise3])\n.then(results => {\nconsole.log('Results:', results);\n// results[0] is from promise1\n// results[1] is from promise2\n// results[2] is the content of myfile.txt\n})\n.catch(error => {\nconsole.error('Error in one of the promises:', error);\n});",
        "function getUser(userId) {\nreturn new Promise((resolve, reject) => {\n// Simulating database call\nsetTimeout(() => {\nresolve({ id: userId, name: 'John' });\n}, 1000);\n});\n}\n\nfunction getUserPosts(user) {\nreturn new Promise((resolve, reject) => {\n// Simulating API call\nsetTimeout(() => {\nresolve(['Post 1', 'Post 2', 'Post 3']);\n}, 1000);\n});\n}\n\n// Chain the promises\ngetUser(123)\n.then(user => {\nconsole.log('User:', user);\nreturn getUserPosts(user);\n})\n.then(posts => {\nconsole.log('Posts:', posts);\n})\n.catch(error => {\nconsole.error('Error:', error);\n});",
        "myPromise\n.then(\nresult => console.log(result),\nerror => console.error(error)\n);",
        "myPromise\n.then(result => console.log(result))\n.catch(error => console.error(error));",
        "myPromise\n.then(result => console.log(result))\n.catch(error => console.error(error))\n.finally(() => console.log('Operation completed'));",
        "const fs = require('fs').promises;\nconst promise1 = Promise.resolve('First result');\nconst promise2 = new Promise((resolve) => setTimeout(() => resolve('Second result'), 1000));\nconst promise3 = fs.readFile('data.txt', 'utf8'); // Read local file instead of fetch\n\nPromise.all([promise1, promise2, promise3])\n.then(results => {\nconsole.log('Results:', results);\n// results[0] is from promise1\n// results[1] is from promise2\n// results[2] is the content of data.txt\n})\n.catch(error => {\nconsole.error('Error in one of the promises:', error);\n});",
        "const promise1 = new Promise(resolve => setTimeout(() => resolve('First result'), 1000));\nconst promise2 = new Promise(resolve => setTimeout(() => resolve('Second result'), 500));\n\nPromise.race([promise1, promise2])\n.then(result => {\nconsole.log('Fastest result:', result);\n// Will log 'Second result' because promise2 is faster\n});",
        "function fetchData() {\nreturn new Promise((resolve, reject) => {\n// Simulating an error\nreject(new Error('Network error'));\n});\n}\n\nfetchData()\n.then(\ndata => console.log('Data:', data),\nerror => console.log('Error handled in then:', error.message)\n);\n\n// Alternative method using catch\nfetchData()\n.then(data => console.log('Data:', data))\n.catch(error => console.log('Error handled in catch:', error.message));",
        ".catch()",
        "Promise",
        "resolve",
        "reject",
        ".then()",
        "then(onFulfilled, onRejected)",
        "catch(onRejected)",
        "finally(onFinally)",
        "Promise.all(iterable)",
        "Promise.race(iterable)",
        "Promise.allSettled(iterable)",
        "Promise.resolve(value)",
        "Promise.reject(reason)",
        "then()",
        "catch()",
        ".then(null, errorHandler)",
        "finally()",
        "Promise.all()",
        "Promise.race()"
      ]
    },
    {
      "title": "Node.js Async/Await",
      "summary": "Introduction to Async/Await\nAsync/await is a modern way to handle asynchronous operations in Node.js, building on top of Promises to create even more readable code.\nIntroduced in Node.js 7.6 and standardized in ES2017, async/await allows you to write asynchronous code that looks and behaves more like synchronous code.\nAsync/await is basically Promises with a more readable syntax. This makes your code cleaner and more maintainable.\nAsync/await makes asynchronous code look and more feel like synchronous code. It does not block the main thread, but is easy to follow and understand.\nSyntax and Usage\nThe syntax consists of two keywords:\nasync: Used to declare an asynchronous function that returns a Promise\nawait: Used to pause execution until a Promise is resolved, can only be used inside async functions\nExample: Basic Async/AwaitGet your own Node.js Server\nExample: Reading a File with Async/Await\nREMOVE ADS\nError Handling with Try/Catch\nOne of the advantages of async/await is that you can use traditional try/catch blocks for error handling, making your code more readable.\nExample: Error Handling with Async/Await\nYou can also mix async/await with Promise .catch() for different scenarios:\nRunning Promises in Parallel\nAlthough async/await makes code look synchronous, sometimes you need to run operations in parallel for better performance.\nExample: Sequential vs Parallel Operations\nAsync/Await vs Promises vs Callbacks\nLet's see how the same task is handled with different asynchronous patterns:\nWith Callbacks\nWith Promises\nWith Async/Await\nBest Practices\nWhen working with async/await in Node.js, follow these best practices:\nRemember that async functions always return Promises\nasync function myFunction() {\nreturn 'Hello';\n}\n\n// This returns a Promise that resolves to 'Hello', not the string 'Hello' directly\nconst result = myFunction();\nconsole.log(result); // Promise { 'Hello' }\n\n// You need to await it or use .then()\nmyFunction().then(message => console.log(message)); // Hello\nUse Promise.all for concurrent operations\nWhen operations can run in parallel, use Promise.all to improve performance.\nWhen operations can run in parallel, use Promise.all to improve performance.\nAlways handle errors\nUse try/catch blocks or chain a .catch() to the async function call.\nUse try/catch blocks or chain a .catch() to the async function call.\nAvoid mixing async/await with callbacks\nConvert callback-based functions to Promises using util.promisify or custom wrappers.\nconst util = require('util');\nconst fs = require('fs');\n\n// Convert callback-based function to Promise-based\nconst readFile = util.promisify(fs.readFile);\n\nasync function readFileContents() {\nconst data = await readFile('file.txt', 'utf8');\nreturn data;\n}\nConvert callback-based functions to Promises using util.promisify or custom wrappers.\nCreate clean async functions\nKeep async functions focused on a single responsibility.\nKeep async functions focused on a single responsibility.\nBest Practice: Be aware of the \"top-level await\" feature available in ECMAScript modules (ESM) in Node.js 14.8.0 and above, which allows using await outside of async functions at the module level.",
      "examples": [
        "async function getData() {\nconsole.log('Starting...');\nconst result = await someAsyncOperation();\nconsole.log(`Result: ${result}`);\nreturn result;\n}\n\nfunction someAsyncOperation() {\nreturn new Promise(resolve => {\nsetTimeout(() => resolve('Operation completed'), 1000);\n});\n}\n\n// Call the async function\ngetData().then(data => console.log('Final data:', data));",
        "const fs = require('fs').promises;\n\nasync function readFile() {\ntry {\nconst data = await fs.readFile('myfile.txt', 'utf8');\nconsole.log(data);\n} catch (error) {\nconsole.error('Error reading file:', error);\n}\n}\n\nreadFile();",
        "async function fetchUserData() {\ntry {\nconst response = await fetch('https://api.example.com/users/1');\nif (!response.ok) {\nthrow new Error(`HTTP error: ${response.status}`);\n}\nconst user = await response.json();\nconsole.log('User data:', user);\nreturn user;\n} catch (error) {\nconsole.error('Error fetching user data:', error);\nthrow error; // Re-throw the error if needed\n}\n}",
        "// Using catch with an async function\nfetchUserData().catch(error => {\nconsole.log('Caught outside of async function:', error.message);\n});",
        "// Helper function to simulate an API call\nfunction fetchData(id) {\nreturn new Promise(resolve => {\nsetTimeout(() => resolve(`Data for ID ${id}`), 1000);\n});\n}\n\n// Sequential operation - takes ~3 seconds\nasync function fetchSequential() {\nconsole.time('sequential');\nconst data1 = await fetchData(1);\nconst data2 = await fetchData(2);\nconst data3 = await fetchData(3);\nconsole.timeEnd('sequential');\nreturn [data1, data2, data3];\n}\n\n// Parallel operation - takes ~1 second\nasync function fetchParallel() {\nconsole.time('parallel');\nconst results = await Promise.all([\nfetchData(1),\nfetchData(2),\nfetchData(3)\n]);\nconsole.timeEnd('parallel');\nreturn results;\n}\n\n// Demo\nasync function runDemo() {\nconsole.log('Running sequentially...');\nconst seqResults = await fetchSequential();\nconsole.log(seqResults);\n\nconsole.log('\\nRunning in parallel...');\nconst parResults = await fetchParallel();\nconsole.log(parResults);\n}\n\nrunDemo();",
        "function getUser(userId, callback) {\nsetTimeout(() => {\ncallback(null, { id: userId, name: 'John' });\n}, 1000);\n}\n\nfunction getUserPosts(user, callback) {\nsetTimeout(() => {\ncallback(null, ['Post 1', 'Post 2']);\n}, 1000);\n}\n\n// Using callbacks\ngetUser(1, (error, user) => {\nif (error) {\nconsole.error(error);\nreturn;\n}\nconsole.log('User:', user);\n\ngetUserPosts(user, (error, posts) => {\nif (error) {\nconsole.error(error);\nreturn;\n}\nconsole.log('Posts:', posts);\n});\n});",
        "function getUserPromise(userId) {\nreturn new Promise(resolve => {\nsetTimeout(() => {\nresolve({ id: userId, name: 'John' });\n}, 1000);\n});\n}\n\nfunction getUserPostsPromise(user) {\nreturn new Promise(resolve => {\nsetTimeout(() => {\nresolve(['Post 1', 'Post 2']);\n}, 1000);\n});\n}\n\n// Using promises\ngetUserPromise(1)\n.then(user => {\nconsole.log('User:', user);\nreturn getUserPostsPromise(user);\n})\n.then(posts => {\nconsole.log('Posts:', posts);\n})\n.catch(error => {\nconsole.error(error);\n});",
        "// Using async/await\nasync function getUserAndPosts() {\ntry {\nconst user = await getUserPromise(1);\nconsole.log('User:', user);\n\nconst posts = await getUserPostsPromise(user);\nconsole.log('Posts:', posts);\n} catch (error) {\nconsole.error(error);\n}\n}\n\ngetUserAndPosts();",
        "async function myFunction() {\nreturn 'Hello';\n}\n\n// This returns a Promise that resolves to 'Hello', not the string 'Hello' directly\nconst result = myFunction();\nconsole.log(result); // Promise { 'Hello' }\n\n// You need to await it or use .then()\nmyFunction().then(message => console.log(message)); // Hello",
        "const util = require('util');\nconst fs = require('fs');\n\n// Convert callback-based function to Promise-based\nconst readFile = util.promisify(fs.readFile);\n\nasync function readFileContents() {\nconst data = await readFile('file.txt', 'utf8');\nreturn data;\n}",
        "async",
        "await",
        ".catch()",
        "Promise.all"
      ]
    },
    {
      "title": "Node.js Error Handling",
      "summary": "Why Handle Errors?\nErrors are inevitable in any program, but how you handle them makes all the difference. In Node.js, proper error handling is crucial because:\nIt prevents applications from crashing unexpectedly\nIt provides meaningful feedback to users\nIt makes debugging easier with proper error context\nIt helps maintain application stability in production\nIt ensures resources are properly cleaned up\nCommon Error Types in Node.js\nUnderstanding different error types helps in handling them appropriately:\n1. Standard JavaScript ErrorsGet your own Node.js Server\n2. System Errors\nBasic Error Handling\nNode.js follows several patterns for error handling:\nError-First Callbacks\nThe most common pattern in Node.js core modules where the first argument to a callback is an error object (if any occurred).\nExample: Error-First Callback\nModern Error Handling\nUsing try...catch with Async/Await\nWith async/await, you can use try/catch blocks for both synchronous and asynchronous code:\nExample: try/catch with Async/Await\nREMOVE ADS\nGlobal Error Handling\nUncaught Exceptions\nFor unexpected errors, you can listen for uncaughtException to perform cleanup before exiting:\nExample: Global Error Handlers\nError Handling Best Practices\nDos and Don'ts\nHandle errors at the appropriate level\nLog errors with sufficient context\nUse custom error types for different scenarios\nClean up resources in finally blocks\nValidate input to catch errors early\nIgnore errors (empty catch blocks)\nExpose sensitive error details to clients\nUse try/catch for flow control\nSwallow errors without logging them\nContinue execution after unrecoverable errors\nCustom Error Types\nSummary\nEffective error handling is a critical aspect of building robust Node.js applications.\nBy understanding different error types, using appropriate patterns, and following best practices, you can create applications that are more stable, maintainable, and user-friendly.\nRemember that good error handling is not just about preventing crashes—it's about providing meaningful feedback, maintaining data integrity, and ensuring a good user experience even when things go wrong.",
      "examples": [
        "// SyntaxError\nJSON.parse('{invalid json}');\n\n// TypeError\nnull.someProperty;\n\n// ReferenceError\nunknownVariable;",
        "// ENOENT: No such file or directory\nconst fs = require('fs');\nfs.readFile('nonexistent.txt', (err) => {\nconsole.error(err.code); // 'ENOENT'\n});\n\n// ECONNREFUSED: Connection refused\nconst http = require('http');\nconst req = http.get('http://nonexistent-site.com', (res) => {});\nreq.on('error', (err) => {\nconsole.error(err.code); // 'ECONNREFUSED' or 'ENOTFOUND'\n});",
        "const fs = require('fs');\n\nfunction readConfigFile(filename, callback) {\nfs.readFile(filename, 'utf8', (err, data) => {\nif (err) {\n// Handle specific error types\nif (err.code === 'ENOENT') {\nreturn callback(new Error(`Config file ${filename} not found`));\n} else if (err.code === 'EACCES') {\nreturn callback(new Error(`No permission to read ${filename}`));\n}\n// For all other errors\nreturn callback(err);\n}\n\n// Process data if no error\ntry {\nconst config = JSON.parse(data);\ncallback(null, config);\n} catch (parseError) {\ncallback(new Error(`Invalid JSON in ${filename}`));\n}\n});\n}\n\n// Usage\nreadConfigFile('config.json', (err, config) => {\nif (err) {\nconsole.error('Failed to read config:', err.message);\n// Handle the error (e.g., use default config)\nreturn;\n}\nconsole.log('Config loaded successfully:', config);\n});",
        "const fs = require('fs').promises;\n\nasync function loadUserData(userId) {\ntry {\nconst data = await fs.readFile(`users/${userId}.json`, 'utf8');\nconst user = JSON.parse(data);\n\nif (!user.email) {\nthrow new Error('Invalid user data: missing email');\n}\n\nreturn user;\n} catch (error) {\n// Handle different error types\nif (error.code === 'ENOENT') {\nthrow new Error(`User ${userId} not found`);\n} else if (error instanceof SyntaxError) {\nthrow new Error('Invalid user data format');\n}\n// Re-throw other errors\nthrow error;\n} finally {\n// Cleanup code that runs whether successful or not\nconsole.log(`Finished processing user ${userId}`);\n}\n}\n\n// Usage\n(async () => {\ntry {\nconst user = await loadUserData(123);\nconsole.log('User loaded:', user);\n} catch (error) {\nconsole.error('Failed to load user:', error.message);\n// Handle error (e.g., show to user, retry, etc.)\n}\n})();",
        "// Handle uncaught exceptions (synchronous errors)\nprocess.on('uncaughtException', (error) => {\nconsole.error('UNCAUGHT EXCEPTION! Shutting down...');\nconsole.error(error.name, error.message);\n\n// Perform cleanup (close database connections, etc.)\nserver.close(() => {\nconsole.log('Process terminated due to uncaught exception');\nprocess.exit(1); // Exit with failure\n});\n});\n\n// Handle unhandled promise rejections\nprocess.on('unhandledRejection', (reason, promise) => {\nconsole.error('UNHANDLED REJECTION! Shutting down...');\nconsole.error('Unhandled Rejection at:', promise, 'Reason:', reason);\n\n// Close server and exit\nserver.close(() => {\nprocess.exit(1);\n});\n});\n\n// Example of an unhandled promise rejection\nPromise.reject(new Error('Something went wrong'));\n\n// Example of an uncaught exception\nsetTimeout(() => {\nthrow new Error('Uncaught exception after timeout');\n}, 1000);",
        "class ValidationError extends Error {\nconstructor(message, field) {\nsuper(message);\nthis.name = 'ValidationError';\nthis.field = field;\nthis.statusCode = 400;\n}\n}\n\nclass NotFoundError extends Error {\nconstructor(resource) {\nsuper(`${resource} not found`);\nthis.name = 'NotFoundError';\nthis.statusCode = 404;\n}\n}\n\n// Usage\nfunction getUser(id) {\nif (!id) {\nthrow new ValidationError('User ID is required', 'id');\n}\n// ...\n}"
      ]
    },
    {
      "title": "Node.js Modules",
      "summary": "What is a Module in Node.js?\nModules are the building blocks of Node.js applications, allowing you to organize code into logical, reusable components. They help in:\nOrganizing code into manageable files\nEncapsulating functionality\nPreventing global namespace pollution\nImproving code maintainability and reusability\nNode.js supports two module systems: CommonJS (traditional) and ES Modules (ECMAScript modules).\nThis page covers CommonJS, while ES Modules are covered separately.\nCore Built-in Modules\nNode.js provides several built-in modules that are compiled into the binary.\nHere are some of the most commonly used ones:\nfs - File system operations\nhttp - HTTP server and client\npath - File path utilities\nos - Operating system utilities\nevents - Event handling\nutil - Utility functions\nstream - Stream handling\ncrypto - Cryptographic functions\nurl - URL parsing\nquerystring - URL query string handling\nTo use any built-in module, use the require() function:\nExample: Using Multiple Built-in ModulesGet your own Node.js Server\nNow you can use the module's features, like creating a server:\nExample: Simple HTTP Server\nCreating and Exporting Modules\nIn Node.js, any file with a .js extension is a module. You can export functionality from a module in several ways:\n1. Exporting Multiple Items\nAdd properties to the exports object for multiple exports:\nExample: utils.js\n2. Exporting a Single Item\nTo export a single item (function, object, etc.), assign it to module.exports:\n3. Using Your Modules\nImport and use your custom modules using require() with a relative or absolute path:\nExample: app.js\nModule Loading and Caching\nNode.js caches modules after the first time they are loaded. This means that subsequent require() calls return the cached version.\nModule Resolution\nWhen you require a module, Node.js looks for it in this order:\nCore Node.js modules (like fs, http)\nNode modules in node_modules folders\nLocal files (using ./ or ../ prefix)\nRun the example in your terminal:\nVisit http://localhost:8080 to see the result in your browser.\nBest Practices\nKeep modules focused on a single responsibility\nUse meaningful file and directory names\nGroup related functionality together\nUse index.js for module entry points\nPrefer named exports for utilities\nUse default exports for single-class modules\nDocument your module's API\nHandle module initialization if needed\nSummary\nModules are a key concept in Node.js. They enable you to organize code into reusable, maintainable units.\nBy understanding how to create, export, and use modules effectively, you can build scalable and well-structured applications.\nKey takeaways:\nNode.js uses CommonJS modules by default\nUse require() to import and module.exports to export\nModules are cached after first load\nFollow best practices for module organization and structure",
      "examples": [
        "const http = require('http');",
        "http.createServer((req, res) => {\nres.writeHead(200, {'Content-Type': 'text/html'});\nres.end('Hello World!');\n}).listen(8080);",
        "// Exporting multiple functions\nconst getCurrentDate = () => new Date().toISOString();\n\nconst formatCurrency = (amount, currency = 'USD') => {\nreturn new Intl.NumberFormat('en-US', {\nstyle: 'currency',\ncurrency: currency\n}).format(amount);\n};\n\n// Method 1: Exporting multiple items\nexports.getCurrentDate = getCurrentDate;\nexports.formatCurrency = formatCurrency;\n\n// Method 2: Exporting an object with multiple properties\n// module.exports = { getCurrentDate, formatCurrency };",
        "class Logger {\nconstructor(name) {\nthis.name = name;\n}\n\nlog(message) {\nconsole.log(`[${this.name}] ${message}`);\n}\n\nerror(error) {\nconsole.error(`[${this.name}] ERROR:`, error.message);\n}\n}\n\n// Exporting a single class\nmodule.exports = Logger;",
        "const http = require('http');\nconst path = require('path');\n\n// Importing custom modules\nconst { getCurrentDate, formatCurrency } = require('./utils');\nconst Logger = require('./logger');\n\n// Create a logger instance\nconst logger = new Logger('App');\n\n// Create server\nconst server = http.createServer((req, res) => {\ntry {\nlogger.log(`Request received for ${req.url}`);\n\nres.writeHead(200, { 'Content-Type': 'text/html' });\nres.write(`<h1>Welcome to our app!</h1>`);\nres.write(`<p>Current date: ${getCurrentDate()}</p>`);\nres.write(`<p>Formatted amount: ${formatCurrency(99.99)}</p>`);\nres.end();\n} catch (error) {\nlogger.error(error);\nres.writeHead(500, { 'Content-Type': 'text/plain' });\nres.end('Internal Server Error');\n}\n});\n\n// Start server\nconst PORT = process.env.PORT || 3000;\nserver.listen(PORT, () => {\nlogger.log(`Server running at http://localhost:${PORT}`);\n});",
        "C:\\Users\\<Your Name>> node demo_module.js",
        "fs",
        "http",
        "path",
        "os",
        "events",
        "util",
        "stream",
        "crypto",
        "url",
        "querystring",
        "require()",
        ".js",
        "exports",
        "module.exports",
        "node_modules",
        "./",
        "../",
        "index.js"
      ]
    },
    {
      "title": "Node.js ES Modules",
      "summary": "Introduction to ES Modules\nES Modules (ESM) is the official standard format for packaging JavaScript code for reuse.\nIt was introduced in ES6 (ES2015) and is now supported in Node.js.\nPrior to ES Modules, Node.js exclusively used the CommonJS module format (require/exports).\nNow developers can choose between CommonJS and ES Modules based on their project needs.\nES Modules provides a more structured and statically analyzable way to work with modules compared to CommonJS, with benefits like tree-shaking for smaller builds.\nCommonJS vs ES Modules\nHere's how CommonJS and ES Modules differ:\nExample: CommonJS ModuleGet your own Node.js Server\nExample: ES Module\nEnabling ES Modules\nThere are several ways to enable ES Modules in Node.js:\n1. Using the .mjs File Extension\nThe simplest way is to use the .mjs extension for your files.\nNode.js will automatically treat these files as ES Modules.\n2. Setting \"type\": \"module\" in package.json\nTo use ES Modules with regular .js files, add the following to your package.json:\nWith this setting, all .js files in your project will be treated as ES Modules.\n3. Using the --input-type=module Flag\nFor scripts run directly with the node command, you can specify the module system:\nNote: If you're working with a codebase that primarily uses CommonJS but you want to use ES Modules in one file, using the .mjs extension is the most explicit and least error-prone approach.\nREMOVE ADS\nImport and Export Syntax\nES Modules provide more flexible ways to import and export code compared to CommonJS.\nExport Syntax\nImport Syntax\nDynamic Imports\nES Modules support dynamic imports, allowing you to load modules conditionally or on-demand.\nExample: Dynamic Imports\nUse Case: Dynamic imports are great for code-splitting, lazy-loading modules, or conditionally loading modules based on runtime conditions.\nTop-level Await\nUnlike CommonJS, ES Modules support top-level await, allowing you to use await outside of async functions at the module level.\nExample: Top-level Await\nTop-level await is especially useful for:\nLoading configuration from files or remote sources\nConnecting to databases before exporting functionality\nConditional imports or module initialization\nBest Practices\nWhen working with ES Modules in Node.js, follow these best practices:\n1. Be Clear About File Extensions\nAlways include file extensions in your import statements for local files:\n2. Use Directory Indexes Properly\nFor directory imports, create index.mjs files:\n3. Choose the Right Export Style\nUse named exports for multiple functions/values, and default exports for main functionality:\n4. Handle the Transition from CommonJS\nWhen working with a codebase that mixes CommonJS and ES Modules:\nES Modules can import from CommonJS modules using default import\nCommonJS can require() ES Modules only with dynamic import()\nUse the compatibility helpers in the Node.js 'module' package for interoperability\n5. Dual Package Hazard\nFor npm packages that support both module systems, use the \"exports\" field in package.json to specify different entry points:\nNode.js Support: ES Modules are fully supported in Node.js since v12, with better support in v14+.\nFor older versions, you may need a transpiler like Babel.",
      "examples": [
        "// math.js (CommonJS)\nfunction add(a, b) {\nreturn a + b;\n}\n\nfunction subtract(a, b) {\nreturn a - b;\n}\n\nmodule.exports = {\nadd,\nsubtract\n};\n\n// app.js (CommonJS)\nconst math = require('./math');\nconsole.log(math.add(5, 3)); // 8",
        "// math.mjs (ES Module)\nexport function add(a, b) {\nreturn a + b;\n}\n\nexport function subtract(a, b) {\nreturn a - b;\n}\n\n// app.mjs (ES Module)\nimport { add, subtract } from './math.mjs';\nconsole.log(add(5, 3)); // 8",
        "{\n\"name\": \"my-package\",\n\"version\": \"1.0.0\",\n\"type\": \"module\"\n}",
        "node --input-type=module script.js",
        "// Multiple named exports\nexport function sayHello() {\nconsole.log('Hello');\n}\n\nexport function sayGoodbye() {\nconsole.log('Goodbye');\n}\n\n// Alternative: export list at the end\nfunction add(a, b) {\nreturn a + b;\n}\n\nfunction subtract(a, b) {\nreturn a - b;\n}\n\nexport { add, subtract };",
        "// Only one default export per module\nexport default function() {\nconsole.log('I am the default export');\n}\n\n// Or with a named function/class/object\nfunction mainFunction() {\nreturn 'Main functionality';\n}\n\nexport default mainFunction;",
        "// Combining default and named exports\nexport const VERSION = '1.0.0';\n\nfunction main() {\nconsole.log('Main function');\n}\n\nexport { main as default }; // Alternative way to set default",
        "// Import specific named exports\nimport { sayHello, sayGoodbye } from './greetings.mjs';\nsayHello(); // Hello\n\n// Rename imports to avoid naming conflicts\nimport { add as sum, subtract as minus } from './math.mjs';\nconsole.log(sum(5, 3)); // 8\n\n// Import all named exports as an object\nimport * as math from './math.mjs';\nconsole.log(math.add(7, 4)); // 11",
        "// Import the default export\nimport mainFunction from './main.mjs';\nmainFunction();\n\n// You can name the default import anything you want\nimport anyNameYouWant from './main.mjs';\nanyNameYouWant();",
        "// Import both default and named exports\nimport main, { VERSION } from './main.mjs';\nconsole.log(VERSION); // 1.0.0\nmain(); // Main function",
        "// app.mjs\nasync function loadModule(moduleName) {\ntry {\n// Dynamic import returns a promise\nconst module = await import(`./${moduleName}.mjs`);\nreturn module;\n} catch (error) {\nconsole.error(`Failed to load ${moduleName}:`, error);\n}\n}\n\n// Load a module based on a condition\nconst moduleName = process.env.NODE_ENV === 'production' ? 'prod' : 'dev';\n\nloadModule(moduleName).then(module => {\nmodule.default(); // Call the default export\n});\n\n// Or with simpler await syntax\n(async () => {\nconst mathModule = await import('./math.mjs');\nconsole.log(mathModule.add(10, 5)); // 15\n})();",
        "// data-loader.mjs\n// This would cause an error in CommonJS or in a script\n// But works at the top level in an ES Module\n\nconsole.log('Loading data...');\n\n// Top-level await - the module's execution pauses here\nconst response = await fetch('https://jsonplaceholder.typicode.com/todos/1');\nconst data = await response.json();\n\nconsole.log('Data loaded!');\n\nexport { data };\n\n// When another module imports this one, it will only get the exports\n// after all the top-level await operations have completed",
        "// Good\nimport { someFunction } from './utils.mjs';\n\n// Bad - might not work depending on configuration\nimport { someFunction } from './utils';",
        "// utils/index.mjs\nexport * from './string-utils.mjs';\nexport * from './number-utils.mjs';\n\n// app.mjs\nimport { formatString, add } from './utils/index.mjs';",
        "// For libraries with many utilities, use named exports\nexport function validate() { /* ... */ }\nexport function format() { /* ... */ }\n\n// For components or classes that are the primary export\nexport default class UserService { /* ... */ }",
        "// Importing CommonJS module from ESM\nimport fs from 'fs'; // The default import is module.exports\n\n// Importing ESM from CommonJS (Node.js 12+)\n// In a CommonJS module:\n(async () => {\nconst { default: myEsmModule } = await import('./my-esm-module.mjs');\n})();",
        "{\n\"name\": \"my-package\",\n\"exports\": {\n\".\": {\n\"import\": \"./index.mjs\",\n\"require\": \"./index.cjs\"\n}\n}\n}"
      ]
    },
    {
      "title": "Node.js NPM",
      "summary": "What is NPM?\nNPM is a package manager for Node.js packages, or modules if you like.\nwww.npmjs.com hosts thousands of free packages to download and use.\nThe NPM program is installed on your computer when you install Node.js\nIf you installed Node.js, NPM is already ready to run on your computer!\nWhat is a Package?\nA package in Node.js contains all the files you need for a module.\nModules are JavaScript libraries you can include in your project.\nDownload a Package\nDownloading a package is very easy.\nOpen the command line interface and tell NPM to download the package you want.\nI want to download a package called \"upper-case\":\nDownload \"upper-case\":\nNow you have downloaded and installed your first package!\nNPM creates a folder named \"node_modules\", where the package will be placed.\nAll packages you install in the future will be placed in this folder.\nMy project now has a folder structure like this:\nC:\\Users\\My Name\\node_modules\\upper-case\nREMOVE ADS\nUsing a Package\nOnce the package is installed, it is ready to use.\nInclude the \"upper-case\" package the same way you include any other module:\nCreate a Node.js file that will convert the output \"Hello World!\" into upper-case letters:\nExampleGet your own Node.js Server\nSave the code above in a file called \"demo_uppercase.js\", and initiate the file:\nInitiate demo_uppercase:\nIf you have followed the same steps on your computer, you will see the same result as the example: http://localhost:8080\nGlobal Packages\nPackages can be installed globally, making them available as command-line tools anywhere on your system.\nGlobal packages are typically used for CLI tools and utilities.\nInstall a package globally:\nExample: Install the http-server package globally\nAfter installation, you can run the package from any directory:\nNote: On some systems, you might need administrator/root privileges to install packages globally.\nOn Unix-like systems, use sudo before the command.\nUpdating Packages\nTo keep your packages up to date, you can update them using the following commands:\nUpdate a specific package:\nUpdate all packages in your project:\nCheck for outdated packages:\nTip: To update npm itself, run: npm install -g npm@latest\nUninstalling a Package\nTo remove a package that you no longer need, you can use the uninstall command:\nRemove a package:\nRemove a global package:\nRemove a package and its dependencies:\nNote: The --save flag updates your package.json file to remove the dependency.\nFor older versions of npm, you might need to use --save-dev for development dependencies.",
      "examples": [
        "C:\\Users\\Your Name>npm install upper-case",
        "let uc = require('upper-case');",
        "let http = require('http');\nlet uc = require('upper-case');\nhttp.createServer(function (req, res) {\nres.writeHead(200, {'Content-Type': 'text/html'});\nres.write(uc.upperCase(\"Hello World!\"));\nres.end();\n}).listen(8080);",
        "C:\\Users\\Your Name>node demo_uppercase.js",
        "npm install -g package-name",
        "npm install -g http-server",
        "http-server",
        "npm update package-name",
        "npm update",
        "npm outdated",
        "npm uninstall package-name",
        "npm uninstall -g package-name",
        "npm uninstall --save package-name",
        "C:\\Users\\My Name\\node_modules\\upper-case",
        "sudo",
        "npm install -g npm@latest",
        "--save",
        "--save-dev"
      ]
    },
    {
      "title": "Node.js package.json",
      "summary": "What is package.json?\npackage.json is a special file that describes your Node.js project.\nIt contains information about your app, such as its name, version, dependencies, scripts, and more.\nThis file is essential for managing and sharing Node.js projects, especially when using npm (Node Package Manager).\nCreating package.json\nYou can create a package.json file by running the following command in your project folder:\nThis command will ask you a series of questions about your project and generate a package.json file.\nFor a quick setup with default values, use:\nREMOVE ADS\nExample package.json\nHere is a simple example of a package.json file:\nThis file describes the app, sets the main file to index.js, and defines a start script.\nAdding Dependencies\nWhen you install a package with npm, it is added to the dependencies section of package.json:\nThis command adds Express to your project and updates package.json automatically.\nCommon package.json Fields\nBasic Metadata\nScripts\nDefine custom scripts that can be run with npm run <script-name>:\nDependencies\nSpecify project dependencies with version ranges:\nDev Dependencies\nDevelopment-only dependencies (not installed in production):\nVersion Ranges\n^4.17.21 - Compatible with 4.x.x (up to but not including 5.0.0)\n~4.17.21 - Patch updates only (4.17.x)\n4.17.21 - Exact version\nlatest - Latest stable version\ngit+https://... - Git repository\nEngines\nSpecify Node.js and npm version requirements:\nRepository and Bugs\nWorking with package.json\nAdding Dependencies\nUpdating Dependencies\nRunning Scripts\nBest Practices\nAlways specify exact versions in dependencies for production apps\nUse npm ci in CI/CD pipelines for reproducible builds\nKeep your package-lock.json file in version control\nUse .npmignore to exclude unnecessary files from published packages\nRegularly update dependencies to get security patches\nSummary\npackage.json is the heart of any Node.js project, containing metadata, scripts, and dependency information.\nUnderstanding its structure and fields is essential for effective Node.js development.",
      "examples": [
        "npm init",
        "npm init -y",
        "{\n\"name\": \"my-node-app\",\n\"version\": \"1.0.0\",\n\"description\": \"A simple Node.js app\",\n\"main\": \"index.js\",\n\"scripts\": {\n\"start\": \"node index.js\"\n},\n\"author\": \"Your Name\",\n\"license\": \"ISC\"\n}",
        "npm install express",
        "\"dependencies\": {\n\"express\": \"^5.1.0\"\n}",
        "{\n\"name\": \"my-package\",\n\"version\": \"1.0.0\",\n\"description\": \"A brief description of your package\",\n\"main\": \"index.js\",\n\"type\": \"module\", // or \"commonjs\"\n\"keywords\": [\"example\", \"package\", \"node\"],\n\"author\": \"Your Name\n\"\n,\n\"license\": \"MIT\",\n\"homepage\": \"https://example.com/my-package\"\n} com>",
        "\"scripts\": {\n\"start\": \"node index.js\",\n\"dev\": \"nodemon index.js\",\n\"test\": \"jest\",\n\"build\": \"webpack --mode production\",\n\"lint\": \"eslint .\",\n\"prepare\": \"husky install\"\n}",
        "\"dependencies\": {\n\"express\": \"^4.18.2\",\n\"mongoose\": \"~7.0.0\",\n\"lodash\": \"4.17.21\"\n},",
        "\"devDependencies\": {\n\"nodemon\": \"^2.0.22\",\n\"jest\": \"^29.5.0\",\n\"eslint\": \"^8.38.0\"\n}",
        "\"engines\": {\n\"node\": \">=14.0.0 <17.0.0\",\n\"npm\": \">=6.0.0\"\n}",
        "\"repository\": {\n\"type\": \"git\",\n\"url\": \"https://github.com/username/repo.git\"\n},\n\"bugs\": {\n\"url\": \"https://github.com/username/repo/issues\"\n}",
        "# Install and save to dependencies\nnpm install package-name\n\n# Install and save to devDependencies\nnpm install --save-dev package-name\n\n# Install exact version\nnpm install package-name@1.2.3",
        "# Update a specific package\nnpm update package-name\n\n# Update all packages\nnpm update\n\n# Check for outdated packages\nnpm outdated",
        "# Run a script\nnpm run script-name\n\n# Run start script (can be called with just 'npm start')\nnpm start\n\n# Run test script (can be called with just 'npm test')\nnpm test",
        "index.js",
        "dependencies",
        "npm run <script-name>",
        "^4.17.21",
        "~4.17.21",
        "4.17.21",
        "latest",
        "git+https://...",
        "npm ci",
        "package-lock.json",
        ".npmignore"
      ]
    },
    {
      "title": "Node.js NPM Scripts",
      "summary": "What are NPM Scripts?\nNPM scripts are commands you define in your package.json file to automate tasks like:\nRunning your app\nTesting\nBuilding\nCleaning up files\nThey make it easy to manage common tasks with simple commands.\nDefining Scripts in package.json\nInside package.json, the scripts section lets you name and define commands:\nEach script can be run from the command line using npm run <script-name>.\nREMOVE ADS\nRunning NPM Scripts\nTo run a script, use:\nFor the special start script, you can just use:\nAnd for test:\nCommon Uses for NPM Scripts\nStart your app\nRun tests\nUse tools like nodemon or webpack\nBuild or bundle your code\nLint or format your code\nSummary\nNPM scripts help automate and simplify project tasks.\nDefine them in package.json and run them easily with npm.",
      "examples": [
        "{\n\"scripts\": {\n\"start\": \"node index.js\",\n\"test\": \"echo \\\"Running tests...\\\" && exit 0\",\n\"dev\": \"nodemon index.js\"\n}\n}",
        "npm run dev",
        "npm start",
        "npm test",
        "scripts",
        "npm run <script-name>"
      ]
    },
    {
      "title": "Node.js Managing Dependencies",
      "summary": "What is Dependency Management?\nDependency management is the process of tracking, installing, updating, and removing the external packages your application depends on.\nIt helps ensure your applications remains stable, secure, and maintainable over time.\nnpm (Node Package Manager) is the default package manager for Node.js, but alternatives like Yarn and pnpm are also popular.\nThe key components of Node.js dependency management include:\nThe package.json file for declaring dependencies\nLock files (package-lock.json or yarn.lock) for dependency versioning\nPackage manager commands to install, update, and remove packages\nSecurity tools to identify and fix vulnerabilities\nUnderstanding Semantic Versioning\nNode.js packages follow semantic versioning (SemVer), using a three-part version number: MAJOR.MINOR.PATCH\nMAJOR: Incremented for incompatible API changes\nMINOR: Incremented for backward-compatible new features\nPATCH: Incremented for backward-compatible bug fixes\nIn package.json, version requirements can be specified using special characters:\nExample: Different Version SpecificationsGet your own Node.js Server\nREMOVE ADS\nInstalling Dependencies\nThere are several ways to install dependencies in a Node.js project:\nInstalling All Dependencies\nThis command reads the package.json file and installs all dependencies listed there.\nInstalling a Specific Package\nThis installs the latest version of the package and adds it to your dependencies in package.json.\nInstalling a Specific Version\nInstalling Without Saving to package.json\nInstalling Globally\nGlobal packages are installed system-wide rather than in the project's node_modules directory.\nTypes of Dependencies\nNode.js projects can have several types of dependencies, each serving a different purpose:\nRegular Dependencies\nThese are packages required for your application to run in production.\nDevelopment Dependencies\nThese are packages needed only for local development and testing, like testing frameworks or build tools.\nPeer Dependencies\nSpecified in package.json to indicate compatibility with other packages without actually including them:\nThis tells users that your package expects React 17.x to be installed in their project.\nOptional Dependencies\nThese packages enhance functionality but aren't required for the core application to work.\nTip: Use dependencies for packages needed in production, and devDependencies for packages only needed during development or testing.\nPackage Lock Files\nLock files ensure consistent installations across different environments by recording the exact version of each package and its dependencies.\npackage-lock.json (npm)\nThis file is automatically generated when npm modifies the node_modules tree or package.json.\nyarn.lock (Yarn)\nYarn's lock file serves a similar purpose but has a different format.\nImportant: Always commit your lock files to version control to ensure consistent installations across your team and deployment environments.\nUpdating Dependencies\nCheck for Outdated Packages\nUpdate a Specific Package\nUpdate All Packages\nUpdate npm Itself\nUsing npm-check-updates\nFor more control over updates, you can use the npm-check-updates package:\nSecurity and Auditing\nAudit Your Dependencies\nFix Security Vulnerabilities\nForce Fix All Issues (Use with Caution)\nCheck for Known Vulnerabilities\nBest Practices\nUse exact versions in production: Pin your dependencies to exact versions to prevent unexpected updates.\nRegularly update dependencies: Keep your dependencies up to date to benefit from security patches and new features.\nAudit your dependencies: Regularly check for known vulnerabilities in your dependencies.\nUse a lock file: Always commit your lock file to version control.\nMinimize dependencies: Only include packages that you actually need.\nUse scoped packages: For internal packages, use scopes to avoid naming conflicts.\nDocument your dependencies: Include information about why each dependency is needed in your project's documentation.\nTroubleshooting Common Issues\nClearing the npm Cache\nDeleting node_modules and Reinstalling\nChecking for Peer Dependency Issues\nFixing Broken Dependencies\nSummary\nEffective dependency management is crucial for maintaining a healthy Node.js project.\nBy understanding how to properly install, update, and manage your dependencies, you can ensure that your application remains stable, secure, and maintainable over time.\nRemember to regularly audit your dependencies for security vulnerabilities and keep them up to date to benefit from the latest features and security patches.",
      "examples": [
        "{\n\"dependencies\": {\n\"express\": \"^2.8.1\", // Any 2.x.x version (2.8.1 or higher)\n\"lodash\": \"~2.8.1\", // Any 2.8.x version (2.8.1 or higher)\n\"moment\": \"2.8.1\", // Exactly version 2.8.1\n\"axios\": \">=2.8.1\", // Version 2.8.1 or any higher version\n\"debug\": \"2.x\" // Any version starting with 2\n}\n}",
        "npm install",
        "npm install express",
        "npm install express@4.17.1",
        "npm install express --no-save",
        "npm install -g nodemon",
        "npm install express --save # or simply npm install express",
        "npm install jest --save-dev # or npm install jest -D",
        "{\n\"name\": \"my-plugin\",\n\"version\": \"1.0.0\",\n\"peerDependencies\": {\n\"react\": \"^17.0.0\"\n}\n}",
        "npm install fancy-feature --save-optional\n# or\nnpm install fancy-feature -O",
        "{\n\"name\": \"my-app\",\n\"version\": \"1.0.0\",\n\"lockfileVersion\": 3,\n\"requires\": true,\n\"packages\": {\n\"node_modules/express\": {\n\"version\": \"4.18.2\",\n\"resolved\": \"https://registry.npmjs.org/express/-/express-4.18.2.tgz\",\n\"dependencies\": {\n\"accepts\": \"~1.3.8\",\n\"array-flatten\": \"1.1.1\"\n}\n}\n}\n}",
        "npm outdated",
        "npm update express",
        "npm update",
        "npm install -g npm@latest",
        "# Install npm-check-updates globally\nnpm install -g npm-check-updates\n\n# Check for updates\nncu\n\n# Update package.json\nncu -u\n\n# Install updated packages\nnpm install",
        "npm audit",
        "npm audit fix",
        "npm audit fix --force",
        "npm audit\n\n# Or using npx with the 'audit' package\nnpx audit",
        "npm cache clean --force",
        "rm -rf node_modules\nrm package-lock.json\nnpm install",
        "npm ls",
        "npm rebuild",
        "package.json",
        "package-lock.json",
        "yarn.lock",
        "MAJOR.MINOR.PATCH",
        "node_modules",
        "dependencies",
        "devDependencies",
        "npm-check-updates"
      ]
    },
    {
      "title": "Node.js Publish a Package",
      "summary": "What Does it Mean to Publish a Package?\nPublishing a package means making your Node.js module or project available for others to install and use via the npm registry.\nThis is how open-source libraries and tools are shared with the Node.js community.\nWhen you publish a package, it becomes available for anyone to install using npm install your-package-name.\nNote: Make sure your package provides value, and that it is not a duplicate of an existing package on NPM.\nPreparing Your Package\n1. Initialize Package\nCreate a new directory and initialize your package:\n2. Essential Files\nA package should include these key files:\npackage.json - Metadata about your package\nREADME.md - Documentation (supports Markdown)\nindex.js - Main entry point (or specify in package.json)\nLICENSE - Terms of use (MIT, ISC, etc.)\n.gitignore - To exclude node_modules, logs, etc.\n.npmignore - Optional, to exclude files from the published package\n3. Package.json Essentials\nEnsure your package.json has these minimum fields:\nCreating an npm Account\n1. Sign Up\nCreate an account at npmjs.com/signup if you don't have one.\n2. Verify Your Email\nCheck your email and verify your account before publishing.\n3. Login via CLI\nOpen your terminal and run:\nYou'll be prompted for:\nUsername\nPassword\nEmail (must match your npm account)\nOne-time password (if you have 2FA enabled)\n4. Check Login Status\nPublishing Your Package\n1. Check Name Availability\nIf the package with that name does not already exist, you can use that name.\nIf it does, you'll need to choose a different name in your package.json.\n2. Test Package Locally\nBefore publishing, test your package locally:\n3. Publish to npm Registry\n4. Publish with a Specific Tag\n5. Publish a Public Package (if using npm paid account)\nREMOVE ADS\nUpdating Your Package\n1. Update the Version Number\nUse semantic versioning (SemVer) to update your package version:\n2. Update Changelog\nUpdate your CHANGELOG.md to document the changes in this version.\n3. Publish the Update\n4. Tag the Release (Optional)\nIf you're using Git, create a tag for the release:\nManaging Published Packages\nUnpublishing a Package\nTo remove a package from the npm registry:\nImportant: Unpublishing is strongly discouraged as it can break other projects that depend on your package. Instead, consider using npm deprecate.\nDeprecating a Package\nIf you want to prevent users from installing a version but keep it available for existing users:\nTransferring Ownership\nTo transfer a package to another user or organization:\nBest Practices\nFollow Semantic Versioning - Use MAJOR.MINOR.PATCH version numbers appropriately\nWrite Good Documentation - Include clear usage examples in your README\nAdd Tests - Include unit tests and document how to run them\nUse .npmignore - Only publish necessary files\nAdd Keywords - Help others discover your package\nChoose the Right License - Make your terms clear to users\nMaintain a Changelog - Document changes between versions\nUse Continuous Integration - Automate testing and publishing\nSummary\nPublishing packages to npm is a great way to share your code with the Node.js community.\nIf you follow best practices and maintain your packages well, you can contribute valuable tools that others can build upon.\nRemember: With great power comes great responsibility. When you publish a package, you're making a commitment to maintain it or clearly communicate its status to users.",
      "examples": [
        "mkdir my-package\ncd my-package\nnpm init -y",
        "{\n\"name\": \"your-package-name\",\n\"version\": \"1.0.0\",\n\"description\": \"A brief description of your package\",\n\"main\": \"index.js\",\n\"scripts\": {\n\"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n},\n\"keywords\": [\"keyword1\", \"keyword2\"],\n\"author\": \"Your Name <your.email@example.com>\",\n\"license\": \"MIT\"\n}",
        "npm login",
        "npm whoami",
        "npm view <package-name>",
        "# In your package directory\nnpm link\n\n# In another project directory\nnpm link <package-name>",
        "# First, make sure you're in the right directory\ncd path/to/your/package\n\n# Publish to the public npm registry\nnpm publish",
        "npm publish --tag beta",
        "npm publish --access public",
        "# For a patch release (bug fixes)\nnpm version patch\n\n# For a minor release (backward-compatible features)\nnpm version minor\n\n# For a major release (breaking changes)\nnpm version major",
        "npm publish",
        "git tag -a v1.0.0 -m \"Initial release\"\ngit push origin v1.0.0",
        "# Unpublish a specific version\nnpm unpublish <package-name>@<version>\n\n# Unpublish the entire package (only works within 72 hours of publishing)\nnpm unpublish <package-name> --force",
        "# Deprecate a specific version\nnpm deprecate <package-name>@<version> \"message\"\n\n# Example\nnpx deprecate my-package@1.0.0 \"This version is no longer maintained. Please upgrade to v2.0.0\"",
        "npm owner add <username> <package-name>",
        "npm install your-package-name",
        "package.json",
        "npm deprecate"
      ]
    },
    {
      "title": "Node.js HTTP Module",
      "summary": "The Built-in HTTP Module\nNode.js includes a powerful built-in HTTP module that enables you to create HTTP servers and make HTTP requests.\nThis module is essential for building web applications and APIs in Node.js.\nKey Features\nCreate HTTP servers to handle requests and send responses\nMake HTTP requests to other servers\nHandle different HTTP methods (GET, POST, PUT, DELETE, etc.)\nWork with request and response headers\nHandle streaming data for large payloads\nIncluding the HTTP Module\nTo use the HTTP module, include it in your application using the require() method:\nCreating an HTTP Server\nThe HTTP module's createServer() method creates an HTTP server that listens for requests on a specified port and executes a callback function for each request.\nBasic HTTP Server Example\nUnderstanding the Code\nhttp.createServer() - Creates a new HTTP server instance\nThe callback function is executed for each request with two parameters:\nreq - The request object (http.IncomingMessage)\nres - The response object (http.ServerResponse)\nreq - The request object (http.IncomingMessage)\nres - The response object (http.ServerResponse)\nres.writeHead() - Sets the response status code and headers\nres.end() - Sends the response and ends the connection\nserver.listen() - Starts the server on the specified port\nRunning the Server\nSave the code in a file named server.js\nRun the server using Node.js:\nVisit http://localhost:3000 in your browser to see the response.\nREMOVE ADS\nWorking with HTTP Headers\nHTTP headers let you send additional information with your response.\nThe res.writeHead() method is used to set the status code and response headers.\nSetting Response Headers\nCommon HTTP Status Codes\nCommon Response Headers\nContent-Type: Specifies the media type of the content (e.g., text/html, application/json)\nContent-Length: The length of the response body in bytes\nLocation: Used in redirects (with 3xx status codes)\nSet-Cookie: Sets HTTP cookies on the client\nCache-Control: Directives for caching mechanisms\nAccess-Control-Allow-Origin: For CORS support\nReading Request Headers\nYou can access request headers using the req.headers object:\nWorking with URLs and Query Strings\nNode.js provides built-in modules to work with URLs and query strings, making it easy to handle different parts of a URL and parse query parameters.\nAccessing the Request URL\nThe req.url property contains the URL string that was requested, including any query parameters.\nThis is part of the http.IncomingMessage object.\nParsing URLs with the URL Module\nThe url module provides utilities for URL resolution and parsing.\nIt can parse a URL string into a URL object with properties for each part of the URL.\nFor the following request:\nThe server would respond with:\nWorking with Query Strings\nFor more advanced query string handling, you can use the querystring module:\nurl.parse(urlString, [parseQueryString], [slashesDenoteHost]): Parse a URL string into an object\nurl.format(urlObject): Format a URL object into a URL string\nurl.resolve(from, to): Resolve a target URL relative to a base URL\nnew URL(input, [base]): The WHATWG URL API (recommended for new code)\nquerystring.parse(str, [sep], [eq], [options]): Parse a query string into an object\nquerystring.stringify(obj, [sep], [eq], [options]): Stringify an object into a query string\nHandling Different HTTP Methods\nRESTful APIs commonly use different HTTP methods (GET, POST, PUT, DELETE, etc.) to perform different operations on resources.\nHere's how to handle different HTTP methods in a Node.js HTTP server:\nTesting the API with cURL\nYou can test this API using cURL commands:\nBest Practices for HTTP Methods\nGET: Retrieve a resource or collection of resources (should be idempotent)\nPOST: Create a new resource (not idempotent)\nPUT: Update an existing resource or create it if it doesn't exist (idempotent)\nPATCH: Partially update a resource\nDELETE: Remove a resource (idempotent)\nHEAD: Same as GET but without the response body\nOPTIONS: Describe the communication options for the target resource\nError Handling\nAlways include proper error handling and appropriate HTTP status codes:\n200 OK - Successful GET/PUT/PATCH\n201 Created - Successful resource creation\n204 No Content - Successful DELETE\n400 Bad Request - Invalid request data\n401 Unauthorized - Authentication required\n403 Forbidden - Not enough permissions\n404 Not Found - Resource doesn't exist\n500 Internal Server Error - Server-side error\nStreaming Responses\nNode.js streams are powerful for handling large amounts of data efficiently. The HTTP module works well with streams for both reading request bodies and writing responses.\nBenefits of Streaming\nMemory Efficiency: Processes data in chunks instead of loading everything into memory\nFaster Time to First Byte: Starts sending data as soon as it's available\nBackpressure Handling: Automatically handles slow clients by pausing the read stream\nCommon Use Cases for Streaming\nFile uploads/downloads\nReal-time data processing\nProxying requests\nVideo/audio streaming\nLog processing",
      "examples": [
        "// Using CommonJS require (Node.js default)\nconst http = require('http');\n\n// Or using ES modules (Node.js 14+ with \"type\": \"module\" in package.json)\n// import http from 'http';",
        "// Import the HTTP module\nconst http = require('http');\n\n// Create a server object\nconst server = http.createServer((req, res) => {\n// Set the response HTTP header with HTTP status and Content type\nres.writeHead(200, { 'Content-Type': 'text/plain' });\n\n// Send the response body as 'Hello, World!'\nres.end('Hello, World!\\n');\n});\n\n// Define the port to listen on const PORT = 3000;\n\n// Start the server and listen on the specified port\nserver.listen(PORT, 'localhost', () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n});",
        "node server.js",
        "const http = require('http');\n\nconst server = http.createServer((req, res) => {\n// Set status code and multiple headers\nres.writeHead(200, {\n'Content-Type': 'text/html',\n'X-Powered-By': 'Node.js',\n'Cache-Control': 'no-cache, no-store, must-revalidate',\n'Set-Cookie': 'sessionid=abc123; HttpOnly'\n});\n\nres.end('<h1>Hello, World!</h1>');\n});\n\nserver.listen(3000, () => {\nconsole.log('Server running at http://localhost:3000/');\n});",
        "const http = require('http');\n\nconst server = http.createServer((req, res) => {\n// Log all request headers\nconsole.log('Request Headers:', req.headers);\n\n// Get specific headers (case-insensitive)\nconst userAgent = req.headers['user-agent'];\nconst acceptLanguage = req.headers['accept-language'];\n\nres.writeHead(200, { 'Content-Type': 'text/plain' });\nres.end(`User-Agent: ${userAgent}\\nAccept-Language: ${acceptLanguage}`);\n});\n\nserver.listen(3000);",
        "const http = require('http');\n\nconst server = http.createServer((req, res) => {\n// Get the URL and HTTP method\nconst { url, method } = req;\n\nres.writeHead(200, { 'Content-Type': 'text/plain' });\nres.end(`You made a ${method} request to ${url}`);\n});\n\nserver.listen(3000, () => {\nconsole.log('Server running at http://localhost:3000/');\n});",
        "const http = require('http');\nconst url = require('url');\n\nconst server = http.createServer((req, res) => {\n// Parse the URL\nconst parsedUrl = url.parse(req.url, true);\n\n// Get different parts of the URL\nconst pathname = parsedUrl.pathname; // The path without query string\nconst query = parsedUrl.query; // The query string as an object\n\nres.writeHead(200, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify({\npathname,\nquery,\nfullUrl: req.url\n}, null, 2));\n});\n\nserver.listen(3000);",
        "GET /products?category=electronics&sort=price&page=2 HTTP/1.1",
        "{\n\"pathname\": \"/products\",\n\"query\": {\n\"category\": \"electronics\",\n\"sort\": \"price\",\n\"page\": \"2\"\n},\n\"fullUrl\": \"/products?category=electronics&sort=price&page=2\"\n}",
        "const http = require('http');\nconst { URL } = require('url');\nconst querystring = require('querystring');\n\nconst server = http.createServer((req, res) => {\n// Using the newer URL API (Node.js 10+)\nconst baseURL = 'http://' + req.headers.host + '/';   const parsedUrl = new URL(req.url, baseURL);\n\n// Get query parameters\nconst params = Object.fromEntries(parsedUrl.searchParams);\n\n// Example of building a query string\nconst queryObj = {\nname: 'John Doe',\nage: 30,\ninterests: ['programming', 'music']\n};\nconst queryStr = querystring.stringify(queryObj);\n\nres.writeHead(200, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify({\npath: parsedUrl.pathname,\nparams,\nexampleQueryString: queryStr\n}, null, 2));\n});\n\nserver.listen(3000);",
        "const http = require('http');\nconst { URL } = require('url');\n\n// In-memory data store (for demonstration)\nlet todos = [\n{ id: 1, task: 'Learn Node.js', completed: false },\n{ id: 2, task: 'Build an API', completed: false }\n];\n\nconst server = http.createServer((req, res) => {\nconst { method, url } = req;\nconst parsedUrl = new URL(url, `http://${req.headers.host}`);\nconst pathname = parsedUrl.pathname;\n\n// Set CORS headers (for development)\nres.setHeader('Access-Control-Allow-Origin', '*');\nres.setHeader('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');\nres.setHeader('Access-Control-Allow-Headers', 'Content-Type');\n\n// Handle preflight requests\nif (method === 'OPTIONS') {\nres.writeHead(204);\nres.end();\nreturn;\n}\n\n// Route: GET /todos\nif (method === 'GET' && pathname === '/todos') {\nres.writeHead(200, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify(todos));\n}\n// Route: POST /todos\nelse if (method === 'POST' && pathname === '/todos') {\nlet body = '';\nreq.on('data', chunk => {\nbody += chunk.toString();\n});\n\nreq.on('end', () => {\ntry {\nconst newTodo = JSON.parse(body);\nnewTodo.id = todos.length > 0 ? Math.max(...todos.map(t => t.id)) + 1 : 1;\ntodos.push(newTodo);\nres.writeHead(201, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify(newTodo));\n} catch (error) {\nres.writeHead(400, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify({ error: 'Invalid JSON' }));\n}\n});\n}\n\n// Route: PUT /todos/:id\nelse if (method === 'PUT' && pathname.startsWith('/todos/')) {\nconst id = parseInt(pathname.split('/')[2]);\nlet body = '';\n\nreq.on('data', chunk => {\nbody += chunk.toString();\n});\n\nreq.on('end', () => {\ntry {\nconst updatedTodo = JSON.parse(body);\nconst index = todos.findIndex(t => t.id === id);\n\nif (index === -1) {\nres.writeHead(404, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify({ error: 'Todo not found' }));\n} else {\ntodos[index] = { ...todos[index], ...updatedTodo };\nres.writeHead(200, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify(todos[index]));\n}\n} catch (error) {\nres.writeHead(400, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify({ error: 'Invalid JSON' }));\n}\n});\n}\n\n// Route: DELETE /todos/:id\nelse if (method === 'DELETE' && pathname.startsWith('/todos/')) {\nconst id = parseInt(pathname.split('/')[2]);\nconst index = todos.findIndex(t => t.id === id);\n\nif (index === -1) {\nres.writeHead(404, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify({ error: 'Todo not found' }));\n} else {\ntodos = todos.filter(t => t.id !== id);\nres.writeHead(204);\nres.end();\n}\n}\n\n// 404 Not Found\nelse {\nres.writeHead(404, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify({ error: 'Not Found' }));\n}\n});\n\nconst PORT = 3000;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n});",
        "curl http://localhost:3000/todos",
        "curl -X POST http://localhost:3000/todos \\\n-H \"Content-Type: application/json\" \\\n-d '{\"task\":\"New Task\",\"completed\":false}'",
        "curl -X PUT http://localhost:3000/todos/1 \\\n-H \"Content-Type: application/json\" \\\n-d '{\"completed\":true}'",
        "curl -X DELETE http://localhost:3000/todos/1",
        "const http = require('http');\nconst fs = require('fs');\nconst path = require('path');\n\nconst server = http.createServer((req, res) => {\n// Get the file path from the URL\nconst filePath = path.join(__dirname, req.url);\n\n// Check if file exists\nfs.access(filePath, fs.constants.F_OK, (err) => {\nif (err) {\nres.statusCode = 404;\nres.end('File not found');\nreturn;\n}\n\n// Get file stats\nfs.stat(filePath, (err, stats) => {\nif (err) {\nres.statusCode = 500;\nres.end('Server error');\nreturn;\n}\n\n// Set appropriate headers\nres.setHeader('Content-Length', stats.size);\nres.setHeader('Content-Type', 'application/octet-stream');\n\n// Create read stream and pipe to response\nconst stream = fs.createReadStream(filePath);\n\n// Handle errors\nstream.on('error', (err) => {\nconsole.error('Error reading file:', err);\nif (!res.headersSent) {\nres.statusCode = 500;\nres.end('Error reading file');\n}\n});\n\n// Pipe the file to the response\nstream.pipe(res);\n});\n});\n});\n\nconst PORT = 3000;\nserver.listen(PORT, () => {\nconsole.log(`File server running at http://localhost:${PORT}/`);\n});",
        "require()",
        "createServer()",
        "http.createServer()",
        "req",
        "res",
        "res.writeHead()",
        "res.end()",
        "server.listen()",
        "server.js",
        "Content-Type",
        "Content-Length",
        "Location",
        "Set-Cookie",
        "Cache-Control",
        "Access-Control-Allow-Origin",
        "req.headers",
        "req.url",
        "http.IncomingMessage",
        "url",
        "querystring",
        "url.parse(urlString, [parseQueryString], [slashesDenoteHost])",
        "url.format(urlObject)",
        "url.resolve(from, to)",
        "new URL(input, [base])",
        "querystring.parse(str, [sep], [eq], [options])",
        "querystring.stringify(obj, [sep], [eq], [options])",
        "200 OK",
        "201 Created",
        "204 No Content",
        "400 Bad Request",
        "401 Unauthorized",
        "403 Forbidden",
        "404 Not Found",
        "500 Internal Server Error"
      ]
    },
    {
      "title": "Node.js HTTPS Module",
      "summary": "Introduction to the HTTPS Module\nThe HTTPS module is a core Node.js module that provides an implementation of the HTTPS protocol, which is essentially HTTP over TLS/SSL.\nIt's a secure version of the HTTP module, providing encrypted communication between clients and servers.\nWhy Use HTTPS?\nHTTPS is crucial for modern web applications because it:\nEncrypts Data: Protects sensitive information like passwords, credit card numbers, and personal data from eavesdropping\nAuthenticates Servers: Verifies that clients are communicating with the intended server\nEnsures Data Integrity: Prevents data from being modified or corrupted during transfer\nBuilds Trust: Visual indicators (like the padlock icon) increase user confidence\nImproves SEO: Search engines prioritize HTTPS websites in search results\nEnables Modern Features: Many web APIs (like Geolocation, Service Workers) require HTTPS\nHow HTTPS Works\nClient initiates a secure connection to the server\nServer presents its SSL/TLS certificate to the client\nClient verifies the certificate with a trusted Certificate Authority (CA)\nEncrypted session is established using asymmetric encryption\nSymmetric encryption is used for the actual data transfer\nNote: Modern HTTPS uses TLS (Transport Layer Security), which is the successor to SSL (Secure Sockets Layer). The terms are often used interchangeably, but SSL is now considered deprecated.\nImportant: As of 2023, all major browsers require HTTPS for new web features and APIs. Many browsers also mark non-HTTPS sites as \"Not Secure.\"\nGetting Started with HTTPS\nImporting the Module\nTo use the HTTPS module in your Node.js application, you can import it using CommonJS or ES modules syntax:\nHTTPS vs HTTP API\nThe HTTPS module has the same interface as the HTTP module, with the main difference being that it creates connections using TLS/SSL.\nThis means all the methods and events available in the HTTP module are also available in the HTTPS module.\nNote: The main difference in usage is that HTTPS requires SSL/TLS certificates, while HTTP does not.\nSSL/TLS Certificates\nHTTPS requires SSL/TLS certificates to establish secure connections. There are several types of certificates:\nTypes of Certificates\nSelf-Signed Certificates: For development and testing (not trusted by browsers)\nDomain Validated (DV): Basic validation, just verifies domain ownership\nOrganization Validated (OV): Validates organization details\nExtended Validation (EV): Highest level of validation, shows company name in browser\nWildcard Certificates: Secures all subdomains of a domain\nMulti-Domain (SAN) Certificates: Secures multiple domains with one certificate\nGenerating Self-Signed Certificates\nFor development, you can create self-signed certificates using OpenSSL:\nNote: If there is no key.pem file present, you need to use the \"-newkey\" option instead of \"-key\" in the command above.\nSecurity Note: Self-signed certificates will trigger security warnings in browsers because they're not signed by a trusted Certificate Authority.\nOnly use them for development and testing purposes.\nObtaining Trusted Certificates\nFor production, obtain certificates from trusted Certificate Authorities (CAs):\nPaid CAs: DigiCert, GlobalSign, Comodo, etc.\nFree CAs: Let's Encrypt, ZeroSSL, Cloudflare\nLet's Encrypt is a popular free, automated, and open Certificate Authority that provides trusted certificates.\nCreating an HTTPS Server\nOnce you have your SSL/TLS certificates ready, you can create an HTTPS server in Node.js.\nThe HTTPS server API is very similar to the HTTP server API, with the main difference being the SSL/TLS configuration.\nBasic HTTPS Server Example\nHere's how to create a basic HTTPS server:\nNote: On Unix-like systems, ports below 1024 require root privileges. For production, it's common to run Node.js on a high port (like 3000, 8080) and use a reverse proxy like Nginx or Apache to handle SSL termination.\nAdvanced Server Configuration\nFor production environments, you might need more advanced SSL/TLS configuration:\nSecurity Best Practices:\nAlways use the latest stable version of Node.js for security updates\nKeep your dependencies up to date using `npm audit` and `npm update`\nUse environment variables for sensitive configuration (never commit secrets to version control)\nImplement rate limiting to prevent abuse\nRegularly rotate your SSL/TLS certificates\nMonitor your server for security vulnerabilities\nUse a reverse proxy like Nginx or Apache in production for additional security features\nTesting Your HTTPS Server\nTo test your HTTPS server, you can use curl or a web browser:\nOpen your web browser and navigate to https://localhost:3000\nIf using a self-signed certificate, you'll need to accept the security warning\nFor development, you can add your self-signed certificate to your trusted root certificates\nREMOVE ADS\nMaking HTTPS Requests\nThe HTTPS module allows you to make secure HTTP requests to other servers.\nThis is essential for interacting with secure APIs and web services.\nBasic GET Request\nHere's how to make a simple GET request to an HTTPS endpoint:\nUsing https.get() for Simple Requests\nFor simple GET requests, you can use the more concise https.get() method. This is a convenience method that automatically sets the HTTP method to GET and calls req.end() for you.\nMaking POST Requests\nTo send data to a server, you can use a POST request.\nHere's how to make a secure POST request with JSON data:\nUsing Promises with HTTPS Requests\nTo make HTTPS requests more manageable, you can wrap them in a Promise:\nBest Practices for HTTPS Requests:\nAlways validate and sanitize input data before sending it in a request\nUse environment variables for sensitive information like API keys\nImplement proper error handling and timeouts\nSet appropriate headers (Content-Type, Accept, User-Agent)\nHandle redirects appropriately (3xx status codes)\nImplement retry logic for transient failures\nConsider using a library like axios or node-fetch for more complex scenarios\nHTTPS Server with Express.js\nWhile you can use the core HTTPS module directly, most Node.js applications use a web framework like Express.js to handle HTTP/HTTPS requests.\nHere's how to set up an Express application with HTTPS support.\nBasic Express.js HTTPS Server\nUsing Environment Variables\nIt's a best practice to use environment variables for configuration. Create a .env file:\nThen use the dotenv package to load them:\nProduction Deployment\nIn production, it's recommended to use a reverse proxy like Nginx or Apache in front of your Node.js application. This provides:\nSSL/TLS termination\nLoad balancing\nStatic file serving\nRequest caching\nRate limiting\nBetter security headers\nBest Practices for Express.js with HTTPS:\nAlways use helmet middleware for security headers\nSet secure session options (if using sessions)\nUse environment variables for configuration\nImplement proper error handling and logging\nUse a reverse proxy in production\nKeep your dependencies up to date\nUse HTTP/2 for better performance\nImplement rate limiting to prevent abuse\nUse CORS middleware if your API is accessed from different domains\nHTTP/2 with Node.js\nHTTP/2 is a major revision of the HTTP protocol that provides significant performance improvements over HTTP/1.1. When combined with HTTPS, it offers both security and performance benefits for modern web applications.\nBenefits of HTTP/2\nKey Features of HTTP/2:\nMultiplexing: Multiple requests/responses can be sent in parallel over a single connection, eliminating head-of-line blocking\nHeader Compression: Reduces overhead by compressing HTTP headers (HPACK algorithm)\nServer Push: Server can proactively send resources to the client before they're requested\nBinary Protocol: More efficient to parse than HTTP/1.1's text-based format\nStream Prioritization: More important resources can be loaded first\nConnection Multiplexing: Multiple streams can share a single TCP connection\nHTTP/2 Server Example\nHTTP/2 with Express.js\nTo use HTTP/2 with Express.js, you can use the spdy package, which provides HTTP/2 support for Express applications:\nTesting HTTP/2 Support\nYou can verify that your server is using HTTP/2 with these methods:\nOpen Chrome DevTools (F12 or right-click → Inspect)\nGo to the Network tab\nRight-click on the column headers and enable \"Protocol\"\nLook for \"h2\" in the Protocol column for HTTP/2 requests\nClick on a request to see detailed protocol information\nNote: HTTP/2 requires HTTPS in browsers, though the protocol itself doesn't require encryption. All major browsers only support HTTP/2 over TLS (HTTPS).\nImportant: When using HTTP/2, ensure your SSL/TLS configuration is up to date and follows security best practices, as many HTTP/2 features rely on a secure connection.\nComparing HTTP and HTTPS\nSummary and Best Practices\nIn this comprehensive guide, we've explored the Node.js HTTPS module and its capabilities for creating secure web applications. Here's a summary of the key points and best practices:\nKey Takeaways\nHTTPS is Essential: Modern web development requires HTTPS to ensure data security, user privacy, and compliance with web standards.\nCertificate Management: Properly manage SSL/TLS certificates, whether using self-signed certificates for development or trusted certificates from CAs for production.\nSecurity First: Always implement security best practices, including proper TLS configuration, secure headers, and input validation.\nPerformance Matters: Leverage HTTP/2 for improved performance through features like multiplexing, header compression, and server push.\nProduction Readiness: Use reverse proxies (like Nginx) in production for better security, performance, and reliability.\nSecurity Checklist\nBefore deploying your HTTPS-enabled application to production, verify:\nUse TLS 1.2 or higher (1.3 recommended)\nImplement HSTS (HTTP Strict Transport Security)\nUse secure cipher suites and disable weak ones\nKeep your Node.js and dependencies updated\nImplement proper error handling and logging\nSet secure cookie flags (Secure, HttpOnly, SameSite)\nUse Content Security Policy (CSP) headers\nImplement rate limiting and request validation\nPerformance Optimization\nEnable HTTP/2 for better performance\nImplement session resumption to reduce TLS handshake overhead\nUse OCSP stapling to improve TLS handshake performance\nOptimize your certificate chain (keep it short and complete)\nEnable session tickets for better performance with session resumption\nRemember that security is an ongoing process. Regularly audit your application, keep dependencies updated, and stay informed about the latest security best practices and vulnerabilities.",
      "examples": [
        "// Using require()\nconst https = require('https');",
        "// Using import (requires \"type\": \"module\" in package.json)\nimport https from 'https';",
        "# Generate a private key (RSA 2048-bit)\nopenssl genrsa -out key.pem 2048\n\n# Generate a self-signed certificate (valid for 365 days)\nopenssl req -new -x509 -key key.pem -out cert.pem -days 365 -nodes",
        "# Create a config file (san.cnf)\ncat > san.cnf << EOF\n[req]\ndistinguished_name = req_distinguished_name\nx509_extensions = v3_req\nprompt = no\n[req_distinguished_name]\nC = US\nST = State\nL = City\nO = Organization\nOU = Organizational Unit\nCN = localhost\n[v3_req]\nkeyUsage = keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth\nsubjectAltName = @alt_names\n[alt_names]\nDNS.1 = localhost\nIP.1 = 127.0.0.1\nEOF\n\n# Generate key and certificate with SAN\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 \\\n-keyout key.pem -out cert.pem -config san.cnf -extensions 'v3_req'",
        "const https = require('https');\nconst fs = require('fs');\nconst path = require('path');\n\n// Path to your SSL/TLS certificate and key\nconst sslOptions = {\nkey: fs.readFileSync(path.join(__dirname, 'key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'cert.pem')),\n// Enable all security features\nminVersion: 'TLSv1.2',\n// Recommended security settings\nsecureOptions: require('constants').SSL_OP_NO_SSLv3 |\nrequire('constants').SSL_OP_NO_TLSv1 |\nrequire('constants').SSL_OP_NO_TLSv1_1\n};\n\n// Create the HTTPS server\nconst server = https.createServer(sslOptions, (req, res) => {\n// Security headers\nres.setHeader('Strict-Transport-Security', 'max-age=31536000; includeSubDomains');\nres.setHeader('X-Content-Type-Options', 'nosniff');\nres.setHeader('X-Frame-Options', 'SAMEORIGIN');\nres.setHeader('X-XSS-Protection', '1; mode=block');\nres.setHeader('Referrer-Policy', 'strict-origin-when-cross-origin');\n\n// Handle different routes\nif (req.url === '/') {\nres.writeHead(200, { 'Content-Type': 'text/html; charset=utf-8' });\nres.end('<h1>Welcome to the Secure Server</h1><p>Your connection is encrypted!</p>');\n} else if (req.url === '/api/status') {\nres.writeHead(200, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify({ status: 'ok', time: new Date().toISOString() }));\n} else {\nres.writeHead(404, { 'Content-Type': 'text/plain' });\nres.end('404 Not Found');\n}\n});\n\n// Handle server errors\nserver.on('error', (error) => {\nconsole.error('Server error:', error);\n});\n\n// Start the server on port 3000 (HTTPS default is 443 but requires root)\nconst PORT = process.env.PORT || 3000;\nserver.listen(PORT, '0.0.0.0', () => {\nconsole.log(`Server running at https://localhost:${PORT}`);\nconsole.log('Press Ctrl+C to stop the server');\n});",
        "const https = require('https');\nconst fs = require('fs');\nconst path = require('path');\nconst tls = require('tls');\n\n// Path to your SSL/TLS files\nconst sslOptions = {\n// Certificate and key\nkey: fs.readFileSync(path.join(__dirname, 'privkey.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'cert.pem')),\nca: [\nfs.readFileSync(path.join(__dirname, 'chain.pem'))\n],\n\n// Recommended security settings\nminVersion: 'TLSv1.2',\nmaxVersion: 'TLSv1.3',\nciphers: [\n'TLS_AES_256_GCM_SHA384',\n'TLS_CHACHA20_POLY1305_SHA256',\n'TLS_AES_128_GCM_SHA256',\n'ECDHE-ECDSA-AES256-GCM-SHA384',\n'ECDHE-RSA-AES256-GCM-SHA384',\n'ECDHE-ECDSA-CHACHA20-POLY1305',\n'ECDHE-RSA-CHACHA20-POLY1305',\n'ECDHE-ECDSA-AES128-GCM-SHA256',\n'ECDHE-RSA-AES128-GCM-SHA256'   ].join(':'),\nhonorCipherOrder: true,\n\n// Enable OCSP Stapling\nrequestCert: true,\nrejectUnauthorized: true,\n\n// Enable session resumption\nsessionTimeout: 300, // 5 minutes\nsessionIdContext: 'my-secure-app',\n\n// Enable HSTS preload\nhsts: {\nmaxAge: 63072000, // 2 years in seconds\nincludeSubDomains: true,\npreload: true\n},\n\n// Enable secure renegotiation\nsecureOptions: require('constants').SSL_OP_LEGACY_SERVER_CONNECT |\nrequire('constants').SSL_OP_NO_SSLv3 |\nrequire('constants').SSL_OP_NO_TLSv1 |\nrequire('constants').SSL_OP_NO_TLSv1_1 |\nrequire('constants').SSL_OP_CIPHER_SERVER_PREFERENCE\n};\n\n// Create the HTTPS server\nconst server = https.createServer(sslOptions, (req, res) => {\n// Security headers\nconst securityHeaders = {\n'Strict-Transport-Security': 'max-age=63072000; includeSubDomains; preload',\n'X-Content-Type-Options': 'nosniff',\n'X-Frame-Options': 'DENY',\n'X-XSS-Protection': '1; mode=block',\n'Content-Security-Policy': \"default-src 'self'\",\n'Referrer-Policy': 'strict-origin-when-cross-origin',\n'Permissions-Policy': 'geolocation=(), microphone=(), camera=()',\n};\n\nObject.entries(securityHeaders).forEach(([key, value]) => {\nres.setHeader(key, value);\n});\n\n// Handle requests\nif (req.url === '/') {\nres.writeHead(200, { 'Content-Type': 'text/html; charset=utf-8' });\nres.end('<h1>Secure Node.js Server</h1><p>Your connection is secure!</p>');\n} else {\nres.writeHead(404, { 'Content-Type': 'text/plain' });\nres.end('404 Not Found');\n}\n});\n\n// Handle server errors\nserver.on('error', (error) => {\nconsole.error('Server error:', error);\n});\n\n// Handle uncaught exceptions\nprocess.on('uncaughtException', (error) => {\nconsole.error('Uncaught exception:', error);\n// Perform graceful shutdown\nserver.close(() => process.exit(1));\n});\n\n// Handle unhandled promise rejections\nprocess.on('unhandledRejection', (reason, promise) => {\nconsole.error('Unhandled Rejection at:', promise, 'reason:', reason);\n});\n\n// Handle graceful shutdown\nconst gracefulShutdown = () => {\nconsole.log('Shutting down gracefully...');\nserver.close(() => {\nconsole.log('Server closed');\nprocess.exit(0);\n});\n\n// Force close server after 10 seconds\nsetTimeout(() => {\nconsole.error('Forcing shutdown...');\nprocess.exit(1);\n}, 10000);\n};\n\n// Listen for shutdown signals\nprocess.on('SIGTERM', gracefulShutdown);\nprocess.on('SIGINT', gracefulShutdown);\n\n// Start the server\nconst PORT = process.env.PORT || 3000;\nconst HOST = process.env.HOST || '0.0.0.0';\n\nserver.listen(PORT, HOST, () => {\nconst { address, port } = server.address();\nconsole.log(`Server running at https://${address}:${port}`);\n\n// Output server information\nconsole.log('Node.js version:', process.version);\nconsole.log('Environment:', process.env.NODE_ENV || 'development');\nconsole.log('PID:', process.pid);\n});",
        "# Skip certificate verification (for self-signed certs)\ncurl -k https://localhost:3000\n\n# With certificate verification (for trusted certs)\ncurl --cacert /path/to/ca.pem https://yourdomain.com",
        "const https = require('https');\nconst { URL } = require('url');\n\n// Parse the target URL\nconst apiUrl = new URL('https://api.example.com/data');\n\n// Request options\nconst options = {\nhostname: apiUrl.hostname,\nport: 443,\npath: apiUrl.pathname + apiUrl.search,\nmethod: 'GET',\nheaders: {\n'User-Agent': 'MySecureApp/1.0',\n'Accept': 'application/json',\n'Cache-Control': 'no-cache'\n},\n// Security settings\nrejectUnauthorized: true, // Verify the server certificate (default: true)\n// Timeout in milliseconds\ntimeout: 10000, // 10 seconds\n};\n\nconsole.log(`Making request to: https://${options.hostname}${options.path}`);\n\n// Make the HTTPS request\nconst req = https.request(options, (res) => {\nconst { statusCode, statusMessage, headers } = res;\nconst contentType = headers['content-type'] || '';\n\nconsole.log(`Status: ${statusCode} ${statusMessage}`);\nconsole.log('Headers:', headers);\n\n// Handle redirects\nif (statusCode >= 300 && statusCode < 400 && headers.location) {\nconsole.log(`Redirecting to: ${headers.location}`);\n// In a real app, you'd handle the redirect\nres.resume(); // Discard the response body\nreturn;\n}\n\n// Check for successful response\nlet error;\nif (statusCode !== 200) {\nerror = new Error(`Request Failed.\\nStatus Code: ${statusCode}`);\n} else if (!/^application\\/json/.test(contentType)) {\nerror = new Error(`Invalid content-type.\\nExpected application/json but received ${contentType}`);\n}\nif (error) {\nconsole.error(error.message);\nres.resume(); // Consume response data to free up memory\nreturn;\n}\n\n// Process the response\nlet rawData = '';\nres.setEncoding('utf8');\n\n// Collect chunks of data\nres.on('data', (chunk) => {\nrawData += chunk;\n});\n\n// Process the complete response\nres.on('end', () => {\ntry {\nconst parsedData = JSON.parse(rawData);\nconsole.log('Response data:', parsedData);\n} catch (e) {\nconsole.error('Error parsing JSON:', e.message);\n}\n});\n});\n\n// Handle request errors\nreq.on('error', (e) => {\nconsole.error(`Request error: ${e.message}`);\nif (e.code === 'ECONNRESET') {\nconsole.error('Connection was reset by the server');\n} else if (e.code === 'ETIMEDOUT') {\nconsole.error('Request timed out');\n}\n});\n\n// Set a timeout for the entire request (including DNS lookup, TCP connect, etc.)\nreq.setTimeout(15000, () => {\nreq.destroy(new Error('Request timeout after 15 seconds'));\n});\n\n// Handle socket errors (network-level errors)\nreq.on('socket', (socket) => {\nsocket.on('error', (error) => {\nconsole.error('Socket error:', error.message);\nreq.destroy(error);\n});\n// Set a timeout for the socket connection\nsocket.setTimeout(5000, () => {\nreq.destroy(new Error('Socket timeout after 5 seconds'));\n});\n});\n\n// End the request (required to send it)\nreq.end();",
        "const https = require('https');\nconst { URL } = require('url');\n\n// Parse the URL\nconst url = new URL('https://jsonplaceholder.typicode.com/posts/1');\n\n// Request options const options = {\nhostname: url.hostname,\npath: url.pathname,\nmethod: 'GET',\nheaders: {\n'Accept': 'application/json',\n'User-Agent': 'MySecureApp/1.0'\n}\n};\n\nconsole.log(`Fetching data from: ${url}`);\n\n// Make the GET request const req = https.get(options, (res) => {\nconst { statusCode } = res;\nconst contentType = res.headers['content-type'];\n\nif (statusCode !== 200) {\nconsole.error(`Request failed with status code: ${statusCode}`);\nres.resume(); // Consume response data to free up memory\nreturn;\n}\n\nif (!/^application\\/json/.test(contentType)) {\nconsole.error(`Expected JSON but got ${contentType}`);\nres.resume();\nreturn;\n}\n\nlet rawData = '';\nres.setEncoding('utf8');\n\n// Collect data chunks\nres.on('data', (chunk) => {     rawData += chunk;\n});\n\n// Process complete response\nres.on('end', () => {\ntry {\nconst parsedData = JSON.parse(rawData);\nconsole.log('Received data:', parsedData);\n} catch (e) {\nconsole.error('Error parsing JSON:', e.message);\n}\n});\n});\n\n// Handle errors\nreq.on('error', (e) => {\nconsole.error(`Error: ${e.message}`);\n});\n\n// Set a timeout\nreq.setTimeout(10000, () => {\nconsole.error('Request timeout');\nreq.destroy();\n});",
        "const https = require('https');\nconst { URL } = require('url');\n\n// Request data\nconst postData = JSON.stringify({\ntitle: 'foo',\nbody: 'bar',\nuserId: 1\n});\n\n// Parse the URL\nconst url = new URL('https://jsonplaceholder.typicode.com/posts');\n\n// Request options\nconst options = {\nhostname: url.hostname,\nport: 443,\npath: url.pathname,\nmethod: 'POST',\nheaders: {\n'Content-Type': 'application/json',\n'Content-Length': Buffer.byteLength(postData),\n'User-Agent': 'MySecureApp/1.0',\n'Accept': 'application/json'\n},\ntimeout: 10000 // 10 seconds\n};\n\nconsole.log('Sending POST request to:', url.toString());\n\n// Create the request\nconst req = https.request(options, (res) => {\nconsole.log(`Status Code: ${res.statusCode}`);\nconsole.log('Headers:', res.headers);\n\nlet responseData = '';\nres.setEncoding('utf8');\n\n// Collect response data\nres.on('data', (chunk) => {\nresponseData += chunk;\n});\n\n// Process complete response\nres.on('end', () => {\ntry {\nconst parsedData = JSON.parse(responseData);\nconsole.log('Response:', parsedData);\n} catch (e) {\nconsole.error('Error parsing response:', e.message);\n}\n});\n});\n\n// Handle errors\nreq.on('error', (e) => {\nconsole.error(`Request error: ${e.message}`);\n});\n\n// Set a timeout\nreq.setTimeout(15000, () => {\nreq.destroy(new Error('Request timeout after 15 seconds'));\n});\n\n// Write data to request body\nreq.write(postData);\n\n// End the request\nreq.end();",
        "const https = require('https');\nconst { URL } = require('url');\n\n/**\n* Makes an HTTPS request and returns a Promise\n* @param {Object} options - Request options\n* @param {string|Buffer} [data] - Request body (for POST, PUT, etc.)\n* @returns {Promise<Object>} - Resolves with response data\n*/\nfunction httpsRequest(options, data = null) {\nreturn new Promise((resolve, reject) => {\nconst req = https.request(options, (res) => {\nlet responseData = '';\n\n// Collect response data\nres.on('data', (chunk) => {\nresponseData += chunk;\n});\n\n// Process complete response\nres.on('end', () => {\ntry {\nconst contentType = res.headers['content-type'] || '';\nconst isJSON = /^application\\/json/.test(contentType);\n\nconst response = {\nstatusCode: res.statusCode,\nheaders: res.headers,\ndata: isJSON ? JSON.parse(responseData) : responseData\n};\n\nif (res.statusCode >= 200 && res.statusCode < 300) {\nresolve(response);\n} else {\nconst error = new Error(`Request failed with status code ${res.statusCode}`);\nerror.response = response;\nreject(error);\n}\n} catch (e) {\ne.response = { data: responseData };\nreject(e);\n}\n});\n});\n\n// Handle errors\nreq.on('error', (e) => {\nreject(e);\n});\n\n// Set timeout\nreq.setTimeout(options.timeout || 10000, () => {\nreq.destroy(new Error('Request timeout'));\n});\n\n// Write data if provided\nif (data) {\nreq.write(data);\n}\n\n// End the request\nreq.end();\n});\n}\n\n// Example usage\nasync function fetchData() {\ntry {\nconst url = new URL('https://jsonplaceholder.typicode.com/posts/1');\n\nconst options = {\nhostname: url.hostname,\npath: url.pathname,\nmethod: 'GET',\nheaders: {\n'Accept': 'application/json'\n},\ntimeout: 5000\n};\n\nconst response = await httpsRequest(options);\nconsole.log('Response:', response.data);\n} catch (error) {\nconsole.error('Error:', error.message);\nif (error.response) {\nconsole.error('Response data:', error.response.data);\n}\n}\n}\n\n// Run the example\nfetchData();",
        "const express = require('express');\nconst https = require('https');\nconst fs = require('fs');\nconst path = require('path');\nconst helmet = require('helmet'); // Security middleware\n\n// Create Express app\nconst app = express();\n\n// Security middleware\napp.use(helmet());\n\n// Parse JSON and URL-encoded bodies\napp.use(express.json());\napp.use(express.urlencoded({ extended: true }));\n\n// Serve static files from 'public' directory\napp.use(express.static(path.join(__dirname, 'public'), {\ndotfiles: 'ignore',\netag: true,\nextensions: ['html', 'htm'],\nindex: 'index.html',\nmaxAge: '1d',\nredirect: true\n}));\n\n// Routes\napp.get('/', (req, res) => {\nres.send('<h1>Welcome to Secure Express Server</h1>');\n});\n\napp.get('/api/status', (req, res) => {\nres.json({\nstatus: 'operational',\ntimestamp: new Date().toISOString(),\nenvironment: process.env.NODE_ENV || 'development',\nnodeVersion: process.version\n});\n});\n\n// Error handling middleware\napp.use((err, req, res, next) => {\nconsole.error(err.stack);\nres.status(500).json({ error: 'Something went wrong!' });\n});\n\n// 404 handler\napp.use((req, res) => {\nres.status(404).json({ error: 'Not Found' });\n});\n\n// SSL/TLS options\nconst sslOptions = {\nkey: fs.readFileSync(path.join(__dirname, 'key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'cert.pem')),\n// Enable HTTP/2 if available\nallowHTTP1: true,\n// Recommended security options\nminVersion: 'TLSv1.2',\nciphers: [\n'TLS_AES_256_GCM_SHA384',\n'TLS_CHACHA20_POLY1305_SHA256',\n'TLS_AES_128_GCM_SHA256',\n'ECDHE-RSA-AES128-GCM-SHA256',\n'!DSS',\n'!aNULL',\n'!eNULL',\n'!EXPORT',\n'!DES',\n'!RC4',\n'!3DES',\n'!MD5',\n'!PSK'\n].join(':'),\nhonorCipherOrder: true\n};\n\n// Create HTTPS server\nconst PORT = process.env.PORT || 3000;\nconst server = https.createServer(sslOptions, app);\n\n// Handle unhandled promise rejections\nprocess.on('unhandledRejection', (reason, promise) => {\nconsole.error('Unhandled Rejection at:', promise, 'reason:', reason);\n});\n\n// Handle uncaught exceptions\nprocess.on('uncaughtException', (error) => {\nconsole.error('Uncaught Exception:', error);\n// Perform cleanup and exit if needed\nprocess.exit(1);\n});\n\n// Graceful shutdown\nconst gracefulShutdown = (signal) => {\nconsole.log(`\\nReceived ${signal}. Shutting down gracefully...`);\n\nserver.close(() => {\nconsole.log('HTTP server closed.');\n// Close database connections, etc.\nprocess.exit(0);\n});\n\n// Force close server after 10 seconds\nsetTimeout(() => {\nconsole.error('Forcing shutdown...');\nprocess.exit(1);\n}, 10000);\n};\n\n// Listen for shutdown signals\nprocess.on('SIGTERM', gracefulShutdown);\nprocess.on('SIGINT', gracefulShutdown);\n\n// Start the server\nconst HOST = process.env.HOST || '0.0.0.0';\nserver.listen(PORT, HOST, () => {\nconsole.log(`Express server running at https://${HOST}:${PORT}`);\nconsole.log('Environment:', process.env.NODE_ENV || 'development');\nconsole.log('Press Ctrl+C to stop the server');\n});",
        "NODE_ENV=development PORT=3000\nHOST=0.0.0.0\nSSL_KEY_PATH=./key.pem\nSSL_CERT_PATH=./cert.pem",
        "require('dotenv').config();\n\n// Access environment variables\nconst PORT = process.env.PORT || 3000;\nconst HOST = process.env.HOST || '0.0.0.0';\nconst sslOptions = {\nkey: fs.readFileSync(process.env.SSL_KEY_PATH),\ncert: fs.readFileSync(process.env.SSL_CERT_PATH)\n// ... other options\n};",
        "server {\nlisten 443 ssl http2;\nserver_name yourdomain.com;\n\n# SSL configuration\nssl_certificate /path/to/your/cert.pem;\nssl_certificate_key /path/to/your/key.pem;\n\n# Security headers\nadd_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\nadd_header X-Content-Type-Options \"nosniff\" always;\nadd_header X-Frame-Options \"SAMEORIGIN\" always;\nadd_header X-XSS-Protection \"1; mode=block\" always;\n\n# Proxy to Node.js app\nlocation / {\nproxy_pass http://localhost:3000;\nproxy_http_version 1.1;\nproxy_set_header Upgrade $http_upgrade;\nproxy_set_header Connection 'upgrade';\nproxy_set_header Host $host;\nproxy_cache_bypass $http_upgrade;\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header X-Forwarded-Proto $scheme;\n}\n\n# Serve static files directly\nlocation /static/ {\nroot /path/to/your/app/public;\nexpires 30d;\naccess_log off;\n}\n}\n\n# Redirect HTTP to HTTPS\nserver {\nlisten 80;\nserver_name yourdomain.com;\nreturn 301 https://$host$request_uri;\n}\n\n# Redirect HTTP to HTTPS\nserver {\nlisten 80;\nserver_name yourdomain.com;\nreturn 301 https://$host$request_uri;\n}",
        "const http2 = require('http2');\nconst fs = require('fs');\nconst path = require('path');\n\n// SSL/TLS options\nconst serverOptions = {\nkey: fs.readFileSync(path.join(__dirname, 'key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'cert.pem')),\nallowHTTP1: true, // Fallback to HTTP/1.1 if needed\n\n// Recommended security settings\nminVersion: 'TLSv1.2',\nciphers: [\n'TLS_AES_256_GCM_SHA384',\n'TLS_CHACHA20_POLY1305_SHA256',\n'TLS_AES_128_GCM_SHA256',\n'ECDHE-ECDSA-AES256-GCM-SHA384',\n'!aNULL',\n'!eNULL',\n'!EXPORT',\n'!DES',\n'!RC4',\n'!3DES',\n'!MD5',\n'!PSK'\n].join(':'),\nhonorCipherOrder: true\n};\n\n// Create HTTP/2 server\nconst server = http2.createSecureServer(serverOptions);\n\n// Handle incoming requests\nserver.on('stream', (stream, headers) => {\nconst method = headers[':method'];\nconst path = headers[':path'];\nconst scheme = headers[':scheme'];\nconst authority = headers[':authority'];\n\nconsole.log(`${method} ${path} (HTTP/2)`);\n\n// Handle different routes\nif (path === '/') {\n// Set response headers\nstream.respond({\n'content-type': 'text/html; charset=utf-8',\n':status': 200,\n'x-powered-by': 'Node.js HTTP/2',\n'cache-control': 'public, max-age=3600'\n});\n\n// Send HTML response\nstream.end(`\n<!DOCTYPE html>\n<html>\n<head>\n<title>HTTP/2 Server</title>\n<link rel=\"stylesheet\" href=\"/styles.css\">\n</head>\n<body>\n<h1>Hello from HTTP/2 Server!</h1>\n<p>This page is served over HTTP/2.</p>\n<div id=\"data\">Loading data...</div>\n<script src=\"/app.js\"></script>\n</body>\n</html>\n`);\n}\n// API endpoint\nelse if (path === '/api/data' && method === 'GET') {\nstream.respond({\n'content-type': 'application/json',\n':status': 200,\n'cache-control': 'no-cache'\n});\n\nstream.end(JSON.stringify({\nmessage: 'Data from HTTP/2 API',\ntimestamp: new Date().toISOString(),\nprotocol: 'HTTP/2',\nserver: 'Node.js HTTP/2 Server'\n}));\n}\n// Server Push example\nelse if (path === '/push') {\n// Push additional resources\nstream.pushStream({ ':path': '/styles.css' }, (err, pushStream) => {\nif (err) {\nconsole.error('Push stream error:', err);\nreturn;\n}\npushStream.respond({\n'content-type': 'text/css',\n':status': 200\n});\npushStream.end('body { font-family: Arial, sans-serif; margin: 2em; }');\n}\nstream.respond({\n'content-type': 'text/html; charset=utf-8',\n':status': 200\n});\nstream.end('<h1>Server Push Example</h1><link rel=\"stylesheet\" href=\"/styles.css\">');\n}\n// 404 Not Found\nelse {\nstream.respond({\n'content-type': 'text/plain',\n':status': 404\n});\nstream.end('404 - Not Found');\n}\n});\n\n// Handle errors\nserver.on('error', (err) => {\nconsole.error('Server error:', err);\nprocess.exit(1);\n});\n\n// Start the server\nconst PORT = process.env.PORT || 8443;\nserver.listen(PORT, '0.0.0.0', () => {\nconsole.log(`HTTP/2 server running at https://localhost:${PORT}`);\nconsole.log('Environment:', process.env.NODE_ENV || 'development');\nconsole.log('Press Ctrl+C to stop the server');\n});\n\n// Graceful shutdown\nconst gracefulShutdown = (signal) => {\nconsole.log(`\\nReceived ${signal}. Shutting down gracefully...`);\nserver.close(() => {\nconsole.log('HTTP/2 server closed.');\nprocess.exit(0);\n});\n\n// Force close server after 10 seconds\nsetTimeout(() => {\nconsole.error('Forcing shutdown...');\nprocess.exit(1);\n}, 10000);\n};\n\n// Listen for shutdown signals\nprocess.on('SIGTERM', gracefulShutdown);\nprocess.on('SIGINT', gracefulShutdown);",
        "npm install spdy --save",
        "const express = require('express');\nconst spdy = require('spdy');\nconst fs = require('fs');\nconst path = require('path');\n\nconst app = express();\n\n// Your Express middleware and routes here\napp.get('/', (req, res) => {\nres.send('Hello from Express over HTTP/2!');\n});\n\n// SSL/TLS options\nconst options = {\nkey: fs.readFileSync(path.join(__dirname, 'key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'cert.pem')),\nspdy: {\nprotocols: ['h2', 'http/1.1'], // Allow both HTTP/2 and HTTP/1.1\nplain: false, // Use TLS\n'x-forwarded-for': true\n}\n};\n\n// Create HTTP/2 server with Express\nconst PORT = process.env.PORT || 3000;\nspdy.createServer(options, app).listen(PORT, () => {\nconsole.log(`Express server with HTTP/2 running on port ${PORT}`);\n});",
        "# Check if server supports HTTP/2\ncurl -I --http2 https://localhost:8443\n\n# Force HTTP/2 with verbose output\ncurl -v --http2 https://localhost:8443\n\n# Test with HTTP/2 prior knowledge (no upgrade)\ncurl --http2-prior-knowledge -I https://localhost:8443",
        "-newkey",
        "-key",
        "https://localhost:3000",
        "https.get()",
        "req.end()",
        "axios",
        "node-fetch",
        ".env",
        "dotenv",
        "helmet",
        "spdy"
      ]
    },
    {
      "title": "Node.js File System Module",
      "summary": "Introduction to Node.js File System\nThe Node.js File System module (fs) provides a comprehensive set of methods for working with the file system on your computer.\nIt allows you to perform file I/O operations in both synchronous and asynchronous ways.\nNote: The File System module is a core Node.js module, so no installation is required.\nImporting the File System Module\nYou can import the File System module using CommonJS require() or ES modules import syntax:\nPromise-based API\nNode.js provides promise-based versions of the File System API in the fs/promises namespace, which is recommended for modern applications:\nCommon Use Cases\nRead and write files\nCreate and delete files\nAppend to files\nRename and move files\nChange file permissions\nCreate and remove directories\nList directory contents\nWatch for file changes\nGet file/directory stats\nCheck file existence\nFile streams\nFile descriptors\nSymbolic links\nFile watching\nWorking with file permissions\nPerformance Tip: For large files, consider using streams (fs.createReadStream and fs.createWriteStream) to avoid high memory usage.\nReading Files\nNode.js provides several methods to read files, including both callback-based and promise-based approaches.\nThe most common method is fs.readFile().\nNote: Always handle errors when working with file operations to prevent your application from crashing.\nReading Files with Callbacks\nHere's how to read a file using the traditional callback pattern:\nmyfile.txt\nCreate a Node.js file that reads the text file, and return the content:\nReading Files with Promises (Modern Approach)\nUsing fs.promises or util.promisify for cleaner async/await syntax:\nReading Files Synchronously\nFor simple scripts, you can use synchronous methods, but avoid them in production servers as they block the event loop:\nBest Practice: Always specify the character encoding (like 'utf8') when reading text files to get a string instead of a Buffer.\nREMOVE ADS\nCreating and Writing Files\nNode.js provides several methods for creating and writing to files.\nHere are the most common approaches:\n1. Using fs.writeFile()\nCreates a new file or overwrites an existing file with the specified content:\n2. Using fs.appendFile()\nAppends content to a file, creating the file if it doesn't exist:\n3. Using File Handles\nFor more control over file operations, you can use file handles:\n4. Using Streams for Large Files\nFor writing large amounts of data, use streams to avoid high memory usage:\nFile Flags: When opening files, you can specify different modes:\n'w' - Open for writing (file is created or truncated)\n'wx' - Like 'w' but fails if the path exists\n'w+' - Open for reading and writing (file is created or truncated)\n'a' - Open for appending (file is created if it doesn't exist)\n'ax' - Like 'a' but fails if the path exists\n'r+' - Open for reading and writing (file must exist)\nDeleting Files and Directories\nNode.js provides several methods to delete files and directories.\nHere's how to handle different deletion scenarios:\n1. Deleting a Single File\nUse fs.unlink() to delete a file:\n2. Deleting Multiple Files\nTo delete multiple files, you can use Promise.all() with fs.unlink():\n3. Deleting Directories\nTo delete directories, you have several options depending on your needs:\n4. Emptying a Directory Without Deleting It\nTo remove all files and subdirectories within a directory but keep the directory itself:\nSecurity Note: Be extremely careful with file deletion, especially when using recursive options or wildcards. Always validate and sanitize file paths to prevent directory traversal attacks.\nRenaming and Moving Files\nThe fs.rename() method can be used for both renaming and moving files.\nIt's a versatile method for file system operations that involve changing file paths.\n1. Basic File Renaming\nTo rename a file in the same directory:\n2. Moving Files Between Directories\nYou can use fs.rename() to move files between directories:\n3. Batch Renaming Files\nTo rename multiple files matching a pattern:\n4. Atomic Rename Operations\nFor critical operations, use a temporary file to ensure atomicity:\nCross-Platform Note: The fs.rename() operation is atomic on Unix-like systems but may not be on Windows.\nFor cross-platform atomic operations, consider using a temporary file approach as shown in the example above.",
      "examples": [
        "const fs = require('fs');",
        "import fs from 'fs';\n// Or for specific methods:\n// import { readFile, writeFile } from 'fs/promises';",
        "// Using promises (Node.js 10.0.0+)\nconst fs = require('fs').promises;\n\n// Or with destructuring\nconst { readFile, writeFile } = require('fs').promises;\n\n// Or with ES modules\n// import { readFile, writeFile } from 'fs/promises';",
        "This is the content of myfile.txt",
        "const fs = require('fs');\n\n// Read file asynchronously with callback\nfs.readFile('myfile.txt', 'utf8', (err, data) => {\nif (err) {\nconsole.error('Error reading file:', err);\nreturn;\n}\nconsole.log('File content:', data);\n});\n\n// For binary data (like images), omit the encoding\nfs.readFile('image.png', (err, data) => {\nif (err) throw err;\n// data is a Buffer containing the file content\nconsole.log('Image size:', data.length, 'bytes');\n});",
        "// Using fs.promises (Node.js 10.0.0+)\nconst fs = require('fs').promises;\n\nasync function readFileExample() {\ntry {\nconst data = await fs.readFile('myfile.txt', 'utf8');\nconsole.log('File content:', data);\n} catch (err) {\nconsole.error('Error reading file:', err);\n}\n}\n\nreadFileExample();\n\n// Or with util.promisify (Node.js 8.0.0+)\nconst { promisify } = require('util');\nconst readFileAsync = promisify(require('fs').readFile);\n\nasync function readWithPromisify() {\ntry {\nconst data = await readFileAsync('myfile.txt', 'utf8');\nconsole.log(data);\n} catch (err) {\nconsole.error(err);\n}\n}\n\nreadWithPromisify();",
        "const fs = require('fs');\n\ntry {\n// Read file synchronously\nconst data = fs.readFileSync('myfile.txt', 'utf8');\nconsole.log('File content:', data);\n} catch (err) {\nconsole.error('Error reading file:', err);\n}",
        "const fs = require('fs').promises;\n\nasync function writeFileExample() {\ntry {\n// Write text to a file\nawait fs.writeFile('myfile.txt', 'Hello, World!', 'utf8');\n\n// Write JSON data\nconst data = { name: 'John', age: 30, city: 'New York' };\nawait fs.writeFile('data.json', JSON.stringify(data, null, 2), 'utf8');\n\nconsole.log('Files created successfully');\n} catch (err) {\nconsole.error('Error writing files:', err);\n}\n}\n\nwriteFileExample();",
        "const fs = require('fs').promises;\n\nasync function appendToFile() {\ntry {\n// Append a timestamped log entry\nconst logEntry = `${new Date().toISOString()}: Application started\\n`;\nawait fs.appendFile('app.log', logEntry, 'utf8');\n\nconsole.log('Log entry added');\n} catch (err) {\nconsole.error('Error appending to file:', err);\n}\n}\n\nappendToFile();",
        "const fs = require('fs').promises;\n\nasync function writeWithFileHandle() {\nlet fileHandle;\n\ntry {\n// Open a file for writing (creates if doesn't exist)\nfileHandle = await fs.open('output.txt', 'w');\n\n// Write content to the file\nawait fileHandle.write('First line\\n');\nawait fileHandle.write('Second line\\n');\nawait fileHandle.write('Third line\\n');\n\nconsole.log('Content written successfully');\n} catch (err) {\nconsole.error('Error writing to file:', err);\n} finally {\n// Always close the file handle\nif (fileHandle) {\nawait fileHandle.close();\n}\n}\n}\n\nwriteWithFileHandle();",
        "const fs = require('fs');\nconst { pipeline } = require('stream/promises');\nconst { Readable } = require('stream');\n\nasync function writeLargeFile() {\n// Create a readable stream (could be from HTTP request, etc.)\nconst data = Array(1000).fill().map((_, i) => `Line ${i + 1}: ${'x'.repeat(100)}\\n`);\nconst readable = Readable.from(data);\n\n// Create a writable stream to a file\nconst writable = fs.createWriteStream('large-file.txt');\n\ntry {\n// Pipe the data from readable to writable\nawait pipeline(readable, writable);\nconsole.log('Large file written successfully');\n} catch (err) {\nconsole.error('Error writing file:', err);\n}\n}\n\nwriteLargeFile();",
        "const fs = require('fs').promises;\n\nasync function deleteFile() {\nconst filePath = 'file-to-delete.txt';\n\ntry {\n// Check if file exists before deleting\nawait fs.access(filePath);\n\n// Delete the file\nawait fs.unlink(filePath);\nconsole.log('File deleted successfully');\n} catch (err) {\nif (err.code === 'ENOENT') {\nconsole.log('File does not exist');\n} else {\nconsole.error('Error deleting file:', err);\n}\n}\n}\n\ndeleteFile();",
        "const fs = require('fs').promises;\nconst path = require('path');\n\nasync function deleteFiles() {\nconst filesToDelete = [\n'temp1.txt',\n'temp2.txt',\n'temp3.txt'\n];\n\ntry {\n// Delete all files in parallel\nawait Promise.all(\nfilesToDelete.map(file =>\nfs.unlink(file).catch(err => {\nif (err.code !== 'ENOENT') {\nconsole.error(`Error deleting ${file}:`, err);\n}\n})\n)\n);\n\nconsole.log('Files deleted successfully');\n} catch (err) {\nconsole.error('Error during file deletion:', err);\n}\n}\n\ndeleteFiles();",
        "const fs = require('fs').promises;\nconst path = require('path');\n\nasync function deleteDirectory(dirPath) {\ntry {\n// Check if the directory exists\nconst stats = await fs.stat(dirPath);\n\nif (!stats.isDirectory()) {\nconsole.log('Path is not a directory');\nreturn;\n}\n\n// For Node.js 14.14.0+ (recommended)\nawait fs.rm(dirPath, { recursive: true, force: true });\n\n// For older Node.js versions (deprecated but still works)\n// await fs.rmdir(dirPath, { recursive: true });\n\nconsole.log('Directory deleted successfully');\n} catch (err) {\nif (err.code === 'ENOENT') {\nconsole.log('Directory does not exist');\n} else {\nconsole.error('Error deleting directory:', err);\n}\n}\n}\n\n// Usage\ndeleteDirectory('directory-to-delete');",
        "const fs = require('fs').promises;\nconst path = require('path');\n\nasync function emptyDirectory(dirPath) {\ntry {\n// Read the directory\nconst files = await fs.readdir(dirPath, { withFileTypes: true });\n\n// Delete all files and directories in parallel\nawait Promise.all(\nfiles.map(file => {\nconst fullPath = path.join(dirPath, file.name);\nreturn file.isDirectory()\n? fs.rm(fullPath, { recursive: true, force: true })\n: fs.unlink(fullPath);\n})\n);\n\nconsole.log('Directory emptied successfully');\n} catch (err) {\nconsole.error('Error emptying directory:', err);\n}\n}\n\n// Usage\nemptyDirectory('directory-to-empty');",
        "const fs = require('fs').promises;\n\nasync function renameFile() {\nconst oldPath = 'old-name.txt';\nconst newPath = 'new-name.txt';\n\ntry {\n// Check if source file exists\nawait fs.access(oldPath);\n\n// Check if destination file already exists\ntry {\nawait fs.access(newPath);\nconsole.log('Destination file already exists');\nreturn;\n} catch (err) {\n// Destination doesn't exist, safe to proceed\n}\n\n// Perform the rename\nawait fs.rename(oldPath, newPath);\nconsole.log('File renamed successfully');\n} catch (err) {\nif (err.code === 'ENOENT') {\nconsole.log('Source file does not exist');\n} else {\nconsole.error('Error renaming file:', err);\n}\n}\n}\n\n// Usage\nrenameFile();",
        "const fs = require('fs').promises;\nconst path = require('path');\n\nasync function moveFile() {\nconst sourceFile = 'source/file.txt';\nconst targetDir = 'destination';\nconst targetFile = path.join(targetDir, 'file.txt');\n\ntry {\n// Ensure source file exists\nawait fs.access(sourceFile);\n\n// Create target directory if it doesn't exist\nawait fs.mkdir(targetDir, { recursive: true });\n\n// Move the file\nawait fs.rename(sourceFile, targetFile);\n\nconsole.log('File moved successfully');\n} catch (err) {\nif (err.code === 'ENOENT') {\nconsole.log('Source file does not exist');\n} else if (err.code === 'EXDEV') {\nconsole.log('Cross-device move detected, using copy+delete fallback');\nawait moveAcrossDevices(sourceFile, targetFile);\n} else {\nconsole.error('Error moving file:', err);\n}\n}\n}\n\n// Helper function for cross-device moves\nasync function moveAcrossDevices(source, target) {\ntry {\n// Copy the file\nawait fs.copyFile(source, target);\n\n// Delete the original\nawait fs.unlink(source);\n\nconsole.log('File moved across devices successfully');\n} catch (err) {\n// Clean up if something went wrong\ntry { await fs.unlink(target); } catch (e) {}\nthrow err;\n}\n}\n\n// Usage\nmoveFile();",
        "const fs = require('fs').promises;\nconst path = require('path');\n\nasync function batchRename() {\nconst directory = 'images';\nconst pattern = /^image(\\d+)\\.jpg$/;\n\ntry {\n// Read directory contents\nconst files = await fs.readdir(directory);\n\n// Process each file\nfor (const file of files) {\nconst match = file.match(pattern);\nif (match) {\nconst [_, number] = match;\nconst newName = `photo-${number.padStart(3, '0')}.jpg`;\nconst oldPath = path.join(directory, file);\nconst newPath = path.join(directory, newName);\n\n// Skip if the new name is the same as the old name\nif (oldPath !== newPath) {\nawait fs.rename(oldPath, newPath);\nconsole.log(`Renamed: ${file} - ${newName}`);\n}\n}\n}\n\nconsole.log('Batch rename completed');\n} catch (err) {\nconsole.error('Error during batch rename:', err);\n}\n}\n\nbatchRename();",
        "const fs = require('fs').promises;\nconst path = require('path');\nconst os = require('os');\n\nasync function updateFileAtomic(filePath, newContent) {\nconst tempPath = path.join(\nos.tmpdir(),\n`temp-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`\n);\n\ntry {\n// 1. Write to temp file\nawait fs.writeFile(tempPath, newContent, 'utf8');\n\n// 2. Verify the temp file was written correctly\nconst stats = await fs.stat(tempPath);\nif (stats.size === 0) {\nthrow new Error('Temporary file is empty');\n}\n\n// 3. Rename (atomic on most systems)\nawait fs.rename(tempPath, filePath);\n\nconsole.log('File updated atomically');\n} catch (err) {\n// Clean up temp file if it exists\ntry { await fs.unlink(tempPath); } catch (e) {}\n\nconsole.error('Atomic update failed:', err);\nthrow err;\n}\n}\n\n// Usage\nupdateFileAtomic('important-config.json', JSON.stringify({ key: 'value' }, null, 2));",
        "require()",
        "import",
        "fs/promises",
        "fs.createReadStream",
        "fs.createWriteStream",
        "fs.readFile()",
        "fs.promises",
        "util.promisify",
        "fs.writeFile()",
        "fs.appendFile()",
        "'w'",
        "'wx'",
        "'w+'",
        "'a'",
        "'ax'",
        "'r+'",
        "fs.unlink()",
        "fs.rename()"
      ]
    },
    {
      "title": "Node.js Path Module",
      "summary": "What is the Path Module?\nThe Path module is a built-in Node.js module that provides tools for handling and transforming file paths across different operating systems.\nSince Windows uses backslashes (\\) and POSIX systems (Linux, macOS) use forward slashes (/), the Path module helps write cross-platform code that works correctly on any system.\nKey Benefits:\nCross-platform path handling\nPath manipulation and normalization\nEasy file extension extraction\nPath resolution and joining\nWorking with relative and absolute paths\nUsing the Path Module\nThe Path module is a core module in Node.js, so no installation is needed.\nYou can import it using either CommonJS or ES modules syntax:\nBest Practice: For better tree-shaking and smaller bundle sizes, import only the methods you need when using ES modules.\nPath Module Methods\npath.basename()\nReturns the last portion of a path, similar to the Unix basename command.\n__dirname and __filename\nIn Node.js, __dirname and __filename are special variables available in CommonJS modules that provide the directory name and file name of the current module.\nBest Practices:\nUse path.join() or path.resolve() with __dirname to build file paths in CommonJS modules.\nFor ES modules, use import.meta.url with fileURLToPath and dirname to get the equivalent functionality.\nWhen using __dirname with path.join(), you can safely use forward slashes as they'll be normalized to the correct platform separator.\npath.extname()\nReturns the extension of a path, from the last occurrence of the . character to the end of the string.\npath.join()\nJoins all given path segments together using the platform-specific separator as a delimiter, then normalizes the resulting path.\nNote: path.join() is preferred over string concatenation with + as it handles different path separators across operating systems.\npath.resolve()\nResolves a sequence of paths or path segments into an absolute path, processing from right to left until an absolute path is constructed.\nTip: path.resolve() is commonly used with __dirname to create absolute paths relative to the current module's location.\npath.parse()\nReturns an object whose properties represent significant elements of the path.\nNote: The output of path.parse() can be passed to path.format() to reconstruct the path.\npath.format()\nReturns a path string from an object, which is the opposite of path.parse().\nNote: When using path.format(), if the dir and root properties are provided, root is ignored.\npath.normalize()\nNormalizes the given path, resolving .. and . segments and removing redundant separators.\nSecurity Note: While path.normalize() resolves .. sequences, it doesn't protect against directory traversal attacks. Always validate and sanitize user input when working with file paths.\npath.relative()\nReturns the relative path from the first path to the second path, or an empty string if the paths are the same.\nTip: path.relative() is particularly useful when you need to generate relative URLs or create portable paths between different locations in your project.\npath.isAbsolute()\nDetermines if the given path is an absolute path. An absolute path will always resolve to the same location, regardless of the working directory.\nNote: On Windows, paths starting with a drive letter followed by a colon (e.g., 'C:\\\\') are considered absolute, as are UNC paths (e.g., '\\\\\\\\server\\\\share').\nPath Properties\npath.sep\nProvides the platform-specific path segment separator.\nThis is a read-only property that returns the default path segment separator for the current operating system.\nBest Practice: Always use path.sep instead of hardcoding path separators to ensure cross-platform compatibility in your Node.js applications.\npath.delimiter\nProvides the platform-specific path delimiter used to separate paths in environment variables like PATH.\nNote: The path.delimiter is primarily used for working with environment variables like PATH or NODE_PATH that contain multiple paths.\npath.win32\nProvides access to Windows-specific path methods, allowing you to work with Windows-style paths regardless of the operating system you're running on.\nUse Case: The path.win32 object is particularly useful when your application needs to work with Windows-style paths on non-Windows platforms, such as when processing paths from a Windows system log or configuration file.\npath.posix\nProvides access to POSIX-compliant path methods, ensuring consistent forward-slash path handling across all platforms.\nUse Case: The path.posix object is particularly useful when you need to ensure consistent path handling for web applications, configuration files, or when working with APIs that expect POSIX-style paths, regardless of the underlying operating system.\nCommon Use Cases and Best Practices\nWorking with Module Paths\nUnderstanding and working with module paths is crucial for building maintainable Node.js applications. Here are some common patterns and best practices for path handling in real-world scenarios.\nIn ECMAScript modules (files with .mjs extension or when \"type\": \"module\" is set in package.json), __dirname and __filename are not available. Here's how to handle paths in ES modules:\nKey Points:\nUse import.meta.url to get the current module's URL\nConvert URL to file path with fileURLToPath() when needed\nFor path resolution, use the URL constructor with import.meta.url as the base\nContinue using path.join() and other path methods for cross-platform compatibility\nAdvanced Path Handling Patterns\nHere are some advanced patterns for working with paths in real-world applications.\nSecurity Considerations\nWhen working with file paths, security should always be a top priority. Here are some important security considerations and best practices:\nSecurity Best Practices:\nAlways validate and sanitize user-provided paths\nUse path.normalize() to prevent directory traversal\nImplement proper file type validation\nSet appropriate file permissions\nUse the principle of least privilege\nConsider using a security linter like eslint-plugin-security\nCross-Platform Development\nWhen developing cross-platform applications, it's important to handle path differences between operating systems correctly.\nCross-Platform Tips:\nAlways use path.join() instead of string concatenation\nUse path.sep when you need the platform-specific separator\nHandle case sensitivity differences (Windows is case-insensitive)\nBe aware of path length limitations on different platforms\nTest your application on all target platforms\nSummary\nThe Node.js Path module is an essential tool for working with file paths in a consistent and platform-independent manner.\nIt provides a rich set of utilities that help with:\nParsing and formatting file paths\nNormalizing and resolving paths\nWorking with relative and absolute paths\nManipulating path components\nWriting cross-platform code that works on any operating system\nBy using the Path module, you can write more robust and portable code that handles file paths correctly across different environments.",
      "examples": [
        "const path = require('path');\n\n// Destructure specific methods if needed\nconst { join, resolve, basename } = require('path');",
        "import path from 'path';\n\n// Or import specific methods\nimport { join, resolve, basename } from 'path';",
        "const path = require('path');\n\n// Get filename from a path\nconst filename = path.basename('/users/docs/file.txt');\nconsole.log(filename);\n\n// Get filename without extension\nconst filenameWithoutExt = path.basename('/users/docs/file.txt', '.txt');\nconsole.log(filenameWithoutExt);",
        "// CommonJS module (e.g., app.js)\nconst path = require('path');\n\n// Get the directory name of the current module\nconsole.log('Directory name:', __dirname);\n\n// Get the file name of the current module\nconsole.log('File name:', __filename);\n\n// Building paths relative to the current module\nconst configPath = path.join(__dirname, 'config', 'app-config.json');\nconsole.log('Config file path:', configPath);\n\n// Getting the directory name using path.dirname()\nconsole.log('Directory using path.dirname():', path.dirname(__filename));",
        "// ES Module (e.g., app.mjs or \"type\": \"module\" in package.json)\nimport { fileURLToPath } from 'url';\nimport { dirname } from 'path';\n\n// Get the current module's URL\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = dirname(__filename);\n\nconsole.log('ES Module file path:', __filename);\nconsole.log('ES Module directory:', __dirname);\n\n// Example with dynamic imports\nasync function loadConfig() {\nconst configPath = new URL('../config/app-config.json', import.meta.url);\nconst config = await import(configPath, { with: { type: 'json' } });\nreturn config;\n}",
        "const path = require('path');\n\nconst extension = path.extname('file.txt');\nconsole.log(extension);\n\nconsole.log(path.extname('index.html'));\nconsole.log(path.extname('index.coffee.md'));\nconsole.log(path.extname('index.'));\nconsole.log(path.extname('index'));\nconsole.log(path.extname('.index'));",
        "const path = require('path');\n\n// Join path segments\nconst fullPath = path.join('/users', 'docs', 'file.txt');\nconsole.log(fullPath); // Output depends on OS\n\n// Handle relative paths and navigation\nconsole.log(path.join('/users', '../system', './logs', 'file.txt'));\n\n// Handle multiple slashes\nconsole.log(path.join('users', '//docs', 'file.txt')); // Normalizes slashes",
        "const path = require('path');\n\n// 1. Resolve relative to current working directory\nconsole.log(path.resolve('file.txt'));\n\n// 2. Resolve with multiple segments\nconsole.log(path.resolve('/users', 'docs', 'file.txt'));\n\n// 3. Right-to-left processing\nconsole.log(path.resolve('/first', '/second', 'third')); // '/second/third'\n\n// 4. Using __dirname for module-relative paths\nconsole.log(path.resolve(__dirname, 'config', 'app.json'));",
        "const path = require('path');\n\n// Parse a file path\nconst pathInfo = path.parse('/users/docs/file.txt');\nconsole.log(pathInfo);\n/* Output on Unix/macOS:\n{\nroot: '/',\ndir: '/users/docs',\nbase: 'file.txt',\next: '.txt',\nname: 'file'\n}\n*/\n\n// Accessing parsed components\nconsole.log('Directory:', pathInfo.dir); // /users/docs\nconsole.log('Filename:', pathInfo.base); // file.txt\nconsole.log('Name only:', pathInfo.name); // file\nconsole.log('Extension:', pathInfo.ext); // .txt",
        "const path = require('path');\n\n// Method 1: Using dir and base\nconst pathString1 = path.format({\ndir: '/users/docs',\nbase: 'file.txt'\n});\nconsole.log(pathString1); // '/users/docs/file.txt'\n\n// Method 2: Using root, dir, name, and ext\nconst pathString2 = path.format({\nroot: '/',\ndir: '/users/docs',\nname: 'file',\next: '.txt'\n});\nconsole.log(pathString2); // '/users/docs/file.txt'\n\n// Practical example: Modify and reconstruct a path\nconst parsedPath = path.parse('/users/docs/old-file.txt');\nparsedPath.base = 'new-file.md';\nconst newPath = path.format(parsedPath);\nconsole.log(newPath); // '/users/docs/new-file.md'",
        "const path = require('path');\n\n// Resolve relative navigation\nconsole.log(path.normalize('/users/./docs/../data/file.txt')); // '/users/data/file.txt'\n\n// Handle multiple consecutive slashes\nconsole.log(path.normalize('/users//docs////file.txt')); // '/users/docs/file.txt'\n\n// Windows-style paths (automatically handled)\nconsole.log(path.normalize('C:\\\\users\\\\docs\\\\..\\\\file.txt')); // 'C:\\\\users\\\\file.txt'\n\n// Edge cases console.log(path.normalize('')); // '.'\nconsole.log(path.normalize('.')); // '.'\nconsole.log(path.normalize('..')); // '..'\nconsole.log(path.normalize('/..')); // '/'",
        "const path = require('path');\n\n// Basic relative path\nconsole.log(path.relative('/users/docs/file.txt', '/users/images/photo.jpg'));\n// Output: '../../images/photo.jpg'\n\n// Same directory\nconsole.log(path.relative('/users/docs/file1.txt', '/users/docs/file2.txt'));\n// Output: 'file2.txt'\n\n// Same file\nconsole.log(path.relative('/users/docs/file.txt', '/users/docs/file.txt'));\n// Output: ''\n\n// Different roots (Windows)\nconsole.log(path.relative('C:\\\\user\\\\test\\\\aaa', 'C:\\\\user\\\\impl\\\\bbb'));\n// Output: '..\\\\..\\\\impl\\\\bbb'\n\n// Practical example: Creating a relative path for web\nconst absolutePath = '/var/www/static/images/logo.png';\nconst webRoot = '/var/www/';\nconst webPath = path.relative(webRoot, absolutePath).replace(/\\\\/g, '/');\nconsole.log(webPath); // 'static/images/logo.png'",
        "const path = require('path');\n\n// POSIX (Unix/Linux/macOS)\nconsole.log(path.isAbsolute('/users/docs')); // true\nconsole.log(path.isAbsolute('users/docs')); // false\n\n// Windows\nconsole.log(path.isAbsolute('C:\\\\temp')); // true\nconsole.log(path.isAbsolute('temp')); // false\n\n// UNC paths (Windows network paths)\nconsole.log(path.isAbsolute('\\\\\\\\server\\\\share')); // true\n\n// Practical example: Ensure absolute path for config files\nfunction ensureAbsolute(configPath) {\nreturn path.isAbsolute(configPath)\n? configPath\n: path.resolve(process.cwd(), configPath);\n}\n\nconsole.log(ensureAbsolute('config.json')); // Resolves to absolute path\nconsole.log(ensureAbsolute('/etc/app/config.json')); // Already absolute",
        "const path = require('path');\n\n// Get the platform-specific separator\nconsole.log(`Path separator: ${JSON.stringify(path.sep)}`); // '\\\\' on Windows, '/' on POSIX\n\n// Building paths safely across platforms\nconst parts = ['users', 'docs', 'file.txt'];\nconst filePath = parts.join(path.sep);\nconsole.log('Built path:', filePath);\n\n// Splitting paths correctly\nconst pathToSplit = process.platform === 'win32'\n? 'C:\\\\Users\\\\docs\\\\file.txt'\n: '/users/docs/file.txt';\nconst pathParts = pathToSplit.split(path.sep);\nconsole.log('Split path:', pathParts);\n\n// Normalizing paths with the correct separator\nconst normalized = path.normalize(`users${path.sep}docs${path.sep}..${path.sep}file.txt`);\nconsole.log('Normalized path:', normalized);",
        "const path = require('path');\n\n// Get the platform-specific delimiter\nconsole.log(`Path delimiter: ${JSON.stringify(path.delimiter)}`); // ';' on Windows, ':' on POSIX\n\n// Working with PATH environment variable\nfunction findInPath(executable) {\nif (!process.env.PATH) return null;\n\n// Split PATH into directories\nconst pathDirs = process.env.PATH.split(path.delimiter);\n\n// Check each directory for the executable\nfor (const dir of pathDirs) {\ntry {\nconst fullPath = path.join(dir, executable);\nrequire('fs').accessSync(fullPath, require('fs').constants.X_OK);\nreturn fullPath;\n} catch (err) {\n// File not found or not executable\ncontinue;\n}\n}\nreturn null;\n}\n\n// Example: Find node executable in PATH\nconst nodePath = findInPath(process.platform === 'win32' ? 'node.exe' : 'node');\nconsole.log('Node.js path:', nodePath || 'Not found in PATH');",
        "const path = require('path');\n\n// Always use Windows-style path handling\nconst winPath = 'C:\\\\Users\\\\user\\\\Documents\\\\file.txt';\nconsole.log('Windows basename:', path.win32.basename(winPath));\nconsole.log('Windows dirname:', path.win32.dirname(winPath));\n\n// Normalize Windows paths\nconsole.log('Normalized path:', path.win32.normalize('C:\\\\\\\\temp\\\\\\\\foo\\\\..\\\\bar\\\\file.txt'));\n\n// Convert between forward and backward slashes\nconst mixedPath = 'C:/Users/User/Documents//file.txt';\nconsole.log('Normalized mixed slashes:', path.win32.normalize(mixedPath));\n\n// Working with UNC paths\nconst uncPath = '\\\\\\\\server\\\\share\\\\folder\\\\file.txt';\nconsole.log('UNC path components:', path.win32.parse(uncPath));",
        "const path = require('path');\n\n// Always use POSIX-style path handling\nconst posixPath = '/home/user/documents/file.txt';\nconsole.log('POSIX basename:', path.posix.basename(posixPath));\nconsole.log('POSIX dirname:', path.posix.dirname(posixPath));\n\n// Normalize POSIX paths\nconsole.log('Normalized path:', path.posix.normalize('/usr/local//bin/../lib/file.txt'));\n\n// Working with relative paths\nconsole.log('Relative path:', path.posix.relative('/data/test/aaa', '/data/impl/bbb'));\n\n// Joining paths with POSIX separators\nconst urlPath = ['static', 'images', 'logo.png'].join(path.posix.sep);\nconsole.log('URL path:', urlPath); // 'static/images/logo.png'",
        "const path = require('path');\nconst fs = require('fs/promises') ;\n\n// Current module's directory and file info\nconsole.log('Module directory:', __dirname);\nconsole.log('Module file path:', __filename);\n\n// Common path patterns\nconst paths = {\n// Configuration files relative to project root\nconfig: path.join(__dirname, '..', 'config', 'app.json'),\n\n// Logs directory (create if doesn't exist)\nlogs: path.join(__dirname, '..', 'logs'),\n\n// Public assets\npublic: path.join(__dirname, '..', 'public'),\n\n// Uploads directory with proper permissions\nuploads: path.join(__dirname, '..', 'uploads')\n};\n\n// Ensure directories exist\nasync function ensureDirectories() {\ntry {\nawait Promise.all([\nfs.mkdir(paths.logs, { recursive: true }),\nfs.mkdir(paths.public, { recursive: true }),\nfs.mkdir(paths.uploads, { recursive: true, mode: 0o755 })\n]);\nconsole.log('All directories ready');\n} catch (error) {\nconsole.error('Error creating directories:', error);\n}\n}\n\n// Example: Load configuration\nasync function loadConfig() {\ntry {\nconst configData = await fs.readFile(paths.config, 'utf8');\nreturn JSON.parse(configData);\n} catch (error) {\nconsole.error('Error loading config:', error.message);\nreturn {};\n}\n}\n\n// Example: Log to application log\nasync function logToFile(message) {\ntry {\nconst logFile = path.join(paths.logs, `${new Date().toISOString().split('T')[0]}.log`);\nconst logMessage = `[${new Date().toISOString()}] ${message}\\n`;\nawait fs.appendFile(logFile, logMessage, 'utf8');\n} catch (error) {\nconsole.error('Error writing to log:', error);\n}\n}\n\n// Initialize and run examples\n(async () => {\nawait ensureDirectories();\nconst config = await loadConfig();\nconsole.log('Loaded config:', config);\nawait logToFile('Application started');\n})();",
        "// ES Module (app.mjs or with \"type\": \"module\" in package.json)\nimport { fileURLToPath } from 'url';\nimport { dirname, join } from 'path';\nimport { promises as fs } from 'fs';\n\n// Get current module's directory and file path\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = dirname(__filename);\n\n// Utility function for path resolution in ES modules\nfunction resolvePath(relativePath) {\nreturn new URL(relativePath, import.meta.url).pathname;\n}\n\n// Example usage\nconst configPath = join(__dirname, '..', 'config', 'settings.json');\nconst assetPath = resolvePath('../assets/logo.png');\n\n// Dynamic imports with paths relative to current module\nasync function loadModule(modulePath) {\nconst fullPath = new URL(modulePath, import.meta.url);\nreturn import(fullPath);\n}",
        "const path = require('path');\nconst fs = require('fs/promises');\nconst os = require('os');\n\n// Path utility class\nclass PathUtils {\nstatic get tempDir() {\nreturn path.join(os.tmpdir(), 'myapp');\n}\n\nstatic get userHome() {\nreturn process.env.HOME || process.env.USERPROFILE || os.homedir();\n}\n\nstatic async ensureDirectory(dirPath) {\ntry {\nawait fs.mkdir(dirPath, { recursive: true, mode: 0o755 });\nreturn true;\n} catch (error) {\nif (error.code !== 'EEXIST') throw error;\nreturn false;\n}\n}\n\nstatic isSafePath(baseDir, targetPath) {\nconst normalizedBase = path.resolve(baseDir);\nconst normalizedTarget = path.resolve(targetPath);\nreturn normalizedTarget.startsWith(normalizedBase);\n}\n\nstatic getUniqueFilename(dir, filename) {\nconst { name, ext } = path.parse(filename);\nlet counter = 1;\nlet candidate = filename;\n\nwhile (fs.existsSync(path.join(dir, candidate))) {\ncandidate = `${name} (${counter++})${ext}`;\n}\nreturn candidate;\n}\n}\n\n// Example usage\n(async () => {\n// Ensure temp directory exists\nawait PathUtils.ensureDirectory(PathUtils.tempDir);\n\n// Safe file operations\nconst userUploads = path.join(PathUtils.userHome, 'uploads');\nconst safePath = path.join(userUploads, 'profile.jpg');\n\nif (PathUtils.isSafePath(userUploads, safePath)) {\nconsole.log('Path is safe for operations');\n} else {\nconsole.error('Potential path traversal attack detected!');\n}\n\n// Generate unique filename\nconst uniqueName = PathUtils.getUniqueFilename(\nuserUploads,\n'document.pdf'\n);\nconsole.log('Unique filename:', uniqueName);\n\n// Working with file extensions\nconst filePath = '/users/john/docs/report.pdf';\nconst fileInfo = {\nname: path.basename(filePath, path.extname(filePath)),\next: path.extname(filePath),\ndir: path.dirname(filePath)\n};\nconsole.log('File info:', fileInfo);\n})();",
        "const path = require('path');\nconst fs = require('fs').promises;\n\n// 1. Prevent directory traversal attacks\nfunction safeJoin(base, ...paths) {\nconst targetPath = path.join(base, ...paths);\nconst normalizedPath = path.normalize(targetPath);\n\n// Ensure the resulting path is still within the base directory\nif (!normalizedPath.startsWith(path.resolve(base))) {\nthrow new Error('Access denied: Path traversal detected');\n}\n\nreturn normalizedPath;\n}\n\n// 2. Validate file extensions\nconst ALLOWED_EXTENSIONS = new Set(['.jpg', '.jpeg', '.png', '.gif']);\n\nfunction hasValidExtension(filePath) {\nconst ext = path.extname(filePath).toLowerCase();\nreturn ALLOWED_EXTENSIONS.has(ext);\n}\n\n// 3. Safe file operations\nasync function safeReadFile(baseDir, relativePath) {\nconst safePath = safeJoin(baseDir, relativePath);\n\n// Additional security checks\nif (!hasValidExtension(safePath)) {\nthrow new Error('Invalid file type');\n}\n\nconst stats = await fs.stat(safePath);\nif (!stats.isFile()) {\nthrow new Error('Not a file');\n}\n\nreturn fs.readFile(safePath, 'utf8');\n}\n\n// Example usage\n(async () => {\nconst UPLOAD_DIR = path.join(process.cwd(), 'uploads');\nconst userInput = '../../../etc/passwd'; // Malicious input\n\ntry {\n// This will throw an error due to path traversal attempt\nconst content = await safeReadFile(UPLOAD_DIR, userInput);\nconsole.log('File content:', content);\n} catch (error) {\nconsole.error('Security error:', error.message);\n}\n})();",
        "const path = require('path');\n\n// Platform detection\nconst isWindows = process.platform === 'win32';\nconst isMac = process.platform === 'darwin';\nconst isLinux = process.platform === 'linux';\n\n// Platform-specific paths\nconst appDataDir = isWindows\n? path.join(process.env.APPDATA || path.join(process.env.USERPROFILE, 'AppData', 'Roaming'))\n: path.join(process.env.HOME || process.env.USERPROFILE, isMac ? 'Library/Application Support' : '.config');\n\n// Application-specific directories\nconst appName = 'MyApp';\nconst appDir = path.join(appDataDir, appName);\n\n// Ensure application directory exists\nrequire('fs').mkdirSync(appDir, { recursive: true });\n\n// Platform-specific temporary directory\nconst tempDir = path.join(require('os').tmpdir(), appName);\n\n// Example: Platform-agnostic path handling\nfunction getConfigPath() {\nconst configName = 'config.json';\n\n// Development vs production paths\nif (process.env.NODE_ENV === 'development') {\nreturn path.join(process.cwd(), 'config', configName);\n}\n\n// Production path\nreturn path.join(appDir, configName);\n}\n\nconsole.log('Application directory:', appDir);\nconsole.log('Temporary directory:', tempDir);\nconsole.log('Config file path:', getConfigPath());",
        "\\",
        "/",
        "basename",
        "__dirname",
        "__filename",
        "path.join()",
        "path.resolve()",
        "import.meta.url",
        "fileURLToPath",
        "dirname",
        ".",
        "+",
        "path.parse()",
        "path.format()",
        "dir",
        "root",
        "..",
        "path.normalize()",
        "path.relative()",
        "path.sep",
        "PATH",
        "path.delimiter",
        "NODE_PATH",
        "path.win32",
        "path.posix",
        ".mjs",
        "\"type\": \"module\"",
        "fileURLToPath()",
        "URL",
        "eslint-plugin-security"
      ]
    },
    {
      "title": "Node.js OS Module",
      "summary": "What is the OS Module?\nThe OS module in Node.js provides a powerful set of utilities for interacting with the underlying operating system.\nKey Features:\nRetrieve system information (CPU, memory, platform, etc.)\nAccess user and network information\nWork with file paths and directories in a cross-platform way\nMonitor system resources and performance\nHandle operating system signals and errors\nGetting Started with the OS Module\nImporting the Module\nThe OS module is a core Node.js module, so no installation is needed.\nYou can import it using CommonJS or ES modules syntax:\nBasic Usage Example\nHere's a quick example showing some common OS module methods:\nOS Module Reference\nNote: All OS module methods are synchronous and return results immediately.\nFor performance-critical applications, consider caching the results of methods that might be called frequently, such as os.cpus() or os.networkInterfaces().\nSystem Information\nos.arch()\nReturns the operating system CPU architecture for which the Node.js binary was compiled.\nos.platform()\nReturns a string identifying the operating system platform.\nos.type()\nReturns the operating system name as returned by uname on POSIX systems, or from the ver command on Windows.\nos.release()\nReturns the operating system release number.\nos.version()\nReturns a string identifying the kernel version. On Windows, this includes build information.\nUser and Environment\nos.userInfo()\nReturns information about the currently effective user.\nos.homedir()\nReturns the home directory of the current user.\nos.hostname()\nReturns the hostname of the operating system.\nos.tmpdir()\nReturns the operating system's default directory for temporary files.\nSystem Resources\nos.cpus()\nReturns an array of objects containing information about each logical CPU core.\nReturn the total and free system memory in bytes, respectively.\nos.loadavg()\nReturns an array containing the 1, 5, and 15 minute load averages.\nNetwork Information\nReturns an object containing network interfaces that have been assigned a network address.\nos.uptime()\nReturns the system uptime in seconds.\nos.networkInterfaces()\nReturns an object containing information about network interfaces.\nOS Constants and Utilities\nReturns an object containing commonly used operating system specific constants for error codes, process signals, and more.\nReturns the end-of-line marker for the current operating system.\nBest Practices\nAlways use path.join() instead of string concatenation for file paths to ensure cross-platform compatibility.\nWhen writing files, be aware of line endings. Use os.EOL for cross-platform compatibility.\nCheck available memory before performing memory-intensive operations.\nPractical Examples\nSystem Information Dashboard\nThis example creates a comprehensive system information report:\nResource Monitor\nThis example creates a basic resource monitor that updates every second:\nPlatform-Specific Behavior\nThis example demonstrates how to adapt your application's behavior based on the operating system:\nSummary\nThe Node.js OS module provides a powerful set of tools for interacting with the operating system.\nWith it, you can:\nRetrieve system information such as CPU architecture, platform, and release version\nMonitor memory usage and CPU performance\nAccess user information like home directory and username\nGet network interface information\nDetermine system uptime\nUse operating system-specific constants and end-of-line markers\nThese capabilities are particularly useful for:\nBuilding cross-platform applications that adapt to the host environment\nMonitoring system resources\nCreating diagnostic tools\nMaking path and file-related operations that work correctly across different operating systems\nOptimizing application performance based on available system resources\nBy using the OS module, you can make your Node.js applications more robust, efficient, and adaptable to different operating environments.",
      "examples": [
        "const os = require('os');",
        "import os from 'os';\n// or\nimport { arch, platform, cpus } from 'os';",
        "const os = require('os');\n\n// Basic system information\nconsole.log(`OS Platform: ${os.platform()}`);\nconsole.log(`OS Type: ${os.type()}`);\nconsole.log(`OS Release: ${os.release()}`);\nconsole.log(`CPU Architecture: ${os.arch()}`);\nconsole.log(`Hostname: ${os.hostname()}`);\n\n// Memory information\nconst totalMemGB = (os.totalmem() / (1024 * 1024 * 1024)).toFixed(2);\nconst freeMemGB = (os.freemem() / (1024 * 1024 * 1024)).toFixed(2);\nconsole.log(`Memory: ${freeMemGB}GB free of ${totalMemGB}GB`);\n\n// User information\nconst userInfo = os.userInfo();\nconsole.log(`Current User: ${userInfo.username}`);\nconsole.log(`Home Directory: ${os.homedir()}`);",
        "const os = require('os');\n\n// Get CPU architecture\nconsole.log(`CPU Architecture: ${os.arch()}`);\n\n// Common values:\n// - 'x64' for 64-bit systems\n// - 'arm' for ARM processors\n// - 'arm64' for 64-bit ARM\n// - 'ia32' for 32-bit x86\n// - 'mips' for MIPS processors",
        "const os = require('os');\n\n// Get platform information\nconst platform = os.platform();\nconsole.log(`Platform: ${platform}`);\n\n// Common values:\n// - 'darwin' for macOS\n// - 'win32' for Windows (both 32-bit and 64-bit)\n// - 'linux' for Linux\n// - 'freebsd' for FreeBSD\n// - 'openbsd' for OpenBSD",
        "const os = require('os');\n\n// Get OS type\nconsole.log(`OS Type: ${os.type()}`);\n\n// Examples:\n// - 'Linux' on Linux\n// - 'Darwin' on macOS\n// - 'Windows_NT' on Windows",
        "const os = require('os');\n\n// Get OS release information\nconsole.log(`OS Release: ${os.release()}`);\n\n// Examples:\n// - '10.0.19044' on Windows 10\n// - '21.6.0' on macOS Monterey\n// - '5.15.0-46-generic' on Ubuntu",
        "const os = require('os');\n\n// Get kernel version\nconsole.log(`Kernel Version: ${os.version()}`);\n\n// Example output:\n// - Windows: 'Windows 10 Enterprise 10.0.19044'\n// - Linux: '#49-Ubuntu SMP Tue Aug 2 08:49:28 UTC 2022'\n// - macOS: 'Darwin Kernel Version 21.6.0: ...'",
        "const os = require('os');\n\n// Get current user information\nconst user = os.userInfo();\nconsole.log('User Information:');\nconsole.log(`- Username: ${user.username}`);\nconsole.log(`- User ID: ${user.uid}`);\nconsole.log(`- Group ID: ${user.gid}`);\nconsole.log(`- Home Directory: ${user.homedir}`);\n\n// On Windows, you can also get the user's domain\nif (os.platform() === 'win32') {\nconsole.log(`- Domain: ${user.domain || 'N/A'}`);\n}\n\n// Note: user.shell is only available on POSIX platforms\nif (user.shell) {\nconsole.log(`- Default Shell: ${user.shell}`);\n}",
        "const os = require('os');\nconst path = require('path');\n\n// Get the home directory\nconst homeDir = os.homedir();\nconsole.log(`Home Directory: ${homeDir}`);\n\n// Example: Create a path to a config file in the user's home directory\nconst configPath = path.join(homeDir, '.myapp', 'config.json');\nconsole.log(`Config file will be saved to: ${configPath}`);",
        "const os = require('os');\n\n// Get the system hostname\nconst hostname = os.hostname();\nconsole.log(`Hostname: ${hostname}`);\n\n// Example: Use hostname in logging or configuration\nconsole.log(`Server started on ${hostname} at ${new Date().toISOString()}`);",
        "const os = require('os');\n\n// Get the system default temp dir\nconsole.log(`Temporary Directory: ${os.tmpdir()}`);",
        "const os = require('os');\n\n// Get CPU information\nconst cpus = os.cpus();\nconsole.log(`Number of CPU Cores: ${cpus.length}`);\n\n// Display information about each CPU core\ncpus.forEach((cpu, index) => {\nconsole.log(`\\nCPU Core ${index + 1}:`);\nconsole.log(`- Model: ${cpu.model}`);\nconsole.log(`- Speed: ${cpu.speed} MHz`);\nconsole.log('- Times (ms):', {     user: cpu.times.user,\nnice: cpu.times.nice,\nsys: cpu.times.sys,\nidle: cpu.times.idle,\nirq: cpu.times.irq\n});\n});\n// Calculate total CPU usage (example, requires two measurements)\nfunction calculateCpuUsage(prevCpus) {\nconst currentCpus = os.cpus();\nconst usage = [];\n\nfor (let i = 0; i < currentCpus.length; i++) {\nconst current = currentCpus[i];\nconst prev = prevCpus ? prevCpus[i] : { times: { user: 0, nice: 0, sys: 0, idle: 0, irq: 0 } };\n\nconst prevIdle = prev.times.idle;\nconst idle = current.times.idle - prevIdle;\n\nlet total = 0;\nfor (const type in current.times) {\ntotal += current.times[type] - (prev.times[type] || 0);\n}\n\nconst usagePercent = ((1 - idle / total) * 100).toFixed(1);\nusage.push(parseFloat(usagePercent));\n}\n\nreturn {\nperCore: usage,\naverage: (usage.reduce((a, b) => a + b, 0) / usage.length).toFixed(1),\ncpus: currentCpus\n};\n}\n\n// Example usage of CPU usage calculation\nconsole.log('\\nCPU Usage (requires two measurements):');\nconst firstMeasure = os.cpus();\n\n// Simulate some CPU work\nfor (let i = 0; i < 1000000000; i++) {}\nconst usage = calculateCpuUsage(firstMeasure);\nconsole.log(`Average CPU Usage: ${usage.average}%`);",
        "const os = require('os');\n\n// Format bytes to human-readable format\nfunction formatBytes(bytes, decimals = 2) {\nif (bytes === 0) return '0 Bytes';\nconst k = 1024;\nconst dm = decimals < 0 ? 0 : decimals;\nconst sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'];\nconst i = Math.floor(Math.log(bytes) / Math.log(k));\nreturn parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + ' ' + sizes[i];\n}\n\n// Get memory information\nconst totalMem = os.totalmem();\nconst freeMem = os.freemem();\nconst usedMem = totalMem - freeMem;\nconst usagePercent = ((usedMem / totalMem) * 100).toFixed(2);\n\nconsole.log('Memory Information:');\nconsole.log(`- Total Memory: ${formatBytes(totalMem)}`);\nconsole.log(`- Free Memory: ${formatBytes(freeMem)} (${((freeMem / totalMem) * 100).toFixed(2)}%)`);\nconsole.log(`- Used Memory: ${formatBytes(usedMem)} (${usagePercent}%)`);\n\n// Example: Check if there's enough free memory\nconst MIN_FREE_MEMORY = 200 * 1024 * 1024; // 200MB\nif (freeMem < MIN_FREE_MEMORY) {\nconsole.warn('Warning: Low on memory!');\n} else {\nconsole.log('System has sufficient memory available');\n}",
        "const os = require('os');\n\n// Get load averages\nconst loadAverages = os.loadavg();\nconsole.log('System Load Averages (1, 5, 15 min):', loadAverages);\n\n// On Linux/Unix, load average represents the average system load over the last 1, 5, and 15 minutes\n// The values represent the number of processes in the system run queue\nconst [oneMin, fiveMin, fifteenMin] = loadAverages;\nconst cpuCount = os.cpus().length;\n\nconsole.log(`1-minute load average: ${oneMin.toFixed(2)} (${(oneMin / cpuCount * 100).toFixed(1)}% of ${cpuCount} cores)`);\nconsole.log(`5-minute load average: ${fiveMin.toFixed(2)}`);\nconsole.log(`15-minute load average: ${fifteenMin.toFixed(2)}`);\n\n// Example: Check if system is under heavy load\nconst isSystemOverloaded = oneMin > cpuCount * 1.5;\nif (isSystemOverloaded) {\nconsole.warn('Warning: System is under heavy load!');\n} else {\nconsole.log('System load is normal');\n}",
        "const os = require('os');\n\n// Get network interfaces information\nconst networkInterfaces = os.networkInterfaces();\n\nconsole.log('Network Interfaces:');\n\n// Iterate over each network interface\nObject.entries(networkInterfaces).forEach(([name, addresses]) => {\nconsole.log(`\\nInterface: ${name}`);\naddresses.forEach((address) => {\nconsole.log(`- Family: ${address.family}`);\nconsole.log(` Address: ${address.address}`);\nconsole.log(` Netmask: ${address.netmask}`);\nconsole.log(` MAC: ${address.mac || 'N/A'}`);\nconsole.log(` Internal: ${address.internal}`);\n});\n});\n\n// Example: Find the first non-internal IPv4 address\nfunction getLocalIpAddress() {\nconst interfaces = os.networkInterfaces();\nfor (const name of Object.keys(interfaces)) {\nfor (const iface of interfaces[name]) {\nif (iface.family === 'IPv4' && !iface.internal) {\nreturn iface.address;\n}\n}\n}\nreturn '127.0.0.1'; // Fallback to localhost\n}\n\nconst localIp = getLocalIpAddress();\nconsole.log(`\\nLocal IP Address: ${localIp}`);",
        "const os = require('os');\n\n// Get system uptime in seconds\nconst uptime = os.uptime();\nconsole.log(`System Uptime: ${uptime} seconds`);\n\n// Format uptime in a more readable way\nconst uptimeDays = Math.floor(uptime / (60 * 60 * 24));\nconst uptimeHours = Math.floor((uptime % (60 * 60 * 24)) / (60 * 60));\nconst uptimeMinutes = Math.floor((uptime % (60 * 60)) / 60);\nconst uptimeSeconds = Math.floor(uptime % 60);\n\nconsole.log(`System has been running for: ${uptimeDays} days, ${uptimeHours} hours, ${uptimeMinutes} minutes, ${uptimeSeconds} seconds`);",
        "const os = require('os');\n\n// Get network interfaces\nconst networkInterfaces = os.networkInterfaces();\nconsole.log('Network Interfaces:');\nconsole.log(JSON.stringify(networkInterfaces, null, 2));\n\n// Iterate through network interfaces\nObject.keys(networkInterfaces).forEach((interfaceName) => {\nconsole.log(`\\nInterface: ${interfaceName}`);\n\nnetworkInterfaces[interfaceName].forEach((interface) => {\nconsole.log(` Address Family: ${interface.family}`);\nconsole.log(` IP Address: ${interface.address}`);\nconsole.log(` Netmask: ${interface.netmask}`);\nif (interface.mac) {\nconsole.log(` MAC Address: ${interface.mac}`);\n}\nconsole.log(` Internal: ${interface.internal ? 'Yes' : 'No'}`);\n});\n});\n\n// Function to get primary IPv4 address (non-internal)\nfunction getPrimaryIPv4Address() {\nconst interfaces = os.networkInterfaces();\nfor (const name of Object.keys(interfaces)) {\nfor (const interface of interfaces[name]) {\n// Skip internal and non-IPv4 addresses\nif (!interface.internal && interface.family === 'IPv4') {\nreturn interface.address;\n}\n}\n}\nreturn 'No IPv4 address found';\n}\n\nconsole.log(`\\nPrimary IPv4 Address: ${getPrimaryIPv4Address()}`);",
        "const os = require('os');\n\n// Get all signal constants\nconsole.log('Signal Constants:', os.constants.signals);\n\n// Example: Handle common signals\nprocess.on('SIGINT', () => {\nconsole.log('Received SIGINT. Performing cleanup...');\nprocess.exit(0);\n});\n\nprocess.on('SIGTERM', () => {\nconsole.log('Received SIGTERM. Shutting down gracefully...');\nprocess.exit(0);\n});\n\nconsole.log('Process is running. Press Ctrl+C to exit.');",
        "const os = require('os');\nconst fs = require('fs');\n\n// Get the end-of-line marker for the current OS\nconsole.log('End of Line character:', JSON.stringify(os.EOL));\n\n// Example: Write a file with platform-specific line endings\nconst lines = [\n'First line',\n'Second line',\n'Third line'\n];\n\n// Join lines with the correct EOL character\nconst content = lines.join(os.EOL);\nfs.writeFileSync('output.txt', content);\nconsole.log('File written with platform-appropriate line endings');",
        "// Good\nconst filePath = path.join(os.homedir(), 'app', 'config.json');\n\n// Bad (won't work on Windows)\nconst badPath = `${os.homedir()}/app/config.json`;",
        "const content = `First Line${os.EOL}Second Line${os.EOL}Third Line`;\nfs.writeFileSync('output.txt', content, 'utf8');",
        "const MIN_FREE_MEMORY_MB = 500; // 500MB minimum free memory\n\nfunction canPerformMemoryIntensiveOperation() {\nconst freeMemMB = os.freemem() / (1024 * 1024);\nreturn freeMemMB > MIN_FREE_MEMORY_MB;\n}\n\nif (!canPerformMemoryIntensiveOperation()) {\nconsole.warn('Not enough free memory to perform this operation');\n// Handle the error appropriately\n}",
        "const os = require('os');\n\nfunction getSystemInfo() {\nconst info = {\nos: {\ntype: os.type(),\nplatform: os.platform(),\narchitecture: os.arch(),\nrelease: os.release(),\nhostname: os.hostname(),\nuptime: formatUptime(os.uptime())\n},\nuser: {\nusername: os.userInfo().username,\nhomedir: os.homedir(),\ntempdir: os.tmpdir()\n},\nmemory: {\ntotal: formatBytes(os.totalmem()),\nfree: formatBytes(os.freemem()),\nusage: `${((1 - os.freemem() / os.totalmem()) * 100).toFixed(2)}%`\n},\ncpu: {\nmodel: os.cpus()[0].model,\ncores: os.cpus().length,\nspeed: `${os.cpus()[0].speed} MHz`\n}\n};\n\nreturn info;\n}\n\nfunction formatUptime(seconds) {\nconst days = Math.floor(seconds / (60 * 60 * 24));\nconst hours = Math.floor((seconds % (60 * 60 * 24)) / (60 * 60));\nconst minutes = Math.floor((seconds % (60 * 60)) / 60);\nconst secs = Math.floor(seconds % 60);\n\nreturn `${days}d ${hours}h ${minutes}m ${secs}s`;\n}\n\nfunction formatBytes(bytes) {\nconst sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];\nif (bytes === 0) return '0 Bytes';\nconst i = parseInt(Math.floor(Math.log(bytes) / Math.log(1024)));\nreturn `${(bytes / Math.pow(1024, i)).toFixed(2)} ${sizes[i]}`;\n}\n\n// Display the system information dashboard\nconst systemInfo = getSystemInfo();\nconsole.log('======= SYSTEM INFORMATION DASHBOARD =======');\nconsole.log(JSON.stringify(systemInfo, null, 2));\n\n// Display in a more formatted way\nconsole.log('\\n======= FORMATTED SYSTEM INFORMATION =======');\nconsole.log(`OS: ${systemInfo.os.type} (${systemInfo.os.platform} ${systemInfo.os.architecture})`);\nconsole.log(`Version: ${systemInfo.os.release}`);\nconsole.log(`Hostname: ${systemInfo.os.hostname}`);\nconsole.log(`Uptime: ${systemInfo.os.uptime}`);\nconsole.log(`User: ${systemInfo.user.username}`);\nconsole.log(`Home Directory: ${systemInfo.user.homedir}`);\nconsole.log(`CPU: ${systemInfo.cpu.model}`);\nconsole.log(`Cores: ${systemInfo.cpu.cores}`);\nconsole.log(`Speed: ${systemInfo.cpu.speed}`);\nconsole.log(`Memory Total: ${systemInfo.memory.total}`);\nconsole.log(`Memory Free: ${systemInfo.memory.free}`);\nconsole.log(`Memory Usage: ${systemInfo.memory.usage}`);",
        "const os = require('os');\n\nfunction monitorResources() {\nconsole.clear(); // Clear console for a cleaner display\n\nconst now = new Date().toLocaleTimeString();\nconsole.log(`======= RESOURCE MONITOR (${now}) =======`);\n\n// CPU Usage\nconst cpus = os.cpus();\nconsole.log(`\\nCPU Cores: ${cpus.length}`);\n\n// Calculate CPU usage (this is approximate since we need two measurements)\nconst cpuUsage = cpus.map((cpu, index) => {\nconst total = Object.values(cpu.times).reduce((acc, tv) => acc + tv, 0);\nconst idle = cpu.times.idle;\nconst usage = ((total - idle) / total * 100).toFixed(1);\nreturn `Core ${index}: ${usage}% used`;\n});\n\nconsole.log(cpuUsage.join('\\n'));\n\n// Memory Usage\nconst totalMem = os.totalmem();\nconst freeMem = os.freemem();\nconst usedMem = totalMem - freeMem;\n\nconsole.log('\\nMemory Usage:');\nconsole.log(`Total: ${formatBytes(totalMem)}`);\nconsole.log(`Used: ${formatBytes(usedMem)} (${(usedMem / totalMem * 100).toFixed(1)}%)`);\nconsole.log(`Free: ${formatBytes(freeMem)} (${(freeMem / totalMem * 100).toFixed(1)}%)`);\n\n// System Uptime\nconsole.log(`\\nSystem Uptime: ${formatUptime(os.uptime())}`);\n\n// Process Info\nconsole.log('\\nProcess Information:');\nconsole.log(`PID: ${process.pid}`);\nconsole.log(`Memory Usage: ${formatBytes(process.memoryUsage().rss)}`);\nconsole.log(`User: ${os.userInfo().username}`);\n}\n\nfunction formatBytes(bytes) {\nconst sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];\nif (bytes === 0) return '0 Bytes';\nconst i = parseInt(Math.floor(Math.log(bytes) / Math.log(1024)));\nreturn `${(bytes / Math.pow(1024, i)).toFixed(2)} ${sizes[i]}`;\n}\n\nfunction formatUptime(seconds) {\nconst days = Math.floor(seconds / (60 * 60 * 24));\nconst hours = Math.floor((seconds % (60 * 60 * 24)) / (60 * 60));\nconst minutes = Math.floor((seconds % (60 * 60)) / 60);\nconst secs = Math.floor(seconds % 60);\n\nreturn `${days}d ${hours}h ${minutes}m ${secs}s`;\n}\n\n// Initial display\nmonitorResources();\n\n// Update every second (note: in a real application, you might not want\n// to update this frequently as it uses CPU resources)\nconst intervalId = setInterval(monitorResources, 1000);\n\n// In a real application, you would need to handle cleanup:\n// clearInterval(intervalId);\n\n// For this example, we'll run for 10 seconds then stop\nconsole.log('Monitor will run for 10 seconds...');\nsetTimeout(() => {\nclearInterval(intervalId);\nconsole.log('\\nResource monitoring stopped.');\n}, 10000);",
        "const os = require('os');\nconst fs = require('fs');\nconst path = require('path');\n\n// Function to determine a good location for app data based on the OS\nfunction getAppDataPath(appName) {\nconst platform = os.platform();\n\nlet appDataPath;\n\nswitch (platform) {\ncase 'win32': // Windows\nappDataPath = path.join(process.env.APPDATA || '', appName);\nbreak;\ncase 'darwin': // macOS\nappDataPath = path.join(os.homedir(), 'Library', 'Application Support', appName);\nbreak;\ncase 'linux': // Linux\nappDataPath = path.join(os.homedir(), '.config', appName);\nbreak;\ndefault: // Fallback for other platforms\nappDataPath = path.join(os.homedir(), `.${appName}`);\n}\n\nreturn appDataPath;\n}\n\n// Function to get appropriate command based on OS\nfunction getOpenCommand() {\nconst platform = os.platform();\n\nswitch (platform) {\ncase 'win32': // Windows\nreturn 'start';\ncase 'darwin': // macOS\nreturn 'open';\ndefault: // Linux and others\nreturn 'xdg-open';\n}\n}\n\n// Example usage\nconst appName = 'myapp';\nconst appDataPath = getAppDataPath(appName);\nconst openCommand = getOpenCommand();\n\nconsole.log(`OS Platform: ${os.platform()}`);\nconsole.log(`OS Type: ${os.type()}`);\nconsole.log(`Recommended App Data Path: ${appDataPath}`);\nconsole.log(`Open Command: ${openCommand}`);\n\n// Example of platform-specific behavior\nconsole.log('\\nPlatform-Specific Actions:');\n\nif (os.platform() === 'win32') {\nconsole.log('- Using Windows-specific registry functions');\nconsole.log('- Setting up Windows service');\n} else if (os.platform() === 'darwin') {\nconsole.log('- Using macOS keychain for secure storage');\nconsole.log('- Setting up launchd agent');\n} else if (os.platform() === 'linux') {\nconsole.log('- Using Linux systemd for service management');\nconsole.log('- Setting up dbus integration');\n}\n\n// Example of checking for available memory and adjusting behavior\nconst availableMemGB = os.freemem() / (1024 * 1024 * 1024);\nconsole.log(`\\nAvailable Memory: ${availableMemGB.toFixed(2)} GB`);\n\nif (availableMemGB < 0.5) {\nconsole.log('Low memory mode activated: reducing cache size and disabling features');\n} else if (availableMemGB > 4) {\nconsole.log('High memory mode activated: increasing cache size and enabling all features');\n} else {\nconsole.log('Standard memory mode activated: using default settings');\n}\n\n// Example of CPU core detection for parallel processing\nconst cpuCount = os.cpus().length;\nconsole.log(`\\nCPU Cores: ${cpuCount}`);\n\nconst recommendedWorkers = Math.max(1, cpuCount - 1); // Leave one core for the system\nconsole.log(`Recommended worker processes: ${recommendedWorkers}`);",
        "os.cpus()",
        "os.networkInterfaces()",
        "uname",
        "ver",
        "path.join()",
        "os.EOL"
      ]
    },
    {
      "title": "Node.js URL Module",
      "summary": "The Built-in URL Module\nThe URL module provides utilities for URL resolution and parsing.\nIt can be used to split up a web address into readable parts, construct URLs, and handle different URL components.\nGetting Started\nTo include the URL module, use the require() method.\nIn modern Node.js (v10.0.0+), you can use either the legacy API or the newer URL class (WHATWG URL API):\nExampleGet your own Node.js Server\nParse an address with the url.parse() method, and it will return a URL object with each part of the address as properties:\nExample\nSplit a web address into readable parts:\nURL Parsing and Formatting\nURL Object Properties\nWhen you parse a URL, you get a URL object with the following properties:\nhref: The full URL that was parsed\nprotocol: The protocol scheme (e.g., 'http:')\nhost: The full host portion (e.g., 'example.com:8080')\nhostname: The hostname portion (e.g., 'example.com')\nport: The port number if specified\npathname: The path section of the URL\nsearch: The query string including the leading ?\nquery: Either the query string without the ?, or a parsed query object\nhash: The fragment identifier including the #\nLegacy API vs WHATWG URL API\nExample\nURLSearchParams API\nThe URLSearchParams API provides utility methods to work with the query string of a URL:\nExample\nNode.js File Server\nNow we know how to parse the query string, and in a previous chapter we learned how to make Node.js behave as a file server.\nLet us combine the two, and serve the file requested by the client.\nCreate two html files and save them in the same folder as your node.js files.\nsummer.html\nwinter.html\nREMOVE ADS\nCreate a Node.js file that opens the requested file and returns the content to the client. If anything goes wrong, throw a 404 error:\ndemo_fileserver.js:\nRemember to initiate the file:\nInitiate demo_fileserver.js:\nIf you have followed the same steps on your computer, you should see two different results when opening these two addresses:\nhttp://localhost:8080/summer.html\nWill produce this result:\nhttp://localhost:8080/winter.html\nWill produce this result:\nBest Practices\n1. Always Validate and Sanitize URLs\nExample\n2. Constructing URLs Safely\nExample\n3. Handling Query Parameters\nExample",
      "examples": [
        "// Using the legacy API\nconst url = require('url');\n\n// Using the modern URL class (WHATWG API)\nconst { URL } = require('url');",
        "let url = require('url');",
        "let url = require('url');\nlet adr = 'http://localhost:8080/default.htm?year=2017&month=february';\nlet q = url.parse(adr, true);\n\nconsole.log(q.host);\nconsole.log(q.pathname);\nconsole.log(q.search);\n\nlet qdata = q.query;\nconsole.log(qdata.month);",
        "const { URL } = require('url');\n\n// Using the WHATWG URL API (recommended for new code)\nconst myURL = new URL('https://example.org:8080/p/a/t/h?query=string#hash');\nconsole.log(myURL.hostname); // 'example.org'\nconsole.log(myURL.pathname); // '/p/a/t/h'\nconsole.log(myURL.searchParams.get('query')); // 'string'\n\n// Using the legacy API\nconst parsedUrl = require('url').parse('https://example.org:8080/p/a/t/h?query=string#hash');\nconsole.log(parsedUrl.host); // 'example.org:8080'\nconsole.log(parsedUrl.query); // 'query=string'",
        "const { URL, URLSearchParams } = require('url');\n\nconst myURL = new URL('https://example.com/?name=Kai&age=30');\nconst params = new URLSearchParams(myURL.search);\n\n// Get a parameter\nconsole.log(params.get('name'));\n\n// Add a parameter\nparams.append('city', 'Stavanger');\n// Delete a parameter\nparams.delete('age');\n// Convert to string\nconsole.log(params.toString());",
        "<!DOCTYPE html>\n<html>\n<body>\n<h1>Summer</h1>\n<p>I love the sun!</p>\n</body>\n</html>",
        "<!DOCTYPE html>\n<html>\n<body>\n<h1>Winter</h1>\n<p>I love the snow!</p>\n</body>\n</html>",
        "let http = require('http');\nlet url = require('url');\nlet fs = require('fs');\n\nhttp.createServer(function (req, res) {\nlet q = url.parse(req.url, true);\nlet filename = \".\" + q.pathname;\nfs.readFile(filename, function(err, data) {\nif (err) {\nres.writeHead(404, {'Content-Type': 'text/html'});\nreturn res.end(\"404 Not Found\");\n}\n\nres.writeHead(200, {'Content-Type': 'text/html'});\nres.write(data);\nreturn res.end();\n});\n}).listen(8080);",
        "C:\\Users\\Your Name>node demo_fileserver.js",
        "<h1>Summer</h1>\n<p>I love the sun!</p>",
        "<h1>Winter</h1>\n<p>I love the snow!</p>",
        "function isValidHttpUrl(string) {\ntry {\nconst url = new URL(string);\nreturn url.protocol === 'http:' || url.protocol === 'https:';\n} catch (err) {\nreturn false;\n}\n}\n\nconsole.log(isValidHttpUrl('https://example.com')); // true\nconsole.log(isValidHttpUrl('ftp://example.com')); // false",
        "const { URL } = require('url');\n\n// Safe way to construct URLs\nfunction createProfileUrl(domain, username) {\nreturn new URL(`/users/${encodeURIComponent(username)}`, domain).href;\n}\n\nconsole.log(createProfileUrl('https://example.com', 'johndoe'));\n// 'https://example.com/users/johndoe'",
        "const { URL } = require('url');\n\n// Parse URL with query parameters\nconst url = new URL('https://example.com/search?q=node.js&lang=en');\n\n// Get all parameters\nconsole.log(url.searchParams.toString()); // 'q=node.js&lang=en'\n\n// Get specific parameter\nconsole.log(url.searchParams.get('q')); // 'node.js'\n\n// Check if parameter exists\nconsole.log(url.searchParams.has('lang')); // true\n\n// Add new parameter\nurl.searchParams.append('page', '2');\nconsole.log(url.href);\n// 'https://example.com/search?q=node.js&lang=en&page=2'",
        "require()",
        "URL",
        "url.parse()",
        "href",
        "protocol",
        "host",
        "hostname",
        "port",
        "pathname",
        "search",
        "query",
        "hash",
        "URLSearchParams"
      ]
    },
    {
      "title": "Node.js Events",
      "summary": "Core Concepts of Events in Node.js\nEvery action on a computer is an event, like when a connection is made or a file is opened.\nObjects in Node.js can fire events, like the readStream object fires events when opening and closing a file:\nExampleGet your own Node.js Server\nGetting Started with Events in Node.js\nNode.js uses an event-driven architecture where objects called \"emitters\" emit named events that cause function objects (\"listeners\") to be called.\nBasic Example\nEventEmitter Class\nThe EventEmitter class is fundamental to Node.js's event-driven architecture.\nIt provides the ability to create and handle custom events.\nCreating an Event Emitter\nTo use the EventEmitter, you need to create an instance of it:\nREMOVE ADS\nThe EventEmitter Object\nYou can assign event handlers to your own events with the EventEmitter object.\nIn the example below we have created a function that will be executed when a \"scream\" event is fired.\nTo fire an event, use the emit() method.\nExample\nCommon EventEmitter Patterns\n1. Passing Arguments to Event Handlers\n2. Handling Events Only Once\n3. Error Handling\nBest Practices\n1. Always Handle Errors\n2. Use Named Functions for Better Stack Traces\n3. Clean Up Listeners",
      "examples": [
        "let fs = require('fs');\nlet rs = fs.createReadStream('./demofile.txt');\nrs.on('open', function () {\nconsole.log('The file is open');\n});",
        "// Import the events module\nconst EventEmitter = require('events');\n\n// Create an event emitter instance\nconst myEmitter = new EventEmitter();\n\n// Register an event listener\nmyEmitter.on('greet', () => {\nconsole.log('Hello there!');\n});\n\n// Emit the event\nmyEmitter.emit('greet'); // Outputs: Hello there!",
        "let events = require('events');\nlet eventEmitter = new events.EventEmitter();",
        "let events = require('events');\nlet eventEmitter = new events.EventEmitter();\n\n//Create an event handler:\nlet myEventHandler = function () {\nconsole.log('I hear a scream!');\n}\n\n//Assign the event handler to an event:\neventEmitter.on('scream', myEventHandler);\n\n//Fire the 'scream' event:\neventEmitter.emit('scream');",
        "const EventEmitter = require('events');\nconst emitter = new EventEmitter();\n\n// Emit event with arguments\nemitter.on('userJoined', (username, userId) => {\nconsole.log(`${username} (${userId}) has joined the chat`);\n});\n\nemitter.emit('userJoined', 'JohnDoe', 42);\n// Outputs: JohnDoe (42) has joined the chat",
        "const EventEmitter = require('events');\nconst emitter = new EventEmitter();\n\n// This listener will be called only once\nemitter.once('connection', () => {\nconsole.log('First connection established');\n});\n\nemitter.emit('connection'); // This will trigger the listener\nemitter.emit('connection'); // This won't trigger the listener again",
        "const EventEmitter = require('events');\nconst emitter = new EventEmitter();\n\n// Always handle 'error' events\nemitter.on('error', (err) => {\nconsole.error('An error occurred:', err.message);\n});\n\n// This will trigger the error handler\nemitter.emit('error', new Error('Something went wrong'));",
        "// Good practice: Always listen for 'error' events\nmyEmitter.on('error', (err) => {\nconsole.error('Error in event emitter:', err);\n});",
        "// Instead of anonymous functions\nfunction handleData(data) {\nconsole.log('Received data:', data);\n}\n\nmyEmitter.on('data', handleData);",
        "// Add a listener\nconst listener = () => console.log('Event occurred');\nmyEmitter.on('event', listener);\n\n// Later, remove the listener when no longer needed\nmyEmitter.off('event', listener);",
        "EventEmitter",
        "emit()"
      ]
    },
    {
      "title": "Node.js Streams",
      "summary": "What are Streams?\nIn Node.js, streams are collections of data, which might not be available in full at once and don't have to fit in memory.\nThink of them as conveyor belts that move data from one place to another, allowing you to work with each piece as it arrives rather than waiting for the whole dataset.\nStreams are one of Node.js's most powerful features and are used extensively in:\nFile system operations (reading/writing files)\nHTTP requests and responses\nData compression and decompression\nDatabase operations\nReal-time data processing\nGetting Started with Streams\nStreams are one of the fundamental concepts in Node.js for handling data efficiently.\nThey allow you to process data in chunks as it becomes available, rather than loading everything into memory at once.\nBasic Stream ExampleGet your own Node.js Server\nWhy Use Streams?\nThere are several advantages to using streams:\nMemory Efficiency: Process large files without loading them entirely into memory\nTime Efficiency: Start processing data as soon as you have it, instead of waiting for all the data\nComposability: Build powerful data pipelines by connecting streams\nBetter User Experience: Deliver data to users as it becomes available (e.g., video streaming)\nImagine reading a 1GB file on a server with 512MB of RAM:\nWithout streams: You'd crash the process attempting to load the entire file into memory\nWith streams: You process the file in small chunks (e.g., 64KB at a time)\nCore Stream Types\nNode.js provides four fundamental types of streams, each serving a specific purpose in data handling:\nNote: All streams in Node.js are instances of EventEmitter, which means they emit events that can be listened to and handled.\nREMOVE ADS\nReadable Streams\nReadable streams let you read data from a source. Examples include:\nReading from a file\nHTTP responses on the client\nHTTP requests on the server\nprocess.stdin\nCreating a Readable Stream\nReading Modes\nReadable streams operate in one of two modes:\nFlowing Mode: Data is read from the source and provided to your application as quickly as possible using events\nPaused Mode: You must explicitly call stream.read() to get chunks of data from the stream\nWritable Streams\nWritable streams let you write data to a destination. Examples include:\nWriting to a file\nHTTP requests on the client\nHTTP responses on the server\nprocess.stdout\nCreating a Writable Stream\nHandling Backpressure\nWhen writing to a stream, if the data is being written faster than it can be processed, backpressure occurs.\nThe write() method returns a boolean indicating if it's safe to continue writing.\nPipe\nThe pipe() method connects a readable stream to a writable stream, automatically managing the flow of data and handling backpressure.\nIt's the easiest way to consume streams.\nChaining Pipes\nYou can chain multiple streams together using pipe().\nThis is especially useful when working with transform streams.\nNote: The pipe() method returns the destination stream, which enables chaining.\nDuplex and Transform Streams\nDuplex Streams\nDuplex streams are both readable and writable, like a two-way pipe.\nA TCP socket is a good example of a duplex stream.\nTransform Streams\nTransform streams are duplex streams that can modify data as it passes through.\nThey're ideal for processing data in pipelines.\nStream Events\nAll streams are instances of EventEmitter and emit several events:\nReadable Stream Events\ndata: Emitted when the stream has data available to read\nend: Emitted when there's no more data to be consumed\nerror: Emitted if an error occurs while reading\nclose: Emitted when the stream's underlying resource has been closed\nreadable: Emitted when data is available to be read\nWritable Stream Events\ndrain: Emitted when the stream is ready to accept more data after a write() method has returned false\nfinish: Emitted when all data has been flushed to the underlying system\nerror: Emitted if an error occurs while writing\nclose: Emitted when the stream's underlying resource has been closed\npipe: Emitted when the pipe() method is called on a readable stream\nunpipe: Emitted when the unpipe() method is called on a readable stream\nThe stream.pipeline() Method\nThe pipeline() function (available since Node.js v10.0.0) is a more robust way to pipe streams together, especially for error handling.\nNote: pipeline() will properly clean up all the streams if an error occurs in any of them, preventing potential memory leaks.\nObject Mode Streams\nBy default, streams work with strings and Buffer objects.\nHowever, streams can be set to 'object mode' to work with JavaScript objects.\nAdvanced Stream Patterns\n1. Error Handling with pipeline()\nThe pipeline() method is the recommended way to handle errors in stream chains:\n2. Object Mode Streams\nStreams can work with JavaScript objects instead of just strings and buffers:\nPractical Examples\nHTTP Streaming\nStreams are used extensively in HTTP requests and responses.\nProcessing Large CSV Files\nBest Practices\nError Handling: Always handle error events on streams to prevent application crashes.\nUse pipeline(): Prefer stream.pipeline() over .pipe() for better error handling and cleanup.\nHandle Backpressure: Respect the return value of write() to avoid memory issues.\nEnd Streams: Always call end() on writable streams when you're done.\nAvoid Synchronous Operations: Don't block the event loop with synchronous operations inside stream handlers.\nBuffer Size: Be mindful of highWaterMark (buffer size) settings.\nWarning: Mishandling streams can lead to memory leaks and performance issues.\nAlways handle errors and end streams properly.\nSummary\nStreams are a fundamental concept in Node.js that allow for efficient data handling. They:\nProcess data piece by piece without loading everything into memory\nProvide better memory efficiency for large datasets\nAllow processing to start before all data is available\nEnable powerful data processing pipelines\nAre used extensively in core Node.js APIs",
      "examples": [
        "const fs = require('fs');\n\n// Create a readable stream from a file\nconst readableStream = fs.createReadStream('input.txt', 'utf8');\n// Create a writable stream to a file\nconst writableStream = fs.createWriteStream('output.txt');\n\n// Pipe the data from readable to writable stream\nreadableStream.pipe(writableStream);\n\n// Handle completion and errors\nwritableStream.on('finish', () => {\nconsole.log('File copy completed!');\n});\n\nreadableStream.on('error', (err) => {\nconsole.error('Error reading file:', err);\n});\n\nwritableStream.on('error', (err) => {\nconsole.error('Error writing file:', err);\n});",
        "const fs = require('fs');\n\n// Create a readable stream from a file\nconst readableStream = fs.createReadStream('myfile.txt', {\nencoding: 'utf8',\nhighWaterMark: 64 * 1024 // 64KB chunks\n});\n\n// Events for readable streams\nreadableStream.on('data', (chunk) => {\nconsole.log(`Received ${chunk.length} bytes of data.`);\nconsole.log(chunk);\n});\n\nreadableStream.on('end', () => {\nconsole.log('No more data to read.');\n});\n\nreadableStream.on('error', (err) => {\nconsole.error('Error reading from stream:', err);\n});",
        "const fs = require('fs');\n\n// Paused mode example\nconst readableStream = fs.createReadStream('myfile.txt', {\nencoding: 'utf8',\nhighWaterMark: 64 * 1024 // 64KB chunks\n});\n\n// Manually consume the stream using read()\nreadableStream.on('readable', () => {\nlet chunk;\nwhile (null !== (chunk = readableStream.read())) {\nconsole.log(`Read ${chunk.length} bytes of data.`);\nconsole.log(chunk);\n} });\n\nreadableStream.on('end', () => {\nconsole.log('No more data to read.');\n});",
        "const fs = require('fs');\n\n// Create a writable stream to a file\nconst writableStream = fs.createWriteStream('output.txt');\n\n// Write data to the stream\nwritableStream.write('Hello, ');\nwritableStream.write('World!');\nwritableStream.write('\\nWriting to a stream is easy!');\n\n// End the stream\nwritableStream.end();\n\n// Events for writable streams\nwritableStream.on('finish', () => {\nconsole.log('All data has been written to the file.');\n});\n\nwritableStream.on('error', (err) => {\nconsole.error('Error writing to stream:', err);\n});",
        "const fs = require('fs');\n\nconst writableStream = fs.createWriteStream('output.txt');\n\nfunction writeData() {\nlet i = 100;\nfunction write() {\nlet ok = true;\ndo {\ni--;\nif (i === 0) {\n// Last time, close the stream\nwritableStream.write('Last chunk!\\n');\nwritableStream.end();\n} else {\n// Continue writing data\nconst data = `Data chunk ${i}\\n`;\n// Write and check if we should continue\nok = writableStream.write(data);\n}\n}\nwhile (i > 0 && ok);\n\nif (i > 0) {\n// We need to wait for the drain event before writing more\nwritableStream.once('drain', write);\n}\n}\nwrite();\n}\n\nwriteData();\nwritableStream.on('finish', () => {\nconsole.log('All data written successfully.');\n});",
        "const fs = require('fs');\n\n// Create readable and writable streams\nconst readableStream = fs.createReadStream('source.txt');\nconst writableStream = fs.createWriteStream('destination.txt');\n\n// Pipe the readable stream to the writable stream\nreadableStream.pipe(writableStream);\n\n// Handle completion and errors\nreadableStream.on('error', (err) => {\nconsole.error('Read error:', err);\n});\n\nwritableStream.on('error', (err) => {\nconsole.error('Write error:', err);\n});\n\nwritableStream.on('finish', () => {\nconsole.log('File copy completed!');\n});",
        "const fs = require('fs');\nconst zlib = require('zlib');\n\n// Create a pipeline to read a file, compress it, and write to a new file\nfs.createReadStream('source.txt')\n.pipe(zlib.createGzip()) // Compress the data\n.pipe(fs.createWriteStream('destination.txt.gz'))\n.on('finish', () => {\nconsole.log('File compressed successfully!');\n});",
        "const net = require('net');\n\n// Create a TCP server\nconst server = net.createServer((socket) => {\n// 'socket' is a duplex stream\n\n// Handle incoming data (readable side)\nsocket.on('data', (data) => {\nconsole.log('Received:', data.toString());\n\n// Echo back (writable side)\nsocket.write(`Echo: ${data}`);\n});\n\nsocket.on('end', () => {\nconsole.log('Client disconnected');\n});\n});\n\nserver.listen(8080, () => {\nconsole.log('Server listening on port 8080');\n});\n\n// To test, you can use a tool like netcat or telnet:\n// $ nc localhost 8080\n// or create a client:\n/*\nconst client = net.connect({ port: 8080 }, () => {\nconsole.log('Connected to server');\nclient.write('Hello from client!');\n});\n\nclient.on('data', (data) => {\nconsole.log('Server says:', data.toString());\nclient.end(); // Close the connection\n});\n*/",
        "const { Transform } = require('stream');\nconst fs = require('fs');\n\n// Create a transform stream that converts text to uppercase\nclass UppercaseTransform extends Transform {\n_transform(chunk, encoding, callback) {\n// Transform the chunk to uppercase\nconst upperChunk = chunk.toString().toUpperCase();\n// Push the transformed data\nthis.push(upperChunk);\n// Signal that we're done with this chunk\ncallback();\n}\n}\n\n// Create an instance of our transform stream\nconst uppercaseTransform = new UppercaseTransform();\n\n// Create a readable stream from a file\nconst readableStream = fs.createReadStream('input.txt');\n\n// Create a writable stream to a file\nconst writableStream = fs.createWriteStream('output-uppercase.txt');\n\n// Pipe the data through our transform stream\nreadableStream\n.pipe(uppercaseTransform)\n.pipe(writableStream)\n.on('finish', () => {\nconsole.log('Transformation completed!');\n});",
        "const { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\n// Create a pipeline that handles errors properly\npipeline(\nfs.createReadStream('source.txt'),\nzlib.createGzip(),\nfs.createWriteStream('destination.txt.gz'),\n(err) => {\nif (err) {\nconsole.error('Pipeline failed:', err);\n} else {\nconsole.log('Pipeline succeeded!');\n}\n}\n);",
        "const { Readable, Writable, Transform } = require('stream');\n\n// Create a readable stream in object mode\nconst objectReadable = new Readable({\nobjectMode: true,\nread() {} // Implementation required but can be no-op\n});\n\n// Create a transform stream in object mode\nconst objectTransform = new Transform({\nobjectMode: true,\ntransform(chunk, encoding, callback) {\n// Add a property to the object\nchunk.transformed = true;\nchunk.timestamp = new Date();\nthis.push(chunk);\ncallback();\n} });\n\n// Create a writable stream in object mode\nconst objectWritable = new Writable({\nobjectMode: true,\nwrite(chunk, encoding, callback) {\nconsole.log('Received object:', chunk);\ncallback();\n} });\n\n// Connect the streams\nobjectReadable\n.pipe(objectTransform)\n.pipe(objectWritable);\n\n// Push some objects to the stream\nobjectReadable.push({ name: 'Object 1', value: 10 });\nobjectReadable.push({ name: 'Object 2', value: 20 });\nobjectReadable.push({ name: 'Object 3', value: 30 });\nobjectReadable.push(null); // Signal the end of data",
        "const { pipeline } = require('stream');\nconst fs = require('fs');\nconst zlib = require('zlib');\n\npipeline(\nfs.createReadStream('input.txt'),\nzlib.createGzip(),\nfs.createWriteStream('output.txt.gz'),\n(err) => {\nif (err) {\nconsole.error('Pipeline failed:', err);\n} else {\nconsole.log('Pipeline succeeded');\n}\n}\n);",
        "const { Readable } = require('stream');\n\n// Create a readable stream in object mode\nconst objectStream = new Readable({\nobjectMode: true,\nread() {}\n});\n// Push objects to the stream\nobjectStream.push({ id: 1, name: 'Alice' });\nobjectStream.push({ id: 2, name: 'Bob' });\nobjectStream.push(null); // Signal end of stream\n// Consume the stream\nobjectStream.on('data', (obj) => {\nconsole.log('Received:', obj);\n});",
        "const http = require('http');\nconst fs = require('fs');\n\n// Create an HTTP server\nconst server = http.createServer((req, res) => {\n// Handle different routes\nif (req.url === '/') {\n// Send a simple response\nres.writeHead(200, { 'Content-Type': 'text/html' });\nres.end('<h1>Stream Demo</h1><p>Try <a href=\"/file\">streaming a file</a> or <a href=\"/video\">streaming a video</a>.</p>');\n}\nelse if (req.url === '/file') {\n// Stream a large text file\nres.writeHead(200, { 'Content-Type': 'text/plain' });\nconst fileStream = fs.createReadStream('largefile.txt', 'utf8');\n\n// Pipe the file to the response (handles backpressure automatically)\nfileStream.pipe(res);\n\n// Handle errors\nfileStream.on('error', (err) => {\nconsole.error('File stream error:', err);\nres.statusCode = 500;\nres.end('Server Error');\n});\n}\nelse if (req.url === '/video') {\n// Stream a video file with proper headers\nconst videoPath = 'video.mp4';\nconst stat = fs.statSync(videoPath);\nconst fileSize = stat.size;\nconst range = req.headers.range;\n\nif (range) {\n// Handle range requests for video seeking\nconst parts = range.replace(/bytes=/, \"\").split(\"-\");\nconst start = parseInt(parts[0], 10);\nconst end = parts[1] ? parseInt(parts[1], 10) : fileSize - 1;\nconst chunksize = (end - start) + 1;\n\nconst videoStream = fs.createReadStream(videoPath, { start, end });\nres.writeHead(206, {\n'Content-Range': `bytes ${start}-${end}/${fileSize}`,\n'Accept-Ranges': 'bytes',\n'Content-Length': chunksize,\n'Content-Type': 'video/mp4'\n});\n\nvideoStream.pipe(res);\n} else {\n// No range header, send entire video\nres.writeHead(200, {\n'Content-Length': fileSize,\n'Content-Type': 'video/mp4'\n});\n\nfs.createReadStream(videoPath).pipe(res);\n}\n}&br>   else {\n// 404 Not Found\nres.writeHead(404, { 'Content-Type': 'text/plain' });\nres.end('Not Found');\n}\n});\n\n// Start the server\nserver.listen(8080, () => {\nconsole.log('Server running at http://localhost:8080/');\n});",
        "const fs = require('fs');\nconst { Transform } = require('stream');\nconst csv = require('csv-parser'); // npm install csv-parser\n\n// Create a transform stream to filter and transform CSV data\nconst filterTransform = new Transform({\nobjectMode: true,\ntransform(row, encoding, callback) {\n// Only pass through rows that meet our criteria\nif (parseInt(row.age) > 18) {\n// Modify the row\nrow.isAdult = 'Yes';\n// Push the transformed row\nthis.push(row);\n}\n}\ncallback();\n}\n});\n\n// Create a writable stream for the results\nconst results = [];\nconst writeToArray = new Transform({\nobjectMode: true,\ntransform(row, encoding, callback) {\nresults.push(row);\ncallback();\n}\n});\n\n// Create the processing pipeline\nfs.createReadStream('people.csv')\n.pipe(csv())\n.pipe(filterTransform)\n.pipe(writeToArray)\n.on('finish', () => {\nconsole.log(`Processed ${results.length} records:`);\nconsole.log(results);\n}\n})\n.on('error', (err) => {\nconsole.error('Error processing CSV:', err);\n}\n});",
        "stream.read()",
        "write()",
        "pipe()",
        "data",
        "end",
        "error",
        "close",
        "readable",
        "drain",
        "false",
        "finish",
        "pipe",
        "unpipe",
        "unpipe()",
        "pipeline()",
        "stream.pipeline()",
        ".pipe()",
        "end()"
      ]
    },
    {
      "title": "Node.js Buffer Module",
      "summary": "What is the Buffer Module?\nThe Buffer module in Node.js is used to handle binary data.\nBuffers are similar to arrays of integers but are fixed-length and correspond to raw memory allocations outside the V8 JavaScript engine.\nNode.js provides the Buffer class as a global object, so you don't need to require or import it explicitly.\nNote: Since Node.js v6.0.0, the Buffer constructor is deprecated in favor of the new Buffer methods.\nUsing the constructor could lead to security vulnerabilities due to uninitialized memory.\nGetting Started with Buffers\nBuffers in Node.js are used to handle binary data directly.\nThey are similar to arrays of integers but are fixed in size and represent raw memory allocations outside the V8 heap.\nBasic Buffer ExampleGet your own Node.js Server\nCreating Buffers\nThere are several ways to create buffers in Node.js, each with different performance and safety characteristics:\nThere are several ways to create buffers in Node.js:\n1. Buffer.alloc()\nCreates a new Buffer of the specified size, initialized with zeros.\nThis is the safest way to create a new buffer as it ensures no old data is present.\n2. Buffer.allocUnsafe()\nCreates a new Buffer of the specified size, but doesn't initialize the memory.\nThis is faster than Buffer.alloc() but may contain old or sensitive data.\nAlways fill the buffer before use if security is a concern.\nWarning: Buffer.allocUnsafe() is faster than Buffer.alloc() but can expose sensitive data.\nOnly use it when you understand the security implications and plan to immediately fill the entire buffer.\n3. Buffer.from()\nCreates a new Buffer from various sources like strings, arrays, or ArrayBuffer. This is the most flexible way to create buffers from existing data.\nREMOVE ADS\nUsing Buffers\nWriting to Buffers\nYou can write data to a buffer using various methods:\nReading from Buffers\nYou can read data from a buffer using various methods:\nIterating Through Buffers\nBuffers can be iterated like arrays:\nBuffer Methods\nBuffer.compare()\nCompares two buffers and returns a number indicating whether the first one comes before, after, or is the same as the second one in sort order:\nbuffer.copy()\nCopies data from one buffer to another:\nbuffer.slice()\nCreates a new buffer that references the same memory as the original, but with offset and cropped to the given end:\nNote: Since buffer.slice() creates a view of the same memory, modifying either the original buffer or the slice will affect the other.\nbuffer.toString()\nDecodes a buffer to a string using a specified encoding:\nbuffer.equals()\nCompares two buffers for content equality:\nWorking with Encodings\nBuffers work with various encodings when converting between strings and binary data:\nSupported encodings in Node.js include:\nutf8: Multi-byte encoded Unicode characters (default)\nascii: ASCII characters only (7-bit)\nlatin1: Latin-1 encoding (ISO 8859-1)\nbase64: Base64 encoding\nhex: Hexadecimal encoding\nbinary: Binary encoding (deprecated)\nucs2/utf16le: 2 or 4 bytes, little-endian encoded Unicode characters\nAdvanced Buffer Operations\nConcatenating Buffers\nYou can combine multiple buffers into one using Buffer.concat():\nSearching in Buffers\nBuffers provide methods to search for values or sequences:\nBuffer and Streams\nBuffers are commonly used with streams for efficient data processing:\nBuffer and File System\nBuffers are commonly used for file system operations:\nBuffer Performance Considerations\nMemory Usage: Buffers consume memory outside the JavaScript heap, which can be both an advantage (less garbage collection pressure) and a disadvantage (must be carefully managed)\nAllocation: Buffer.allocUnsafe() is faster than Buffer.alloc() but comes with security considerations\nString Conversion: Converting large buffers to strings or vice versa can be expensive\nPooling: For applications that frequently create small buffers, consider implementing a buffer pool to reduce allocation overhead\nBuffer Security Considerations\nSecurity Warning: Buffers can contain sensitive data from memory.\nAlways be cautious when handling buffers, especially when they might be exposed to users or logged.\nBest Practices:\nAvoid using Buffer.allocUnsafe() unless performance is critical and you immediately fill the buffer\nZero-fill buffers after use when they contained sensitive information\nBe careful when sharing buffer instances or slices, as changes are reflected across all references\nValidate buffer inputs when receiving binary data from external sources\nSummary\nThe Node.js Buffer class is an essential tool for working with binary data. Key points to remember:\nBuffers provide a way to handle binary data in JavaScript\nUse Buffer.alloc(), Buffer.from(), and Buffer.allocUnsafe() to create buffers\nBuffers can be manipulated with methods like write(), toString(), slice(), and copy()\nBuffers support various encodings including UTF-8, Base64, and Hex\nBuffers are commonly used in file I/O, network operations, and binary data processing\nConsider performance and security implications when working with buffers",
      "examples": [
        "// Create a buffer from a string\nconst buf = Buffer.from('Hello, Node.js!');\n\n// Buffers can be converted to strings\nconsole.log(buf.toString()); // 'Hello, Node.js!'\n\n// Access individual bytes\nconsole.log(buf[0]); // 72 (ASCII for 'H')\n\n// Buffers have a fixed length\nconsole.log(buf.length); // 15",
        "// Create a buffer of 10 bytes filled with zeros\nconst buffer1 = Buffer.alloc(10);\nconsole.log(buffer1);",
        "// Create an uninitialized buffer of 10 bytes\nconst buffer2 = Buffer.allocUnsafe(10);\nconsole.log(buffer2);\n\n// Fill the buffer with zeros for security\nbuffer2.fill(0);\nconsole.log(buffer2);",
        "// Create a buffer from a string\nconst buffer3 = Buffer.from('Hello, World!');\nconsole.log(buffer3);\n\nconsole.log(buffer3.toString());\n\n// Create a buffer from an array of integers\nconst buffer4 = Buffer.from([65, 66, 67, 68, 69]);\nconsole.log(buffer4);\n\nconsole.log(buffer4.toString());\n\n// Create a buffer from another buffer\nconst buffer5 = Buffer.from(buffer4);\nconsole.log(buffer5);",
        "// Create an empty buffer\nconst buffer = Buffer.alloc(10);\n\n// Write a string to the buffer\nbuffer.write('Hello');\nconsole.log(buffer);\n\nconsole.log(buffer.toString());\n\n// Write bytes at specific positions\nbuffer[5] = 44; // ASCII for ','\nbuffer[6] = 32; // ASCII for space\nbuffer.write('Node', 7);\nconsole.log(buffer.toString());",
        "// Create a buffer from a string\nconst buffer = Buffer.from('Hello, Node.js!');\n\n// Read the entire buffer as a string\nconsole.log(buffer.toString());\n\n// Read a portion of the buffer (start at position 7, end before position 11)\nconsole.log(buffer.toString('utf8', 7, 11));\n\n// Read a single byte\nconsole.log(buffer[0]);\n\n// Convert the ASCII code to a character\nconsole.log(String.fromCharCode(buffer[0]));",
        "// Create a buffer from a string\nconst buffer = Buffer.from('Hello');\n\n// Iterate using for...of loop\nfor (const byte of buffer) {\nconsole.log(byte);\n}\n\n// Iterate using forEach\nbuffer.forEach((byte, index) => {\nconsole.log(`Byte at position ${index}: ${byte}`);\n});",
        "const buffer1 = Buffer.from('ABC');\nconst buffer2 = Buffer.from('BCD');\nconst buffer3 = Buffer.from('ABC');\n\nconsole.log(Buffer.compare(buffer1, buffer2));\nconsole.log(Buffer.compare(buffer2, buffer1));\nconsole.log(Buffer.compare(buffer1, buffer3));",
        "// Create source and target buffers\nconst source = Buffer.from('Hello, World!');\nconst target = Buffer.alloc(source.length);\n\n// Copy from source to target\nsource.copy(target);\n\nconsole.log(target.toString());\n\n// Create a target buffer for partial copy\nconst partialTarget = Buffer.alloc(5);\n\n// Copy only part of the source (starting at index 7)\nsource.copy(partialTarget, 0, 7);\n\nconsole.log(partialTarget.toString());",
        "const buffer = Buffer.from('Hello, World!');\n\n// Create a slice from position 7 to the end\nconst slice = buffer.slice(7);\nconsole.log(slice.toString());\n\n// Create a slice from position 0 to 5\nconst slice2 = buffer.slice(0, 5);\nconsole.log(slice2.toString());\n\n// Important: slices share memory with original buffer\nslice[0] = 119; // ASCII for 'w' (lowercase)\nconsole.log(slice.toString());\nconsole.log(buffer.toString());",
        "const buffer = Buffer.from('Hello, World!');\n\n// Default encoding is UTF-8\nconsole.log(buffer.toString());\n\n// Specify encoding\nconsole.log(buffer.toString('utf8'));\n\n// Decode only a portion of the buffer\nconsole.log(buffer.toString('utf8', 0, 5));\n\n// Using different encodings\nconst hexBuffer = Buffer.from('48656c6c6f', 'hex');\nconsole.log(hexBuffer.toString());\n\nconst base64Buffer = Buffer.from('SGVsbG8=', 'base64');\nconsole.log(base64Buffer.toString());",
        "const buffer1 = Buffer.from('Hello');\nconst buffer2 = Buffer.from('Hello');\nconst buffer3 = Buffer.from('World');\n\nconsole.log(buffer1.equals(buffer2));\n\nconsole.log(buffer1.equals(buffer3));\n\nconsole.log(buffer1 === buffer2);",
        "// Create a string\nconst str = 'Hello, World!';\n\n// Convert to different encodings\nconst utf8Buffer = Buffer.from(str, 'utf8');\nconsole.log('UTF-8:', utf8Buffer);\n\nconst base64Str = utf8Buffer.toString('base64');\nconsole.log('Base64 string:', base64Str);\n\nconst hexStr = utf8Buffer.toString('hex');\nconsole.log('Hex string:', hexStr);\n\n// Convert back to original\nconst fromBase64 = Buffer.from(base64Str, 'base64').toString('utf8');\nconsole.log('From Base64:', fromBase64);\n\nconst fromHex = Buffer.from(hexStr, 'hex').toString('utf8');\nconsole.log('From Hex:', fromHex);",
        "const buf1 = Buffer.from('Hello, ');\nconst buf2 = Buffer.from('Node.js!');\n\n// Concatenate buffers\nconst combined = Buffer.concat([buf1, buf2]);\nconsole.log(combined.toString()); // 'Hello, Node.js!'\n\n// With a maximum length parameter\nconst partial = Buffer.concat([buf1, buf2], 5);\nconsole.log(partial.toString()); // 'Hello'",
        "const buf = Buffer.from('Hello, Node.js is awesome!');\n\n// Find the first occurrence of a value\nconsole.log(buf.indexOf('Node')); // 7\n\n// Check if buffer contains a value\nconsole.log(buf.includes('awesome')); // true\n\n// Find the last occurrence of a value\nconsole.log(buf.lastIndexOf('e')); // 24",
        "const fs = require('fs');\nconst { Transform } = require('stream');\n\n// Create a transform stream that processes data in chunks\nconst transformStream = new Transform({\ntransform(chunk, encoding, callback) {\n// Process each chunk (which is a Buffer)\nconst processed = chunk.toString().toUpperCase();\nthis.push(Buffer.from(processed));\ncallback();\n}\n});\n// Create a read stream from a file\nconst readStream = fs.createReadStream('input.txt');\n// Create a write stream to a file\nconst writeStream = fs.createWriteStream('output.txt');\n// Process the file in chunks\nreadStream.pipe(transformStream).pipe(writeStream);",
        "const fs = require('fs');\n\n// Write buffer to file\nconst writeBuffer = Buffer.from('Hello, Node.js!');\nfs.writeFile('buffer.txt', writeBuffer, (err) => {\nif (err) throw err;\nconsole.log('File written successfully');\n\n// Read file into buffer\nfs.readFile('buffer.txt', (err, data) => {\nif (err) throw err;\n\n// 'data' is a buffer\nconsole.log('Read buffer:', data);\nconsole.log('Buffer content:', data.toString());\n\n// Read only part of the file into a buffer\nconst smallBuffer = Buffer.alloc(5);\nfs.open('buffer.txt', 'r', (err, fd) => {\nif (err) throw err;\n\n// Read 5 bytes starting at position 7\nfs.read(fd, smallBuffer, 0, 5, 7, (err, bytesRead, buffer) => {\nif (err) throw err;\n\nconsole.log('Partial read:', buffer.toString());\n// Output: Node.\n\nfs.close(fd, (err) => {\nif (err) throw err;\n});\n});\n});\n});\n});",
        "// Simple buffer pool implementation\nclass BufferPool {\nconstructor(bufferSize = 1024, poolSize = 10) {\nthis.bufferSize = bufferSize;\nthis.pool = Array(poolSize).fill().map(() => Buffer.alloc(bufferSize));\n\nthis.used = Array(poolSize).fill(false);\n}\n\n// Get a buffer from the pool\nget() {\nconst index = this.used.indexOf(false);\nif (index === -1) {\n// Pool is full, create a new buffer\nconsole.log('Pool full, allocating new buffer');\nreturn Buffer.alloc(this.bufferSize);\n}\nthis.used[index] = true;\nreturn this.pool[index];\n}\n\n// Return a buffer to the pool\nrelease(buffer) {\nconst index = this.pool.indexOf(buffer);\nif (index !== -1) {\n// Zero the buffer for security\nbuffer.fill(0);\nthis.used[index] = false;\n}\n}\n}\n\n// Usage example\nconst pool = new BufferPool(10, 3); // 3 buffers of 10 bytes each\n\nconst buf1 = pool.get();\nconst buf2 = pool.get();\nconst buf3 = pool.get();\nconst buf4 = pool.get(); // This will allocate a new buffer\n\nbuf1.write('Hello');\nconsole.log(buf1.toString()); // Hello\n\n// Return buf1 to the pool\npool.release(buf1);\n\n// Get another buffer (should reuse buf1)\nconst buf5 = pool.get();\nconsole.log(buf5.toString()); // Should be empty (zeros)",
        "// Example: Safely handling sensitive data\nfunction processPassword(password) {\n// Create a buffer to hold the password\nconst passwordBuffer = Buffer.from(password);\n\n// Process the password (e.g., hashing)\nconst hashedPassword = hashPassword(passwordBuffer);\n\n// Zero out the original password buffer for security\npasswordBuffer.fill(0);\n\nreturn hashedPassword;\n}\n\n// Simple hashing function for demonstration\nfunction hashPassword(buffer) {\n// In a real application, you would use a cryptographic hash function\n// This is a simplified example\nlet hash = 0;\nfor (let i = 0; i < buffer.length; i++) {\nhash = ((hash < 5) - hash) + buffer[i];\nhash |= 0; // Convert to 32-bit integer\n}\nreturn hash.toString(16);\n}\n\n// Usage\nconst password = 'secret123';\nconst hashedPassword = processPassword(password);\nconsole.log('Hashed password:', hashedPassword);",
        "Buffer.alloc()",
        "Buffer.allocUnsafe()",
        "buffer.slice()",
        "Buffer.concat()",
        "Buffer.from()",
        "write()",
        "toString()",
        "slice()",
        "copy()"
      ]
    },
    {
      "title": "Node.js Crypto Module",
      "summary": "What is the Crypto Module?\nThe Crypto module is a built-in Node.js module that provides cryptographic functionality including:\nHash functions (SHA-256, SHA-512, etc.)\nHMAC (Hash-based Message Authentication Code)\nSymmetric encryption (AES, DES, etc.)\nAsymmetric encryption (RSA, ECDSA, etc.)\nDigital signatures and verification\nSecure random number generation\nThe Crypto module is essential for applications that need to handle sensitive information securely.\nThe Crypto module wraps the OpenSSL library, providing access to well-established and tested cryptographic algorithms.\nThis module is often used to handle sensitive data, such as:\nUser authentication and password storage\nSecure data transmission\nFile encryption and decryption\nSecure communication channels\nGetting Started with Crypto\nHere's a quick example of using the Crypto module to hash a string:\nBasic Hashing ExampleGet your own Node.js Server\nInstalling the Crypto Module\nThe Crypto module is included in Node.js by default.\nYou can use it by requiring it in your script:\nHash Functions\nHashing is a one-way transformation of data into a fixed-length string of characters.\nHash functions have several important properties:\nDeterministic: Same input always produces the same output\nFixed Length: Output is always the same size regardless of input size\nOne-Way: Extremely difficult to reverse the process\nAvalanche Effect: Small changes in input produce significant changes in output\nCommon use cases include:\nPassword storage\nData integrity verification\nDigital signatures\nContent addressing (e.g., Git, IPFS)\nCreating a Hash\nIn this example:\ncreateHash() creates a hash object with the specified algorithm\nupdate() updates the hash content with the given data\ndigest() calculates the digest and outputs it in the specified format\nREMOVE ADS\nCommon Hash Algorithms\nWarning: MD5 and SHA-1 are considered cryptographically weak and should not be used for security-critical applications.\nUse SHA-256, SHA-384, or SHA-512 instead.\nPassword Security\nWhen handling passwords, it's crucial to use specialized password hashing functions that are designed to be computationally expensive to prevent brute-force attacks.\nHere's why simple hashes are insufficient:\nNever store passwords in plain text or with simple hashes like MD5 or SHA-1.\nThese can be easily cracked using rainbow tables or brute-force attacks.\nKey Concepts for Password Security\nSalting: Add a unique random value to each password before hashing\nKey Stretching: Make the hashing process intentionally slow to prevent brute-force attacks\nWork Factor: Control how computationally intensive the hashing process is\nHere's how to properly hash passwords in Node.js:\nWhat is a salt?\nA salt is a random string that is unique to each user.\nIt's combined with the password before hashing to ensure that even if two users have the same password, their hashes will be different.\nThis prevents attackers from using precomputed tables (like rainbow tables) to crack multiple passwords at once.\nNote: For password hashing in a production environment, consider using a dedicated library like bcrypt or argon2 that is specifically designed for secure password handling.\nHMAC (Hash-based Message Authentication Code)\nHMAC is a specific type of message authentication code (MAC) involving a cryptographic hash function and a secret cryptographic key.\nIt provides both data integrity and authentication.\nWhen to Use HMAC\nAPI request verification\nSecure cookies and sessions\nData integrity checks\nWebhook verification\nHMAC Security Properties\nMessage Integrity: Any change to the message will produce a different HMAC\nAuthenticity: Only parties with the secret key can generate valid HMACs\nNo Encryption: HMAC doesn't encrypt the message, only verifies its integrity\nHMAC for Message Verification\nNote: Always use timingSafeEqual() for cryptographic comparisons to prevent timing attacks.\nSymmetric Encryption\nSymmetric encryption uses the same key for both encryption and decryption.\nIt's generally faster than asymmetric encryption and is ideal for:\nBulk data encryption\nDatabase encryption\nFilesystem encryption\nSecure messaging (combined with key exchange)\nCommon Symmetric Algorithms\nNote: Always use authenticated encryption modes like AES-GCM or AES-CCM when possible, as they provide both confidentiality and authenticity.\nAES (Advanced Encryption Standard)\nWarning: Never reuse the same initialization vector (IV) with the same key.\nAlways generate a new random IV for each encryption operation.\nOther Symmetric Algorithms\nThe Crypto module supports various symmetric encryption algorithms.\nYou can see the available ciphers with:\nAsymmetric Encryption\nAsymmetric encryption (public-key cryptography) uses a pair of mathematically related keys:\nPublic Key: Can be shared publicly, used for encryption\nPrivate Key: Must be kept secret, used for decryption\nCommon Use Cases\nSecure key exchange (e.g., TLS/SSL handshake)\nDigital signatures\nEmail encryption (PGP/GPG)\nBlockchain and cryptocurrencies\nCommon Asymmetric Algorithms\nPerformance Note: Asymmetric encryption is much slower than symmetric encryption.\nFor encrypting large amounts of data, use a hybrid approach:\nGenerate a random symmetric key\nEncrypt your data with the symmetric key\nEncrypt the symmetric key with the recipient's public key\nSend both the encrypted data and encrypted key\nRSA (Rivest-Shamir-Adleman)\nNote: RSA is typically used for encrypting small amounts of data (like encryption keys) due to performance constraints.\nFor larger data, use a hybrid approach: encrypt the data with a symmetric algorithm (like AES) and encrypt the symmetric key with RSA.\nDigital Signatures\nDigital signatures provide a way to verify the authenticity and integrity of messages, software, or digital documents.\nRandom Data Generation\nGenerating secure random data is important for many cryptographic operations, such as creating keys, salts, and initialization vectors.\nSecurity Best Practices\nWhen using the Crypto module, keep these best practices in mind:\nUse modern algorithms: Avoid MD5, SHA-1, and other outdated algorithms\nSecure key management: Store keys securely, rotate them regularly, and never hardcode them\nUse random IVs: Generate a new random IV for each encryption operation\nAdd authentication: Use authenticated encryption modes like GCM when possible\nConstant-time comparisons: Always use crypto.timingSafeEqual() for comparing security-critical values\nKey derivation: Use appropriate key derivation functions like scrypt, bcrypt, or PBKDF2 for password-based keys\nStay updated: Keep Node.js updated to get security fixes and support for newer algorithms\nFollow standards: Adhere to established cryptographic standards and protocols\nWarning: Cryptography is complex, and mistakes can lead to serious security vulnerabilities.\nWhen implementing critical security features, consider consulting a security specialist or using well-established libraries designed for specific cryptographic tasks.\nSummary\nThe Node.js Crypto module provides a wide range of cryptographic functionality:\nHash functions for data integrity and fingerprinting\nHMAC for authentication and integrity checks\nSymmetric encryption for securing data with shared keys\nAsymmetric encryption for secure communication and digital signatures\nRandom data generation for cryptographic operations\nDigital signatures for authenticity verification\nBy understanding and properly implementing these cryptographic concepts, you can build secure applications that protect sensitive data and communications.",
      "examples": [
        "const crypto = require('crypto');\n\n// Create a SHA-256 hash of a string\nconst hash = crypto.createHash('sha256')\n.update('Hello, Node.js!')\n.digest('hex');\nconsole.log('SHA-256 Hash:', hash);",
        "const crypto = require('crypto');",
        "const crypto = require('crypto');\n\n// Create a hash object\nconst hash = crypto.createHash('sha256');\n\n// Update the hash with data\nhash.update('Hello, World!');\n\n// Get the digest in hexadecimal format\nconst digest = hash.digest('hex');\nconsole.log(digest);",
        "const crypto = require('crypto');\nconst data = 'Hello, World!';\n\n// MD5 (not recommended for security-critical applications)\nconst md5 = crypto.createHash('md5').update(data).digest('hex');\nconsole.log('MD5:', md5);\n\n// SHA-1 (not recommended for security-critical applications)\nconst sha1 = crypto.createHash('sha1').update(data).digest('hex');\nconsole.log('SHA-1:', sha1);\n\n// SHA-256\nconst sha256 = crypto.createHash('sha256').update(data).digest('hex');\nconsole.log('SHA-256:', sha256);\n\n// SHA-512\nconst sha512 = crypto.createHash('sha512').update(data).digest('hex');\nconsole.log('SHA-512:', sha512);",
        "const crypto = require('crypto');\n\n// Function to hash a password\nfunction hashPassword(password) {\n// Generate a random salt (16 bytes)\nconst salt = crypto.randomBytes(16).toString('hex');\n\n// Use scrypt for password hashing (recommended)\nconst hash = crypto.scryptSync(password, salt, 64).toString('hex');\n\n// Return both salt and hash for storage\nreturn { salt, hash };\n}\n\n// Function to verify a password\nfunction verifyPassword(password, salt, hash) {\nconst hashedPassword = crypto.scryptSync(password, salt, 64).toString('hex');\nreturn hashedPassword === hash;\n}\n\n// Example usage\nconst password = 'mySecurePassword';\n\n// Hash the password for storage\nconst { salt, hash } = hashPassword(password);\nconsole.log('Salt:', salt);\nconsole.log('Hash:', hash);\n\n// Verify a login attempt\nconst isValid = verifyPassword(password, salt, hash);\nconsole.log('Password valid:', isValid); // true\n\nconst isInvalid = verifyPassword('wrongPassword', salt, hash);\nconsole.log('Wrong password valid:', isInvalid); // false",
        "const crypto = require('crypto');\n\n// Secret key\nconst secretKey = 'mySecretKey';\n\n// Create an HMAC\nconst hmac = crypto.createHmac('sha256', secretKey);\n\n// Update with data\nhmac.update('Hello, World!');\n\n// Get the digest\nconst hmacDigest = hmac.digest('hex');\nconsole.log('HMAC:', hmacDigest);",
        "const crypto = require('crypto');\n\n// Function to create an HMAC for a message\nfunction createSignature(message, key) {\nconst hmac = crypto.createHmac('sha256', key);\nhmac.update(message);\nreturn hmac.digest('hex');\n}\n\n// Function to verify a message's signature\nfunction verifySignature(message, signature, key) {\nconst expectedSignature = createSignature(message, key);\nreturn crypto.timingSafeEqual(\nBuffer.from(signature, 'hex'),\nBuffer.from(expectedSignature, 'hex')\n);\n}\n\n// Example usage\nconst secretKey = 'verySecretKey';\nconst message = 'Important message to verify';\n\n// Sender creates a signature\nconst signature = createSignature(message, secretKey);\nconsole.log('Message:', message);\nconsole.log('Signature:', signature);\n\n// Receiver verifies the signature\ntry {\nconst isValid = verifySignature(message, signature, secretKey);\nconsole.log('Signature valid:', isValid); // true\n\n// Try with a tampered message\nconst isInvalid = verifySignature('Tampered message', signature, secretKey);\nconsole.log('Tampered message valid:', isInvalid); // false\n} catch (error) {\nconsole.error('Verification error:', error.message);\n}",
        "const crypto = require('crypto');\n\n// Function to encrypt data\nfunction encrypt(text, key) {\n// Generate a random initialization vector\nconst iv = crypto.randomBytes(16);\n\n// Create cipher with AES-256-CBC\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\n\n// Encrypt the data\nlet encrypted = cipher.update(text, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\n// Return both the encrypted data and the IV\nreturn {\niv: iv.toString('hex'),\nencryptedData: encrypted\n};\n}\n\n// Function to decrypt data\nfunction decrypt(encryptedData, iv, key) {\n// Create decipher\nconst decipher = crypto.createDecipheriv(\n'aes-256-cbc',\nkey,\nBuffer.from(iv, 'hex')\n);\n\n// Decrypt the data\nlet decrypted = decipher.update(encryptedData, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nreturn decrypted;\n}\n\n// Example usage\n// Note: In a real application, use a properly generated and securely stored key\nconst key = crypto.scryptSync('secretPassword', 'salt', 32); // 32 bytes = 256 bits\nconst message = 'This is a secret message';\n\n// Encrypt\nconst { iv, encryptedData } = encrypt(message, key);\nconsole.log('Original:', message);\nconsole.log('Encrypted:', encryptedData);\nconsole.log('IV:', iv);\n\n// Decrypt\nconst decrypted = decrypt(encryptedData, iv, key);\nconsole.log('Decrypted:', decrypted);",
        "const crypto = require('crypto');\n\n// List available cipher algorithms\nconsole.log(crypto.getCiphers());",
        "const crypto = require('crypto');\n\n// Generate RSA key pair\nfunction generateKeyPair() {\nreturn crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048, // Key size in bits\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n}\n\n// Encrypt with public key\nfunction encryptWithPublicKey(text, publicKey) {\nconst buffer = Buffer.from(text, 'utf8');\nconst encrypted = crypto.publicEncrypt(\n{\nkey: publicKey,\npadding: crypto.constants.RSA_PKCS1_OAEP_PADDING\n},\nbuffer\n);\nreturn encrypted.toString('base64');\n}\n\n// Decrypt with private key\nfunction decryptWithPrivateKey(encryptedText, privateKey) {\nconst buffer = Buffer.from(encryptedText, 'base64');\nconst decrypted = crypto.privateDecrypt(\n{\nkey: privateKey,\npadding: crypto.constants.RSA_PKCS1_OAEP_PADDING\n},\nbuffer\n);\nreturn decrypted.toString('utf8');\n}\n\n// Generate keys\nconst { publicKey, privateKey } = generateKeyPair();\nconsole.log('Public Key:', publicKey.substring(0, 50) + '...');\nconsole.log('Private Key:', privateKey.substring(0, 50) + '...');\n\n// Example usage\nconst message = 'This message is encrypted with RSA';\nconst encrypted = encryptWithPublicKey(message, publicKey);\nconsole.log('Encrypted:', encrypted.substring(0, 50) + '...');\n\nconst decrypted = decryptWithPrivateKey(encrypted, privateKey);\nconsole.log('Decrypted:', decrypted);",
        "const crypto = require('crypto');\n\n// Generate RSA key pair\nconst { publicKey, privateKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Function to sign a message\nfunction signMessage(message, privateKey) {\nconst signer = crypto.createSign('sha256');\nsigner.update(message);\nreturn signer.sign(privateKey, 'base64');\n}\n\n// Function to verify a signature\nfunction verifySignature(message, signature, publicKey) {\nconst verifier = crypto.createVerify('sha256');\nverifier.update(message);\nreturn verifier.verify(publicKey, signature, 'base64');\n}\n\n// Example usage\nconst message = 'This message needs to be signed';\nconst signature = signMessage(message, privateKey);\nconsole.log('Message:', message);\nconsole.log('Signature:', signature.substring(0, 50) + '...');\n\n// Verify the signature\nconst isValid = verifySignature(message, signature, publicKey);\nconsole.log('Signature valid:', isValid); // true\n\n// Verify with a modified message\nconst isInvalid = verifySignature('Modified message', signature, publicKey);\nconsole.log('Modified message valid:', isInvalid); // false",
        "const crypto = require('crypto');\n\n// Generate random bytes\nconst randomBytes = crypto.randomBytes(16);\nconsole.log('Random bytes:', randomBytes.toString('hex'));\n\n// Generate a random string (Base64)\nconst randomString = crypto.randomBytes(32).toString('base64');\nconsole.log('Random string:', randomString);\n\n// Generate a random number between 1 and 100\nfunction secureRandomNumber(min, max) {\n// Ensure we have enough randomness\nconst range = max - min + 1;\nconst bytesNeeded = Math.ceil(Math.log2(range) / 8);\nconst maxValue = 256 ** bytesNeeded;\n\n// Generate random bytes and convert to a number\nconst randomBytes = crypto.randomBytes(bytesNeeded);\nconst randomValue = randomBytes.reduce((acc, byte, i) => {\nreturn acc + byte * (256 ** i);\n}, 0);\n\n// Scale to our range and shift by min\nreturn min + Math.floor((randomValue * range) / maxValue);\n}\n\n// Example: Generate 5 random numbers\nfor (let i = 0; i < 5; i++) {\nconsole.log(`Random number ${i+1}:`, secureRandomNumber(1, 100));\n}",
        "createHash()",
        "update()",
        "digest()",
        "bcrypt",
        "argon2",
        "timingSafeEqual()",
        "crypto.timingSafeEqual()"
      ]
    },
    {
      "title": "Node.js Timers Module",
      "summary": "What is the Timers Module?\nThe Timers module provides functions that help schedule code execution at specific times or intervals.\nUnlike browser JavaScript, Node.js timing functions are provided as part of the Timers module, though they are available globally without requiring an explicit import.\nKey features include:\nDelayed execution with setTimeout()\nRepeated execution with setInterval()\nImmediate execution in the next event loop with setImmediate()\nPromise-based APIs for modern async/await patterns\nThese capabilities are essential for building responsive applications, implementing polling, handling delayed operations, and more.\nGetting Started with Timers\nHere's a quick example of using the Timers module to schedule code execution:\nBasic Timer ExampleGet your own Node.js Server\nUsing the Timers Module\nThe Timers module's functions are available globally, so you don't need to require them explicitly.\nHowever, if you want to access advanced features or for clarity, you can import the module:\nsetTimeout() and clearTimeout()\nThe setTimeout() function schedules execution of a callback after a specified amount of time (in milliseconds).\nIt returns a Timeout object that can be used to cancel the timeout.\nCommon Use Cases\nDelaying execution of non-critical tasks\nImplementing timeouts for operations\nBreaking up CPU-intensive tasks\nImplementing retry logic\nPromise-Based setTimeout\nNode.js 15.0.0 and later provide a promises-based API for timers:\nREMOVE ADS\nsetInterval() and clearInterval()\nThe setInterval() function calls a function repeatedly at specified intervals (in milliseconds).\nIt returns an Interval object that can be used to stop the interval.\nCommon Use Cases\nPolling for updates\nRunning periodic maintenance tasks\nImplementing heartbeat mechanisms\nUpdating UI elements at regular intervals\nNote: The actual interval between executions may be longer than specified if the event loop is blocked by other operations.\nPromise-Based setInterval\nUsing the promises API for intervals:\nsetImmediate() and clearImmediate()\nThe setImmediate() function schedules a callback to run in the next iteration of the event loop, after I/O events but before timers.\nIt's similar to using setTimeout(callback, 0) but more efficient.\nWhen to Use setImmediate()\nWhen you want to execute code after the current operation completes\nTo break up long-running operations into smaller chunks\nTo ensure callbacks run after I/O operations complete\nIn recursive functions to prevent stack overflows\nThe execution order will typically be:\nStart\nEnd\nnextTick callback\nsetTimeout callback or setImmediate callback (order can vary)\nNote: The order of execution between setTimeout(0) and setImmediate() can be unpredictable when called from the main module.\nHowever, inside an I/O callback, setImmediate() will always execute before any timers.\nCanceling an Immediate\nprocess.nextTick()\nAlthough not part of the Timers module, process.nextTick() is a related function that defers a callback until the next iteration of the event loop, but executes it before any I/O events or timers.\nKey Characteristics\nRuns before any I/O events or timers\nHigher priority than setImmediate()\nProcesses all queued callbacks before the event loop continues\nCan lead to I/O starvation if overused\nWhen to Use process.nextTick()\nTo ensure a callback runs after the current operation but before any I/O\nTo break up long-running operations\nTo allow event handlers to be set up after an object is created\nTo ensure consistent API behavior (e.g., making constructors work with or without `new`)\nNote: process.nextTick() fires immediately on the same phase of the event loop, while setImmediate() fires on the following iteration or 'tick' of the event loop.\nAdvanced Timer Patterns\nDebouncing\nPrevent a function from being called too frequently by delaying its execution:\nThrottling\nLimit how often a function can be called over time:\nSequential Timeouts\nExecute a series of operations with delays between them:\nTimer Behavior and Best Practices\nTimer Precision and Performance\nNode.js timers are not precise to the millisecond. The actual delay might be slightly longer due to:\nSystem load and CPU usage\nEvent loop blocking operations\nOther timers and I/O operations\nSystem timer resolution (typically 1-15ms)\nMemory and Resource Management\nProper management of timers is crucial to prevent memory leaks and excessive resource usage:\nAlways clear intervals and timeouts when they're no longer needed\nStore timer IDs in a way that allows for cleanup\nBe cautious with closures in timer callbacks\nUse clearTimeout() and clearInterval() in cleanup functions\nRemember to clear timers when they're no longer needed, especially in long-running applications, to prevent memory leaks:\nZero-Delay Timeouts\nWhen using setTimeout(callback, 0), the callback doesn't execute immediately.\nIt executes after the current event loop cycle completes, which can be used to \"break up\" CPU-intensive tasks:",
      "examples": [
        "const { setTimeout, setInterval, setImmediate } = require('timers');\n\nconsole.log('Starting timers...');\n\n// Execute once after delay\nsetTimeout(() => {\nconsole.log('This runs after 1 second');\n}, 1000);\n\n// Execute repeatedly at interval\nlet counter = 0;\nconst interval = setInterval(() => {\ncounter++;\nconsole.log(`Interval tick ${counter}`);\nif (counter >= 3) clearInterval(interval);\n}, 1000);\n\n// Execute in the next event loop iteration\nsetImmediate(() => {\nconsole.log('This runs in the next iteration of the event loop');\n});\n\nconsole.log('Timers scheduled');",
        "const timers = require('timers');\n\n// Or, for the promises API (Node.js 15.0.0+)\nconst timersPromises = require('timers/promises');",
        "// Basic usage\nsetTimeout(() => {\nconsole.log('This message is displayed after 2 seconds');\n}, 2000);\n\n// With arguments\nsetTimeout((name) => {\nconsole.log(`Hello, ${name}!`);\n}, 1000, 'World');\n\n// Storing and clearing a timeout\nconst timeoutId = setTimeout(() => {\nconsole.log('This will never be displayed');\n}, 5000);\n\n// Cancel the timeout before it executes\nclearTimeout(timeoutId);\nconsole.log('Timeout has been cancelled');",
        "const { setTimeout } = require('timers/promises');\n\nasync function delayedGreeting() {\nconsole.log('Starting...');\n\n// Wait for 2 seconds\nawait setTimeout(2000);\n\nconsole.log('After 2 seconds');\n\n// Wait for 1 second with a value\nconst result = await setTimeout(1000, 'Hello, World!');\n\nconsole.log('After 1 more second:', result);\n}\n\ndelayedGreeting().catch(console.error);",
        "// Basic interval\nlet counter = 0;\nconst intervalId = setInterval(() => {\ncounter++;\nconsole.log(`Interval executed ${counter} times`);\n\n// Stop after 5 executions\nif (counter >= 5) {\nclearInterval(intervalId);\nconsole.log('Interval stopped');\n}\n}, 1000);\n\n// Interval with arguments\nconst nameInterval = setInterval((name) => {\nconsole.log(`Hello, ${name}!`);\n}, 2000, 'Node.js');\n\n// Stop the name interval after 6 seconds\nsetTimeout(() => {\nclearInterval(nameInterval);\nconsole.log('Name interval stopped');\n}, 6000);",
        "const { setInterval } = require('timers/promises');\n\nasync function repeatedGreeting() {\nconsole.log('Starting interval...');\n\n// Create an async iterator from setInterval\nconst interval = setInterval(1000, 'tick');\n\n// Limit to 5 iterations\nlet counter = 0;\n\nfor await (const tick of interval) {\nconsole.log(counter + 1, tick);\ncounter++;\n\nif (counter >= 5) {\nbreak; // Exit the loop, stopping the interval\n}\n}\n\nconsole.log('Interval finished');\n}\n\nrepeatedGreeting().catch(console.error);",
        "console.log('Start');\n\nsetTimeout(() => {\nconsole.log('setTimeout callback');\n}, 0);\n\nsetImmediate(() => {\nconsole.log('setImmediate callback');\n});\n\nprocess.nextTick(() => {\nconsole.log('nextTick callback');\n});\n\nconsole.log('End');",
        "const immediateId = setImmediate(() => {\nconsole.log('This will not be displayed');\n});\n\nclearImmediate(immediateId);\nconsole.log('Immediate has been cancelled');",
        "console.log('Start');\n\n// Schedule three different types of callbacks\nsetTimeout(() => {\nconsole.log('setTimeout executed');\n}, 0);\n\nsetImmediate(() => {\nconsole.log('setImmediate executed');\n});\n\nprocess.nextTick(() => {\nconsole.log('nextTick executed');\n});\n\nconsole.log('End');",
        "function debounce(func, delay) {\nlet timeoutId;\nreturn function(...args) {\nclearTimeout(timeoutId);\ntimeoutId = setTimeout(() => func.apply(this, args), delay);\n};\n}\n// Example usage\nconst handleResize = debounce(() => {\nconsole.log('Window resized');\n}, 300);\n// Call handleResize() on window resize",
        "function throttle(func, limit) {\nlet inThrottle = false;\nreturn function(...args) {\nif (!inThrottle) {\nfunc.apply(this, args);\ninThrottle = true;\nsetTimeout(() => inThrottle = false, limit);\n}\n};\n}\n// Example usage\nconst handleScroll = throttle(() => {\nconsole.log('Handling scroll');\n}, 200);\n// Call handleScroll() on window scroll",
        "function sequentialTimeouts(callbacks, delay = 1000) {\nlet index = 0;\nfunction next() {\nif (index < callbacks.length) {\ncallbacks[index]();\nindex++;\nsetTimeout(next, delay);\n}\n}\nnext();\n}\n// Example usage\nsequentialTimeouts([\n() => console.log('Step 1'),\n() => console.log('Step 2'),\n() => console.log('Step 3')\n], 1000);",
        "const desiredDelay = 100; // 100ms\nconst start = Date.now();\n\nsetTimeout(() => {\nconst actualDelay = Date.now() - start;\nconsole.log(`Desired delay: ${desiredDelay}ms`);\nconsole.log(`Actual delay: ${actualDelay}ms`);\nconsole.log(`Difference: ${actualDelay - desiredDelay}ms`);\n}, desiredDelay);",
        "// Leak: Interval keeps running even if not needed\nfunction startService() {\nsetInterval(() => {\nfetchData();\n}, 1000);\n}\n// Leak: Timeout with closure over large object\nfunction processData(data) {\nsetTimeout(() => {\nconsole.log('Processing complete');\n// 'data' is kept in memory until the timeout fires\n}, 10000, data);\n}",
        "// Bad practice in a server context\nfunction startServer() {\nsetInterval(() => {\n// This interval will run forever and prevent proper cleanup\nconsole.log('Server is running...');\n}, 60000);\n}\n\n// Better practice\nfunction startServer() {\nconst intervalId = setInterval(() => {\nconsole.log('Server is running...');\n}, 60000);\n\n// Store the interval ID for later cleanup\nreturn {\nstop: () => {\nclearInterval(intervalId);\nconsole.log('Server stopped');\n}\n};\n}\n\n// Example usage\nconst server = startServer();\n\n// Stop the server after 3 minutes\nsetTimeout(() => {\nserver.stop();\n}, 180000);",
        "function processArray(array, processFunction) {\nconst chunkSize = 1000;\nlet index = 0;\n\nfunction processChunk() {\nconst chunk = array.slice(index, index + chunkSize);\nchunk.forEach(processFunction);\n\nindex += chunkSize;\n\nif (index < array.length) {\nsetTimeout(processChunk, 0); // Yield to the event loop\n} else {\nconsole.log('Processing complete');\n}\n}\n\nprocessChunk();\n}\n\n// Example usage\nconst bigArray = Array(10000).fill().map((_, i) => i);\n\nconsole.log('Starting processing...');\nprocessArray(bigArray, (item) => {\n// Simple processing\nif (item % 5000 === 0) {\nconsole.log(`Processed item ${item}`);\n}\n});\nconsole.log('This will log before processing completes');",
        "setTimeout()",
        "setInterval()",
        "setImmediate()",
        "Timeout",
        "Interval",
        "setTimeout(callback, 0)",
        "setTimeout(0)",
        "process.nextTick()",
        "clearTimeout()",
        "clearInterval()"
      ]
    },
    {
      "title": "Node.js DNS Module",
      "summary": "Introduction to the DNS Module\nThe DNS (Domain Name System) module provides functionality for name resolution in Node.js.\nIt offers two main APIs:\nCallback-based API: Traditional Node.js style with callback functions\nPromise-based API: Modern async/await support via dns.promises\nKey features include:\nResolving domain names to IP addresses (A/AAAA records)\nPerforming reverse DNS lookups (PTR records)\nQuerying various DNS record types (MX, TXT, SRV, etc.)\nCreating custom DNS resolvers with specific settings\nConfiguring DNS server settings programmatically\nNote: The DNS module can operate in two distinct modes - using the operating system's facilities or performing direct network DNS queries.\nThis affects how hostname resolution works in your application.\nGetting Started with DNS\nHere's a quick example of using the DNS module to look up a domain's IP address:\nBasic DNS LookupGet your own Node.js Server\nImporting and Setup\nTo use the DNS module, you can import it in your Node.js application using either the callback or promise-based API:\nCallback-based API\nPromise-based API (Node.js 10.0.0+)\nNote: The promise-based API is generally preferred for new code as it works better with modern async/await patterns and provides better error handling.\nBasic DNS Lookups\nThe DNS module provides several methods for looking up domain names and IP addresses. The most common operations are:\ndns.lookup(): Uses the operating system's facilities to resolve hostnames\ndns.resolve*(): Performs DNS queries directly to name servers\ndns.reverse(): Performs reverse DNS lookups (IP to hostname)\nResolving Domain Names to IP Addresses\nNote: The dns.lookup() method uses the operating system's facilities for name resolution and does not necessarily perform any network communication.\nLooking Up All IP Addresses for a Domain\nREMOVE ADS\nDNS Record Types\nThe DNS module supports lookups for various DNS record types:\nAdvanced DNS Operations\n1. Custom DNS Resolution\nCreate a custom DNS resolver with specific settings for more control over DNS lookups:\nNote: Creating a custom resolver is useful when you want to use specific DNS servers instead of the system's defaults, or when you need different settings for different lookups.\n2. Network vs. Operating System Level Resolution\nThe DNS module offers two different approaches to name resolution:\nWarning: Due to these differences, the results from dns.lookup() and dns.resolve*() methods may not always match, especially in environments with custom host configurations.\n3. Error Handling and Retries\nRobust DNS handling requires proper error management. Here's how to handle common DNS errors and implement retry logic:\nNote: DNS errors can be temporary due to network issues or DNS propagation delays.\nIn production applications, you might want to implement retry logic with exponential backoff.\nPerformance Optimization\nDNS lookups can be a performance bottleneck in applications. Here are strategies to optimize DNS resolution:\n1. Caching\nImplement a simple DNS cache to avoid repeated lookups for the same domain:\n2. Parallel Lookups\nUse Promise.all() to perform multiple DNS lookups in parallel:\n3. Custom Resolvers and Timeouts\nConfigure custom DNS servers and timeouts for better control:\nDNS Module vs. Third-Party DNS Libraries\nPopular third-party DNS libraries for Node.js include:\ndns-packet: Low-level DNS packet encoding/decoding\nnative-dns: More complete DNS implementation\ndns2: Modern DNS library with promise support\nSummary\nThe Node.js DNS module provides essential functionality for interacting with the Domain Name System. Key features include:\nLooking up IP addresses for domain names\nResolving various DNS record types (A, AAAA, MX, TXT, etc.)\nPerforming reverse DNS lookups\nCreating custom resolvers with specific settings\nBoth callback-based and promise-based APIs\nUnderstanding the DNS module is crucial for applications that need to interact with network resources by domain name, implement custom name resolution logic, or verify domain-related information.",
      "examples": [
        "const dns = require('dns');\n\n// Look up a domain name\ndns.lookup('example.com', (err, address, family) => {\nif (err) {\nconsole.error('Lookup error:', err);\nreturn;\n}\nconsole.log(`IP address: ${address}`);\nconsole.log(`IP version: IPv${family}`);\n});",
        "// Import the DNS module\nconst dns = require('dns');\n\n// Example usage\ndns.lookup('example.com', (err, address, family) => {\nif (err) throw err;\nconsole.log(`Resolved: ${address} (IPv${family})`);\n});",
        "// Import the promises API\nconst { promises: dns } = require('dns');\n// Or: const dns = require('dns').promises;\n// Example with async/await\nasync function lookupDomain(domain) {\ntry {\nconst address = await dns.lookup(domain);\nconsole.log(`Resolved: ${address.address} (IPv${address.family})`);\n} catch (err) {\nconsole.error('Lookup failed:', err);\n}\n}\nlookupDomain('example.com');",
        "const dns = require('dns');\n\n// Callback-based API\ndns.lookup('www.example.com', (err, address, family) => {\nif (err) throw err;\nconsole.log('IP address: %s', address);\nconsole.log('IP version: IPv%s', family);\n});",
        "const dns = require('dns').promises;\n\n// Promise-based API\nasync function lookupExample() {\ntry {\nconst result = await dns.lookup('www.example.com');\nconsole.log('IP address:', result.address);\nconsole.log('IP version: IPv' + result.family);\n} catch (err) {\nconsole.error('Lookup failed:', err);\n}\n}\n\nlookupExample();",
        "const dns = require('dns');\n\n// Get all IPv4 addresses\ndns.resolve4('www.google.com', (err, addresses) => {\nif (err) throw err;\n\nconsole.log('IPv4 addresses:');\naddresses.forEach(address => {\nconsole.log(` ${address}`);\n});\n\n// Perform a reverse lookup on the first IP\ndns.reverse(addresses[0], (err, hostnames) => {\nif (err) throw err;\n\nconsole.log(`Reverse lookup for ${addresses[0]}:`);\nhostnames.forEach(hostname => {\nconsole.log(` ${hostname}`);\n});\n});\n});",
        "const dns = require('dns');\n\n// Create a new resolver\nconst resolver = new dns.Resolver();\n\n// Set custom server (Google's public DNS)\nresolver.setServers(['8.8.8.8', '8.8.4.4']);\n\n// Use the custom resolver\nresolver.resolve4('www.example.com', (err, addresses) => {\nif (err) throw err;\n\nconsole.log('Addresses resolved using Google DNS:');\naddresses.forEach(addr => {\nconsole.log(` ${addr}`);\n});\n});\n\n// See what servers are configured\nconsole.log('Current resolver servers:', resolver.getServers());",
        "const dns = require('dns');\n\nfunction lookupWithErrorHandling(domain) {\ndns.lookup(domain, (err, address, family) => {\nif (err) {\nconsole.error(`DNS lookup failed for ${domain}`);\n\n// Check specific error codes\nswitch (err.code) {\ncase 'ENOTFOUND':\nconsole.error(' Domain name not found');\nbreak;\ncase 'ETIMEDOUT':\nconsole.error(' DNS lookup timed out');\nbreak;\ncase 'ENODATA':\nconsole.error(' Domain exists but no data of requested type');\nbreak;\ncase 'ESERVFAIL':\nconsole.error(' DNS server returned general failure');\nbreak;\ndefault:\nconsole.error(` Error code: ${err.code}`);\n}\n\nreturn;\n}\n\nconsole.log(`DNS lookup successful for ${domain}`);\nconsole.log(` IP address: ${address}`);\nconsole.log(` IP version: IPv${family}`);\n});\n}\n\n// Test with valid and invalid domains\nlookupWithErrorHandling('www.google.com');\nlookupWithErrorHandling('this-domain-does-not-exist-123456789.com');",
        "const dns = require('dns');\nconst util = require('util');\nconst lookup = util.promisify(dns.lookup);\nconst dnsCache = new Map();\nasync function cachedLookup(domain) {\nif (dnsCache.has(domain)) {\nconsole.log('Cache hit for:', domain);\nreturn dnsCache.get(domain);\n}\nconsole.log('Cache miss for:', domain);\nconst result = await lookup(domain);\ndnsCache.set(domain, result);\nreturn result;\n}\n// Example usage\n(async () => {\nconst domains = ['google.com', 'facebook.com', 'google.com'];\nfor (const domain of domains) {\nconst result = await cachedLookup(domain);\nconsole.log(`${domain} → ${result.address}`);\n}\n})();",
        "const dns = require('dns').promises;\nasync function lookupMultiple(domains) {\ntry {\nconst lookups = domains.map(domain => dns.lookup(domain));\nconst results = await Promise.all(lookups);\nreturn domains.map((domain, i) => ({\ndomain,\n...results[i]\n}));\n} catch (err) {\nconsole.error('One or more lookups failed:', err);\nthrow err;\n}\n}\n// Example usage\nlookupMultiple(['google.com', 'facebook.com', 'github.com'])\n.then(results => console.log(results))\n.catch(console.error);",
        "const dns = require('dns');\nconst { Resolver } = dns;\n\n// Create a custom resolver with timeout\nconst resolver = new Resolver();\nresolver.setServers(['8.8.8.8', '1.1.1.1']); // Google and Cloudflare DNS\n// Set timeout for all operations (in ms)\nconst TIMEOUT = 2000;\nasync function resolveWithTimeout(domain, rrtype = 'A') {\nreturn new Promise((resolve, reject) => {\nconst timer = setTimeout(() => {\nreject(new Error(`DNS query timed out after ${TIMEOUT}ms`));\n}, TIMEOUT);\n\nresolver.resolve(domain, rrtype, (err, addresses) => {\nclearTimeout(timer);\nif (err) return reject(err);\nresolve(addresses);\n});\n});\n}\n// Example usage\nresolveWithTimeout('example.com')\n.then(console.log)\n.catch(console.error);",
        "dns.promises",
        "dns.lookup()",
        "dns.resolve*()",
        "dns.reverse()",
        "resolve4()",
        "resolve6()",
        "resolveMx()",
        "resolveTxt()",
        "resolveSrv()",
        "resolveNs()",
        "resolveCname()",
        "resolveSoa()",
        "resolvePtr()",
        "resolveNaptr()",
        "resolveAny()",
        "getaddrinfo()",
        "dns.resolve*(), dns.reverse()",
        "Promise.all()",
        "dns-packet",
        "native-dns",
        "dns2"
      ]
    },
    {
      "title": "Node.js Assert Module",
      "summary": "What is the Assert Module?\nThe Assert module provides a simple yet powerful set of assertion tests for validating invariants in your code.\nIt's a core Node.js module that doesn't require installation.\nKey features include:\nSimple truthy/falsy assertions\nStrict and loose equality checks\nDeep object comparison\nError throwing and handling\nSupport for async/await patterns\nNote: While not as feature-rich as testing frameworks like Jest or Mocha, the Assert module is lightweight and perfect for simple testing needs or when you want to avoid external dependencies.\nGetting Started with Assert\nHere's a quick example of using the Assert module to test a simple function:\nBasic Assertion ExampleGet your own Node.js Server\nImporting and Setup\nThere are several ways to import and use the Assert module in your Node.js application:\nCommonJS Import (Node.js)\nES Modules (Node.js 12+)\nBest Practice: The strict mode is recommended as it provides more accurate comparisons and better error messages.\nIt's also more aligned with future versions of Node.js where strict mode will be the default.\nCore Assertion Methods\nThe Assert module provides several methods for making assertions about values in your code.\nThese methods form the foundation of testing with the Assert module.\nassert(value[, message])\nTests if a value is truthy. If the value is falsy, an AssertionError is thrown.\nassert.ok(value[, message])\nThis is an alias for assert().\nValue Comparison\nThe Assert module provides multiple ways to compare values, each with different behaviors regarding type coercion and object comparison.\nassert.equal(actual, expected[, message])\nTests shallow, coercive equality between the actual and expected parameters using the equality operator (==).\nassert.strictEqual(actual, expected[, message])\nTests strict equality between the actual and expected parameters using the strict equality operator (===).\nBest Practice: It's recommended to use strictEqual() over equal() to avoid unexpected type coercion issues.\nObject and Array Comparison\nWhen working with objects and arrays, you'll need to use deep equality checks to compare their contents rather than just their references.\nFor comparing objects and arrays, Node.js provides deep equality functions:\nTests for deep equality between the actual and expected parameters with loose equality (==).\nTests for deep equality between the actual and expected parameters with strict equality (===).\nInequality and Negation\nJust as important as checking for equality is verifying that values are not equal when they shouldn't be.\nassert.notEqual(actual, expected[, message])\nTests shallow, coercive inequality using the inequality operator (!=).\nassert.notStrictEqual(actual, expected[, message])\nTests strict inequality using the strict inequality operator (!==).\nDeep Inequality\nTests for deep inequality with loose inequality.\nTests for deep inequality with strict inequality.\nError Handling\nTesting that your code throws the expected errors is a critical part of writing robust applications.\nThe Assert module provides several methods for this purpose.\nassert.throws(fn[, error][, message])\nExpects the function fn to throw an error. If not, an AssertionError is thrown.\nassert.doesNotThrow(fn[, error][, message])\nExpects the function fn to not throw an error. If it does, the error is propagated.\nTesting Asynchronous Code\nModern JavaScript makes heavy use of asynchronous patterns.\nThe Assert module provides utilities for testing both Promise-based and callback-based asynchronous code.\nassert.rejects(asyncFn[, error][, message])\nAwaits the asyncFn promise or async function and expects it to reject.\nassert.doesNotReject(asyncFn[, error][, message])\nAwaits the asyncFn promise or async function and expects it to fulfill.\nOther Assertion Methods\nassert.match(string, regexp[, message])\nExpects the string input to match the regular expression.\nassert.fail([message])\nThrows an AssertionError with the provided message or a default message.\nStrict Mode\nNode.js provides a strict mode for assertions which uses strict equality for all comparisons.\nIt's recommended to use strict mode for more predictable results.\nWhen to Use Node.js Assert vs Testing Frameworks\nUse Node.js Assert When:\nWriting simple scripts or small utilities\nCreating quick tests during development\nYou want to avoid external dependencies\nBuilding internal Node.js modules\nUse a Testing Framework (Jest, Mocha, etc.) When:\nWorking on larger projects\nYou need features like test runners, reporters, and mocking\nBuilding applications that require comprehensive test coverage\nYou need better error reporting and test organization\nFor serious application testing, consider using the built-in Node.js Test Runner introduced in Node.js v18 or a dedicated testing framework like Jest, Mocha, or AVA.",
      "examples": [
        "const assert = require('assert').strict;\n\n// Function to test\nfunction add(a, b) {\nif (typeof a !== 'number' || typeof b !== 'number') {\nthrow new TypeError('Inputs must be numbers');\n}\nreturn a + b;\n}\n// Test cases\nassert.strictEqual(add(2, 3), 5, '2 + 3 should equal 5');\n// Test error case\nassert.throws(\n() => add('2', 3),\nTypeError,\n'Should throw TypeError for non-number input'\n);\nconsole.log('All tests passed!');",
        "// Basic require\nconst assert = require('assert');\n\n// Using strict mode (recommended)\nconst assert = require('assert').strict;\n\n// Destructuring specific methods\nconst { strictEqual, deepStrictEqual, throws } = require('assert');\n\n// For async/await tests\nconst { rejects, doesNotReject } = require('assert').strict;",
        "// Using default import\nimport assert from 'assert';\n\n// Using strict mode with ESM\nimport { strict as assert } from 'assert';\n\n// Importing specific methods\nimport { strictEqual, deepStrictEqual } from 'assert';\n\n// Dynamic import\nconst { strict: assert } = await import('assert');",
        "const assert = require('assert');\n\n// This will pass\nassert(true);\nassert(1);\nassert('string');\nassert({});\n\ntry {\n// This will throw an AssertionError\nassert(false, 'This value is not truthy');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}\n\ntry {\n// These will also throw errors\nassert(0);\nassert('');\nassert(null);\nassert(undefined);\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "const assert = require('assert');\n\n// These assertions are equivalent\nassert.ok(true, 'This value is truthy');\nassert(true, 'This value is truthy');",
        "const assert = require('assert');\n\n// These will pass (coercive equality)\nassert.equal(1, 1);\nassert.equal('1', 1); // String is coerced to number\nassert.equal(true, 1); // Boolean is coerced to number\n\ntry {\n// This will throw an error\nassert.equal(1, 2, '1 is not equal to 2');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "const assert = require('assert');\n\n// This will pass\nassert.strictEqual(1, 1);\n\ntry {\n// These will throw errors (strict equality)\nassert.strictEqual('1', 1, 'String \"1\" is not strictly equal to number 1');\nassert.strictEqual(true, 1, 'true is not strictly equal to 1');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "const assert = require('assert');\n\n// Objects with the same structure\nconst obj1 = { a: 1, b: { c: 2 } };\nconst obj2 = { a: 1, b: { c: 2 } };\nconst obj3 = { a: '1', b: { c: '2' } };\n\n// These will pass\nassert.deepEqual(obj1, obj2);\nassert.deepStrictEqual(obj1, obj2);\n\n// This will pass (loose equality)\nassert.deepEqual(obj1, obj3);\n\ntry {\n// This will throw an error (strict equality)\nassert.deepStrictEqual(obj1, obj3, 'Objects are not strictly deep-equal');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}\n\n// Arrays\nconst arr1 = [1, 2, [3, 4]];\nconst arr2 = [1, 2, [3, 4]];\nconst arr3 = ['1', '2', ['3', '4']];\n\n// These will pass\nassert.deepEqual(arr1, arr2);\nassert.deepStrictEqual(arr1, arr2);\n\n// This will pass (loose equality)\nassert.deepEqual(arr1, arr3);\n\ntry {\n// This will throw an error (strict equality)\nassert.deepStrictEqual(arr1, arr3, 'Arrays are not strictly deep-equal');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "const assert = require('assert');\n\n// These will pass\nassert.notEqual(1, 2);\nassert.notStrictEqual('1', 1);\n\ntry {\n// This will throw an error\nassert.notEqual(1, '1', '1 is coercively equal to \"1\"');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}\n\ntry {\n// This will throw an error\nassert.notStrictEqual(1, 1, '1 is strictly equal to 1');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "const assert = require('assert');\n\nconst obj1 = { a: 1, b: 2 };\nconst obj2 = { a: 1, b: 3 };\nconst obj3 = { a: '1', b: '2' };\n\n// These will pass\nassert.notDeepEqual(obj1, obj2);\nassert.notDeepStrictEqual(obj1, obj2);\nassert.notDeepStrictEqual(obj1, obj3);\n\ntry {\n// This will throw an error (loose equality)\nassert.notDeepEqual(obj1, obj3, 'obj1 is loosely deep-equal to obj3');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "const assert = require('assert');\n\n// Function that throws an error\nfunction throwingFunction() {\nthrow new Error('Error thrown');\n}\n\n// This will pass\nassert.throws(throwingFunction);\n\n// Check for a specific error message\nassert.throws(\nthrowingFunction,\n/Error thrown/,\n'Unexpected error message'\n);\n\n// Check for a specific error type\nassert.throws(\nthrowingFunction,\nError,\n'Wrong error type'\n);\n\n// Check with a validation function\nassert.throws(\nthrowingFunction,\nfunction(err) {\nreturn err instanceof Error && /thrown/.test(err.message);\n},\n'Error validation failed'\n);\n\ntry {\n// This will throw an AssertionError\nassert.throws(() => {\n// This function doesn't throw\nreturn 'no error';\n}, 'Expected function to throw');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "const assert = require('assert');\n\n// This will pass\nassert.doesNotThrow(() => {\nreturn 'no error';\n});\n\ntry {\n// This will throw the original error\nassert.doesNotThrow(() => {\nthrow new Error('This will be thrown');\n}, 'Unexpected error');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "const assert = require('assert');\n\nasync function asyncTest() {\n// Function that returns a rejecting promise\nfunction failingAsyncFunction() {\nreturn Promise.reject(new Error('Async error'));\n}\n\n// This will pass\nawait assert.rejects(\nfailingAsyncFunction(),\n/Async error/\n);\n\n// This will also pass\nawait assert.rejects(\nasync () => {\nthrow new Error('Async function error');\n},\n{\nname: 'Error',\nmessage: 'Async function error'\n}\n);\n\ntry {\n// This will throw an AssertionError\nawait assert.rejects(\nPromise.resolve('success'),\n'Expected promise to reject'\n);\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}\n}\n\n// Run the async test\nasyncTest().catch(err => console.error(`Unhandled error: ${err.message}`));",
        "const assert = require('assert');\n\nasync function asyncTest() {\n// This will pass\nawait assert.doesNotReject(\nPromise.resolve('success')\n);\n\n// This will also pass\nawait assert.doesNotReject(\nasync () => {\nreturn 'async function success';\n}\n);\n\ntry {\n// This will throw the original rejection reason\nawait assert.doesNotReject(\nPromise.reject(new Error('Failure')),\n'Expected promise to fulfill'\n);\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}\n}\n\n// Run the async test\nasyncTest().catch(err => console.error(`Unhandled error: ${err.message}`));",
        "const assert = require('assert');\n\n// This will pass\nassert.match('I love Node.js', /Node\\.js/);\n\ntry {\n// This will throw an AssertionError\nassert.match('Hello World', /Node\\.js/, 'String does not match the pattern');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "const assert = require('assert');\n\ntry {\n// This always throws an AssertionError\nassert.fail('This test always fails');\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "// Import the strict version of assert\nconst assert = require('assert').strict;\n\n// These are equivalent\nassert.strictEqual(1, 1);\nassert.equal(1, 1); // In strict mode, this is the same as strictEqual\n\n// These are equivalent\nassert.deepStrictEqual({ a: 1 }, { a: 1 });\nassert.deepEqual({ a: 1 }, { a: 1 }); // In strict mode, this is the same as deepStrictEqual\n\ntry {\n// This will throw an error in strict mode\nassert.equal('1', 1);\n} catch (err) {\nconsole.error(`Error: ${err.message}`);\n}",
        "assert()",
        "assert.equal(actual, expected[, message])",
        "==",
        "assert.strictEqual(actual, expected[, message])",
        "===",
        "strictEqual()",
        "equal()",
        "assert.deepEqual(actual, expected[, message])",
        "assert.deepStrictEqual(actual, expected[, message])",
        "assert.notEqual(actual, expected[, message])",
        "!=",
        "assert.notStrictEqual(actual, expected[, message])",
        "!==",
        "assert.notDeepEqual(actual, expected[, message])",
        "assert.notDeepStrictEqual(actual, expected[, message])",
        "assert.throws(fn[, error][, message])",
        "fn",
        "assert.doesNotThrow(fn[, error][, message])",
        "assert.rejects(asyncFn[, error][, message])",
        "asyncFn",
        "assert.doesNotReject(asyncFn[, error][, message])",
        "assert.match(string, regexp[, message])",
        "assert.fail([message])"
      ]
    },
    {
      "title": "Node.js Util Module",
      "summary": "What is the Util Module?\nThe Util module is a core Node.js module that provides a collection of utility functions for common tasks.\nIt's like a Swiss Army knife for Node.js developers, offering solutions for:\nFormatting strings with placeholders\nInspecting objects for debugging\nConverting between callbacks and Promises\nType checking and validation\nHandling deprecation warnings\nDebugging and logging\nNo external dependencies\nPerformance-optimized utilities\nConsistent with Node.js core\nGreat for debugging and development\nUseful for production code\nNote: While some functions in the Util module are designed for internal use by Node.js itself, many are valuable tools for developers building Node.js applications.\nThe module is included with Node.js, so no installation is required.\nGetting Started with Util\nHere's a practical example that demonstrates several utilities from the Util module in action:\nBasic Usage ExampleGet your own Node.js Server\nImporting and Setup\nThe Util module can be imported in several ways depending on your module system and needs:\nCommonJS (Node.js default)\nES Modules (Node.js 12+)\nBest Practice: For better tree-shaking and smaller bundles, prefer destructuring imports of only the functions you need.\nThe Util module is quite large, and you typically only use a small subset of its functionality.\nString Formatting and Inspection\nThe Util module provides powerful tools for formatting strings and inspecting objects, which are particularly useful for logging and debugging.\nutil.format(format[, ...args])\nReturns a formatted string using the first argument as a printf-like format string.\nThis is similar to console.log() but returns the formatted string instead of printing it.\nFormat Specifiers:\n%s - String\n%d - Number (both integer and float)\n%i - Integer\n%f - Floating point value\n%j - JSON (replaced with '[Circular]' if the argument contains circular references)\n%o - Object (inspect the object)\n%O - Object (inspect the object, with full detail)\n%% - Single percent sign ('%')\nutil.inspect(object[, options])\nReturns a string representation of an object, useful for debugging.\nThis is what Node.js uses internally for printing objects to the console.\nCommon Use Cases:\nDebugging complex objects\nCreating human-readable object representations\nLogging objects with circular references\nCustomizing object display in logs\nCommon Options:\nshowHidden - Show non-enumerable properties (default: false)\ndepth - Number of levels to recurse (default: 2, null for unlimited)\ncolors - Add ANSI color codes (default: false)\ncustomInspect - Use custom inspect functions (default: true)\nshowProxy - Show Proxy details (default: false)\nmaxArrayLength - Maximum number of array elements to include (default: 100)\nbreakLength - Length at which to break object keys (default: 60)\ncompact - Break properties onto new lines (default: true for arrays, false for objects)\nsorted - Sort properties (default: false, true for alphabetical, function for custom sort)\nutil.inspect.custom\nSymbol used to customize object inspection.\nThis allows objects to define their own string representation when inspected.\nBest Practices:\nUse util.inspect.custom for custom inspection rather than inspect() method for better compatibility\nKeep the custom inspection output concise and informative\nInclude important object state in the output\nConsider performance for frequently inspected objects\nHandle circular references to prevent infinite recursion\nPromises and Async Utilities\nNode.js's Util module provides several utilities for working with asynchronous code, making it easier to work with both callback-based and Promise-based APIs.\nutil.promisify(original)\nConverts a callback-based function following the Node.js callback pattern to a function that returns a Promise.\nThis is useful for working with older Node.js APIs that use callbacks.\nWhen to use util.promisify:\nWorking with older Node.js APIs that use callbacks\nConverting callback-based libraries to use Promises\nSimplifying async/await code by removing callbacks\nWorking with functions that follow the Node.js callback pattern (error-first, single result)\nLimitations:\nOnly works with functions that follow the Node.js callback pattern: (err, value) => {}\nDoesn't work with functions that return multiple values in the callback\nCustom promisification may be needed for more complex APIs\nutil.callbackify(original)\nConverts a function that returns a Promise to a function that follows the Node.js callback pattern.\nThis is useful for working with older Node.js APIs that expect callback functions.\nWhen to use util.callbackify:\nIntegrating Promise-based code with callback-based APIs\nMaintaining backward compatibility in libraries\nWorking with APIs that expect Node.js-style callbacks\nGradually migrating from callbacks to Promises\nBest Practices:\nPrefer using Promises directly when possible\nDocument that the function uses callbacks in its JSDoc\nConsider providing both Promise and callback interfaces in your APIs\nHandle Promise rejections properly in the callback\nutil.promisify.custom\nSymbol to customize promisification behavior. This allows you to provide a custom implementation when a function is promisified.\nUse cases for custom promisification:\nFunctions that don't follow the standard callback pattern\nAPIs that return multiple values in the callback\nCustom error handling or transformation of results\nOptimizing performance for specific use cases\nAdding additional functionality during promisification\nType Checking Utilities\nThe Util module provides comprehensive type checking utilities that are more reliable than JavaScript's typeof operator, especially for built-in objects and Node.js-specific types.\nWhy use util.types?\nMore accurate than typeof for many built-in types\nConsistent behavior across Node.js versions\nWorks with Node.js-specific types like Buffer\nBetter performance than manual type checking in many cases\nHandles edge cases properly (e.g., cross-realm objects)\nMany of the type-checking functions in util are deprecated in favor of util.types or JavaScript's built-in type checking methods like Array.isArray().\nutil.types\nThe util.types provides type checking functions for various JavaScript types and Node.js-specific objects:\nDeprecation Utilities\nNode.js provides utilities to help manage API deprecations, making it easier to evolve your codebase while maintaining backward compatibility.\nDeprecation Strategy:\nMark deprecated functions with util.deprecate()\nProvide clear migration instructions in the deprecation message\nInclude a deprecation code for easier tracking\nDocument the deprecation in your API docs\nRemove deprecated functionality in a future major version\nutil.deprecate(fn, msg[, code])\nMarks a function as deprecated, issuing a warning when it's called.\nManaging Deprecation Warnings\nYou can control the display of deprecation warnings using environment variables:\nDebugging and Development Utilities\nNode.js provides several utilities to aid in debugging and development, making it easier to diagnose issues and understand application behavior.\nutil.debuglog(section)\nCreates a function that conditionally writes debug messages to stderr based on the NODE_DEBUG environment variable.\nThis is a lightweight alternative to full-featured logging libraries.\nBest Practices for Debug Logging:\nUse descriptive section names that match your application's modules\nInclude relevant context in debug messages\nUse string placeholders for better performance\nKeep debug messages concise but informative\nConsider the performance impact of computing values for debug messages\nExample Usage:",
      "examples": [
        "const util = require('util');\nconst fs = require('fs');\n\n// Convert callback-based fs.readFile to Promise-based\nconst readFile = util.promisify(fs.readFile);\n// Format strings with placeholders\nconst greeting = util.format('Hello, %s! Today is %s', 'Developer', new Date().toDateString());\nconsole.log(greeting);\n// Inspect an object with custom options\nconst obj = {\nname: 'Test',\nnested: { a: 1, b: [2, 3] },\nfn: function() { return 'test'; }\n};\nconsole.log(util.inspect(obj, { colors: true, depth: 2 }));\n// Use debug logging\nconst debug = util.debuglog('app');\ndebug('This will only show if NODE_DEBUG=app');\n// Example of using promisify with async/await\nasync function readConfig() {\ntry {\nconst data = await readFile('package.json', 'utf8');\nconsole.log('Package name:', JSON.parse(data).name);\n} catch (err) {\nconsole.error('Error reading config:', err);\n}\n}\nreadConfig();",
        "// Import the entire module\nconst util = require('util');\n\n// Import specific functions using destructuring\nconst { promisify, inspect, format } = require('util');\n\n// Using strict mode (recommended)\nconst assert = require('assert').strict;\n\n// For TypeScript users\n// import * as util from 'util';\n// import { promisify, inspect } from 'util';",
        "// Default import\nimport util from 'util';\n\n// Named imports\nimport { promisify, inspect } from 'util';\n\n// Rename imports\nimport { promisify as pify } from 'util';\n\n// Dynamic import (Node.js 14+)\nconst { promisify } = await import('util');\n\n// Using with TypeScript types\n// import * as util from 'util';\n// import type { InspectOptions } from 'util';",
        "const util = require('util');\n\n// Basic formatting\nconst formatted = util.format('Hello, %s!', 'World');\nconsole.log(formatted); // 'Hello, World!'\n\n// Multiple placeholders\nconst multiFormatted = util.format(\n'My name is %s. I am %d years old and I love %s.',\n'Kai',\n30,\n'Node.js'\n);\nconsole.log(multiFormatted);\n// 'My name is Kai. I am 30 years old and I love Node.js.'\n\n// Available specifiers\nconst specifiers = util.format(\n'String: %s, Number: %d, JSON: %j, Character: %c',\n'hello',\n42,\n{ name: 'Object' },\n65  // ASCII code for 'A'\n);\nconsole.log(specifiers);\n\n// Extra arguments are concatenated with spaces\nconst extra = util.format('Hello', 'World', 'from', 'Node.js');\nconsole.log(extra); // 'Hello World from Node.js'",
        "const util = require('util');\n\n// Basic usage\nconst obj = {\nname: 'John',\nage: 30,\nhobbies: ['reading', 'coding'],\naddress: {\ncity: 'New York',\ncountry: 'USA'\n},\ntoString() {\nreturn `${this.name}, ${this.age}`;\n}\n};\n\n// Default inspection\nconsole.log(util.inspect(obj));\n\n// Custom options\nconsole.log(util.inspect(obj, {\ncolors: true, // Add ANSI color codes\ndepth: 0, // Only inspect the first level\nshowHidden: true, // Show non-enumerable properties\ncompact: false, // Don't format objects on a single line\nshowProxy: true, // Show proxy details\nmaxArrayLength: 3, // Limit array elements displayed\nbreakLength: 50, // Line break after 50 characters\nsorted: true // Sort object properties alphabetically\n}));\n\n// Circular references\nconst circular = { name: 'Circular' };\ncircular.self = circular;\nconsole.log(util.inspect(circular));",
        "const util = require('util');\n\n// Class with custom inspection\nclass Person {\nconstructor(name, age) {\nthis.name = name;\nthis.age = age;\nthis._private = 'hidden information';\n}\n\n// Custom inspect method\n[util.inspect.custom](depth, options) {\nreturn `Person(${this.name}, ${this.age})`;\n}\n}\nconst kai = new Person('Kai', 30);\n\n// Custom inspection is used\nconsole.log(util.inspect(kai)); // Person(Kai, 30)\n\n// Directly using console.log also uses custom inspection\nconsole.log(kai); // Person(Kai, 30)",
        "const util = require('util');\nconst fs = require('fs');\n\n// Convert fs.readFile from callback-based to Promise-based\nconst readFilePromise = util.promisify(fs.readFile);\n\n// Now we can use it with async/await or Promise chaining\nasync function readFileExample() {\ntry {\n// Using the promisified function\nconst data = await readFilePromise('package.json', 'utf8');\nconsole.log('File content:', data.substring(0, 100) + '...');\n\n// Error handling with try/catch\nreturn 'File read successfully';\n} catch (err) {\nconsole.error('Error reading file:', err.message);\nreturn 'Error reading file';\n}\n}\n\nreadFileExample().then(result => {\nconsole.log('Result:', result);\n});",
        "const util = require('util');\n\n// A Promise-based function\nasync function fetchUserData(id) {\nif (!id) {\nthrow new Error('ID is required');\n}\n\n// Simulate API request\nreturn {\nid,\nname: `User ${id}`,\nemail: `user${id}@example.com`\n};\n}\n\n// Convert to callback-based\nconst fetchUserDataCallback = util.callbackify(fetchUserData);\n\n// Using the callback-based function\nfetchUserDataCallback(1, (err, user) => {\nif (err) {\nconsole.error('Error:', err);\nreturn;\n}\n\nconsole.log('User data:', user);\n});\n\n// Error handling\nfetchUserDataCallback(null, (err, user) => {\nif (err) {\nconsole.error('Error occurred:', err.message);\nreturn;\n}\n\nconsole.log('User data:', user); // This won't execute\n});",
        "const util = require('util');\n\n// Function with custom promisification\nfunction doSomething(options, callback) {\ncallback(null, 'regular result');\n}\n\n// Define custom promisification\ndoSomething[util.promisify.custom] = (options) => {\nreturn Promise.resolve('custom promisified result');\n};\n\n// Use the custom promisification\nconst promisified = util.promisify(doSomething);\n\n// Compare the results\nasync function compareResults() {\n// Original function with callback\ndoSomething({}, (err, result) => {\nconsole.log('Callback result:', result);\n});\n\n// Custom promisified function\nconst customResult = await promisified({});\nconsole.log('Promisified result:', customResult);\n}\n\ncompareResults();",
        "const util = require('util');\n\n// Example values\nconst values = [\n'string',\n123,\ntrue,\nSymbol('symbol'),\n{ key: 'value' },\n[1, 2, 3],\nnull,\nundefined,\n() => {},\nBigInt(123),\nnew Date(),\n/regex/,\nBuffer.from('buffer'),\nnew Error('error')\n];\n\n// Check types for each value\nvalues.forEach(value => {\nconsole.log(`Value: ${util.inspect(value)}`);\nconsole.log(`- isArray: ${util.types.isArrayBuffer(value)}`);\nconsole.log(`- isDate: ${util.types.isDate(value)}`);\nconsole.log(`- isRegExp: ${util.types.isRegExp(value)}`);\nconsole.log(`- isNativeError: ${util.types.isNativeError(value)}`);\nconsole.log(`- isPromise: ${util.types.isPromise(value)}`);\nconsole.log(`- isPrimitive: ${util.isPrimitive(value)}`);\nconsole.log(`- isString: ${util.isString(value)}`);\nconsole.log(`- isNumber: ${util.isNumber(value)}`);\nconsole.log(`- isBoolean: ${util.isBoolean(value)}`);\nconsole.log(`- isSymbol: ${util.types.isSymbol(value)}`);\nconsole.log(`- isNull: ${value === null}`);\nconsole.log(`- isUndefined: ${value === undefined}`);\nconsole.log(`- isFunction: ${util.types.isFunction(value)}`);\nconsole.log(`- isBuffer: ${Buffer.isBuffer(value)}`);\nconsole.log('---');\n});",
        "const util = require('util');\n\n// JavaScript built-in types\nconsole.log('util.types.isDate(new Date()):',\nutil.types.isDate(new Date()));\nconsole.log('util.types.isRegExp(/test/):',\nutil.types.isRegExp(/test/));\nconsole.log('util.types.isPromise(Promise.resolve()):',\nutil.types.isPromise(Promise.resolve()));\n\n// Node.js-specific types\nconsole.log('util.types.isArrayBuffer(new ArrayBuffer(0)):',\nutil.types.isArrayBuffer(new ArrayBuffer(0)));\nconsole.log('util.types.isSharedArrayBuffer(new SharedArrayBuffer(0)):',\nutil.types.isSharedArrayBuffer(new SharedArrayBuffer(0)));\nconsole.log('util.types.isUint8Array(new Uint8Array()):',\nutil.types.isUint8Array(new Uint8Array()));\n\n// More advanced types\nconsole.log('util.types.isProxy(new Proxy({}, {})):',\nutil.types.isProxy(new Proxy({}, {})));\nconsole.log('util.types.isExternal(Requiring C++ binding):',\n'Not demonstrated in this example');",
        "const util = require('util');\n\n// Original function\nfunction oldFunction(x, y) {\nreturn x + y;\n}\n\n// Deprecate the function\nconst deprecatedFunction = util.deprecate(\noldFunction,\n'oldFunction() is deprecated. Use newFunction() instead.',\n'DEP0001'\n);\n\n// New function\nfunction newFunction(x, y) {\nreturn x + y;\n}\n\n// Using the deprecated function will show a warning\nconsole.log('Result:', deprecatedFunction(5, 10));\n\n// Using the new function\nconsole.log('Result:', newFunction(5, 10));",
        "# Show all deprecation warnings\nNODE_OPTIONS='--trace-deprecation'\n\n# Show only the first occurrence of each deprecation\nNODE_OPTIONS='--no-deprecation'\n\n# Silence all deprecation warnings\nNODE_OPTIONS='--no-warnings'\n\n# Turn deprecation warnings into exceptions\nNODE_OPTIONS='--throw-deprecation'",
        "// Enable debug logging for specific modules\n// NODE_DEBUG=app,db node your-app.js\n\n// In your application\nconst debugApp = util.debuglog('app');\nconst debugDB = util.debuglog('db');\n\n// These will only log when 'app' is in NODE_DEBUG\ndebugApp('Application started with config: %j', config);\n\n// These will only log when 'db' is in NODE_DEBUG\ndebugDB('Connected to database: %s', connectionString);\n\n// Enable all debug logs (not recommended in production)\n// NODE_DEBUG=* node your-app.js",
        "const util = require('util');\n\n// Create debug loggers for different sections\nconst debugApp = util.debuglog('app');\nconst debugDB = util.debuglog('db');\nconst debugAuth = util.debuglog('auth');\n\n// These messages only appear when NODE_DEBUG includes 'app'\ndebugApp('Application starting...');\ndebugApp('Configuration loaded from %j', { source: 'config.json' });\n\n// These messages only appear when NODE_DEBUG includes 'db'\ndebugDB('Connected to database');\ndebugDB('Query executed: %s', 'SELECT * FROM users');\n\n// These messages only appear when NODE_DEBUG includes 'auth'\ndebugAuth('User authenticated: %s', 'john.doe');\n\n// To see these messages, run your app with:\n// NODE_DEBUG=app,db node your-app.js\nconsole.log('Application running normally (this always shows)');",
        "console.log()",
        "%s",
        "%d",
        "%i",
        "%f",
        "%j",
        "'[Circular]'",
        "%o",
        "%O",
        "%%",
        "showHidden",
        "depth",
        "colors",
        "customInspect",
        "showProxy",
        "maxArrayLength",
        "breakLength",
        "compact",
        "sorted",
        "util.inspect.custom",
        "inspect()",
        "util.promisify",
        "(err, value) => {}",
        "util.callbackify",
        "typeof",
        "util.types",
        "Buffer",
        "util",
        "Array.isArray()",
        "util.deprecate()",
        "stderr",
        "NODE_DEBUG"
      ]
    },
    {
      "title": "Node.js Readline Module",
      "summary": "Introduction to the Readline Module\nThe Readline module is a core Node.js module that provides an interface for reading data from a Readable stream (like process.stdin) one line at a time.\nIt's particularly useful for:\nInteractive command-line applications\nConfiguration wizards and setup tools\nCommand-line games\nREPL (Read-Eval-Print Loop) environments\nProcessing large text files line by line\nBuilding custom shells and CLIs\nLine-by-line input processing\nCustomizable prompts and formatting\nTab completion support\nHistory management\nEvent-driven interface\nPromise-based API support\nNote: The Readline module is built into Node.js, so no additional installation is required.\nIt's perfect for any application that needs to interact with users through the command line or process text input in a line-oriented way.\nGetting Started with Readline\nHere's a quick example of using the Readline module to create a simple interactive command-line application:\nBasic Interactive PromptGet your own Node.js Server\nImporting and Setup\nThe Readline module can be imported in several ways depending on your module system and needs:\nCommonJS (Node.js default)\nES Modules (Node.js 12+)\nBest Practice: Always close the readline interface using rl.close() when you're done with it to free up system resources and allow your program to exit cleanly.\nCreating a Readline Interface\nThe createInterface method is the main way to create a readline interface. It takes an options object with several configuration properties:\nBasic Interface Creation\nCommon Options:\ninput: The Readable stream to listen to (default: process.stdin)\noutput: The Writable stream to write to (default: process.stdout)\nprompt: The prompt string to use (default: '> ')\nterminal: If true, treats the output as a TTY (default: output.isTTY)\nhistorySize: Maximum number of history entries (default: 30)\nremoveHistoryDuplicates: If true, removes duplicate history entries (default: false)\ncompleter: Optional function for tab auto-completion\ncrlfDelay: Delay between CR and LF (default: 100ms)\nescapeCodeTimeout: Time to wait for character escape sequences (default: 500ms)\nAdvanced Interface Example\nNote: When creating interfaces for file processing, set terminal: false to disable TTY-specific features and improve performance.\nBasic Readline Methods\nThe Readline module provides several methods for interacting with the user. Here are the most commonly used ones:\n1. rl.question(query, callback)\nDisplays a query to the user and invokes the callback with the user's response. This is one of the most commonly used methods for simple user interactions.\nBest Practices for rl.question():\nAlways handle errors in the callback function\nConsider using promises or async/await for better flow control with multiple questions\nValidate user input before processing\nAlways close the interface when done to free up resources\n2. rl.prompt([preserveCursor])\nWrites the current prompt to output and waits for user input. The optional preserveCursor parameter (boolean) determines if the cursor position should be preserved.\nTips for Using Prompts:\nUse rl.setPrompt() to change the prompt string dynamically\nFor multi-line prompts, include line breaks in the prompt string\nConsider using a library like chalk to add colors to your prompts\nRemember to call rl.prompt() after handling each input to show the prompt again\n3. rl.write(data[, key])\nWrites data to the output stream. The optional key parameter can be used to simulate key presses.\nCommon Use Cases for rl.write():\nDisplaying headers or section titles\nProviding default values in prompts\nSimulating user input for testing\nCreating custom input formatting\n4. rl.close()\nCloses the readline interface and releases control of the input and output streams. This is important to free up system resources and allow your program to exit cleanly.\n5. rl.pause() and rl.resume()\nThese methods allow you to temporarily pause and resume the input stream, which can be useful for controlling the flow of user input.\nWhen to Use Pause/Resume:\nWhen performing long-running operations that shouldn't be interrupted by user input\nWhen temporarily disabling user input during certain operations\nWhen implementing a paging mechanism for long outputs\nWhen you need to throttle input processing\nUsing Promises with Readline\nThe Readline module's callback-based API can be wrapped in promises for more modern, async/await friendly code:\nCreating an Interactive CLI Menu\nYou can use the Readline module to create interactive menus for command-line applications:\nReading a File Line by Line\nBesides interactive input, the Readline module can also read files line by line, which is useful for processing large text files efficiently:\nNote: This approach is memory-efficient for large files as it processes one line at a time rather than loading the entire file into memory.\nTab Completion\nTab completion enhances the user experience by providing command and file path suggestions. The Readline module allows you to implement custom completion logic:\nHow Tab Completion Works:\nUser presses the Tab key\nReadline calls your completer function with the current line and cursor position\nYour function returns completion suggestions\nReadline displays the completions or auto-completes if there's only one match\nMulti-Line Input\nThe Readline module excels at handling multi-line input, making it perfect for text editors, code editors, or any application that needs to collect multiple lines of text from users. Here's how to implement it effectively:\nMulti-Line Input Strategies:\nEnd Marker: Use a special sequence (like .end) to signal the end of input\nBracket Matching: Automatically detect when all opened brackets/parentheses are closed\nDedicated Command: Provide a specific command to submit multi-line input\nTimeout-Based: Use a timer to detect when the user is done typing\nBuilding a Simple REPL\nA Read-Eval-Print Loop (REPL) is an interactive programming environment that reads user input, evaluates it, and prints the result.\nThe Readline module is perfect for building custom REPLs. Here's a comprehensive guide to creating your own:\nKey Components of a REPL:\nRead: Accept user input line by line\nEval: Parse and evaluate the input\nPrint: Display the result or any output\nLoop: Return to the input prompt for the next command\nSpecial Commands: Handle commands like .help, .exit\nError Handling: Gracefully handle syntax errors and exceptions\nBest Practices\nAlways close the interface: Call rl.close() when you're done to clean up resources.\nHandle errors: Implement error handling for all readline operations.\nUse promises: Wrap callback-based methods in promises for cleaner async code.\nConsider UX: Provide clear prompts and feedback to users.\nUse event handlers: Leverage the event-based nature of readline for complex interactions.\nMemory management: Be careful with large files; process them line by line.\nAdd keyboard shortcuts: Implement handlers for common keyboard shortcuts (Ctrl+C, Ctrl+D).\nReadline vs. Other Input Methods\nSummary\nThe Node.js Readline module provides a simple yet powerful way to create interactive command-line interfaces, process text input line by line, and build tools that require user interaction.\nIt's particularly useful for:\nCreating interactive command prompts\nBuilding CLI applications with user input\nProcessing files line by line\nImplementing custom REPL environments\nDeveloping text-based interfaces and games\nWhile simple on the surface, combining Readline with promises, event handling, and proper UX considerations allows you to build sophisticated command-line applications that provide a great user experience.",
      "examples": [
        "const readline = require('readline');\n\n// Create interface for input/output\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\n// Ask a question and handle the response\nrl.question('What is your name? ', (name) => {\nconsole.log(`Hello, ${name}!`);\n\n// Ask follow-up question\nrl.question('How old are you? ', (age) => {\nconsole.log(`In 5 years, you'll be ${parseInt(age) + 5} years old.`);\n\n// Close the interface when done\nrl.close();\n});\n});\n\n// Handle application exit\nrl.on('close', () => {\nconsole.log('Goodbye!');\nprocess.exit(0);\n});",
        "// Basic require\nconst readline = require('readline');\n\n// Import specific methods using destructuring\nconst { createInterface } = require('readline');\n\n// Create interface with default settings\nconst rl = createInterface({\ninput: process.stdin,\noutput: process.stdout\n});",
        "// Using default import\nimport readline from 'readline';\n\n// Using named imports\nimport { createInterface } from 'readline';\n\n// Dynamic import (Node.js 14+)\nconst { createInterface } = await import('readline');\n\n// Create interface\nconst rl = createInterface({\ninput: process.stdin,\noutput: process.stdout\n});",
        "const readline = require('readline');\n\n// Create a basic interface\nconst rl = readline.createInterface({\ninput: process.stdin, // Readable stream to listen to\noutput: process.stdout, // Writable stream to write to\nprompt: '> ', // Prompt to display (default: '> ')\n});",
        "const readline = require('readline');\nconst fs = require('fs');\n\n// Create an interface with advanced options\nconst rl = readline.createInterface({\ninput: fs.createReadStream('input.txt'), // Read from file\noutput: process.stdout, // Write to console\nterminal: false, // Input is not a terminal\nhistorySize: 100, // Larger history\nremoveHistoryDuplicates: true, // Don't store duplicate commands\nprompt: 'CLI> ', // Custom prompt\ncrlfDelay: Infinity, // Handle all CR/LF as single line break\nescapeCodeTimeout: 200 // Faster escape code detection\n});\n\n// Handle each line from the file\nrl.on('line', (line) => {\nconsole.log(`Processing: ${line}`);\n});\n\n// Handle end of file\nrl.on('close', () => {\nconsole.log('Finished processing file');\n});",
        "const readline = require('readline');\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\nrl.question('What is your name? ', (name) => {\nconsole.log(`Hello, ${name}!`);\nrl.close();\n});",
        "function askQuestion(query) {\nreturn new Promise(resolve => {\nrl.question(query, resolve);\n});\n}\n\nasync function userSurvey() {\ntry {\nconst name = await askQuestion('What is your name? ');\nconst age = await askQuestion('How old are you? ');\nconst email = await askQuestion('What is your email? ');\n\nconsole.log('\\n=== User Information ===');\nconsole.log(`Name: ${name}`);\nconsole.log(`Age: ${age}`);\nconsole.log(`Email: ${email}`);\n\n} catch (error) {\nconsole.error('An error occurred:', error);\n} finally {\nrl.close();\n}\n}\n\nuserSurvey();",
        "const readline = require('readline');\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout,\nprompt: 'CLI> '\n});\n// Display initial prompt\nrl.prompt();\n\n// Handle each line of input\nrl.on('line', (line) => {\nconst input = line.trim();\n\nswitch (input) {\ncase 'hello':\nconsole.log('Hello there!');\nbreak;\ncase 'time':\nconsole.log(`Current time: ${new Date().toLocaleTimeString()}`);\nbreak;\ncase 'exit':\nrl.close();\nreturn;\ndefault:\nconsole.log(`You entered: ${input}`);\n}\n\n// Show the prompt again\nrl.prompt();\n});\n\n// Handle application exit\nrl.on('close', () => {\nconsole.log('Goodbye!');\nprocess.exit(0);\n});",
        "const readline = require('readline');\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\n// Display a welcome message\nrl.write('Welcome to the CLI Application!\\n');\nrl.write('='.repeat(30) + '\\n\\n');\n\n// Pre-fill a default value\nrl.question('Enter your username: ', (username) => {\nconsole.log(`Hello, ${username}!`);\n\n// Simulate typing a default value\nrl.write('default@example.com');\n\n// Move cursor to the beginning of the line\nrl.write(null, { ctrl: true, name: 'a' });\n\nrl.question('Enter your email: ', (email) => {\nconsole.log(`Your email is: ${email}`);\nrl.close();\n});\n});",
        "const readline = require('readline');\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\n// Handle application exit\nfunction exitApp() {\nconsole.log('\\nCleaning up resources...');\n\n// Perform any necessary cleanup\n// (e.g., close database connections, write logs, etc.)\n\n// Close the readline interface\nrl.close();\n}\n\n// Handle Ctrl+C\nrl.on('SIGINT', () => {\nconsole.log('\\nReceived SIGINT. Exiting...');\nexitApp();\n});\n\n// Handle normal exit\nrl.on('close', () => {\nconsole.log('Goodbye!');\nprocess.exit(0);\n});\n\n// Start the application\nconsole.log('Application started. Press Ctrl+C to exit.');\nrl.prompt();",
        "const readline = require('readline');\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\nlet isPaused = false;\n\nconsole.log('Type \"pause\" to pause input, \"resume\" to continue, or \"exit\" to quit');\n\nrl.on('line', (input) => {\nconst command = input.trim().toLowerCase();\n\nswitch (command) {\ncase 'pause':\nif (!isPaused) {\nconsole.log('Input paused. Type \"resume\" to continue...');\nrl.pause();\nisPaused = true;\n}\nbreak;\n\ncase 'resume':\nif (isPaused) {\nconsole.log('Resuming input...');\nrl.resume();\nrl.prompt();\nisPaused = false;\n}\nbreak;\n\ncase 'exit':\nconsole.log('Goodbye!');\nrl.close();\nreturn;\n\ndefault:\nif (!isPaused) {\nconsole.log(`You entered: ${input}`);\nrl.prompt();\n}\n}\n});\n\nrl.prompt();",
        "const readline = require('readline');\n\n// Create interface\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\n// Promise-based question function\nfunction askQuestion(query) {\nreturn new Promise(resolve => {\nrl.question(query, resolve);\n});\n}\n\n// Using async/await with readline\nasync function main() {\ntry {\nconst name = await askQuestion('What is your name? ');\nconsole.log(`Hello, ${name}!`);\n\nconst age = await askQuestion('How old are you? ');\nconsole.log(`In 5 years, you'll be ${parseInt(age) + 5} years old.`);\n\nconst location = await askQuestion('Where do you live? ');\nconsole.log(`${location} is a great place!`);\n\nconsole.log('Thank you for your answers!');\n} catch (error) {\nconsole.error('Error:', error);\n} finally {\nrl.close();\n}\n}\n\n// Run the main function\nmain();",
        "const readline = require('readline');\n\n// Create interface\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\n// Menu options\nconst menu = {\n1: 'Show current time',\n2: 'Show system info',\n3: 'Show memory usage',\n4: 'Exit'\n};\n\n// Function to display menu\nfunction displayMenu() {\nconsole.log('\\n===== MAIN MENU =====');\nfor (const [key, value] of Object.entries(menu)) {\nconsole.log(`${key}: ${value}`);\n}\nconsole.log('====================\\n');\n}\n\n// Function to handle menu selection\nasync function handleMenu() {\nlet running = true;\n\nwhile (running) {\ndisplayMenu();\n\nconst answer = await askQuestion('Select an option: ');\n\nswitch (answer) {\ncase '1':\nconsole.log(`Current time: ${new Date().toLocaleTimeString()}`);\nbreak;\n\ncase '2':\nconsole.log('System info:');\nconsole.log(`Platform: ${process.platform}`);\nconsole.log(`Node.js version: ${process.version}`);\nconsole.log(`Process ID: ${process.pid}`);\nbreak;\n\ncase '3':\nconst memory = process.memoryUsage();\nconsole.log('Memory usage:');\nfor (const [key, value] of Object.entries(memory)) {\nconsole.log(`${key}: ${Math.round(value / 1024 / 1024 * 100) / 100} MB`);\n}\nbreak;\n\ncase '4':\nconsole.log('Exiting program. Goodbye!');\nrunning = false;\nbreak;\n\ndefault:\nconsole.log('Invalid option. Please try again.');\n}\n\nif (running) {\nawait askQuestion('\\nPress Enter to continue...');\nconsole.clear(); // Clear console for better UX\n}\n}\n}\n\n// Promise-based question function\nfunction askQuestion(query) {\nreturn new Promise(resolve => {\nrl.question(query, resolve);\n});\n}\n\n// Start the interactive menu\nhandleMenu()\n.finally(() => {\nrl.close();\n});",
        "const fs = require('fs');\nconst readline = require('readline');\n\n// Create a readable stream for the file\nconst fileStream = fs.createReadStream('example.txt');\n\n// Create the readline interface\nconst rl = readline.createInterface({\ninput: fileStream,\ncrlfDelay: Infinity // Recognize all instances of CR LF as a single line break\n});\n\n// Counter for line numbers\nlet lineNumber = 0;\n\n// Process file line by line\nrl.on('line', (line) => {\nlineNumber++;\nconsole.log(`Line ${lineNumber}: ${line}`);\n});\n\n// Handle end of file\nrl.on('close', () => {\nconsole.log(`Finished reading file with ${lineNumber} lines.`);\n});",
        "const readline = require('readline');\nconst fs = require('fs');\nconst path = require('path');\n\n// Available commands for autocompletion\nconst commands = ['help', 'exit', 'list', 'clear', 'info', 'version', 'history'];\n\n// Create the readline interface with a completer function\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout,\nprompt: 'myapp> ',\ncompleter: function(line) {\n// Command completion\nif (!line.includes(' ')) {\nconst hits = commands.filter(c => c.startsWith(line));\n\n// Show all completions if none matches\nreturn [hits.length ? hits : commands, line];\n}\n\n// File path completion (for commands like \"list \")\nif (line.startsWith('list ')) {\nconst dir = line.split(' ')[1] || '.';\ntry {\nlet completions = fs.readdirSync(dir);\n\n// Add trailing slash to directories\ncompletions = completions.map(file => {\nconst fullPath = path.join(dir, file);\nreturn fs.statSync(fullPath).isDirectory() ? file + '/' : file;\n});\n\nconst hits = completions.filter(c => c.startsWith(line.split(' ')[1] || ''));\nreturn [hits.length ? hits : completions, line.split(' ')[1] || ''];\n} catch (err) {\nreturn [[], line];\n}\n}\n\nreturn [[], line];\n}\n});\n\n// Set the prompt\nrl.prompt();\n\n// Handle commands\nrl.on('line', (line) => {\nline = line.trim();\n\nswitch (true) {\ncase line === 'help':\nconsole.log('Available commands:');\ncommands.forEach(cmd => console.log(` ${cmd}`));\nbreak;\n\ncase line === 'exit':\nconsole.log('Goodbye!');\nrl.close();\nreturn;\n\ncase line.startsWith('list'):\nconst dir = line.split(' ')[1] || '.';\ntry {\nconst files = fs.readdirSync(dir);\nconsole.log(`Contents of ${dir}:`);\nfiles.forEach(file => {\nconst stats = fs.statSync(path.join(dir, file));\nconsole.log(` ${file}${stats.isDirectory() ? '/' : ''}`);\n});\n} catch (err) {\nconsole.error(`Error listing directory: ${err.message}`);\n}\nbreak;\n\ncase line === 'clear':\nconsole.clear();\nbreak;\n\ncase line === 'info':\nconsole.log('Node.js CLI Example');\nconsole.log(`Version: 1.0.0`);\nbreak;\n\ncase line === 'version':\nconsole.log(`Node.js version: ${process.version}`);\nbreak;\n\ncase line === 'history':\n// Note: This requires storing history manually\nconsole.log('History feature not fully implemented.');\nbreak;\n\ncase line === '':\n// Do nothing for empty lines\nbreak;\n\ndefault:\nconsole.log(`Unknown command: ${line}`);\nconsole.log('Type \"help\" for available commands');\n}\n\nrl.prompt();\n}).on('close', () => {\nconsole.log('CLI terminated.');\nprocess.exit(0);\n});\n\n// Handle Ctrl+C\nrl.on('SIGINT', () => {\nrl.question('Are you sure you want to exit? (y/n) ', (answer) => {\nif (answer.toLowerCase() === 'y') {\nrl.close();\n} else {\nrl.prompt();\n}\n});\n});",
        "const readline = require('readline');\n\n// Create interface\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout,\nprompt: '> '\n});\n\nconsole.log('Enter your multi-line input. Type \".end\" on a new line to finish:');\nrl.prompt();\n\n// Store lines\nconst lines = [];\n\n// Handle input\nrl.on('line', (line) => {\n// Check for end command\nif (line.trim() === '.end') {\nconsole.log('\\nYour complete input:');\nconsole.log('-'.repeat(30));\nconsole.log(lines.join('\\n'));\nconsole.log('-'.repeat(30));\n\n// Process the input (example: count words)\nconst text = lines.join(' ');\nconst wordCount = text.split(/\\s+/).filter(Boolean).length;\nconst charCount = text.length;\n\nconsole.log(`\\nStatistics:`);\nconsole.log(`Lines: ${lines.length}`);\nconsole.log(`Words: ${wordCount}`);\nconsole.log(`Characters: ${charCount}`);\n\nrl.close();\nreturn;\n}\n\n// Add line to collection\nlines.push(line);\nrl.prompt();\n});",
        "const readline = require('readline');\nconst vm = require('vm');\n\n// Create interface\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout,\nprompt: 'js> '\n});\n\n// Create context for evaluating code\nconst context = vm.createContext({\nconsole,\nNumber,\nString,\nArray,\nObject,\n// Add any other global variables you want to make available\n// You can also add your own functions\nadd: (a, b) => a + b,\nmultiply: (a, b) => a * b\n});\n\nconsole.log('Simple JavaScript REPL (Press Ctrl+C to exit)');\nconsole.log('Type JavaScript code and press Enter to evaluate');\n\n// Show the prompt\nrl.prompt();\n\n// Track multi-line input\nlet buffer = '';\n\n// Handle input\nrl.on('line', (line) => {\n// Add the line to our buffer\nbuffer += line;\n\ntry {\n// Try to evaluate the code\nconst result = vm.runInContext(buffer, context);\n\n// Display the result\nconsole.log('\\x1b[33m%s\\x1b[0m', '=> ' + result);\n\n// Reset the buffer after successful evaluation\nbuffer = '';\n} catch (error) {\n// If it's a syntax error and might be due to incomplete input,\n// continue collecting input\nif (error instanceof SyntaxError &&\nerror.message.includes('Unexpected end of input')) {\n// Continue in multi-line mode\nrl.setPrompt('... ');\n} else {\n// It's a real error, show it and reset buffer\nconsole.error('\\x1b[31m%s\\x1b[0m', 'Error: ' + error.message);\nbuffer = '';\nrl.setPrompt('js> ');\n}\n}\n\nrl.prompt();\n});\n\n// Handle Ctrl+C\nrl.on('SIGINT', () => {\nif (buffer.length > 0) {\n// If there's pending input, clear it\nconsole.log('\\nInput cleared');\nbuffer = '';\nrl.setPrompt('js> ');\nrl.prompt();\n} else {\n// Otherwise exit\nrl.question('\\nAre you sure you want to exit? (y/n) ', (answer) => {\nif (answer.toLowerCase() === 'y') {\nconsole.log('Goodbye!');\nrl.close();\n} else {\nrl.prompt();\n}\n});\n}\n});\n\nrl.on('close', () => {\nconsole.log('REPL closed');\nprocess.exit(0);\n});",
        "process.stdin",
        "rl.close()",
        "createInterface",
        "input",
        "output",
        "process.stdout",
        "prompt",
        "terminal",
        "output.isTTY",
        "historySize",
        "removeHistoryDuplicates",
        "completer",
        "crlfDelay",
        "escapeCodeTimeout",
        "terminal: false",
        "rl.question(query, callback)",
        "rl.question()",
        "rl.prompt([preserveCursor])",
        "preserveCursor",
        "rl.setPrompt()",
        "chalk",
        "rl.prompt()",
        "rl.write(data[, key])",
        "key",
        "rl.write()",
        "rl.pause()",
        "rl.resume()",
        ".end",
        ".help",
        ".exit"
      ]
    },
    {
      "title": "Node.js ES6+ Features",
      "summary": "What is ES6+?\nES6 (ECMAScript 2015) and later versions add powerful new features to JavaScript that make your code more expressive, concise, and safer.\nNode.js has excellent support for modern JavaScript features.\nNode.js Compatibility: All modern versions of Node.js (10+) have excellent support for ES6+ features.\nNewer versions support even more recent JavaScript additions from ES2020 and beyond.\nThese modern JavaScript features help you:\nWrite cleaner, more readable code\nAvoid common JavaScript pitfalls\nCreate more maintainable applications\nReduce the need for external libraries\nlet and const\nThe let and const keywords replaced var as the preferred way to declare variables:\nlet allows you to declare variables that can be reassigned\nconst declares variables that cannot be reassigned (but object properties can still be modified)\nBoth are block-scoped, unlike var which is function-scoped\nExample: let and constGet your own Node.js Server\nArrow Functions\nArrow functions provide a concise syntax for writing functions and automatically bind this to the surrounding context.\nKey benefits of arrow functions:\nShorter syntax for simple functions\nImplicit return for one-line expressions\nLexical this binding (arrow functions don't create their own this context)\nExample: Arrow Functions\nWhen NOT to use arrow functions:\nObject methods (where you need `this` to reference the object)\nConstructor functions (arrow functions can't be used with `new`)\nEvent handlers where `this` should refer to the element\nTemplate Literals\nTemplate literals (template strings) provide an elegant way to create strings with embedded expressions using backticks (`).\nKey features of template literals:\nString interpolation with ${expression} syntax\nMulti-line strings without escape characters\nTagged templates for advanced string processing\nExample: Template Literals\nDestructuring\nDestructuring allows you to extract values from arrays or properties from objects into distinct variables with a concise syntax.\nKey features of destructuring:\nExtract multiple values in a single statement\nAssign default values to extracted properties\nRename properties during extraction\nSkip elements in arrays\nExtract deeply nested properties\nExample: Object Destructuring\nExample: Array Destructuring\nSpread and Rest Operators\nThe spread and rest operators (both written as ...) allow you to work with multiple elements more efficiently.\nSpread operator: Expands iterables (arrays, objects, strings) into individual elements\nRest operator: Collects multiple elements into a single array or object\nExample: Spread Operator\nExample: Rest Operator\nDefault Parameters\nES6+ allows you to specify default values for function parameters, eliminating the need for manual parameter checking in many cases.\nKey benefits of default parameters:\nCleaner function definitions without manual checking\nMore explicit function signatures\nDefault values are only used when parameters are undefined or not provided\nDefault values can be expressions, not just simple values\nExample: Default Parameters\nClasses\nES6 introduced class syntax to JavaScript, providing a clearer and more concise way to create objects and implement inheritance.\nUnder the hood, JavaScript classes are still based on prototypes.\nKey features of JavaScript classes:\nCleaner syntax for creating constructor functions and methods\nBuilt-in support for inheritance using extends\nStatic methods attached to the class, not instances\nGetter and setter methods for more controlled property access\nPrivate fields for better encapsulation (ES2022+)\nExample: Class Basics\nExample: Class Inheritance\nExample: Private Class Fields (ES2022+)\nPromises and Async/Await\nModern JavaScript provides powerful tools for handling asynchronous operations, making it much easier to work with code that involves delays, API calls, or I/O operations.\nPromises\nPromises represent values that may not be available yet.\nThey provide a more elegant way to handle asynchronous operations compared to callbacks.\nA Promise is in one of these states:\nPending: Initial state, neither fulfilled nor rejected\nFulfilled: Operation completed successfully\nRejected: Operation failed\nExample: Basic Promises\nAsync/Await\nAsync/await (introduced in ES2017) provides a cleaner syntax for working with promises, making asynchronous code look and behave more like synchronous code.\nExample: Async/Await\nCommon Async/Await Mistakes:\nForgetting that async functions always return promises\nNot handling errors with try/catch\nRunning operations sequentially when they could run in parallel\nUsing await outside of an async function\nAwaiting non-promise values (unnecessary but harmless)\nES Modules\nES Modules (ESM) provide a standardized way to organize and share code. They were introduced in ES2015 and are now supported natively in Node.js.\nKey benefits of ES Modules:\nStatic module structure (imports are analyzed at compile time)\nDefault and named exports/imports\nBetter dependency management\nTree-shaking (eliminating unused code)\nExample: ES Modules\nFile: math.js\nFile: app.js\nTo use ES Modules in Node.js, you can either:\nUse the .mjs extension for module files\nAdd \"type\": \"module\" to your package.json\nUse the --experimental-modules flag (older Node.js versions)\nThe CommonJS module system (require() and module.exports) is still widely used in Node.js. ES Modules and CommonJS can coexist in the same project, but they have different semantics.\nEnhanced Object Literals\nES6+ introduced several improvements to object literals that make object creation more concise and expressive.\nExample: Enhanced Object Literals\nOptional Chaining and Nullish Coalescing\nModern JavaScript introduces syntax to safely access nested properties and provide fallback values.\nOptional Chaining (?.)\nOptional chaining lets you access deeply nested object properties without worrying about null or undefined values in the chain.\nExample: Optional Chaining\nNullish Coalescing (??)\nThe nullish coalescing operator (??) provides a default value when a value is null or undefined (but not for other falsy values like 0 or \"\").\nExample: Nullish Coalescing\nModern Asynchronous Patterns\nModern JavaScript provides powerful patterns for handling asynchronous operations. Understanding when to use sequential vs parallel execution can significantly improve your application's performance.\nSequential vs Parallel Execution:\nSequential: Operations run one after another, each waiting for the previous to complete\nParallel: Operations run simultaneously, which is more efficient when operations are independent\nExample: Sequential Execution\nExample: Parallel Execution\nWhen to Use Each Pattern:\nUse sequential when operations depend on previous results\nUse parallel when operations are independent and can run simultaneously\nBe mindful of rate limits when making parallel API calls\nConsider using libraries like p-queue for controlled concurrency\nSummary\nES6+ introduced numerous features that have transformed JavaScript programming, making code more readable, maintainable, and robust:\nlet/const: Block-scoped variables with clearer semantics\nArrow functions: Concise syntax and lexical this binding\nTemplate literals: String interpolation and multi-line strings\nDestructuring: Extract values from objects and arrays easily\nSpread/rest operators: Work with collections more efficiently\nDefault parameters: Simpler function definitions\nClasses: Cleaner syntax for object-oriented programming\nPromises and async/await: Better asynchronous code management\nES Modules: Standardized code organization\nEnhanced object literals: More concise object syntax\nOptional chaining & nullish coalescing: Safer property access and defaults\nThese modern features are fully supported in current Node.js versions, allowing you to write cleaner, more expressive code while avoiding common JavaScript pitfalls.",
      "examples": [
        "// Using let (can be changed)\nlet score = 10;\nscore = 20;\n// Using const (cannot be reassigned)\nconst MAX_USERS = 100;\n\n// Block scope with let\nif (true) {\nlet message = 'Hello';\nconsole.log(message); // Works here\n}",
        "// Traditional function\nfunction add(a, b) {\nreturn a + b;\n}\n\n// Arrow function (same as above)\nconst addArrow = (a, b) => a + b;\n\n// Single parameter (no parentheses needed)\nconst double = num => num * 2;\n\n// No parameters (parentheses needed)\nconst sayHello = () => 'Hello!';\n\n// Using with array methods\nconst numbers = [1, 2, 3];\nconst doubled = numbers.map(num => num * 2);\nconsole.log(doubled);",
        "// Basic string interpolation\nconst name = 'Alice';\nconsole.log(`Hello, ${name}!`);\n\n// Multi-line string\nconst message = `\nThis is a multi-line\nstring in JavaScript.\n`;\nconsole.log(message);\n\n// Simple expression\nconst price = 10;\nconst tax = 0.2;\nconsole.log(`Total: $${price * (1 + tax)}`);",
        "// Basic object destructuring\nconst user = { name: 'Alice', age: 30, location: 'New York' };\nconst { name, age } = user;\nconsole.log(name, age);",
        "// Basic array destructuring\nconst colors = ['red', 'green', 'blue'];\nconst [first, second, third] = colors;\nconsole.log(first, second, third);\n\n// Skipping elements\nconst [primary, , tertiary] = colors;\nconsole.log(primary, tertiary);",
        "// Array spread - combining arrays\nconst numbers = [1, 2, 3];\nconst moreNumbers = [4, 5, 6];\nconst combined = [...numbers, ...moreNumbers];\nconsole.log(combined);\n\n// Array spread - converting string to array of characters\nconst chars = [...'hello'];\nconsole.log(chars);",
        "// Rest parameter in functions\nfunction sum(...numbers) {\nreturn numbers.reduce((total, num) => total + num, 0);\n}\nconsole.log(sum(1, 2, 3, 4, 5));",
        "// Basic default parameter\nfunction greet(name = 'Guest') {\nreturn `Hello, ${name}!`;\n}\n\nconsole.log(greet());\nconsole.log(greet('Kai'));",
        "// Simple class with constructor and method\nclass Person {\nconstructor(name, age) {\nthis.name = name;\nthis.age = age;\n}\n\ngreet() {\nreturn `Hello, I'm ${this.name}!`;\n}\n}\n\n// Create an instance\nconst person = new Person('Alice', 25);\nconsole.log(person.greet()); // Hello, I'm Alice!",
        "// Parent class\nclass Animal {\nconstructor(name) {\nthis.name = name;\n}\n\nspeak() {\nreturn `${this.name} makes a sound.`;\n}\n}\n\n// Child class\nclass Dog extends Animal {\nspeak() {\nreturn `${this.name} barks!`;\n}\n}\n\nconst dog = new Dog('Rex');\nconsole.log(dog.speak());",
        "// Class with private field (# prefix)\nclass Counter {\n#count = 0; // Private field\n\nincrement() {\nthis.#count++;\n}\n\ngetCount() {\nreturn this.#count;\n}\n}\n\nconst counter = new Counter();\ncounter.increment();\nconsole.log(counter.getCount());\n// console.log(counter.#count); // Error: Private field",
        "// Creating a promise\nconst fetchData = () => {\nreturn new Promise((resolve, reject) => {\n// Simulating an API call\nsetTimeout(() => {\nconst data = { id: 1, name: 'Product' };\nconst success = true;\n\nif (success) {\nresolve(data); // Fulfilled with data\n} else {\nreject(new Error('Failed to fetch data')); // Rejected with error\n}\n}, 1000);\n});\n};\n\n// Using a promise\nconsole.log('Fetching data...');\n\nfetchData()\n.then(data => {\nconsole.log('Data received:', data);\nreturn data.id; // Return value is passed to the next .then()\n})\n.then(id => {\nconsole.log('Processing ID:', id);\n})\n.catch(error => {\nconsole.error('Error:', error.message);\n})\n.finally(() => {\nconsole.log('Operation completed (success or failure)');\n});\n\nconsole.log('Continuing execution while fetch happens in background');",
        "// Function that returns a promise\nconst fetchUser = (id) => {\nreturn new Promise((resolve, reject) => {\nsetTimeout(() => {\nif (id > 0) {\nresolve({ id, name: `User ${id}` });\n} else {\nreject(new Error('Invalid user ID'));\n}\n}, 1000);\n});\n};\n\n// Using async/await\nasync function getUserData(id) {\ntry {\nconsole.log('Fetching user...');\nconst user = await fetchUser(id); // Waits for the promise to resolve\nconsole.log('User data:', user);\n\n// You can use the result directly\nreturn `${user.name}'s profile`;\n} catch (error) {\n// Handle errors with try/catch\nconsole.error('Error fetching user:', error.message);\nreturn 'Guest profile';\n}\n}\n\n// Async functions always return promises\nconsole.log('Starting...');\ngetUserData(1)\n.then(result => console.log('Result:', result))\n.catch(error => console.error('Unexpected error:', error));\nconsole.log('This runs before getUserData completes');",
        "// Named exports\nexport const PI = 3.14159;\n\nexport function add(a, b) {\nreturn a + b;\n}\n\nexport function multiply(a, b) {\nreturn a * b;\n}\n\n// Default export\nexport default class Calculator {\nadd(a, b) {\nreturn a + b;\n}\n\nsubtract(a, b) {\nreturn a - b;\n}\n}",
        "// Import default export\nimport Calculator from './math.js';\n\n// Import named exports\nimport { PI, add, multiply } from './math.js';\n\n// Import with alias\nimport { add as mathAdd } from './math.js';\n\n// Import all exports as a namespace\nimport * as MathUtils from './math.js';\n\nconst calc = new Calculator();\nconsole.log(calc.subtract(10, 5)); // 5\n\nconsole.log(add(2, 3)); // 5\nconsole.log(mathAdd(4, 5)); // 9\nconsole.log(MathUtils.PI); // 3.14159\nconsole.log(MathUtils.multiply(2, 3)); // 6",
        "// Property shorthand\nconst name = 'Alice';\nconst age = 30;\n\n// Instead of {name: name, age: age}\nconst person = { name, age };\nconsole.log(person);\n\n// Method shorthand\nconst calculator = {\n// Instead of add: function(a, b) { ... }\nadd(a, b) {\nreturn a + b;\n},\nsubtract(a, b) {\nreturn a - b;\n}\n};\nconsole.log(calculator.add(5, 3));",
        "function getUserCity(user) {\nreturn user?.address?.city;\n}\n\nconst user1 = {\nname: 'Alice',\naddress: { city: 'New York', country: 'USA' }\n};\n\nconst user2 = {\nname: 'Bob'\n};\n\nconst user3 = null;\n\nconsole.log(getUserCity(user1)); // 'New York'\nconsole.log(getUserCity(user2)); // undefined\nconsole.log(getUserCity(user3)); // undefined",
        "function calculatePrice(price, tax) {\n// Only uses default if tax is null or undefined\nreturn price + (tax ?? 0.1) * price;\n}\n\nconsole.log(calculatePrice(100, 0)); // 100 (correct! tax of 0 was used)\nconsole.log(calculatePrice(100, null)); // 110 (using default)",
        "// Helper function to simulate an API call\nfunction fetchData(id) {\nreturn new Promise(resolve => {\nsetTimeout(() => resolve(`Data for ID ${id}`), 1000);\n});\n}\n\n// Sequential execution (~3 seconds total)\nasync function fetchSequential() {\nconsole.time('sequential');\nconst data1 = await fetchData(1);\nconst data2 = await fetchData(2);\nconst data3 = await fetchData(3);\nconsole.timeEnd('sequential');\nreturn [data1, data2, data3];\n}\n\n// Run the sequential example\nfetchSequential().then(results => {\nconsole.log('Sequential results:', results);\n});",
        "// Parallel execution (~1 second total)\nasync function fetchParallel() {\nconsole.time('parallel');\nconst results = await Promise.all([\nfetchData(1),\nfetchData(2),\nfetchData(3)\n]);\nconsole.timeEnd('parallel');\nreturn results;\n}\n\n// Run the parallel example\nfetchParallel().then(results => {\nconsole.log('Parallel results:', results);\n});",
        "let",
        "const",
        "var",
        "this",
        "`",
        "${expression}",
        "...",
        "extends",
        ".mjs",
        "\"type\": \"module\"",
        "--experimental-modules",
        "require()",
        "module.exports",
        "p-queue"
      ]
    },
    {
      "title": "Node.js Process Management",
      "summary": "What is Process Management?\nProcess management in Node.js is about controlling your application's lifecycle.\nIt includes:\nStarting and stopping applications\nRestarting after crashes\nMonitoring performance\nHandling system signals\nManaging environment variables\nAccessing Process Information\nThe process object gives you details about and control over the current Node.js process.\nHere are some useful properties:\nExiting a Process\nYou can control when your Node.js program stops using these methods:\nHandling Process Events\nNode.js processes can respond to system signals and events.\nHere are the most common ones:\nProcess Managers\nFor production environments, use a process manager to keep your application running smoothly.\nPM2 is the most popular choice:\n1. Install PM2 Globally\n2. Basic PM2 Commands\n3. PM2 Configuration\nCreate an ecosystem file for advanced configuration:\nPM2 provides many other features like load balancing, monitoring, and log management.\nEnvironment Variables\nEnvironment variables are key-value pairs that configure your application's behavior in different environments.\nBest Practices for Environment Variables:\nNever commit sensitive data to version control\nUse .env for local development\nSet environment variables in production through your hosting platform\nDocument all required environment variables in your README\nChild Processes\nNode.js can run system commands and other scripts using the child_process module.\nProcess Monitoring and Performance\nKey Takeaways\nProcess Object: Access system and process information\nProcess Control: Start, stop, and manage application lifecycle\nEnvironment Variables: Configure app behavior across different environments\nChild Processes: Run system commands and other scripts\nError Handling: Handle uncaught exceptions and rejections\nSignals: Respond to system signals like SIGINT and SIGTERM\nPM2: Essential for production process management\nPerformance Monitoring: Track memory and CPU usage\nEffective process management is crucial for building reliable and maintainable Node.js applications, especially in production environments.",
      "examples": [
        "// Process identification\nconsole.log('Process ID (PID):', process.pid);\n\n// Platform information\nconsole.log('Platform:', process.platform);\nconsole.log('Node.js version:', process.version);\n\n// Memory usage (in bytes)\nconsole.log('Memory usage:', process.memoryUsage());\n\n// Command line arguments\nconsole.log('Arguments:', process.argv);",
        "// Exit with success (status code 0)\nprocess.exit();\n\n// Or explicitly\nprocess.exit(0);",
        "// Exit with error (status code 1)\nprocess.exit(1);",
        "// Run cleanup before exiting\nprocess.on('beforeExit', (code) => {\nconsole.log('About to exit with code:', code);\n});",
        "// Handle Ctrl+C\nprocess.on('SIGINT', () => {\nconsole.log('\\nGot SIGINT. Press Control-D to exit.');\n// Perform cleanup if needed\nprocess.exit(0);",
        "process.on('SIGTERM', () => {\nconsole.log('Received SIGTERM. Cleaning up...');\n// Perform cleanup if needed\nprocess.exit(0);\n});",
        "process.on('SIGTERM', () => {\nconsole.log('Received SIGTERM. Cleaning up...');\nserver.close(() => {\nconsole.log('Server closed');\nprocess.exit(0);\n});\n});",
        "process.on('uncaughtException', (err) => {\nconsole.error('Uncaught Exception:', err);\n// Perform cleanup if needed\nprocess.exit(1); // Exit with error\n});",
        "npm install -g pm2",
        "# Start an application\npm2 start app.js\n\n# List all running applications\npm2 list\n\n# Monitor resources\npm2 monit\n\n# View application logs\npm2 logs\n\n# Stop an application\npm2 stop app_name\n\n# Restart an application\npm2 restart app_name\n\n# Delete an application from PM2\npm2 delete app_name",
        "// ecosystem.config.js\nmodule.exports = {\napps: [{\nname: 'my-app',\nscript: 'app.js',\ninstances: 'max',\nautorestart: true,\nwatch: false,\nmax_memory_restart: '1G',\nenv: {\nNODE_ENV: 'development',\n},\nenv_production: {\nNODE_ENV: 'production',\n}\n}]\n};",
        "// Get a specific environment variable\nconst apiKey = process.env.API_KEY;\n\n// Set a default value if not defined\nconst port = process.env.PORT || 3000;\n\n// Check if running in production\nconst isProduction = process.env.NODE_ENV === 'production';\n\n// List all environment variables\nconsole.log('Environment variables:', process.env);",
        "# Install dotenv package\nnpm install dotenv",
        "// Load environment variables from .env file\nrequire('dotenv').config();\n\n// Now you can access variables from .env\nconsole.log('Database URL:', process.env.DATABASE_URL);",
        "const { exec } = require('child_process');\n\nexec('ls -la', (error, stdout, stderr) => {\nif (error) {\nconsole.error(`Error: ${error.message}`);\nreturn;\n}\nif (stderr) {\nconsole.error(`stderr: ${stderr}`);\nreturn;\n}\nconsole.log(`Output: ${stdout}`);\n});",
        "const { spawn } = require('child_process');\n\n// Better for large data output\nconst child = spawn('find', ['/', '-type', 'f']);\nchild.stdout.on('data', (data) => {\nconsole.log(`Found file: ${data}`);\n});\nchild.stderr.on('data', (data) => {\nconsole.error(`Error: ${data}`);\n});\nchild.on('close', (code) => {\nconsole.log(`Child process exited with code ${code}`);\n});",
        "// Get memory usage in MB\nfunction getMemoryUsage() {\nconst used = process.memoryUsage();\nreturn {\nrss: `${Math.round(used.rss / 1024 / 1024 * 100) / 100} MB`,\nheapTotal: `${Math.round(used.heapTotal / 1024 / 1024 * 100) / 100} MB`,\nheapUsed: `${Math.round(used.heapUsed / 1024 / 1024 * 100) / 100} MB`,\nexternal: `${Math.round(used.external / 1024 / 1024 * 100) / 100} MB`\n};\n}\n\n// Monitor memory usage every 5 seconds\nsetInterval(() => {\nconsole.log('Memory usage:', getMemoryUsage());\n}, 5000);",
        "const startUsage = process.cpuUsage();\n\n// Do some CPU-intensive work\nfor (let i = 0; i < 1000000000; i++) {}\n\nconst endUsage = process.cpuUsage(startUsage);\nconsole.log('CPU usage (user):', endUsage.user / 1000, 'ms');\nconsole.log('CPU usage (system):', endUsage.system / 1000, 'ms');",
        "process",
        ".env",
        "child_process"
      ]
    },
    {
      "title": "Node.js TypeScript",
      "summary": "What is TypeScript?\nTypeScript is a superset of JavaScript that adds optional static typing.\nIt helps you catch errors early and write safer, more maintainable code.\nTake a look at our TypeScript tutorial for more details.\nUsing TypeScript with Node.js\nTo use TypeScript in Node.js projects, you need to install TypeScript and a type definition manager:\nWrite your code in .ts files and compile them to JavaScript with:\nSetting Up a TypeScript Project\nTypeScript Basics\nTypeScript with Node.js\nTypeScript Configuration\nKey Compiler Options:\ntarget: Specify ECMAScript target version\nmodule: Specify module code generation\nstrict: Enable all strict type checking options\noutDir: Redirect output structure to the directory\nrootDir: Specify the root directory of input files\nWhy Use TypeScript with Node.js?\nBenefits of TypeScript:\nType Safety: Catch errors at compile time rather than runtime\nBetter IDE Support: Superior autocompletion and code navigation\nSelf-Documenting Code: Types serve as documentation\nEasier Refactoring: Safely rename variables and update code\nGradual Adoption: Add types incrementally to existing JavaScript code\nWhen to Use TypeScript:\nLarge codebases with multiple developers\nAPIs where type safety is critical\nProjects that will be maintained long-term\nWhen working with complex data structures",
      "examples": [
        "npm install -g typescript\nnpm install --save-dev @types/node",
        "tsc yourfile.ts",
        "npm init -y",
        "npm install --save-dev typescript @types/node",
        "npx tsc --init",
        "// Primitive types\nlet isDone: boolean = false;\nlet count: number = 10;\nlet name: string = 'TypeScript';\n\n// Arrays\nlet numbers: number[] = [1, 2, 3];\nlet names: Array<string> = ['Alice', 'Bob'];\n\n// Tuples\nlet user: [string, number] = ['Alice', 25];\n\n// Enums\nenum Color {Red, Green, Blue}\nlet color: Color = Color.Green;",
        "// Interface interface User {\nid: number;\nname: string;\nemail?: string; // Optional property\n}\n\n// Type alias\ntype Point = {\nx: number;\ny: number;\n};\n\n// Using the interface\nfunction printUser(user: User) {\nconsole.log(`User: ${user.name}`);\n}",
        "// server.ts\nimport http from 'http';\n\nconst server = http.createServer((req, res) => {\nres.statusCode = 200;\nres.setHeader('Content-Type', 'text/plain');\nres.end('Hello, TypeScript!');\n});\n\nconst PORT = process.env.PORT || 3000;\nserver.listen(PORT, () => {\nconsole.log(`Server running on port ${PORT}`);\n});",
        "# Install required packages\nnpm install express\nnpm install --save-dev @types/express",
        "// app.ts\nimport express, { Request, Response } from 'express';\ninterface User {\nid: number;\nname: string;\n}\nconst app = express();\napp.use(express.json());\n// In-memory database\nlet users: User[] = [];\n// Get all users\napp.get('/users', (req: Request, res: Response) => {\nres.json(users);\n});\n// Add new user\napp.post('/users', (req: Request, res: Response) => {\nconst user: User = req.body;\nusers.push(user);\nres.status(201).json(user);\n});\nconst PORT = process.env.PORT || 3000;\napp.listen(PORT, () => {\nconsole.log(`Server running on port ${PORT}`);\n});",
        "{\n\"compilerOptions\": {\n\"target\": \"es2018\",\n\"module\": \"commonjs\",\n\"outDir\": \"./dist\",\n\"rootDir\": \"./src\",\n\"strict\": true,\n\"esModuleInterop\": true,\n\"skipLibCheck\": true,\n\"forceConsistentCasingInFileNames\": true\n},\n\"include\": [\"src/**/*\"],\n\"exclude\": [\"node_modules\"]\n}",
        ".ts",
        "target",
        "module",
        "strict",
        "outDir",
        "rootDir"
      ]
    },
    {
      "title": "Node.js Advanced TypeScript",
      "summary": "Advanced TypeScript for Node.js\nThis guide dives into advanced TypeScript features and patterns specifically useful for Node.js applications.\nFor comprehensive TypeScript documentation, visit TypeScript Tutorial.\nAdvanced Type System Features\nTypeScript's type system provides powerful tools for creating robust and maintainable Node.js applications.\nHere are the key features:\n1. Union and Intersection Types\n2. Type Guards\n3. Advanced Generics\n4. Mapped and Conditional Types\n5. Type Inference and Type Guards\nTypeScript's type inference and type guards help create type-safe code with minimal annotations:\nAdvanced TypeScript Patterns for Node.js\nThese patterns help build more maintainable and type-safe Node.js applications:\n1. Advanced Decorators\n2. Advanced Utility Types\n3. Type-Safe Event Emitters\nTypeScript Best Practices for Node.js\nKey Takeaways:\nLeverage TypeScript's advanced type system for better code safety and developer experience\nUse generics to create flexible and reusable components without losing type safety\nImplement decorators for cross-cutting concerns like logging, validation, and performance monitoring\nUtilize utility types to transform and manipulate types without code duplication\nCreate type-safe abstractions for Node.js-specific patterns like event emitters and streams\nPerformance Considerations:\nBe mindful of complex types that might impact compilation time\nUse type over interface for complex type operations\nConsider using as const for literal types when appropriate\nUse unknown instead of any for type-safe dynamic typing\nFor comprehensive TypeScript documentation and examples, visit our TypeScript Tutorial.",
      "examples": [
        "// Union type\nfunction formatId(id: string | number) {\nreturn `ID: ${id}`;\n}\n\n// Intersection type\ntype User = { name: string } & { id: number };",
        "type Fish = { swim: () => void };\ntype Bird = { fly: () => void };\n\nfunction isFish(pet: Fish | Bird): pet is Fish {\nreturn 'swim' in pet;\n}",
        "// Generic function with constraints\nfunction getProperty<T, K extends keyof T>(obj: T, key: K): T[K] {\nreturn obj[key];\n}\n\n// Generic interface with default type\ninterface PaginatedResponse<T = any> {\ndata: T[];\ntotal: number;\npage: number;\nlimit: number;\n}\n\n// Using generic types with async/await in Node.js\nasync function fetchData<T>(url: string): Promise<T> {\nconst response = await fetch(url);\nreturn response.json();\n}",
        "// Mapped types\ntype ReadonlyUser = {\nreadonly [K in keyof User]: User[K];\n};\n\n// Conditional types\ntype NonNullableUser = NonNullable<User | null | undefined>; // User\n\n// Type inference with conditional types\ntype GetReturnType<T> = T extends (...args: any[]) => infer R ? R : never;\nfunction getUser() {\nreturn { id: 1, name: 'Alice' } as const;\n}\ntype UserReturnType = GetReturnType<typeof getUser>; // { readonly id: 1; readonly name: \"Alice\"; }",
        "// Type inference with variables\nconst name = 'Alice'; // TypeScript infers type: string\nconst age = 30; // TypeScript infers type: number\nconst active = true; // TypeScript infers type: boolean\n\n// Type inference with arrays\nconst numbers = [1, 2, 3]; // TypeScript infers type: number[]\nconst mixed = [1, 'two', true]; // TypeScript infers type: (string | number | boolean)[]\n\n// Type inference with functions\nfunction getUser() {\nreturn { id: 1, name: 'Alice' }; // Return type inferred as { id: number; name: string; }\n}\n\nconst user = getUser(); // user inferred as { id: number; name: string; }\nconsole.log(user.name); // Type checking works on inferred properties",
        "// Parameter decorator with metadata\nfunction validateParam(target: any, key: string, index: number) {\nconst params = Reflect.getMetadata('design:paramtypes', target, key) || [];\nconsole.log(`Validating parameter ${index} of ${key} with type ${params[index]?.name}`);\n}\n\n// Method decorator with factory\nfunction logExecutionTime(msThreshold = 0) {\nreturn function (target: any, key: string, descriptor: PropertyDescriptor) {\nconst originalMethod = descriptor.value;\ndescriptor.value = async function (...args: any[]) {\nconst start = Date.now();\nconst result = await originalMethod.apply(this, args);\nconst duration = Date.now() - start;\nif (duration > msThreshold) {\nconsole.warn(`[Performance] ${key} took ${duration}ms`);\n}\nreturn result;\n};\n};\n}\nclass ExampleService {\n@logExecutionTime(100)\nasync fetchData(@validateParam url: string) {\n// Implementation\n}\n}",
        "// Built-in utility types with examples interface User {\nid: number;\nname: string;\nemail?: string;\ncreatedAt: Date;\n}\n// Create a type with specific properties as required\ntype AtLeast<T, K extends keyof T> = Partial<T> & Pick<T, K>;\ntype UserCreateInput = AtLeast<User, 'name' | 'email'>; // Only name is required\n\n// Create a type that makes specific properties required\nWithRequired<T, K extends keyof T> = T & { [P in K]-?: T[P] };\ntype UserWithEmail = WithRequired<User, 'email'>;\n\n// Extract function return type as a type\ntype UserFromAPI = Awaited<ReturnType<typeof fetchUser>>;",
        "import { EventEmitter } from 'events';\n\ntype EventMap = {\nlogin: (userId: string) => void;\nlogout: (userId: string, reason: string) => void;\nerror: (error: Error) => void;\n};\n\nclass TypedEventEmitter<T extends Record<string, (...args: any[]) => void>> {\nprivate emitter = new EventEmitter();\n\non<K extends keyof T>(event: K, listener: T[K]): void {\nthis.emitter.on(event as string, listener as any);\n}\n\nemit<K extends keyof T>(\nevent: K,\n...args: Parameters<T[K]>\n): boolean {\nreturn this.emitter.emit(event as string, ...args);\n}\n}\n\n// Usage\nconst userEvents = new TypedEventEmitter<EventMap>();\nuserEvents.on('login', (userId) => {\nconsole.log(`User ${userId} logged in`);\n});\n\n// TypeScript will show an error for incorrect argument types\n// userEvents.emit('login', 123);\n// Error: Argument of type 'number' is not assignable to 'string'",
        "type",
        "interface",
        "as const",
        "unknown",
        "any"
      ]
    },
    {
      "title": "Node.js Linting & Formatting",
      "summary": "Code Quality\nConsistent code quality and style is important for Node.js projects, especially in team environments.\nIt helps with:\nReadability and maintainability of code\nEarly bug detection and prevention\nConsistent coding style across the team\nAutomated code reviews\nBetter developer experience\nNote: This guide covers both JavaScript and TypeScript tooling, as they share similar linting and formatting ecosystems.\nESLint: JavaScript/TypeScript Linting\nESLint is the most popular JavaScript/TypeScript linting tool that helps identify and report on patterns found in your code. It's highly configurable and supports:\nCustom rules and configurations\nTypeScript support through @typescript-eslint/parser\nPlugin ecosystem for framework-specific rules\nAutomatic fixing of common issues\nInstallation\nComprehensive ESLint Configuration\nHere's a more complete .eslintrc.json configuration for a Node.js project with TypeScript support:\nAdvanced ESLint Usage\nBeyond basic linting, ESLint offers powerful features for maintaining code quality:\nPrettier: Code Formatter\nPrettier is an opinionated code formatter that enforces a consistent style by parsing your code and re-printing it with its own rules. It supports:\nJavaScript, TypeScript, JSX, CSS, SCSS, JSON, and more\nOpinionated defaults with minimal configuration\nIntegration with ESLint and other tools\nSupport for editor integration\nTip: Use Prettier for formatting and ESLint for catching potential errors and enforcing code patterns.\nInstallation\nComprehensive Prettier Configuration\nHere's a well-documented .prettierrc configuration with common options:\nAdvanced Prettier Usage\nPrettier can be customized and integrated into your workflow in various ways:\nSeamless ESLint + Prettier Integration\nTo avoid conflicts between ESLint and Prettier, set up proper integration:\nImportant: Always install and configure these packages to prevent rule conflicts:\nThen update your ESLint config:\nAdvanced Editor Integration\nPro Tip: Set up your editor to automatically fix and format code on save for maximum productivity.\nVS Code: Ultimate Setup\nFor the best development experience in VS Code, follow these steps:\nInstall the following extensions:\nESLint\nPrettier - Code formatter\nEditorConfig for VS Code\nError Lens (for inline error highlighting)\nESLint\nPrettier - Code formatter\nEditorConfig for VS Code\nError Lens (for inline error highlighting)\nConfigure your VS Code settings.json:\nInstall the ESLint and Prettier extensions\nAdd these settings to your VS Code settings.json:\nOther Editor Setups\nHere are setup instructions for other popular editors:\nWebStorm/IntelliJ: Built-in support for ESLint and Prettier\nAtom: Install linter-eslint and prettier-atom packages\nSublime Text: Install SublimeLinter and SublimeLinter-eslint\nGit Hooks with Husky & lint-staged\nPrevent bad code from being committed by setting up pre-commit hooks that automatically format and lint your code:\nWhy use pre-commit hooks? They ensure consistent code quality across your team by automatically fixing style issues before code is committed.\nEnsure code quality before commits with pre-commit hooks:\nInstallation\nConfiguration (package.json)\nAdvanced Best Practices\n1. Monorepo Setup\nFor projects using a monorepo structure:\n2. Performance Optimization\nFor large projects, optimize ESLint performance:\n3. EditorConfig for Cross-Editor Consistency\nAdd a .editorconfig file to maintain consistent coding styles across different editors and IDEs:\n4. CI/CD Integration\nAdd linting and formatting checks to your CI/CD pipeline:\nLinting Best Practices\nStart with a base config (like eslint:recommended) and extend as needed\nBe consistent with rule severity levels (error, warn, off)\nDocument rule exceptions with comments when necessary\nRegularly update your ESLint and plugin versions\nUse TypeScript-specific rules when working with TypeScript\nFormatting Best Practices\nKeep line lengths reasonable (80-120 characters)\nUse consistent quote style (single or double quotes)\nBe consistent with semicolon usage\nUse trailing commas in objects and arrays for cleaner diffs\nConfigure your editor to format on save\nTeam Workflow\nShare ESLint and Prettier configs across the team\nInclude linting and formatting in CI/CD pipelines\nUse pre-commit hooks to catch issues early\nDocument your code style decisions\nRegularly review and update your code style guide",
      "examples": [
        "npm install --save-dev eslint",
        "{\n\"env\": {\n\"node\": true,\n\"es2021\": true,\n\"browser\": true\n},\n\"extends\": [\n\"eslint:recommended\",\n\"plugin:@typescript-eslint/recommended\"\n],\n\"parser\": \"@typescript-eslint/parser\",\n\"parserOptions\": {\n\"ecmaVersion\": 12,\n\"sourceType\": \"module\"\n},\n\"plugins\": [\"@typescript-eslint\"],\n\"rules\": {\n\"semi\": [\"error\", \"always\"],\n\"quotes\": [\"error\", \"single\"],\n\"indent\": [\"error\", 2],\n\"no-console\": \"warn\",\n\"no-unused-vars\": \"warn\"\n}\n}",
        "# Lint all JavaScript/TypeScript files\nnpx eslint .\n\n# Fix auto-fixable issues\nnpx eslint --fix .\n\n# Lint specific file\nnpx eslint src/index.js",
        "npm install --save-dev --save-exact prettier",
        "{\n\"semi\": true,\n\"singleQuote\": true,\n\"tabWidth\": 2,\n\"trailingComma\": \"es5\",\n\"printWidth\": 100,\n\"bracketSpacing\": true,\n\"arrowParens\": \"avoid\"\n}",
        "# Format all files\nnpx prettier --write .\n\n# Check formatting without making changes\nnpx prettier --check .\n\n# Format specific file\nnpx prettier --write src/index.js",
        "npm install --save-dev eslint-config-prettier eslint-plugin-prettier",
        "{\n\"extends\": [\n\"eslint:recommended\",\n\"plugin:@typescript-eslint/recommended\",\n\"plugin:prettier/recommended\"\n]\n}",
        "{\n\"editor.formatOnSave\": true,\n\"editor.codeActionsOnSave\": {\n\"source.fixAll.eslint\": true\n},\n\"eslint.validate\": [\"javascript\", \"javascriptreact\", \"typescript\", \"typescriptreact\"],\n\"prettier.requireConfig\": true,\n\"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n}",
        "npm install --save-dev husky lint-staged",
        "{\n\"husky\": {\n\"hooks\": {\n\"pre-commit\": \"lint-staged\"\n}\n}\n\"lint-staged\": {\n\"*.{js,jsx,ts,tsx}\": [\n\"eslint --fix\",\n\"prettier --write\"\n],\n\"*.{json,md,yml}\": [\n\"prettier --write\"\n]\n}\n}",
        "// In your root package.json\n{\n\"workspaces\": [\"packages/*\"],\n\"scripts\": {\n\"lint\": \"yarn workspaces run lint\",\n\"format\": \"prettier --write \\\"**/*.{js,jsx,ts,tsx,json,md}\\\"\"\n},\n\"devDependencies\": {\n\"@typescript-eslint/eslint-plugin\": \"^5.0.0\",\n\"@typescript-eslint/parser\": \"^5.0.0\",\n\"eslint\": \"^8.0.0\",\n\"eslint-config-prettier\": \"^8.3.0\",\n\"eslint-plugin-prettier\": \"^4.0.0\",\n\"husky\": \"^7.0.4\",\n\"lint-staged\": \"^12.0.0\",\n\"prettier\": \"^2.5.0\",\n\"typescript\": \"^4.5.0\"\n},\n\"lint-staged\": {\n\"*.{js,jsx,ts,tsx}\": [\n\"eslint --fix\",\n\"prettier --write\"\n],\n\"*.{json,md,yml,yaml}\": [\n\"prettier --write\"\n]\n}\n}",
        "// .eslintrc.js\nmodule.exports = {\ncache: true, // Enable caching\ncacheLocation: '.eslintcache', // Cache file location\nignorePatterns: ['**/node_modules/**', '**/dist/**'], // Ignore patterns\nparserOptions: {\nproject: './tsconfig.json', // Only for TypeScript\nprojectFolderIgnoreList: ['**/node_modules/**']\n}\n};",
        "# EditorConfig is awesome: https://EditorConfig.org\nroot = true\n\n[*]\ncharset = utf-8\nend_of_line = lf\nindent_size = 2\nindent_style = space\ninsert_final_newline = true\ntrim_trailing_whitespace = true\n\n[*.md]\ntrim_trailing_whitespace = false\n\n[*.{json,yml}]\nindent_style = space\nindent_size = 2\n\n[*.{cmd,sh}]\nindent_style = tab",
        "# .github/workflows/ci.yml\nname: CI\n\non: [push, pull_request]\n\njobs:\nlint:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v2\n- uses: actions/setup-node@v2\nwith:\nnode-version: '16'\n- run: npm ci\n- run: npm run lint\n- run: npm run format:check",
        "@typescript-eslint/parser",
        ".eslintrc.json",
        ".prettierrc",
        ".editorconfig",
        "eslint:recommended"
      ]
    },
    {
      "title": "Node.js Frameworks",
      "summary": "Why Use a Framework?\nNode.js frameworks provide structure, organization, and common utilities for building web applications, APIs, and more.\nThey help developers create applications faster by providing ready-made solutions to common development challenges.\nAdvantages of using a framework:\nProductivity: Frameworks provide pre-built solutions for common tasks like routing, middleware management, and templating.\nStandardization: They establish patterns and structures that make code more maintainable and easier to understand.\nCommunity: Popular frameworks have large communities, extensive documentation, and many third-party plugins or extensions.\nSecurity: Well-maintained frameworks often include built-in security features and best practices.\nPerformance: Many frameworks are optimized for performance and provide tools for caching, load balancing, and more.\nTypes of Node.js Frameworks\nNode.js frameworks can be broadly categorized based on their design philosophy and features.\nUnderstanding these categories helps in selecting the right framework for your project's needs.\nFull-Stack Frameworks\nThese frameworks provide solutions for both front-end and back-end development, often with integrated templating engines, ORM systems, and more.\nExamples: Meteor, Sails.js, AdonisJS\nUse When: Building complete web applications with both frontend and backend components\nMinimalist/Micro Frameworks\nThese frameworks focus on being lightweight and provide only the essential features, letting developers add what they need.\nExamples: Express.js, Koa, Fastify\nUse When: Building APIs or simple web services where you want maximum control\nREST API Frameworks\nSpecialized frameworks designed for building RESTful APIs with features like automatic validation, documentation, and versioning.\nExamples: LoopBack, NestJS, Restify\nUse When: Building robust, production-ready APIs with minimal boilerplate\nReal-Time Frameworks\nFrameworks optimized for real-time applications with built-in support for WebSockets and server-sent events.\nExamples: Socket.io, Sails.js, FeathersJS\nUse When: Building chat applications, live updates, or any real-time features\nPopular Node.js Frameworks\nHere's a comprehensive comparison of the most popular Node.js frameworks, their features, and when to use them.\nWhen choosing a framework, consider these factors:\nProject Requirements: Does the framework support your specific needs?\nLearning Curve: How quickly can your team become productive?\nPerformance: Does it meet your performance requirements?\nCommunity & Support: Is there active development and community support?\nEcosystem: Are there plugins and middleware available?\nExpress.js\nExpress is the most popular and widely used Node.js framework, known for its simplicity and flexibility.\nIdeal for: Building web applications and APIs of any size\nLearning Curve: Low to Moderate\nPerformance: Good for most use cases\nEcosystem: Largest in the Node.js ecosystem\nKey Features:\nMinimal and flexible web framework\nRobust routing system\nHTTP utilities and middleware\nTemplate engine support\nServes as the foundation for many other frameworks\nBest For: General-purpose web applications, APIs, and as a foundation for more specialized frameworks.\nExpress.js is covered more closely in our Express.js chapter.\nNest.js\nNest.js is a progressive framework inspired by Angular, built with TypeScript, and designed for building efficient, scalable server-side applications.\nIdeal for: Enterprise applications, microservices, and complex APIs\nLearning Curve: Moderate to High (especially without Angular experience)\nPerformance: Excellent, built on top of Express or Fastify\nEcosystem: Growing rapidly with strong corporate backing\nKey Features:\nTypeScript-first development\nDependency injection system\nModular architecture\nCompatible with most Express middleware\nBuilt-in support for GraphQL, WebSockets, and microservices\nStrong typing and solid architectural patterns\nBest For: Enterprise applications, complex APIs, and microservices architectures, particularly for teams familiar with Angular.\nFastify\nFastify is a web framework focused on providing the best developer experience with minimal overhead and maximum performance.\nIdeal for: High-performance APIs and services\nLearning Curve: Low to Moderate\nPerformance: One of the fastest Node.js frameworks\nEcosystem: Growing, with good plugin support\nKey Features:\nHighly performant (up to 2x faster than Express)\nSchema-based validation using JSON Schema\nPlugin architecture\nBuilt-in logger\nAsynchronous by default\nTypeScript support\nBest For: High-performance applications, APIs where speed is critical, and projects that benefit from schema validation.\nKoa.js\nCreated by the team behind Express, Koa aims to be a smaller, more expressive, and more robust foundation for web applications and APIs.\nIdeal for: Modern web applications and APIs using async/await\nLearning Curve: Moderate (requires understanding of async/await)\nPerformance: Excellent, lighter than Express\nEcosystem: Good, though smaller than Express\nKey Features:\nModern middleware architecture using async/await\nStreamlined error handling\nNo bundled middleware, keeping it light\nBetter error handling through try/catch\nCleaner, more expressive codebase than Express\nBest For: Developers who want more control over their middleware stack and prefer a more modern approach than Express.\nHapi.js\nHapi.js is a rich framework for building applications and services, focusing on configuration rather than code and built-in support for input validation, caching, and error handling.\nKey Features:\nConfiguration-driven architecture\nIntegrated authentication and authorization\nBuilt-in validation with Joi\nCaching\nPlugin system\nDetailed API documentation\nBest For: Enterprise-level applications and teams that prefer configuration over code.\nAdonis.js\nAdonis.js is a full-stack MVC framework for Node.js, inspired by Laravel.\nIt provides a stable ecosystem to write server-side web applications.\nKey Features:\nMVC architecture\nBuilt-in ORM (Lucid)\nAuthentication system\nValidation\nDatabase migrations\nWebSocket support\nTesting tools\nBest For: Full-stack applications, especially for developers familiar with Laravel or other MVC frameworks.\nSocket.io\nWhile not a traditional web framework, Socket.io is essential for real-time, bidirectional communication between web clients and servers.\nBest For: Real-time applications like chat applications, live dashboards, and collaborative tools.\nMeteor\nMeteor is an ultra-simple, full-stack JavaScript platform for building modern web and mobile applications.\nBest For: Full-stack JavaScript applications, particularly when the same codebase should run on both client and server.\nLoopback\nLoopBack is a highly extensible, open-source Node.js framework based on Express that enables you to quickly create dynamic end-to-end REST APIs.\nBest For: Building APIs quickly with minimal coding, especially when connecting to various data sources.\nAPI-Focused Frameworks\nThese frameworks are designed specifically for building APIs and RESTful web services.\nRestify\nRestify is a framework designed specifically for building RESTful web services.\nBest For: Building RESTful APIs at scale, particularly when DTrace observability is important.\nStrapi\nStrapi is a headless CMS and API generator that lets you build APIs without writing any code.\nBest For: Content-heavy applications, headless CMS needs, and rapid API development with a visual interface.\nChoosing the Right Framework\nSelecting the right framework depends on your project's requirements, your team's expertise, and your specific goals. Consider these factors:\nPerformance Requirements\nFor maximum performance: Fastify\nFor balanced performance and features: Express or Koa\nProject Type\nREST APIs: Express, Fastify, or Restify\nFull-stack applications: Adonis.js, Meteor, or Next.js\nEnterprise applications: Nest.js or Loopback\nReal-time applications: Socket.io with Express or Koa\nTeam Experience\nJavaScript developers: Express or Koa\nTypeScript developers: Nest.js\nAngular developers: Nest.js\nLaravel/PHP developers: Adonis.js\nLearning Curve\nEasiest to learn: Express\nModerate learning curve: Koa, Fastify, Hapi\nSteeper learning curve: Nest.js, Adonis.js\nFramework Popularity\nThe popularity of a framework affects community support, available resources, and longevity. As of 2023, framework popularity (from highest to lowest) is roughly:\nExpress.js\nNest.js\nFastify\nKoa.js\nHapi.js\nFramework Comparison\nThis comparison table helps you quickly evaluate different Node.js frameworks based on key criteria:\nGetting Started with a Framework\nProject Structure Best Practices\nFramework Selection Guide\nYou're new to Node.js\nYou need maximum flexibility\nYou want the largest ecosystem\nYou're building a REST API or traditional web app\nYou're building an enterprise application\nYou prefer TypeScript\nYou need dependency injection\nYou're familiar with Angular\nPerformance is critical\nYou're building JSON APIs\nYou want built-in schema validation\nYou prefer async/await\nYou want a more modern Express alternative\nYou prefer using async/await\nYou need better error handling\nYou want more control over the request/response cycle\nNext Steps\nNow that you're familiar with Node.js frameworks, you might want to:\nDive deeper into Express.js, the most popular Node.js framework\nLearn about building RESTful APIs with Node.js\nExplore authentication in Node.js applications\nDiscover how to deploy Node.js applications to production",
      "examples": [
        "const express = require('express');\nconst app = express();\nconst port = 8080;\n\napp.get('/', (req, res) => {\nres.send('Hello World from Express.js!');\n});\n\napp.listen(port, () => {\nconsole.log(`Express server running at http://localhost:${port}`);\n});",
        "// app.controller.ts\nimport { Controller, Get } from '@nestjs/common';\n\n@Controller()\nexport class AppController {\n@Get()\ngetHello(): string {\nreturn 'Hello World from Nest.js!';\n}\n}\n\n// main.ts\nimport { NestFactory } from '@nestjs/core';\nimport { AppModule } from './app.module';\n\nasync function bootstrap() {\nconst app = await NestFactory.create(AppModule);\nawait app.listen(8080);\nconsole.log(`Nest.js server running at http://localhost:8080`);\n}\nbootstrap();",
        "const fastify = require('fastify')({ logger: true });\nconst port = 8080;\n\n// Declare a route\nfastify.get('/', async (request, reply) => {\nreturn { hello: 'Hello World from Fastify!' };\n});\n\n// Run the server\nconst start = async () => {\ntry {\nawait fastify.listen({ port });\nfastify.log.info(`Fastify server running at http://localhost:${port}`);\n} catch (err) {\nfastify.log.error(err);\nprocess.exit(1);\n}\n};\n\nstart();",
        "const Koa = require('koa');\nconst app = new Koa();\nconst port = 8080;\n\n// Response middleware\napp.use(async ctx => {\nctx.body = 'Hello World from Koa.js!';\n});\n\napp.listen(port, () => {\nconsole.log(`Koa server running at http://localhost:${port}`);\n});",
        "const Hapi = require('@hapi/hapi');\n\nconst init = async () => {\nconst server = Hapi.server({\nport: 8080,\nhost: 'localhost'\n});\n\nserver.route({\nmethod: 'GET',\npath: '/',\nhandler: (request, h) => {\nreturn 'Hello World from Hapi.js!';\n}\n});\n\nawait server.start();\nconsole.log(`Hapi server running at ${server.info.uri}`);\n};\n\ninit();",
        "// routes.js\n'use strict'\n\nconst Route = use('Route')\n\nRoute.get('/', () => {\nreturn 'Hello World from Adonis.js!'\n})\n\n// server.js\nconst { Ignitor } = require('@adonisjs/ignitor')\n\nnew Ignitor(require('@adonisjs/fold'))\n.appRoot(__dirname)\n.fireHttpServer()\n.catch(console.error)",
        "const http = require('http');\nconst server = http.createServer();\nconst { Server } = require('socket.io');\nconst io = new Server(server);\nconst port = 8080;\n\nio.on('connection', (socket) => {\nconsole.log('a user connected');\n\nsocket.on('chat message', (msg) => {\nconsole.log('message: ' + msg);\nio.emit('chat message', msg);\n});\n\nsocket.on('disconnect', () => {\nconsole.log('user disconnected');\n});\n});\n\nserver.listen(port, () => {\nconsole.log(`Socket.io server running at http://localhost:${port}`);\n});",
        "// server/main.js\nimport { Meteor } from 'meteor/meteor';\nimport { LinksCollection } from '/imports/api/links';\n\nfunction insertLink({ title, url }) {\nLinksCollection.insert({title, url, createdAt: new Date()});\n}\n\nMeteor.startup(() => {\n// If the Links collection is empty, add some data.\nif (LinksCollection.find().count() === 0) {\ninsertLink({\ntitle: 'W3Schools.com',\nurl: 'https://www.w3schools.com'\n});\n}\n});",
        "// src/controllers/hello.controller.ts\nimport {get} from '@loopback/rest';\n\nexport class HelloController {\n@get('/hello')\nhello(): string {\nreturn 'Hello World from LoopBack!';\n}\n}\n\n// src/application.ts\nimport {ApplicationConfig} from '@loopback/core';\nimport {RestApplication} from '@loopback/rest';\nimport {HelloController} from './controllers/hello.controller';\n\nexport class MyApplication extends RestApplication {\nconstructor(options: ApplicationConfig = {}) {\nsuper(options);\nthis.controller(HelloController);\n}\n}",
        "const restify = require('restify');\n\nconst server = restify.createServer();\nconst port = 8080;\n\nserver.get('/', function(req, res, next) {\nres.send('Hello World from Restify!');\nnext();\n});\n\nserver.listen(port, function() {\nconsole.log(`Restify server running at http://localhost:${port}`);\n});",
        "// Strapi is typically configured through a UI interface rather than code\n\n// Example of programmatically creating content from a controller\nmodule.exports = {\nasync create(ctx) {\n// Create a new article\nconst entity = await strapi.services.article.create(ctx.request.body);\n\n// Return the created article\nreturn entity;\n}\n};",
        "# Create a new project directory\nmkdir my-express-app\ncd my-express-app\n\n# Initialize npm and install Express\nnpm init -y\nnpm install express\n\n# Create main application file (app.js)\ntouch app.js",
        "my-express-app/\n├── node_modules/ # Dependencies\n├── config/ # Configuration files\n│ ├── db.js # Database configuration\n│ └── env.js # Environment variables\n├── controllers/ # Route controllers\n├── models/ # Database models\n├── routes/ # Route definitions\n├── middleware/ # Custom middleware\n├── public/ # Static files\n├── tests/ # Test files\n├── .env # Environment variables\n├── .gitignore # Git ignore file\n├── app.js # Application entry point\n└── package.json # Project configuration"
      ]
    },
    {
      "title": "Node.js Express.js",
      "summary": "What is Express.js?\nExpress.js (or simply Express) is the most popular Node.js web application framework, designed for building web applications and APIs.\nIt's often called the de facto standard server framework for Node.js.\nKey Characteristics:\nMinimal and flexible\nUnopinionated (you decide how to structure your app)\nLightweight and fast\nExtensible through middleware\nHuge ecosystem of plugins and extensions\nWhy Choose Express.js?\nExpress provides a thin layer of fundamental web application features without obscuring Node.js features.\nIt offers:\nA robust routing system\nHTTP helpers (redirection, caching, etc.)\nSupport for middleware to respond to HTTP requests\nA templating engine for dynamic HTML rendering\nError handling middleware\nGetting Started with Express\nExpress can be added to any Node.js project. Here's how to get started with a new Express application.\nPrerequisites\nBefore you begin, make sure you have:\nNode.js installed (v14.0.0 or later recommended)\nnpm (comes with Node.js) or yarn\nA code editor (VS Code, WebStorm, etc.)\nInstalling Express\nTo use Express in your Node.js application, you first need to install it:\nTo install Express and save it in your package.json dependencies:\nHello World Example\nLet's create a simple \"Hello World\" application with Express.\nThis example demonstrates the basic structure of an Express application.\nKey Components:\nImporting the Express module\nCreating an Express application instance\nDefining routes\nStarting the server\nSave this code in a file named app.js and run it with Node.js:\nThen, open your browser and navigate to http://localhost:8080 to see the \"Hello World\" message.\nBasic Routing\nRouting refers to how an application responds to client requests to specific endpoints (URIs) using different HTTP methods (GET, POST, PUT, DELETE, etc.).\nExpress provides simple methods to define routes that correspond to HTTP methods:\napp.get() - Handle GET requests\napp.post() - Handle POST requests\napp.put() - Handle PUT requests\napp.delete() - Handle DELETE requests\napp.all() - Handle all HTTP methods\nRoute Parameters\nRoute parameters are named URL segments that capture values at specific positions in the URL.\nThey are specified in the path with a colon : prefix.\nExample: /users/:userId/books/:bookId\nIn this example, userId and bookId are route parameters that can be accessed via req.params.\nQuery Parameters\nQuery parameters are key-value pairs that appear after the ? in a URL.\nThey are automatically parsed by Express and available in req.query.\nExample URL: http://example.com/search?q=express&page=2\nIn this URL, q=express and page=2 are query parameters that can be accessed as req.query.q and req.query.page.\nAccess this route with a URL like: http://localhost:8080/search?q=express&category=framework\nMiddleware in Express\nMiddleware functions are the backbone of Express applications.\nThey have access to:\nThe request object (req)\nThe response object (res)\nThe next middleware function in the stack (next)\nMiddleware can:\nExecute any code\nModify request and response objects\nEnd the request-response cycle\nCall the next middleware in the stack\nBuilt-in Middleware\nExpress includes several useful middleware functions:\nexpress.json() - Parse JSON request bodies\nexpress.urlencoded() - Parse URL-encoded request bodies\nexpress.static() - Serve static files\nexpress.Router() - Create modular route handlers\nError Handling in Express\nError handling in Express is done through special middleware functions that have four arguments:\n(err, req, res, next).\nKey Points:\nError-handling middleware must have four arguments\nIt should be defined after other app.use() and route calls\nYou can have multiple error-handling middleware functions\nUse next(err) to pass errors to the next error handler\nExpress comes with a default error handler to catch errors that occur during request processing:\nServing Static Files\nExpress can serve static files like images, CSS, and JavaScript using the built-in express.static middleware.\nBest Practices:\nPlace static files in a dedicated directory (commonly public or static)\nMount the static middleware before your routes\nConsider using a CDN in production for better performance\nSet appropriate cache headers for static assets\nTo serve static files such as images, CSS files, and JavaScript files, use the express.static built-in middleware function:\nThis assumes you have a directory named public in the same directory as your script with subdirectories for images, CSS, and JavaScript files.\nRouting in Separate Files\nFor better organization, you can define routes in separate files using Express Router:\nroutes/users.js\nroutes/products.js\napp.js (main file)\nTemplate Engines\nExpress can be configured with template engines to generate dynamic HTML:\nTo use this example, you'll need to install the EJS template engine:\nAnd create a file at views/index.ejs:\nBuilding a RESTful API\nExpress is commonly used to build RESTful APIs. That is covered in our Node.js Express REST API chapter.\nExpress Application Generator\nThe Express Application Generator is a tool that helps you quickly create an Express application skeleton.\nKey Features:\nCreates a well-structured application\nSets up a development environment\nConfigures common middleware\nIncludes error handling\nSupports various template engines\nInstallation: npm install -g express-generator\nUsage: express --view=pug myapp\nExpress provides an application generator tool to quickly create an application skeleton:\nThis creates an application with the following directory structure:\nExpress.js Best Practices\nFollow these best practices to build robust, maintainable Express applications:\nProject Structure: Organize your code by feature or component\nEnvironment Variables: Use dotenv for configuration\nError Handling: Centralize error handling\nLogging: Use a logging library like morgan or winston\nSecurity: Implement security best practices (helmet, rate limiting, etc.)\nValidation: Validate input using libraries like express-validator\nTesting: Write tests using jest, mocha, or similar\nProduction Best Practices\nWhen deploying to production, consider these additional practices:\nSet NODE_ENV to \"production\"\nUse a process manager like PM2 or Forever\nEnable compression with compression middleware\nUse a reverse proxy like Nginx\nImplement proper logging and monitoring\nSet up proper error tracking\nSecurity Best Practices\nUse Helmet to secure your Express apps by setting various HTTP headers\nUse environment variables for configuration\nImplement proper error handling\nUse HTTPS in production\nValidate user input to prevent injection attacks\nSet appropriate CORS policies\nPerformance Best Practices\nUse compression middleware to compress responses\nImplement proper caching strategies\nConsider using a reverse proxy (like Nginx) in front of your Express app\nUse clustering to take advantage of multi-core systems\nOptimize database queries",
      "examples": [
        "npm install express",
        "npm install express --save",
        "const express = require('express');\nconst app = express();\nconst port = 8080;\n\n// Define a route for GET requests to the root URL\napp.get('/', (req, res) => {\nres.send('Hello World from Express!');\n});\n\n// Start the server\napp.listen(port, () => {\nconsole.log(`Example app listening at http://localhost:${port}`);\n});",
        "node app.js",
        "const express = require('express');\nconst app = express();\nconst port = 8080;\n\n// Respond to GET request on the root route\napp.get('/', (req, res) => {\nres.send('GET request to the homepage');\n});\n\n// Respond to POST request on the root route\napp.post('/', (req, res) => {\nres.send('POST request to the homepage');\n});\n\n// Respond to GET request on the /about route\napp.get('/about', (req, res) => {\nres.send('About page');\n});\n\n// Catch all other routes\napp.all('*', (req, res) => {\nres.status(404).send('404 - Page not found');\n});\n\n// Start the server\napp.listen(port, () => {\nconsole.log(`Example app listening at http://localhost:${port}`);\n});",
        "const express = require('express');\nconst app = express();\nconst port = 8080;\n\n// Route with parameters\napp.get('/users/:userId/books/:bookId', (req, res) => {\n// Access parameters using req.params\nres.send(`User ID: ${req.params.userId}, Book ID: ${req.params.bookId}`);\n});\n\napp.listen(port, () => {\nconsole.log(`Example app listening at http://localhost:${port}`);\n});",
        "const express = require('express');\nconst app = express();\nconst port = 8080;\n\n// Route handling query parameters\napp.get('/search', (req, res) => {\n// Access query parameters using req.query\nconst { q, category } = req.query;\nres.send(`Search query: ${q}, Category: ${category || 'none'}`);\n});\n\napp.listen(port, () => {\nconsole.log(`Example app listening at http://localhost:${port}`);\n});",
        "const express = require('express');\nconst app = express();\nconst port = 8080;\n\n// Middleware to parse JSON request bodies\napp.use(express.json());\n\n// Middleware to parse URL-encoded request bodies\napp.use(express.urlencoded({ extended: true }));\n\n// Middleware to serve static files from a directory\napp.use(express.static('public'));\n\n\n// POST route that uses JSON middleware\napp.post('/api/users', (req, res) => {\n// req.body contains the parsed JSON data\nconsole.log(req.body);\nres.status(201).json({ message: 'User created', user: req.body });\n});\n\napp.listen(port, () => {\nconsole.log(`Example app listening at http://localhost:${port}`);\n});",
        "const express = require('express');\nconst app = express();\nconst port = 8080;\n\n// Route that may throw an error\napp.get('/error', (req, res) => {\n// Simulating an error\nthrow new Error('Something went wrong!');\n});\n\n// Route that uses next(error) for asynchronous code\napp.get('/async-error', (req, res, next) => {\n// Simulating an asynchronous operation that fails\nsetTimeout(() => {\ntry {\n// Something that might fail\nconst result = nonExistentFunction(); // This will throw an error\nres.send(result);\n}\ncatch (error) {\nnext(error); // Pass errors to Express\n}\n}, 100);\n});\n\n// Custom error handling middleware\n// Must have four parameters to be recognized as an error handler\napp.use((err, req, res, next) => {\nconsole.error(err.stack);\nres.status(500).send('Something broke!');\n});\n\napp.listen(port, () => {\nconsole.log(`Example app listening at http://localhost:${port}`);\n});",
        "const express = require('express');\nconst path = require('path');\nconst app = express();\nconst port = 8080;\n\n// Serve static files from the 'public' directory\napp.use(express.static('public'));\n\n// You can also specify a virtual path prefix\napp.use('/static', express.static('public'));\n\n// Using absolute path (recommended)\napp.use('/assets', express.static(path.join(__dirname, 'public')));\n\napp.get('/', (req, res) => {\nres.send(`\n<h1>Static Files Example</h1>\n<img src=\"/images/logo.png\" alt=\"Logo\">\n<link rel=\"stylesheet\" href=\"/css/style.css\">\n<script src=\"/js/script.js\"></script>\n`);\n});\n\napp.listen(port, () => {\nconsole.log(`Example app listening at http://localhost:${port}`);\n});",
        "const express = require('express');\nconst router = express.Router();\n\n// Middleware specific to this router\nrouter.use((req, res, next) => {\nconsole.log('Users Router Time:', Date.now());\nnext();\n});\n\n// Define routes\nrouter.get('/', (req, res) => {\nres.send('Users home page');\n});\n\nrouter.get('/:id', (req, res) => {\nres.send(`User profile for ID: ${req.params.id}`);\n});\n\nmodule.exports = router;",
        "const express = require('express');\nconst router = express.Router();\n\n// Define routes\nrouter.get('/', (req, res) => {\nres.send('Products list');\n});\n\nrouter.get('/:id', (req, res) => {\nres.send(`Product details for ID: ${req.params.id}`);\n});\n\nmodule.exports = router;",
        "const express = require('express');\nconst usersRouter = require('./routes/users');\nconst productsRouter = require('./routes/products');\n\nconst app = express();\nconst port = 8080;\n\n// Use the routers\napp.use('/users', usersRouter);\napp.use('/products', productsRouter);\n\napp.get('/', (req, res) => {\nres.send('Main application home page');\n});\n\napp.listen(port, () => {\nconsole.log(`Example app listening at http://localhost:${port}`);\n});",
        "const express = require('express');\nconst app = express();\nconst port = 8080;\n\n// Set the view engine to EJS\napp.set('view engine', 'ejs');\n\n// Set the directory where templates are located\napp.set('views', './views');\n\n// Route that renders a template\napp.get('/', (req, res) => {\nconst data = {\ntitle: 'Express Template Example',\nmessage: 'Hello from EJS!',\nitems: ['Item 1', 'Item 2', 'Item 3']\n};\n\n// Renders the views/index.ejs template\nres.render('index', data);\n});\n\napp.listen(port, () => {\nconsole.log(`Example app listening at http://localhost:${port}`);\n});",
        "npm install ejs",
        "<!DOCTYPE html>\n<html>\n<head>\n<title><%= title %></title>\n</head>\n<body>\n<h1><%= title %></h1>\n<p><%= message %></p>\n\n<h2>Items:</h2>\n<ul>\n<% items.forEach(function(item) { %>\n<li><%= item %></li>\n< % }); %>\n</ul>\n</body>\n</html>",
        "# Install the generator globally\nnpm install -g express-generator\n\n# Create a new Express application\nexpress --view=ejs myapp\n\n# Navigate to the app directory\ncd myapp\n\n# Install dependencies\nnpm install\n\n# Start the app\nnpm start",
        "myapp/\n├── app.js\n├── bin/\n│  └── www\n├── package.json\n├── public/\n│  ├── images/\n│  ├── javascripts/\n│  └── stylesheets/\n│    └── style.css\n├── routes/\n│  ├── index.js\n│  └── users.js\n└── views/\n├── error.ejs\n└── index.ejs",
        "const express = require('express');\nconst helmet = require('helmet');\nconst cors = require('cors');\nconst app = express();\n\n// Security middleware\napp.use(helmet());\n\n// CORS configuration\napp.use(cors({\norigin: 'https://example.com',\nmethods: ['GET', 'POST'],\nallowedHeaders: ['Content-Type', 'Authorization']\n}));\n\n// Other middleware and routes\n// ...",
        "app.js",
        "http://localhost:8080",
        "app.get()",
        "app.post()",
        "app.put()",
        "app.delete()",
        "app.all()",
        ":",
        "/users/:userId/books/:bookId",
        "userId",
        "bookId",
        "req.params",
        "?",
        "req.query",
        "http://example.com/search?q=express&page=2",
        "q=express",
        "page=2",
        "req.query.q",
        "req.query.page",
        "http://localhost:8080/search?q=express&category=framework",
        "req",
        "res",
        "next",
        "express.json()",
        "express.urlencoded()",
        "express.static()",
        "express.Router()",
        "(err, req, res, next)",
        "app.use()",
        "next(err)",
        "express.static",
        "public",
        "static",
        "views/index.ejs",
        "npm install -g express-generator",
        "express --view=pug myapp",
        "dotenv",
        "morgan",
        "winston",
        "express-validator",
        "jest",
        "mocha",
        "NODE_ENV",
        "compression"
      ]
    },
    {
      "title": "Node.js Middleware",
      "summary": "Introduction to Middleware\nMiddleware is a key part of Node.js web applications, particularly in Express.js.\nIt provides a way to add and reuse common functionality across your application's routes and endpoints.\nKey Characteristics of Middleware:\nExecutes during the request-response cycle\nCan modify request and response objects\nCan end the request-response cycle\nCan call the next middleware in the stack\nCan be application-level, router-level, or route-specific\nIt acts as a bridge between the raw request and the final intended route handler.\nAt its core, middleware is a function that has access to:\nThe request object (req)\nThe response object (res)\nThe next middleware function in the application's request-response cycle\nMiddleware functions can perform a variety of tasks:\nExecute any code\nModify request and response objects\nEnd the request-response cycle\nCall the next middleware function in the stack\nThink of middleware as a series of processing layers that requests pass through before receiving a response—like an assembly line for HTTP requests.\nHow Middleware Works in the Request-Response Cycle\nMiddleware functions are executed in the order they are defined, creating a pipeline through which requests flow.\nEach middleware function can perform operations on the request and response objects and decide whether to pass control to the next middleware or end the request-response cycle.\nLifecycle of a Request Through Middleware:\nRequest received by the server\nPassed through each middleware in sequence\nRoute handler processes the request\nResponse flows back through middleware (in reverse order)\nResponse sent to client\nThe basic pattern of middleware in Express.js follows this structure:\nWhen you call next(), the next middleware in the stack is executed.\nIf you don't call next(), the request-response cycle ends and no further middleware runs.\nExample: A Simple Middleware ChainGet your own Node.js Server\nWhen a request is made to the root path ('/'), the following happens:\nMiddleware 1 logs a message and calls next()\nMiddleware 2 logs a message and calls next()\nThe route handler responds with \"Hello World!\"\nREMOVE ADS\nComprehensive Guide to Middleware Types\nUnderstanding the different types of middleware helps in organizing your application's logic effectively.\nMiddleware can be categorized based on its scope, purpose, and how it's mounted in the application.\nChoosing the Right Type: The type of middleware you use depends on your specific needs, such as whether the middleware should run for all requests or specific routes, and whether it needs access to the router instance.\nIn Node.js applications, especially with Express.js, there are several types of middleware:\nApplication-level Middleware\nApplication-level middleware is bound to the Express application instance using app.use() or app.METHOD() functions.\nUse Cases: Logging, authentication, request parsing, and other operations that should run for every request.\nBest Practices: Define application-level middleware before defining routes to ensure they run in the correct order.\nBound to the application instance using app.use() or app.METHOD():\nRouter-level Middleware\nRouter-level middleware works similarly to application-level middleware but is bound to an instance of express.Router().\nUse Cases: Grouping route-specific middleware, API versioning, and organizing routes into logical groups.\nAdvantages: Better code organization, modular routing, and the ability to apply middleware to specific route groups.\nBound to an instance of express.Router():\nError-handling Middleware\nError-handling middleware is defined with four arguments (err, req, res, next) and is used to handle errors that occur during request processing.\nKey Points:\nMust have exactly four parameters\nShould be defined after other app.use() and route calls\nCan be used to centralize error handling logic\nCan forward errors to the next error handler using next(err)\nDefined with four arguments instead of three (err, req, res, next):\nBuilt-in Middleware\nExpress includes several built-in middleware functions that handle common web application tasks.\nCommon Built-in Middleware:\nexpress.json(): Parse JSON request bodies\nexpress.urlencoded(): Parse URL-encoded request bodies\nexpress.static(): Serve static files\nexpress.Router(): Create modular route handlers\nBest Practice: Always use the built-in middleware when possible as they are well-tested and maintained by the Express team.\nExpress comes with some built-in middleware functions:\nThird-party Middleware\nThe Node.js ecosystem offers numerous third-party middleware packages that extend Express functionality.\nPopular Third-party Middleware:\nHelmet: Secure your app by setting various HTTP headers\nMorgan: HTTP request logger\nCORS: Enable CORS with various options\nCompression: Compress HTTP responses\nCookie-parser: Parse Cookie header and populate req.cookies\nInstallation Example: npm install helmet morgan cors compression cookie-parser\nExternal middleware that adds functionality to Express apps:\nCommon Third-party Middleware:\nmorgan (logging)\nhelmet (security)\ncors (cross-origin resource sharing)\ncompression (response compression)\ncookie-parser (cookie handling)\nCreating and Using Custom Middleware\nCreating custom middleware allows you to implement application-specific functionality in a reusable way.\nWell-designed middleware should be focused, testable, and follow the single responsibility principle.\nBest Practices for Custom Middleware:\nKeep middleware focused on a single responsibility\nDocument the middleware's purpose and requirements\nHandle errors appropriately\nConsider performance implications\nMake middleware configurable through options\nCreating your own middleware functions is straightforward and allows you to add custom functionality to your application.\nExample: Simple Logger Middleware\nExample: Authentication Middleware\nExample: Request Validation Middleware\nError-Handling Middleware\nError-handling middleware is special because it takes four parameters instead of three: (err, req, res, next).\nExample: Basic Error Handler\nHandling Async Errors\nFor async middleware, make sure to catch promise rejections and pass them to next():\nNote: Express 5 (currently in beta) will automatically catch Promise rejections and pass them to the error handler.\nMiddleware Execution Order\nThe order in which middleware is defined matters significantly.\nExpress executes middleware in the order they are added to the application.\nExample: Order Matters\nBest practices for middleware order:\nPlace middleware that applies to all requests first (logging, security, body parsing)\nPlace more specific middleware and routes next\nPlace error-handling middleware last\nExample: Recommended Order\nBest Practices\nFollow these best practices when working with middleware in Node.js:\n1. Keep Middleware Focused\nEach middleware should have a single responsibility, following the Single Responsibility Principle.\n2. Use Next() Properly\nAlways call next() unless you're ending the response\nNever call next() after sending a response\nCall next() with an error parameter to trigger error handling\n3. Handle Async Code Properly\nAlways catch errors in async middleware and pass them to next().\n4. Don't Overuse Middleware\nToo many middleware functions can impact performance. Use them judiciously.\n5. Organize by Domain\nGroup related middleware in separate files based on functionality.\n6. Use Conditional Next()\nMiddleware can decide whether to continue the chain based on conditions:\nPro Tip: Create reusable middleware factories by returning functions that generate middleware with specific configurations.",
      "examples": [
        "app.use((req, res, next) => {\n// Middleware code goes here\nconsole.log('Time:', Date.now());\n\n// Call next() to pass control to the next middleware function\nnext();\n});",
        "const express = require('express');\nconst app = express();\n\n// First middleware\napp.use((req, res, next) => {\nconsole.log('Middleware 1: This always runs');\nnext();\n});\n\n// Second middleware\napp.use((req, res, next) => {\nconsole.log('Middleware 2: This also always runs');\nnext();\n});\n\n// Route handler\napp.get('/', (req, res) => {\nres.send('Hello World!');\n});\n\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "const express = require('express');\nconst app = express();\n\n// Application-level middleware\napp.use((req, res, next) => {\nconsole.log('Time:', Date.now());\nnext();\n});",
        "const express = require('express');\nconst router = express.Router();\n\n// Router-level middleware\nrouter.use((req, res, next) => {\nconsole.log('Router specific middleware');\nnext();\n});\n\nrouter.get('/user/:id', (req, res) => {\nres.send('User profile');\n});\n\n// Add the router to the app\napp.use('/api', router);",
        "app.use((err, req, res, next) => {\nconsole.error(err.stack);\nres.status(500).send('Something broke!');\n});",
        "// Parse JSON bodies\napp.use(express.json());\n\n// Parse URL-encoded bodies\napp.use(express.urlencoded({ extended: true }));\n\n// Serve static files\napp.use(express.static('public'));",
        "const morgan = require('morgan');\nconst helmet = require('helmet');\n\n// HTTP request logger\napp.use(morgan('dev'));\n\n// Security headers\napp.use(helmet());",
        "// Create a simple logging middleware\nfunction requestLogger(req, res, next) {\nconst timestamp = new Date().toISOString();\nconsole.log(`${timestamp} - ${req.method} ${req.url}`);\nnext(); // Don't forget to call next()\n}\n\n// Use the middleware\napp.use(requestLogger);",
        "// Authentication middleware\nfunction authenticate(req, res, next) {\nconst authHeader = req.headers.authorization;\n\nif (!authHeader) {\nreturn res.status(401).send('Authentication required');\n}\n\nconst token = authHeader.split(' ')[1];\n\n// Verify the token (simplified)\nif (token === 'secret-token') {\n// Authentication successful\nreq.user = { id: 123, username: 'john' };\nnext();\n} else {\nres.status(403).send('Invalid token');\n}\n}\n\n// Apply to specific routes\napp.get('/api/protected', authenticate, (req, res) => {\nres.json({ message: 'Protected data', user: req.user });\n});",
        "// Validate a user creation request\nfunction validateUserCreation(req, res, next) {\nconst { username, email, password } = req.body;\n\n// Simple validation\nif (!username || username.length < 3) {\nreturn res.status(400).json({ error: 'Username must be at least 3 characters' });\n}\n\nif (!email || !email.includes('@')) {\nreturn res.status(400).json({ error: 'Valid email is required' });\n}\n\nif (!password || password.length < 6) {\nreturn res.status(400).json({ error: 'Password must be at least 6 characters' });\n}\n\n// Validation passed\nnext();\n}\n\n// Apply to user creation route\napp.post('/api/users', validateUserCreation, (req, res) => {\n// Process valid user creation\nres.status(201).json({ message: 'User created successfully' });\n});",
        "const express = require('express');\nconst app = express();\n\n// Regular route that might throw an error\napp.get('/error-demo', (req, res, next) => {\ntry {\n// Simulate an error\nthrow new Error('Something went wrong!');\n} catch (error) {\nnext(error); // Pass error to the error handler\n}\n});\n\n// Error-handling middleware\napp.use((err, req, res, next) => {\nconsole.error(err.stack);\nres.status(500).json({\nmessage: 'An error occurred',\nerror: process.env.NODE_ENV === 'production' ? {} : err\n});\n});",
        "// Async middleware with proper error handling\napp.get('/async-data', async (req, res, next) => {\ntry {\nconst data = await fetchDataFromDatabase();\nres.json(data);\n} catch (error) {\nnext(error); // Pass error to the error handler\n}\n});\n\n// Alternative using Express 4.16+ wrapper\nfunction asyncHandler(fn) {\nreturn (req, res, next) => {\nPromise.resolve(fn(req, res, next)).catch(next);\n};\n}\n\napp.get('/better-async', asyncHandler(async (req, res) => {\nconst data = await fetchDataFromDatabase();\nres.json(data);\n}));",
        "const express = require('express');\nconst app = express();\n\n// This middleware will run first\napp.use((req, res, next) => {\nconsole.log('First middleware');\nnext();\n});\n\n// This middleware will run for /users paths only\napp.use('/users', (req, res, next) => {\nconsole.log('Users middleware');\nnext();\n});\n\n// This route handler will run when matched\napp.get('/users', (req, res) => {\nres.send('Users list');\n});\n\n// This middleware will never run for successfully matched routes\n// because route handlers end the request-response cycle\napp.use((req, res, next) => {\nconsole.log('This will not run for matched routes');\nnext();\n});\n\n// This is a \"catch-all\" middleware for unmatched routes\napp.use((req, res) => {\nres.status(404).send('Not found');\n});",
        "// 1. Application-wide middleware\napp.use(express.json());\napp.use(express.urlencoded({ extended: true }));\napp.use(morgan('dev'));\napp.use(helmet());\n\n// 2. Route-specific middleware\napp.use('/api', authenticate);\n\n// 3. Routes\napp.use('/api/users', userRoutes);\napp.use('/api/products', productRoutes);\n\n// 4. 404 handler\napp.use((req, res) => {\nres.status(404).json({ message: 'Not found' });\n});\n\n// 5. Error handler (always last)\napp.use((err, req, res, next) => {\nconsole.error(err);\nres.status(500).json({ message: 'Server error' });\n});",
        "// middleware/auth.js\nexports.authenticate = (req, res, next) => {\n// Authentication logic\n};\n\nexports.requireAdmin = (req, res, next) => {\n// Admin verification logic\n};\n\n// In your app.js\nconst { authenticate, requireAdmin } = require('./middleware/auth');\n\napp.use('/admin', authenticate, requireAdmin);",
        "// Rate limiting middleware example\nfunction rateLimit(req, res, next) {\nconst ip = req.ip;\n\n// Check if IP has made too many requests\nif (tooManyRequests(ip)) {\nreturn res.status(429).send('Too many requests');\n// Note: we don't call next() here\n}\n\n// Otherwise continue\nnext();\n}",
        "// Middleware factory\nfunction requireRole(role) {\nreturn (req, res, next) => {\nif (req.user && req.user.role === role) {\nnext();\n} else {\nres.status(403).send('Access denied');\n}\n};\n}\n\n// Usage\napp.get('/admin', authenticate, requireRole('admin'), (req, res) => {\nres.send('Admin dashboard');\n});\n\napp.get('/editor', authenticate, requireRole('editor'), (req, res) => {\nres.send('Editor dashboard');\n});",
        "next()",
        "app.use()",
        "app.METHOD()",
        "express.Router()",
        "(err, req, res, next)",
        "next(err)",
        "express.json()",
        "express.urlencoded()",
        "express.static()",
        "req.cookies",
        "npm install helmet morgan cors compression cookie-parser",
        "morgan",
        "helmet",
        "cors",
        "compression",
        "cookie-parser"
      ]
    },
    {
      "title": "Node.js RESTful API",
      "summary": "Understanding RESTful APIs\nREST (Representational State Transfer) is an architectural style for designing networked applications that has become the standard for web services.\nRESTful APIs provide a flexible, lightweight way to integrate applications and enable communication between different systems.\nCore Concepts:\nResources: Everything is a resource (user, product, order)\nRepresentations: Resources can have multiple representations (JSON, XML, etc.)\nStateless: Each request contains all necessary information\nUniform Interface: Consistent way to access and manipulate resources\nRESTful APIs use HTTP requests to perform CRUD operations (Create, Read, Update, Delete) on resources, which are represented as URLs.\nREST is stateless, meaning each request from a client to a server must contain all the information needed to understand and process the request.\nUnlike SOAP or RPC, REST is not a protocol but an architectural style that leverages existing web standards like HTTP, URI, JSON, and XML.\nCore REST Principles\nUnderstanding these principles is crucial for designing effective RESTful APIs.\nThey ensure your API is scalable, maintainable, and easy to use.\nKey Principles in Practice:\nResource-Based: Focus on resources rather than actions\nStateless: Each request is independent and self-contained\nCacheable: Responses define their cacheability\nUniform Interface: Consistent resource identification and manipulation\nLayered System: Client doesn't need to know about the underlying architecture\nThe core principles of REST architecture include:\nClient-Server Architecture: Separation of concerns between the client and the server\nStatelessness: No client context is stored on the server between requests\nCacheability: Responses must define themselves as cacheable or non-cacheable\nLayered System: A client cannot tell whether it is connected directly to the end server\nUniform Interface: Resources are identified in requests, resources are manipulated through representations, self-descriptive messages, and HATEOAS (Hypertext As The Engine Of Application State)\nHTTP Methods and Their Usage\nRESTful APIs use standard HTTP methods to perform operations on resources.\nEach method has specific semantics and should be used appropriately.\nIdempotency and Safety:\nSafe Methods: GET, HEAD, OPTIONS (should not modify resources)\nIdempotent Methods: GET, PUT, DELETE (multiple identical requests = same effect as one)\nNon-Idempotent: POST, PATCH (may have different effects with multiple calls)\nAlways use the most specific method that matches your operation's intent.\nExample: Using Different HTTP MethodsGet your own Node.js Server\nREMOVE ADS\nRESTful API Structure and Design\nA well-designed API follows consistent patterns that make it intuitive and easy to use. Good API design is crucial for developer experience and long-term maintainability.\nDesign Considerations:\nResource Naming: Use nouns, not verbs (e.g., /users not /getUsers)\nPluralization: Use plural for collections (/users/123 not /user/123)\nHierarchy: Nest resources to show relationships (/users/123/orders)\nFiltering/Sorting: Use query parameters for optional operations\nVersioning Strategy: Plan for API versioning from the start (e.g., /v1/users vs /v2/users).\nA well-structured API follows these conventions:\nUse nouns for resources: /users, /products, /orders (not /getUsers)\nUse plurals for collections: /users instead of /user\nNest resources for relationships: /users/123/orders\nUse query parameters for filtering: /products?category=electronics&min_price=100\nKeep URLs consistent: Choose a convention (kebab-case, camelCase) and stick to it\nExample: Well-structured API Routes\nBuilding REST APIs with Node.js and Express\nNode.js with Express.js provides an excellent foundation for building RESTful APIs.\nThe following sections outline best practices and patterns for implementation.\nKey Components:\nExpress Router: For organizing routes\nMiddleware: For cross-cutting concerns\nControllers: For handling request logic\nModels: For data access and business logic\nServices: For complex business logic\nExpress.js is the most popular framework for building REST APIs in Node.js.\nHere's a basic project structure:\nProject Structure\nExample: Setting Up Express Router\nControllers and Models\nSeparating concerns between routes, controllers, and models improves code organization and maintainability:\nExample: Controller Implementation\nAPI Versioning\nVersioning helps you evolve your API without breaking existing clients.\nCommon approaches include:\nURI Path Versioning: /api/v1/users\nQuery Parameter: /api/users?version=1\nCustom Header: X-API-Version: 1\nAccept Header: Accept: application/vnd.myapi.v1+json\nExample: URI Path Versioning\nRequest Validation\nAlways validate incoming requests to ensure data integrity and security.\nLibraries like Joi or express-validator can help:\nExample: Request Validation with Joi\nError Handling\nImplement consistent error handling to provide clear feedback to API consumers:\nExample: Centralized Error Handling\nAPI Documentation\nGood documentation is essential for API adoption.\nTools like Swagger/OpenAPI can automatically generate documentation from code:\nExample: Swagger Documentation\nTesting APIs\nTesting is critical for API reliability.\nUse libraries like Jest, Mocha, or Supertest:\nExample: API Testing with Jest and Supertest\nBest Practices Summary\nFollow REST principles and use appropriate HTTP methods\nUse consistent naming conventions for endpoints\nStructure your API logically with resource-based URLs\nReturn appropriate status codes in responses\nImplement proper error handling with clear messages\nUse pagination for large data sets\nVersion your API to maintain backward compatibility\nValidate all input to prevent security issues\nDocument your API thoroughly\nWrite comprehensive tests to ensure reliability\nUse HTTPS for all production APIs\nImplement rate limiting to prevent abuse",
      "examples": [
        "const express = require('express');\nconst app = express();\n\n// Middleware for parsing JSON\napp.use(express.json());\n\nlet users = [\n{ id: 1, name: 'John Doe', email: 'john@example.com' },\n{ id: 2, name: 'Jane Smith', email: 'jane@example.com' }\n];\n\n// GET - Retrieve all users\napp.get('/api/users', (req, res) => {\nres.json(users);\n});\n\n// GET - Retrieve a specific user\napp.get('/api/users/:id', (req, res) => {\nconst user = users.find(u => u.id === parseInt(req.params.id));\nif (!user) return res.status(404).json({ message: 'User not found' });\nres.json(user);\n});\n\n// POST - Create a new user\napp.post('/api/users', (req, res) => {\nconst newUser = {\nid: users.length + 1,\nname: req.body.name,\nemail: req.body.email\n};\nusers.push(newUser);\nres.status(201).json(newUser);\n});\n\n// PUT - Update a user completely\napp.put('/api/users/:id', (req, res) => {\nconst user = users.find(u => u.id === parseInt(req.params.id));\nif (!user) return res.status(404).json({ message: 'User not found' });\n\nuser.name = req.body.name;\nuser.email = req.body.email;\n\nres.json(user);\n});\n\n// DELETE - Remove a user\napp.delete('/api/users/:id', (req, res) => {\nconst userIndex = users.findIndex(u => u.id === parseInt(req.params.id));\nif (userIndex === -1) return res.status(404).json({ message: 'User not found' });\n\nconst deletedUser = users.splice(userIndex, 1);\nres.json(deletedUser[0]);\n});\n\napp.listen(8080, () => {\nconsole.log('REST API server running on port 8080');\n});",
        "// Good API structure\napp.get('/api/products', getProducts);\napp.get('/api/products/:id', getProductById);\napp.get('/api/products/:id/reviews', getProductReviews);\napp.get('/api/users/:userId/orders', getUserOrders);\napp.post('/api/orders', createOrder);\n\n// Filtering and pagination\napp.get('/api/products?category=electronics&sort=price&limit=10&page=2');",
        "- app.js # Main application file\n- routes/ # Route definitions\n- users.js\n- products.js\n- controllers/ # Request handlers\n- userController.js\n- productController.js\n- models/ # Data models\n- User.js\n- Product.js\n- middleware/ # Custom middleware\n- auth.js\n- validation.js\n- config/ # Configuration files\n- db.js\n- env.js\n- utils/ # Utility functions\n- errorHandler.js",
        "// routes/users.js\nconst express = require('express');\nconst router = express.Router();\nconst { getUsers, getUserById, createUser, updateUser, deleteUser } = require('../controllers/userController');\n\nrouter.get('/', getUsers);\nrouter.get('/:id', getUserById);\nrouter.post('/', createUser);\nrouter.put('/:id', updateUser);\nrouter.delete('/:id', deleteUser);\n\nmodule.exports = router;\n// app.js\nconst express = require('express');\nconst app = express();\nconst userRoutes = require('./routes/users');\n\napp.use(express.json());\napp.use('/api/users', userRoutes);\n\napp.listen(8080, () => {\nconsole.log('Server is running on port 8080');\n});",
        "// controllers/userController.js\nconst User = require('../models/User');\n\nconst getUsers = async (req, res) => {\ntry {\nconst users = await User.findAll();\nres.status(200).json(users);\n} catch (error) {\nres.status(500).json({ message: 'Error retrieving users', error: error.message });\n}\n};\n\nconst getUserById = async (req, res) => {\ntry {\nconst user = await User.findById(req.params.id);\nif (!user) {\nreturn res.status(404).json({ message: 'User not found' });\n}\nres.status(200).json(user);\n} catch (error) {\nres.status(500).json({ message: 'Error retrieving user', error: error.message });\n}\n};\n\nconst createUser = async (req, res) => {\ntry {\nconst user = await User.create(req.body);\nres.status(201).json(user);\n} catch (error) {\nres.status(400).json({ message: 'Error creating user', error: error.message });\n}\n};\n\nmodule.exports = { getUsers, getUserById, createUser };",
        "const express = require('express');\nconst app = express();\n\n// Version 1 routes\nconst v1UserRoutes = require('./routes/v1/users');\napp.use('/api/v1/users', v1UserRoutes);\n\n// Version 2 routes with new features\nconst v2UserRoutes = require('./routes/v2/users');\napp.use('/api/v2/users', v2UserRoutes);\n\napp.listen(8080);",
        "const express = require('express');\nconst Joi = require('joi');\nconst app = express();\n\napp.use(express.json());\n\n// Validation schema\nconst userSchema = Joi.object({\nname: Joi.string().min(3).required(),\nemail: Joi.string().email().required(),\nage: Joi.number().integer().min(18).max(120)\n});\n\napp.post('/api/users', (req, res) => {\n// Validate request body\nconst { error } = userSchema.validate(req.body);\nif (error) {\nreturn res.status(400).json({ message: error.details[0].message });\n}\n\n// Process valid request\n// ...\nres.status(201).json({ message: 'User created successfully' });\n});\n\napp.listen(8080);",
        "// utils/errorHandler.js\nclass AppError extends Error {\nconstructor(statusCode, message) {\nsuper(message);\nthis.statusCode = statusCode;\nthis.status = `${statusCode}`.startsWith('4') ? 'fail' : 'error';\nthis.isOperational = true;\n\nError.captureStackTrace(this, this.constructor);\n}\n}\n\nmodule.exports = { AppError };\n\n// middleware/errorMiddleware.js\nconst errorHandler = (err, req, res, next) => {\nerr.statusCode = err.statusCode || 500;\nerr.status = err.status || 'error';\n\n// Different error responses for development and production\nif (process.env.NODE_ENV === 'development') {\nres.status(err.statusCode).json({\nstatus: err.status,\nmessage: err.message,\nstack: err.stack,\nerror: err\n});\n} else {\n// Production: don't leak error details\nif (err.isOperational) {\nres.status(err.statusCode).json({\nstatus: err.status,\nmessage: err.message\n});\n} else {\n// Programming or unknown errors\nconsole.error('ERROR 💥', err);\nres.status(500).json({\nstatus: 'error',\nmessage: 'Something went wrong'\n});\n}\n}\n};\n\nmodule.exports = { errorHandler };\n\n// Usage in app.js\nconst { errorHandler } = require('./middleware/errorMiddleware');\nconst { AppError } = require('./utils/errorHandler');\n\n// This route throws a custom error\napp.get('/api/error-demo', (req, res, next) => {\nnext(new AppError(404, 'Resource not found'));\n});\n\n// Error handling middleware (must be last)\napp.use(errorHandler);",
        "const express = require('express');\nconst swaggerJsDoc = require('swagger-jsdoc');\nconst swaggerUi = require('swagger-ui-express');\n\nconst app = express();\n\n// Swagger configuration\nconst swaggerOptions = {\ndefinition: {\nopenapi: '3.0.0',\ninfo: {\ntitle: 'User API',\nversion: '1.0.0',\ndescription: 'A simple Express User API'\n},\nservers: [\n{\nurl: 'http://localhost:8080',\ndescription: 'Development server'\n}\n]\n},\napis: ['./routes/*.js'] // Path to the API routes folders\n};\n\nconst swaggerDocs = swaggerJsDoc(swaggerOptions);\napp.use('/api-docs', swaggerUi.serve, swaggerUi.setup(swaggerDocs));\n\n/**\n* @swagger\n* /api/users:\n* get:\n* summary: Returns a list of users\n* description: Retrieve a list of all users\n* responses:\n* 200:\n* description: A list of users\n* content:\n* application/json:\n* schema:\n* type: array\n* items:\n* type: object\n* properties:\n* id:\n* type: integer\n* name:\n* type: string\n* email:\n* type: string\n*/\napp.get('/api/users', (req, res) => {\n// Handler implementation\n});\n\napp.listen(8080);",
        "// tests/users.test.js\nconst request = require('supertest');\nconst app = require('../app');\n\ndescribe('User API', () => {\ndescribe('GET /api/users', () => {\nit('should return all users', async () => {\nconst res = await request(app).get('/api/users');\nexpect(res.statusCode).toBe(200);\nexpect(Array.isArray(res.body)).toBeTruthy();\n});\n});\ndescribe('POST /api/users', () => {\nit('should create a new user', async () => {\nconst userData = {\nname: 'Test User',\nemail: 'test@example.com'\n};\nconst res = await request(app)\n.post('/api/users')\n.send(userData);\n\nexpect(res.statusCode).toBe(201);\nexpect(res.body).toHaveProperty('id');\nexpect(res.body.name).toBe(userData.name);\n});\nit('should validate request data', async () => {\nconst invalidData = {\nemail: 'not-an-email'\n};\nconst res = await request(app)\n.post('/api/users')\n.send(invalidData);\n\nexpect(res.statusCode).toBe(400);\n});\n});\n});",
        "/users",
        "/getUsers",
        "/users/123",
        "/user/123",
        "/users/123/orders",
        "/v1/users",
        "/v2/users"
      ]
    },
    {
      "title": "Node.js API Authentication Guide",
      "summary": "What is API Authentication?\nAPI authentication is the process of verifying the identity of clients accessing your Node.js APIs.\nThis comprehensive guide covers various authentication methods, security best practices, and implementation patterns to help you secure your Node.js applications effectively.\nWhy API Authentication Matters\nIn today's interconnected world, API security is not optional—it's a necessity. Proper authentication helps you:\nSecurity Benefits\nAccess Control: Restrict API access to authorized users only\nData Protection: Safeguard sensitive information from unauthorized access\nIdentity Verification: Ensure users are who they claim to be\nBusiness Benefits\nUsage Analytics: Track API usage by user/application\nMonetization: Implement usage-based billing models\nCompliance: Meet regulatory requirements (GDPR, HIPAA, etc.)\nAuthentication Methods Overview\nDifferent authentication methods serve different use cases. Here's a quick comparison:\nAuthentication Methods\nThere are several approaches to API authentication in Node.js\nSession-Based Authentication\nSession-based authentication uses cookies to maintain user state:\nToken-Based Authentication (JWT)\nJSON Web Tokens (JWT) provide a stateless authentication mechanism that's compact and self-contained.\nUnlike session-based authentication, token-based authentication (JWT) doesn't require a server to store session data.\nThis makes it ideal for stateless API architecture and microservices.\nOAuth 2.0 Authentication\nOAuth 2.0 is the industry-standard protocol for authorization, enabling applications to obtain limited access to user accounts on HTTP services.\nIt works by delegating user authentication to the service that hosts the user account.\nOAuth 2.0 Flow Overview\nUser clicks \"Login with [Provider]\" in your app\nUser is redirected to the provider's login page\nUser authenticates and authorizes your app\nProvider redirects back to your app with an authorization code\nYour app exchanges the code for an access token\nYour app can now access the user's data (within the authorized scope)\nImplementation with Passport.js\nAPI Key Authentication\nAPI keys are a simple way to authenticate clients to your API.\nThey're best suited for server-to-server communication or when you need to identify the calling project without user context.\nBest Practices for API Keys:\nStore keys securely (environment variables, secret management services)\nRotate keys regularly\nUse HTTPS to prevent key exposure\nImplement rate limiting per key\nImplementation Example\nAPI Key Authentication\nAPI keys are a simple way to authenticate requests to your API:\nBasic Authentication\nHTTP Basic authentication uses encoded credentials in the Authorization header:\nMulti-Factor Authentication (MFA)\nAdding an extra layer of security with time-based one-time passwords (TOTP):\nSecurity Best Practices\nImportant: Security is not optional when implementing authentication. Follow these best practices to protect your application and users.\nPassword Security\nNever store plain text passwords - Always use strong hashing algorithms like bcrypt or Argon2\nEnforce strong passwords - Require minimum length, special characters, and numbers\nImplement password rotation - Prompt users to change passwords periodically\nToken Security\nUse short-lived access tokens - 15-60 minutes is typical\nImplement refresh tokens - For obtaining new access tokens without re-authentication\nStore tokens securely - Use HTTP-only, secure, same-site cookies for web apps\nGeneral Security\nAlways use HTTPS - Encrypt all traffic\nImplement rate limiting - Prevent brute force attacks\nUse security headers - Like CSP, X-Content-Type-Options, X-Frame-Options\nLog and monitor - Keep audit logs of authentication attempts\nOAuth 2.0 Security\nUse PKCE - For public clients (mobile/native apps)\nValidate redirect URIs - Prevent open redirect vulnerabilities\nStore client secrets securely - Never in version control\nExample: Secure Password Hashing with bcrypt\nWhen implementing API authentication, follow these security best practices:\nHTTPS Only: Always use HTTPS to encrypt data in transit\nPassword Hashing: Store only hashed passwords using bcrypt or Argon2\nToken Management: Keep tokens short-lived and implement refresh tokens\nRate Limiting: Protect against brute force attacks\nInput Validation: Validate all user inputs to prevent injection attacks\nCORS Configuration: Restrict cross-origin requests appropriately\nSecure Headers: Implement security headers like HSTS and CSP\nAudit Logging: Log authentication events for security monitoring\nExample: Password Hashing with Bcrypt\nCombining Authentication Methods\nIn real-world applications, you often need to combine multiple authentication methods:\nHTTP Headers for Authentication\nWhen implementing API authentication, the HTTP headers used are crucial:\nAuthorization header: This is the standard HTTP header used for sending authentication tokens in most API authentication strategies including JWT, OAuth, and Basic Auth\nCommon format: Authorization: Bearer <token> for JWT and OAuth 2.0\nFormat for Basic Auth: Authorization: Basic <base64-encoded-credentials>\nAuthentication Strategies for Different API Types\nConclusion\nYou've now explored the essential authentication methods for Node.js APIs. Here's a quick recap of what we've covered:\nAuthentication Methods\nSession-based - Traditional approach using server-side sessions\nJWT Tokens - Stateless tokens for distributed systems\nOAuth 2.0 - Industry standard for third-party authentication\nAPI Keys - Simple authentication for server-to-server communication\nSecurity Essentials\nAlways use HTTPS\nHash passwords with bcrypt/Argon2\nUse short-lived tokens\nImplement rate limiting",
      "examples": [
        "const express = require('express');\nconst session = require('express-session');\nconst bodyParser = require('body-parser');\nconst app = express();\n\n// Parse request bodies\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({ extended: true }));\n\n// Configure sessions\napp.use(session({\nsecret: 'your-secret-key',\nresave: false,\nsaveUninitialized: false,\ncookie: { secure: process.env.NODE_ENV === 'production', maxAge: 24 * 60 * 60 * 1000 } // 24 hours\n}));\n\n// Sample user database\nconst users = [\n{ id: 1, username: 'user1', password: 'password1' }\n];\n\n// Login route\napp.post('/login', (req, res) => {\nconst { username, password } = req.body;\n\n// Find user\nconst user = users.find(u => u.username === username && u.password === password);\n\nif (!user) {\nreturn res.status(401).json({ message: 'Invalid credentials' });\n}\n\n// Store user information in session (excluding password)\nreq.session.user = {\nid: user.id,\nusername: user.username\n};\n\nres.json({ message: 'Login successful', user: req.session.user });\n});\n\n// Protected route\napp.get('/profile', (req, res) => {\n// Check if user is logged in\nif (!req.session.user) {\nreturn res.status(401).json({ message: 'Unauthorized' });\n}\n\nres.json({ message: 'Profile accessed', user: req.session.user });\n});\n\n// Logout route\napp.post('/logout', (req, res) => {\n// Destroy session\nreq.session.destroy((err) => {\nif (err) {\nreturn res.status(500).json({ message: 'Logout failed' });\n}\nres.json({ message: 'Logout successful' });\n});\n});\n\n// Start server\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "const express = require('express');\nconst jwt = require('jsonwebtoken');\nconst bodyParser = require('body-parser');\nconst app = express();\n\napp.use(bodyParser.json());\n\nconst JWT_SECRET = 'your-jwt-secret-key';\n\n// Sample user database\nconst users = [\n{ id: 1, username: 'user1', password: 'password1', role: 'user' }\n];\n\n// Login route - generate token\napp.post('/login', (req, res) => {\nconst { username, password } = req.body;\n\n// Find user\nconst user = users.find(u => u.username === username && u.password === password);\n\nif (!user) {\nreturn res.status(401).json({ message: 'Invalid credentials' });\n}\n\n// Create payload for JWT\nconst payload = {\nid: user.id,\nusername: user.username,\nrole: user.role\n};\n\n// Sign token\nconst token = jwt.sign(payload, JWT_SECRET, { expiresIn: '1h' });\n\nres.json({ message: 'Login successful', token });\n});\n\n// Middleware for JWT verification\nconst authenticateJWT = (req, res, next) => {\n// Get auth header - The Authorization header is commonly used to send authentication tokens\nconst authHeader = req.headers.authorization;\n\nif (!authHeader) {\nreturn res.status(401).json({ message: 'Authorization header missing' });\n}\n\n// Extract token from \"Bearer <token>\"\nconst token = authHeader.split(' ')[1];\n\nif (!token) {\nreturn res.status(401).json({ message: 'Token missing' });\n}\n\ntry {\n// Verify token\nconst decoded = jwt.verify(token, JWT_SECRET);\n\n// Attach user to request\nreq.user = decoded;\n\nnext();\n} catch (error) {\nreturn res.status(403).json({ message: 'Invalid or expired token' });\n}\n};\n\n// Protected route\napp.get('/profile', authenticateJWT, (req, res) => {\nres.json({ message: 'Profile accessed', user: req.user });\n});\n\n// Role-based route\napp.get('/admin', authenticateJWT, (req, res) => {\n// Check if user has admin role\nif (req.user.role !== 'admin') {\nreturn res.status(403).json({ message: 'Access denied: admin role required' });\n}\n\nres.json({ message: 'Admin panel accessed' });\n});\n\n// Start server\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "npm install passport passport-google-oauth20 express-session",
        "const express = require('express');\nconst passport = require('passport');\nconst GoogleStrategy = require('passport-google-oauth20').Strategy;\nconst session = require('express-session');\nconst app = express();\n\n// Configure sessions for OAuth 2.0\napp.use(session({\nsecret: 'your-secret-key',\nresave: false,\nsaveUninitialized: false,\ncookie: { secure: process.env.NODE_ENV === 'production' }\n}));\n\n// Initialize Passport\napp.use(passport.initialize());\napp.use(passport.session());\n\n// Configure Google OAuth 2.0 strategy\npassport.use(new GoogleStrategy({\nclientID: 'YOUR_GOOGLE_CLIENT_ID',\nclientSecret: 'YOUR_GOOGLE_CLIENT_SECRET',\ncallbackURL: 'http://localhost:8080/auth/google/callback'\n},\n(accessToken, refreshToken, profile, done) => {\n// In a real app, you'd find or create a user in your database\nconst user = {\nid: profile.id,\ndisplayName: profile.displayName,\nemail: profile.emails[0].value,\nprovider: 'google'\n};\n\nreturn done(null, user);\n}\n));\n\n// Serialize user for session\npassport.serializeUser((user, done) => {\ndone(null, user);\n});\n\n// Deserialize user from session\npassport.deserializeUser((user, done) => {\ndone(null, user);\n});\n\n// Routes for Google OAuth\napp.get('/auth/google',\npassport.authenticate('google', { scope: ['profile', 'email'] })\n);\n\napp.get('/auth/google/callback',\npassport.authenticate('google', { failureRedirect: '/login' }),\n(req, res) => {\n// Successful authentication\nres.redirect('/profile');\n}\n);\n\n// Middleware to check authentication\nconst isAuthenticated = (req, res, next) => {\nif (req.isAuthenticated()) {\nreturn next();\n}\nres.redirect('/login');\n};\n\n// Protected route\napp.get('/profile', isAuthenticated, (req, res) => {\nres.json({ user: req.user });\n});\n\n// Logout route\napp.get('/logout', (req, res) => {\nreq.logout();\nres.redirect('/');\n});\n\n// Start server\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "const express = require('express');\nconst app = express();\n\n// In-memory storage for API keys (use a database in production)\nconst apiKeys = new Map([\n['abc123', { name: 'Mobile App', permissions: ['read:data'] }],\n['def456', { name: 'Web Client', permissions: ['read:data', 'write:data'] }]\n]);\n\n// API key authentication middleware\nconst authenticateApiKey = (req, res, next) => {\nconst apiKey = req.headers['x-api-key'] || req.query.apiKey;\n\nif (!apiKey) {\nreturn res.status(401).json({\nerror: 'API key is required',\ndocs: 'https://your-api-docs.com/authentication'\n});\n}\n\nconst keyData = apiKeys.get(apiKey);\nif (!keyData) {\nreturn res.status(403).json({ error: 'Invalid API key' });\n}\n\n// Attach key data to request for use in route handlers\nreq.apiKey = keyData;\nnext();\n};\n// Protected route using API key\napp.get('/api/data', authenticateApiKey, (req, res) => {\nres.json({\nmessage: 'Access granted',\nclient: req.apiKey.name,\ntimestamp: new Date().toISOString()\n});\n});\n\n// Route to generate a new API key (protected by admin auth in real apps)\napp.post('/api/keys', (req, res) => {\nconst { name, permissions } = req.body;\nconst apiKey = generateApiKey(); // Implement your key generation logic\napiKeys.set(apiKey, { name, permissions });\nres.status(201).json({ apiKey });\n});\n// Helper function to generate API keys\nfunction generateApiKey() {\nreturn [...Array(32)]\n.map(() => Math.floor(Math.random() * 16).toString(16))\n.join('');\n}\n// Start server\nconst PORT = process.env.PORT || 3000;\napp.listen(PORT, () => {\nconsole.log(`Server running on port ${PORT}`);\n});\n// Export for testing\nmodule.exports = { app, apiKeys };",
        "const express = require('express');\nconst app = express();\n\n// Sample API keys database\nconst apiKeys = [\n{ key: 'api-key-1', owner: 'client1', permissions: ['read'] },\n{ key: 'api-key-2', owner: 'client2', permissions: ['read', 'write'] }\n];\n\n// Middleware for API key authentication\nconst authenticateApiKey = (req, res, next) => {\n// Get API key from header or query parameter\nconst apiKey = req.headers['x-api-key'] || req.query.api_key;\n\nif (!apiKey) {\nreturn res.status(401).json({ message: 'API key missing' });\n}\n\n// Find API key in database\nconst keyData = apiKeys.find(k => k.key === apiKey);\n\nif (!keyData) {\nreturn res.status(403).json({ message: 'Invalid API key' });\n}\n\n// Attach key data to request\nreq.apiKeyData = keyData;\n\nnext();\n};\n\n// Protected route with API key\napp.get('/data', authenticateApiKey, (req, res) => {\nres.json({\nmessage: 'Data accessed',\nclient: req.apiKeyData.owner,\ndata: { example: 'API data' }\n});\n});\n\n// Route requiring specific permission\napp.post('/data', authenticateApiKey, (req, res) => {\n// Check if client has write permission\nif (!req.apiKeyData.permissions.includes('write')) {\nreturn res.status(403).json({ message: 'Insufficient permissions' });\n}\n\nres.json({ message: 'Data created successfully' });\n});\n\n// Start server\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "const express = require('express');\nconst app = express();\n\n// Sample user database\nconst users = [\n{ username: 'user1', password: 'password1' }\n];\n\n// Basic authentication middleware\nconst basicAuth = (req, res, next) => {\n// Get Authorization header\nconst authHeader = req.headers.authorization;\n\nif (!authHeader || !authHeader.startsWith('Basic ')) {\n// If no credentials provided, request authentication\nres.setHeader('WWW-Authenticate', 'Basic realm=\"API Authentication\"');\nreturn res.status(401).json({ message: 'Authentication required' });\n}\n\n// Extract and decode credentials   const encodedCredentials = authHeader.split(' ')[1];\nconst decodedCredentials = Buffer.from(encodedCredentials, 'base64').toString('utf-8');\nconst [username, password] = decodedCredentials.split(':');\n\n// Validate credentials\nconst user = users.find(u => u.username === username && u.password === password);\n\nif (!user) {\nres.setHeader('WWW-Authenticate', 'Basic realm=\"API Authentication\"');\nreturn res.status(401).json({ message: 'Invalid credentials' });\n}\n\n// Attach user to request\nreq.user = { username: user.username };\n\nnext();\n};\n\n// Protected route\napp.get('/api/data', basicAuth, (req, res) => {\nres.json({\nmessage: 'Data accessed',\nuser: req.user.username,\ndata: { example: 'Sensitive data' }\n});\n});\n\n// Start server\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "const express = require('express');\nconst bodyParser = require('body-parser');\nconst speakeasy = require('speakeasy');\nconst QRCode = require('qrcode');\nconst jwt = require('jsonwebtoken');\nconst app = express();\n\napp.use(bodyParser.json());\n\n// In-memory database (use a real database in production)\nconst users = [];\nconst JWT_SECRET = 'your-jwt-secret-key';\n\n// Step 1: Register a user and set up MFA\napp.post('/register', (req, res) => {\nconst { username, password } = req.body;\n\n// Check if user already exists\nif (users.find(u => u.username === username)) {\nreturn res.status(400).json({ message: 'Username already exists' });\n}\n\n// Generate secret for TOTP\nconst secret = speakeasy.generateSecret({\nname: `MyApp:${username}`\n});\n\n// Create user\nconst newUser = {\nid: users.length + 1,\nusername,\npassword, // In production, hash passwords!\nmfaSecret: secret.base32,\nmfaEnabled: false\n};\n\nusers.push(newUser);\n\n// Generate QR code for TOTP setup\nQRCode.toDataURL(secret.otpauth_url, (err, dataUrl) => {\nif (err) {\nreturn res.status(500).json({ message: 'Error generating QR code' });\n}\n\nres.json({\nmessage: 'User registered. Please set up MFA.',\nuser: {\nid: newUser.id,\nusername: newUser.username\n},\nmfaSecret: secret.base32,\nqrCode: dataUrl\n});\n});\n});\n\n// Step 2: Verify and enable MFA\napp.post('/verify-mfa', (req, res) => {\nconst { username, token } = req.body;\n\n// Find user\nconst user = users.find(u => u.username === username);\n\nif (!user) {\nreturn res.status(404).json({ message: 'User not found' });\n}\n\n// Verify token against user's secret\nconst verified = speakeasy.totp.verify({\nsecret: user.mfaSecret,\nencoding: 'base32',\ntoken\n});\n\nif (!verified) {\nreturn res.status(400).json({ message: 'Invalid MFA token' });\n}\n\n// Enable MFA for user\nuser.mfaEnabled = true;\n\nres.json({ message: 'MFA enabled successfully' });\n});\n\n// Step 3: Login with MFA\napp.post('/login', (req, res) => {\nconst { username, password } = req.body;\n\n// Find user\nconst user = users.find(u => u.username === username && u.password === password);\n\nif (!user) {\nreturn res.status(401).json({ message: 'Invalid credentials' });\n}\n\n// Check if MFA is enabled\nif (user.mfaEnabled) {\nreturn res.json({\nmessage: 'Password verified. MFA token required.',\nrequireMFA: true,\nuserId: user.id\n});\n}\n\n// If MFA not enabled, generate token directly\nconst token = jwt.sign(\n{ id: user.id, username: user.username },\nJWT_SECRET,\n{ expiresIn: '1h' }\n);\n\nres.json({ message: 'Login successful', token });\n});\n\n// Step 4: Verify MFA token and complete login\napp.post('/verify-login', (req, res) => {\nconst { userId, mfaToken } = req.body;\n\n// Find user\nconst user = users.find(u => u.id === userId);\n\nif (!user) {\nreturn res.status(404).json({ message: 'User not found' });\n}\n\n// Verify MFA token\nconst verified = speakeasy.totp.verify({\nsecret: user.mfaSecret,\nencoding: 'base32',\ntoken: mfaToken\n});\n\nif (!verified) {\nreturn res.status(401).json({ message: 'Invalid MFA token' });\n}\n\n// Generate JWT token\nconst token = jwt.sign(\n{ id: user.id, username: user.username },\nJWT_SECRET,\n{ expiresIn: '1h' }\n);\n\nres.json({ message: 'Login successful', token });\n});\n\n// Start server\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "const bcrypt = require('bcrypt');\nconst saltRounds = 10;\n\n// Hashing a password\nasync function hashPassword(plainPassword) {\nreturn await bcrypt.hash(plainPassword, saltRounds);\n}\n\n// Verifying a password\nasync function verifyPassword(plainPassword, hashedPassword) {\nreturn await bcrypt.compare(plainPassword, hashedPassword);\n}",
        "const bcrypt = require('bcrypt');\nconst express = require('express');\nconst bodyParser = require('body-parser');\nconst app = express();\n\napp.use(bodyParser.json());\n\n// In-memory user database\nconst users = [];\n\n// Register route with password hashing\napp.post('/register', async (req, res) => {\ntry {\nconst { username, password } = req.body;\n\n// Check if username already exists\nif (users.find(u => u.username === username)) {\nreturn res.status(400).json({ message: 'Username already taken' });\n}\n\n// Hash password\nconst saltRounds = 10;\nconst hashedPassword = await bcrypt.hash(password, saltRounds);\n\n// Create new user\nconst newUser = {\nid: users.length + 1,\nusername,\npassword: hashedPassword\n};\n\nusers.push(newUser);\n\nres.status(201).json({\nmessage: 'User registered successfully',\nuserId: newUser.id\n});\n} catch (error) {\nres.status(500).json({ message: 'Error registering user' });\n}\n});\n\n// Login route with password comparison\napp.post('/login', async (req, res) => {\ntry {\nconst { username, password } = req.body;\n\n// Find user\nconst user = users.find(u => u.username === username);\n\nif (!user) {\nreturn res.status(401).json({ message: 'Invalid credentials' });\n}\n\n// Compare password with stored hash\nconst passwordMatch = await bcrypt.compare(password, user.password);\n\nif (!passwordMatch) {\nreturn res.status(401).json({ message: 'Invalid credentials' });\n}\n\n// In a real app, generate and return a token\nres.json({\nmessage: 'Login successful',\nuserId: user.id\n});\n} catch (error) {\nres.status(500).json({ message: 'Error logging in' });\n}\n});\n\n// Start server\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "// JWT authentication with API rate limiting and refresh tokens\nconst express = require('express');\nconst jwt = require('jsonwebtoken');\nconst rateLimit = require('express-rate-limit');\nconst bodyParser = require('body-parser');\nconst app = express();\n\napp.use(bodyParser.json());\n\n// Configure rate limiting\nconst loginLimiter = rateLimit({\nwindowMs: 15 * 60 * 1000, // 15 minutes\nmax: 5, // 5 attempts per window\nmessage: 'Too many login attempts, please try again later'\n});\n\n// JWT configuration\nconst JWT_SECRET = 'your-jwt-secret-key';\nconst JWT_REFRESH_SECRET = 'your-refresh-token-secret';\n\n// Token storage (use a database in production)\nconst tokenBlacklist = new Set();\nconst refreshTokens = new Set();\n\n// Login route with rate limiting\napp.post('/login', loginLimiter, (req, res) => {\nconst { username, password } = req.body;\n\n// Authentication logic (simplified)\nif (username !== 'user1' || password !== 'password1') {\nreturn res.status(401).json({ message: 'Invalid credentials' });\n}\n\n// Generate tokens\nconst accessToken = jwt.sign(\n{ id: 1, username },\nJWT_SECRET,\n{ expiresIn: '15m' } // Short-lived access token\n);\n\nconst refreshToken = jwt.sign(\n{ id: 1, username },\nJWT_REFRESH_SECRET,\n{ expiresIn: '7d' } // Longer-lived refresh token\n);\n\n// Store refresh token\nrefreshTokens.add(refreshToken);\n\nres.json({\nmessage: 'Login successful',\naccessToken,\nrefreshToken\n});\n});\n\n// Refresh token route\napp.post('/refresh-token', (req, res) => {\nconst { refreshToken } = req.body;\n\nif (!refreshToken) {\nreturn res.status(401).json({ message: 'Refresh token required' });\n}\n\n// Check if token exists and is not blacklisted\nif (!refreshTokens.has(refreshToken)) {\nreturn res.status(403).json({ message: 'Invalid refresh token' });\n}\n\ntry {\n// Verify refresh token\nconst decoded = jwt.verify(refreshToken, JWT_REFRESH_SECRET);\n\n// Generate new access token\nconst accessToken = jwt.sign(\n{ id: decoded.id, username: decoded.username },\nJWT_SECRET,\n{ expiresIn: '15m' }\n);\n\nres.json({\nmessage: 'Token refreshed',\naccessToken\n});\n} catch (error) {\n// Remove invalid refresh token\nrefreshTokens.delete(refreshToken);\n\nreturn res.status(403).json({ message: 'Invalid or expired refresh token' });\n}\n});\n\n// JWT verification middleware\nconst authenticateJWT = (req, res, next) => {\nconst authHeader = req.headers.authorization;\n\nif (!authHeader || !authHeader.startsWith('Bearer ')) {\nreturn res.status(401).json({ message: 'Authorization header required' });\n}\n\nconst token = authHeader.split(' ')[1];\n\n// Check if token is blacklisted\nif (tokenBlacklist.has(token)) {\nreturn res.status(403).json({ message: 'Token revoked' });\n}\n\ntry {\n// Verify token\nconst decoded = jwt.verify(token, JWT_SECRET);\nreq.user = decoded;\nnext();\n} catch (error) {\nreturn res.status(403).json({ message: 'Invalid or expired token' });\n}\n};\n\n// Logout route\napp.post('/logout', authenticateJWT, (req, res) => {\nconst authHeader = req.headers.authorization;\nconst token = authHeader.split(' ')[1];\nconst { refreshToken } = req.body;\n\n// Blacklist the current access token\ntokenBlacklist.add(token);\n\n// Remove refresh token if provided\nif (refreshToken) {\nrefreshTokens.delete(refreshToken);\n}\n\nres.json({ message: 'Logout successful' });\n});\n\n// Protected route\napp.get('/protected', authenticateJWT, (req, res) => {\nres.json({\nmessage: 'Protected resource accessed',\nuser: req.user\n});\n});\n\n// Start server\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\nif (!authHeader || !authHeader.startsWith('Bearer ')) {\nreturn res.status(401).json({ message: 'Authorization header required' });\n}\n\nconst token = authHeader.split(' ')[1];\n\n// Check if token is blacklisted\nif (tokenBlacklist.has(token)) {\nreturn res.status(403).json({ message: 'Token revoked' });\n}\n\ntry {\n// Verify token\nconst decoded = jwt.verify(token, JWT_SECRET);\nreq.user = decoded;\nnext();\n} catch (error) {\nreturn res.status(403).json({ message: 'Invalid or expired token' });\n}\n});\n\n// Logout route\napp.post('/logout', authenticateJWT, (req, res) => {\nconst authHeader = req.headers.authorization;\nconst token = authHeader.split(' ')[1];\nconst { refreshToken } = req.body;\n\n// Blacklist the current access token\ntokenBlacklist.add(token);\n\n// Remove refresh token if provided\nif (refreshToken) {\nrefreshTokens.delete(refreshToken);\n}\n\nres.json({ message: 'Logout successful' });\n});\n\n// Protected route\napp.get('/protected', authenticateJWT, (req, res) => {\nres.json({\nmessage: 'Protected resource accessed',\nuser: req.user\n});\n});\n\n// Start server\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "Authorization: Bearer <token>",
        "Authorization: Basic <base64-encoded-credentials>"
      ]
    },
    {
      "title": "Node.js with Frontend Frameworks",
      "summary": "Introduction to Frontend Integration with Node.js\nNode.js provides a backend foundation that integrates with modern JavaScript frontend frameworks, enabling developers to build full-stack applications within just the JavaScript ecosystem.\nThis approach offers several advantages:\nUnified Language: Use JavaScript/TypeScript across the entire stack\nCode Sharing: Share validation, types, and utilities between frontend and backend\nDeveloper Experience: Consistent tooling and package management with npm/yarn\nPerformance: Efficient data transfer with JSON and modern protocols\nEcosystem: Access to a vast collection of packages for both frontend and backend\nCommon Integration Patterns\nNode.js backend exposes RESTful or GraphQL APIs consumed by a separate frontend application.\nNode.js renders initial page on the server for better SEO and performance.\nMultiple frontend applications integrated into a unified experience.\nNode.js with React\nReact is a declarative, efficient, and flexible JavaScript library for building user interfaces.\nIt enables developers to create reusable UI components and efficiently update and render them when data changes.\nWhy Use React with Node.js?\nComponent-Based Architecture: Build encapsulated components that manage their own state\nVirtual DOM: Efficient updates and rendering\nRich Ecosystem: Large community and extensive package ecosystem\nDeveloper Tools: Excellent debugging and development tools\nSetting Up a React App with Node.js Backend\nExample: Node.js API with React FrontendGet your own Node.js Server\nNode.js with Angular\nAngular is a comprehensive platform and framework for building scalable single-page applications using TypeScript.\nIt provides a complete solution with built-in features for routing, forms, HTTP client, and more, making it a robust choice for enterprise applications.\nKey Features of Angular with Node.js\nTypeScript Support: Built with TypeScript for better tooling and type safety\nDependency Injection: Built-in DI system for better component organization\nModular Architecture: Organized into modules, components, and services\nRxJS Integration: Powerful reactive programming with Observables\nAngular CLI: Command-line interface for project generation and build tools\nSetting Up Angular with Node.js Backend\nTip: Use --routing flag to include routing and --style=scss for SCSS styling when creating a new project.\nExample: Node.js API with Angular Frontend\nNode.js with Vue.js\nVue.js is a progressive, approachable, and performant JavaScript framework for building user interfaces.\nIt provides a gentle learning curve and flexible architecture, making it an excellent choice for both small projects and large-scale applications when combined with Node.js backends.\nWhy Choose Vue.js with Node.js?\nProgressive Framework: Scales from a library to a full-featured framework\nReactive Data Binding: Simple and intuitive two-way data binding\nComponent-Based: Build encapsulated, reusable components\nVue CLI: Powerful command-line interface for project scaffolding\nVuex: Centralized state management for complex applications\nSetting Up Vue.js with Node.js Backend\nTip: Choose \"Manually select features\" during project creation to include Vuex, Router, and other essential features.\nExample: Node.js API with Vue.js Frontend\nNode.js with Svelte\nSvelte is a revolutionary approach to building user interfaces that compiles your code to highly efficient vanilla JavaScript at build time, rather than interpreting your application code at runtime.\nThis results in smaller bundle sizes and better performance compared to traditional frameworks.\nWhy Choose Svelte with Node.js?\nNo Virtual DOM: Compiles to vanilla JavaScript for better performance\nSmaller Bundle Size: No framework runtime to ship to the browser\nSimpler Code: Less boilerplate than traditional frameworks\nReactive by Default: Automatic updates without complex state management\nScoped CSS: Component-scoped styles without CSS-in-JS\nSetting Up Svelte with Node.js Backend\nTip: Use npm run build to create a production build that can be served by your Node.js backend.\nExample: Node.js API with Svelte Frontend\nBest Practices for Node.js with Frontend Frameworks\n1. Project Structure & Organization\nMonorepo: Single repository for both frontend and backend\nPolyrepo: Separate repositories with clear API contracts\n2. API Design & Communication\nUse proper HTTP methods (GET, POST, PUT, DELETE)\nReturn appropriate status codes\nImplement consistent response formats\nVersion your API (e.g., /api/v1/...)\n3. Security Best Practices\n4. Performance Optimization\nCode splitting and lazy loading\nImage optimization\nBundle analysis (webpack-bundle-analyzer)\nService workers for offline support\nImplement caching (Redis, Memcached)\nDatabase indexing and query optimization\nConnection pooling\nCompression middleware\n5. Development & Deployment\nAutomated testing (Jest, Cypress)\nDocker for containerization\nBlue-green deployments\nMonitoring and logging",
      "examples": [
        "// Example API endpoint\napp.get('/api/products', (req, res) => {\nres.json([{ id: 1, name: 'Product' }]);\n});",
        "// Next.js page\nexport async function getServerSideProps() {\nconst res = await fetch('https://api.example.com/data');\nreturn { props: { data: await res.json() } };\n}",
        "// Module Federation in webpack.config.js\nnew ModuleFederationPlugin({\nname: 'app1',\nfilename: 'remoteEntry.js',\nexposes: { './Component': './src/Component' }\n})",
        "npx create-react-app my-app\ncd my-app\nnpm start",
        "mkdir backend\ncd backend\nnpm init -y\nnpm install express cors",
        "// Node.js backend (Express)\nconst express = require('express');\nconst cors = require('cors');\nconst app = express();\n\n// Enable CORS for React frontend\napp.use(cors());\n\napp.get('/api/data', (req, res) => {\nres.json({ message: 'Hello from Node!' });\n});\n\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "// React frontend component\nimport { useState, useEffect } from 'react';\n\nfunction App() {\nconst [data, setData] = useState(null);\nconst [loading, setLoading] = useState(true);\n\nuseEffect(() => {\nfetch('http://localhost:8080/api/data')\n.then(res => res.json())\n.then(data => {\nsetData(data);\nsetLoading(false);\n});\n}, []);\n\nreturn (\n<div>\n{loading ? 'Loading...' : data.message}\n</div>\n);\n}",
        "npm install -g @angular/cli",
        "ng new angular-nodejs-app\ncd angular-nodejs-app",
        "// Node.js backend (Express)\nconst express = require('express');\nconst cors = require('cors');\nconst app = express();\n\napp.use(cors());\n\napp.get('/api/users', (req, res) => {\nres.json([\n{ id: 1, name: 'John Doe' },\n{ id: 2, name: 'Jane Smith' }\n]);\n});\n\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "// Angular service (user.service.ts)\nimport { Injectable } from '@angular/core';\nimport { HttpClient } from '@angular/common/http';\nimport { Observable } from 'rxjs';\n\ninterface User {\nid: number;\nname: string;\n}\n\n@Injectable({\nprovidedIn: 'root'\n})\nexport class UserService {\nprivate apiUrl = 'http://localhost:8080/api/users';\n\nconstructor(private http: HttpClient) { }\n\ngetUsers(): Observable<User[]> {\nreturn this.http.get<User[]>(this.apiUrl);\n}\n}",
        "npm install -g @vue/cli",
        "vue create vue-nodejs-app\ncd vue-nodejs-app",
        "// Node.js backend (Express)\nconst express = require('express');\nconst cors = require('cors');\nconst app = express();\n\napp.use(cors());\n\napp.get('/api/products', (req, res) => {\nres.json([\n{ id: 1, name: 'Product A', price: 29.99 },\n{ id: 2, name: 'Product B', price: 49.99 }\n]);\n});\n\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "// Vue.js component\n<template>\n<div>\n<h2>Products</h2>\n<div v-if=\"loading\">Loading...</div>\n<ul v-else>\n<li v-for=\"product in products\" :key=\"product.id\">\n{{ product.name }} - ${{ product.price }}\n</li>\n</ul>\n</div>\n</template>\n\n<script>\nexport default {\ndata() {\nreturn {\nproducts: [],\nloading: true\n};\n},\ncreated() {\nfetch('http://localhost:8080/api/products')\n.then(response => response.json())\n.then(data => {\nthis.products = data;\nthis.loading = false;\n});\n}\n};\n</script>",
        "npx degit sveltejs/template svelte-nodejs-app\ncd svelte-nodejs-app\nnpm install",
        "npm install -D @sveltejs/adapter-node\nnpm run dev",
        "// Node.js backend (Express)\nconst express = require('express');\nconst cors = require('cors');\nconst app = express();\n\napp.use(cors());\n\napp.get('/api/todos', (req, res) => {\nres.json([\n{ id: 1, text: 'Learn Node.js', done: true },\n{ id: 2, text: 'Learn Svelte', done: false },\n{ id: 3, text: 'Build an app', done: false }\n]);\n});\n\napp.listen(8080, () => {\nconsole.log('Server running on port 8080');\n});",
        "<script>\nimport { onMount } from 'svelte';\n\nlet todos = [];\nlet loading = true;\n\nonMount(async () => {\nconst response = await fetch('http://localhost:8080/api/todos');\ntodos = await response.json();\nloading = false;\n});\n\nfunction toggleTodo(id) {\ntodos = todos.map(todo => {\nif (todo.id === id) {\nreturn { ...todo, done: !todo.done };\n}\nreturn todo;\n});\n}\n</script>\n\n<h2>Todo List</h2>\n{#if loading}\n<p>Loading...</p>\n{:else}\n<ul>\n{#each todos as todo (todo.id)}\n<li>\n</li>\ntype=\"checkbox\"\nchecked={todo.done}\non:change={() => toggleTodo(todo.id)}\n/>\n<span class={todo.done ? 'done' : ''}>{todo.text}</span>\n</li>\n{/each}\n</ul>\n{/if}\n\n<style>\n.done {\ntext-decoration: line-through;\ncolor: #888;\n}",
        "project/\n├── backend/ # Node.js backend\n│ ├── src/\n│ ├── package.json\n│ └── ...\n└── frontend/ # Frontend framework\n├── src/\n├── package.json\n└── ...",
        "// Server-side with Socket.io\nio.on('connection', (socket) => {\nsocket.emit('message', 'Welcome!');\nsocket.on('chatMessage', (msg) => {\nio.emit('message', msg);\n});\n});",
        "// Install required packages\nnpm install helmet cors express-rate-limit\nexpress-mongo-sanitize xss-clean hpp",
        "// Basic security setup\napp.use(helmet());\napp.use(cors({ origin: process.env.FRONTEND_URL }));\napp.use(express.json({ limit: '10kb' }));\napp.use(mongoSanitize());\napp.use(xss());",
        "// .env.example\nNODE_ENV=development\nPORT=3000\nMONGODB_URI=your_mongodb_uri\nJWT_SECRET=your_jwt_secret\nFRONTEND_URL=http://localhost:3000",
        "--routing",
        "--style=scss",
        "npm run build"
      ]
    },
    {
      "title": "Node.js MySQL",
      "summary": "Node.js can be used in database applications.\nOne of the most popular databases is MySQL.\nMySQL Database\nTo be able to experiment with the code examples, you should have MySQL installed on your computer.\nYou can download a free MySQL database at https://www.mysql.com/downloads/.\nInstall MySQL Driver\nOnce you have MySQL up and running on your computer, you can access it by using Node.js.\nTo access a MySQL database with Node.js, you need a MySQL driver. This tutorial will use the \"mysql\" module, downloaded from NPM.\nTo download and install the \"mysql\" module, open the Command Terminal and execute the following:\nNow you have downloaded and installed a mysql database driver.\nNode.js can use this module to manipulate the MySQL database:\nREMOVE ADS\nCreate Connection\nStart by creating a connection to the database.\nUse the username and password from your MySQL database.\ndemo_db_connection.js\nSave the code above in a file called \"demo_db_connection.js\" and run the file:\nRun \"demo_db_connection.js\"\nWhich will give you this result:\nNow you can start querying the database using SQL statements.\nQuery a Database\nUse SQL statements to read from (or write to) a MySQL database. This is also called \"to query\" the database.\nThe connection object created in the example above, has a method for querying the database:\nThe query method takes an sql statements as a parameter and returns the result.\nLearn how to read, write, delete, and update a database in the next chapters.\nRead more about SQL statements in our SQL Tutorial.",
      "examples": [
        "C:\\Users\\Your Name>npm install mysql",
        "let mysql = require('mysql');",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nconsole.log(\"Connected!\");\n});",
        "C:\\Users\\Your Name>node demo_db_connection.js",
        "Connected!",
        "con.connect(function(err) {\nif (err) throw err;\nconsole.log(\"Connected!\");\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(\"Result: \" + result);\n});\n});"
      ]
    },
    {
      "title": "Node.js MySQL Create Database",
      "summary": "Creating a Database\nTo create a database in MySQL, use the \"CREATE DATABASE\" statement:\nExample\nCreate a database named \"mydb\":\nSave the code above in a file called \"demo_create_db.js\" and run the file:\nRun \"demo_create_db.js\"\nWhich will give you this result:",
      "examples": [
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nconsole.log(\"Connected!\");\ncon.query(\"CREATE DATABASE mydb\", function (err, result) {\nif (err) throw err;\nconsole.log(\"Database created\");\n});\n});",
        "C:\\Users\\Your Name>node demo_create_db.js",
        "Connected!\nDatabase created"
      ]
    },
    {
      "title": "Node.js MySQL Create Table",
      "summary": "Creating a Table\nTo create a table in MySQL, use the \"CREATE TABLE\" statement.\nMake sure you define the name of the database when you create the connection:\nExampleGet your own Node.js Server\nCreate a table named \"customers\":\nSave the code above in a file called \"demo_create_table.js\" and run the file:\nRun \"demo_create_table.js\"\nWhich will give you this result:\nREMOVE ADS\nPrimary Key\nWhen creating a table, you should also create a column with a unique key for each record.\nThis can be done by defining a column as \"INT AUTO_INCREMENT PRIMARY KEY\" which will insert a unique number for each record. Starting at 1, and increased by one for each record.\nExample\nCreate primary key when creating the table:\nIf the table already exists, use the ALTER TABLE keyword:\nExample\nCreate primary key on an existing table:",
      "examples": [
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nconsole.log(\"Connected!\");\nlet sql = \"CREATE TABLE customers (name VARCHAR(255), address VARCHAR(255))\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(\"Table created\");\n});\n});",
        "C:\\Users\\Your Name>node demo_create_table.js",
        "Connected!\nTable created",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nconsole.log(\"Connected!\");\nlet sql = \"CREATE TABLE customers (id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255), address VARCHAR(255))\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(\"Table created\");\n});\n});",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nconsole.log(\"Connected!\");\nlet sql = \"ALTER TABLE customers ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(\"Table altered\");\n});\n});"
      ]
    },
    {
      "title": "Node.js MySQL Insert Into",
      "summary": "Insert Into Table\nTo fill a table in MySQL, use the \"INSERT INTO\" statement.\nExampleGet your own Node.js Server\nInsert a record in the \"customers\" table:\nSave the code above in a file called \"demo_db_insert.js\", and run the file:\nRun \"demo_db_insert.js\"\nWhich will give you this result:\nREMOVE ADS\nInsert Multiple Records\nTo insert more than one record, make an array containing the values, and insert a question mark in the sql, which will be replaced by the value array:\nINSERT INTO customers (name, address) VALUES ?\nExample\nFill the \"customers\" table with data:\nSave the code above in a file called \"demo_db_insert_multple.js\", and run the file:\nRun \"demo_db_insert_multiple.js\"\nWhich will give you this result:\nThe Result Object\nWhen executing a query, a result object is returned.\nThe result object contains information about how the query affected the table.\nThe result object returned from the example above looks like this:\nThe values of the properties can be displayed like this:\nExample\nReturn the number of affected rows:\nWhich will produce this result:\nGet Inserted ID\nFor tables with an auto increment id field, you can get the id of the row you just inserted by asking the result object.\nNote: To be able to get the inserted id, only one row can be inserted.\nExample\nInsert a record in the \"customers\" table, and return the ID:\nSave the code above in a file called \"demo_db_insert_id.js\", and run the file:\nRun \"demo_db_insert_id.js\"\nWhich will give you something like this in return:",
      "examples": [
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nconsole.log(\"Connected!\");\nlet sql = \"INSERT INTO customers (name, address) VALUES ('Company Inc', 'Highway 37')\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(\"1 record inserted\");\n});\n});",
        "C:\\Users\\Your Name>node demo_db_insert.js",
        "Connected!\n1 record inserted",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nconsole.log(\"Connected!\");\nlet sql = \"INSERT INTO customers (name, address) VALUES ?\";\nlet values = [\n['John', 'Highway 71'],\n['Peter', 'Lowstreet 4'],\n['Amy', 'Apple st 652'],\n['Hannah', 'Mountain 21'],\n['Michael', 'Valley 345'],\n['Sandy', 'Ocean blvd 2'],\n['Betty', 'Green Grass 1'],\n['Richard', 'Sky st 331'],\n['Susan', 'One way 98'],\n['Vicky', 'Yellow Garden 2'],\n['Ben', 'Park Lane 38'],\n['William', 'Central st 954'],\n['Chuck', 'Main Road 989'],\n['Viola', 'Sideway 1633']\n];\ncon.query(sql, [values], function (err, result) {\nif (err) throw err;\nconsole.log(\"Number of records inserted: \" + result.affectedRows);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_insert_multiple.js",
        "Connected!\nNumber of records inserted: 14",
        "{\nfieldCount: 0,\naffectedRows: 14,\ninsertId: 0,\nserverStatus: 2,\nwarningCount: 0,\nmessage: '\\'Records:14  Duplicated: 0  Warnings: 0',\nprotocol41: true,\nchangedRows: 0\n}",
        "console.log(result.affectedRows)",
        "14",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nlet sql = \"INSERT INTO customers (name, address) VALUES ('Michelle', 'Blue Village 1')\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(\"1 record inserted, ID: \" + result.insertId);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_insert_id.js",
        "1 record inserted, ID: 15",
        "INSERT INTO customers (name, address) VALUES ?"
      ]
    },
    {
      "title": "Node.js MySQL Select From",
      "summary": "Selecting From a Table\nTo select data from a table in MySQL, use the \"SELECT\" statement.\nExampleGet your own Node.js Server\nSelect all records from the \"customers\" table, and display the result object:\nSELECT * will return all columns\nSave the code above in a file called \"demo_db_select.js\" and run the file:\nRun \"demo_db_select.js\"\nWhich will give you this result:\nREMOVE ADS\nSelecting Columns\nTo select only some of the columns in a table, use the \"SELECT\" statement followed by the column name.\nExample\nSelect name and address from the \"customers\" table, and display the return object:\nSave the code above in a file called \"demo_db_select2.js\" and run the file:\nRun \"demo_db_select2.js\"\nWhich will give you this result:\nThe Result Object\nAs you can see from the result of the example above, the result object is an array containing each row as an object.\nTo return e.g. the address of the third record, just refer to the third array object's address property:\nExample\nReturn the address of the third record:\nWhich will produce this result:\nThe Fields Object\nThe third parameter of the callback function is an array containing information about each field in the result.\nExample\nSelect all records from the \"customers\" table, and display the fields object:\nSave the code above in a file called \"demo_db_select_fields.js\" and run the file:\nRun \"demo_db_select_fields.js\"\nWhich will give you this result:\nAs you can see from the result of the example above, the fields object is an array containing information about each field as an object.\nTo return e.g. the name of the second field, just refer to the second array item's name property:\nExample\nReturn the name of the second field:\nWhich will produce this result:",
      "examples": [
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\ncon.query(\"SELECT * FROM customers\", function (err, result, fields) {\nif (err) throw err;\nconsole.log(result);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_select.js",
        "[\n{ id: 1, name: 'John', address: 'Highway 71'},\n{ id: 2, name: 'Peter', address: 'Lowstreet 4'},\n{ id: 3, name: 'Amy', address: 'Apple st 652'},\n{ id: 4, name: 'Hannah', address: 'Mountain 21'},\n{ id: 5, name: 'Michael', address: 'Valley 345'},\n{ id: 6, name: 'Sandy', address: 'Ocean blvd 2'},\n{ id: 7, name: 'Betty', address: 'Green Grass 1'},\n{ id: 8, name: 'Richard', address: 'Sky st 331'},\n{ id: 9, name: 'Susan', address: 'One way 98'},\n{ id: 10, name: 'Vicky', address: 'Yellow Garden 2'},\n{ id: 11, name: 'Ben', address: 'Park Lane 38'},\n{ id: 12, name: 'William', address: 'Central st 954'},\n{ id: 13, name: 'Chuck', address: 'Main Road 989'},\n{ id: 14, name: 'Viola', address: 'Sideway 1633'}\n]",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\ncon.query(\"SELECT name, address FROM customers\", function (err, result, fields) {\nif (err) throw err;\nconsole.log(result);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_select2.js",
        "[\n{ name: 'John', address: 'Highway 71'},\n{ name: 'Peter', address: 'Lowstreet 4'},\n{ name: 'Amy', address: 'Apple st 652'},\n{ name: 'Hannah', address: 'Mountain 21'},\n{ name: 'Michael', address: 'Valley 345'},\n{ name: 'Sandy', address: 'Ocean blvd 2'},\n{ name: 'Betty', address: 'Green Grass 1'},\n{ name: 'Richard', address: 'Sky st 331'},\n{ name: 'Susan', address: 'One way 98'},\n{ name: 'Vicky', address: 'Yellow Garden 2'},\n{ name: 'Ben', address: 'Park Lane 38'},\n{ name: 'William', address: 'Central st 954'},\n{ name: 'Chuck', address: 'Main Road 989'},\n{ name: 'Viola', address: 'Sideway 1633'}\n]",
        "console.log(result[2].address);",
        "Apple st 652",
        "C:\\Users\\Your Name>node demo_db_select_fields.js",
        "[\n{\ncatalog: 'def',\ndb: 'mydb',\ntable: 'customers',\norgTable: 'customers',\nname: 'name',\norgName: 'name',\ncharsetNr: 33,\nlength: 765,\ntype: 253,\nflags: 0,\ndecimals: 0,\ndefault: undefined,\nzeroFill: false,\nprotocol41: true\n},\n{\ncatalog: 'def',\ndb: 'mydb',\ntable: 'customers',\norgTable: 'customers',\nname: 'address',\norgName: 'address',\ncharsetNr: 33,\nlength: 765,\ntype: 253,\nflags: 0,\ndecimals: 0,\ndefault: undefined,\nzeroFill: false,\nprotocol41: true\n}\n]",
        "console.log(fields[1].name);",
        "address"
      ]
    },
    {
      "title": "Node.js MySQL Where",
      "summary": "Select With a Filter\nWhen selecting records from a table, you can filter the selection by using the \"WHERE\" statement:\nExampleGet your own Node.js Server\nSelect record(s) with the address \"Park Lane 38\":\nSave the code above in a file called \"demo_db_where.js\" and run the file:\nRun \"demo_db_where.js\"\nWhich will give you this result:\nREMOVE ADS\nWildcard Characters\nYou can also select the records that starts, includes, or ends with a given letter or phrase.\nUse the '%' wildcard to represent zero, one or multiple characters:\nExample\nSelect records where the address starts with the letter 'S':\nSave the code above in a file called \"demo_db_where_s.js\" and run the file:\nRun \"demo_db_where_s.js\"\nWhich will give you this result:\nEscaping Query Values\nWhen query values are variables provided by the user, you should escape the values.\nThis is to prevent SQL injections, which is a common web hacking technique to destroy or misuse your database.\nThe MySQL module has methods to escape query values:\nExample\nEscape query values by using the mysql.escape() method:\nYou can also use a ? as a placeholder for the values you want to escape.\nIn this case, the variable is sent as the second parameter in the query() method:\nExample\nEscape query values by using the placeholder ? method:\nIf you have multiple placeholders, the array contains multiple values, in that order:\nExample\nMultiple placeholders:",
      "examples": [
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\ncon.query(\"SELECT * FROM customers WHERE address = 'Park Lane 38'\", function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_where.js",
        "[\n{ id: 11, name: 'Ben', address: 'Park Lane 38'}\n]",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\ncon.query(\"SELECT * FROM customers WHERE address LIKE 'S%'\", function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_where_s.js",
        "[\n{ id: 8, name: 'Richard', address: 'Sky st 331'},\n{ id: 14, name: 'Viola', address: 'Sideway 1633'}\n]",
        "let adr = 'Mountain 21';\nlet sql = 'SELECT * FROM customers WHERE address = ' + mysql.escape(adr);\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});",
        "let adr = 'Mountain 21';\nlet sql = 'SELECT * FROM customers WHERE address = ?';\ncon.query(sql, [adr], function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});",
        "let name = 'Amy';\nlet adr = 'Mountain 21';\nlet sql = 'SELECT * FROM customers WHERE name = ? OR address = ?';\ncon.query(sql, [name, adr], function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});",
        "mysql.escape()",
        "?"
      ]
    },
    {
      "title": "Node.js MySQL Order By",
      "summary": "Sort the Result\nUse the ORDER BY statement to sort the result in ascending or descending order.\nThe ORDER BY keyword sorts the result ascending by default. To sort the result in descending order, use the DESC keyword.\nExampleGet your own Node.js Server\nSort the result alphabetically by name:\nSave the code above in a file called \"demo_db_orderby.js\" and run the file:\nRun \"demo_db_orderby.js\"\nWhich will give you this result:\nREMOVE ADS\nORDER BY DESC\nUse the DESC keyword to sort the result in a descending order.\nExample\nSort the result reverse alphabetically by name:\nSave the code above in a file called \"demo_db_orderby_desc.js\" and run the file:\nRun \"demo_db_orderby_desc.js\"\nWhich will give you this result:",
      "examples": [
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\ncon.query(\"SELECT * FROM customers ORDER BY name\", function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_orderby.js",
        "[\n{ id: 3, name: 'Amy', address: 'Apple st 652'},\n{ id: 11, name: 'Ben', address: 'Park Lane 38'},\n{ id: 7, name: 'Betty', address: 'Green Grass 1'},\n{ id: 13, name: 'Chuck', address: 'Main Road 989'},\n{ id: 4, name: 'Hannah', address: 'Mountain 21'},\n{ id: 1, name: 'John', address: 'Higheay 71'},\n{ id: 5, name: 'Michael', address: 'Valley 345'},\n{ id: 2, name: 'Peter', address: 'Lowstreet 4'},\n{ id: 8, name: 'Richard', address: 'Sky st 331'},\n{ id: 6, name: 'Sandy', address: 'Ocean blvd 2'},\n{ id: 9, name: 'Susan', address: 'One way 98'},\n{ id: 10, name: 'Vicky', address: 'Yellow Garden 2'},\n{ id: 14, name: 'Viola', address: 'Sideway 1633'},\n{ id: 12, name: 'William', address: 'Central st 954'}\n]",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\ncon.query(\"SELECT * FROM customers ORDER BY name DESC\", function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_orderby_desc.js",
        "[\n{ id: 12, name: 'William', address: 'Central st 954'},\n{ id: 14, name: 'Viola', address: 'Sideway 1633'},\n{ id: 10, name: 'Vicky', address: 'Yellow Garden 2'},\n{ id: 9, name: 'Susan', address: 'One way 98'},\n{ id: 6, name: 'Sandy', address: 'Ocean blvd 2'},\n{ id: 8, name: 'Richard', address: 'Sky st 331'},\n{ id: 2, name: 'Peter', address: 'Lowstreet 4'},\n{ id: 5, name: 'Michael', address: 'Valley 345'},\n{ id: 1, name: 'John', address: 'Higheay 71'},\n{ id: 4, name: 'Hannah', address: 'Mountain 21'},\n{ id: 13, name: 'Chuck', address: 'Main Road 989'},\n{ id: 7, name: 'Betty', address: 'Green Grass 1'},\n{ id: 11, name: 'Ben', address: 'Park Lane 38'},\n{ id: 3, name: 'Amy', address: 'Apple st 652'}\n]"
      ]
    },
    {
      "title": "Node.js MySQL Delete",
      "summary": "Delete Record\nYou can delete records from an existing table by using the \"DELETE FROM\" statement:\nExampleGet your own Node.js Server\nDelete any record with the address \"Mountain 21\":\nNotice the WHERE clause in the DELETE syntax: The WHERE clause specifies which record or records that should be deleted. If you omit the WHERE clause, all records will be deleted!\nSave the code above in a file called \"demo_db_delete.js\" and run the file:\nRun \"demo_db_delete.js\"\nWhich will give you this result:\nREMOVE ADS\nThe Result Object\nWhen executing a query, a result object is returned.\nThe result object contains information about how the query affected the table.\nThe result object returned from the example above looks like this:\nThe values of the properties can be displayed like this:\nExample\nReturn the number of affected rows:\nWhich will produce this result:",
      "examples": [
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nlet sql = \"DELETE FROM customers WHERE address = 'Mountain 21'\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(\"Number of records deleted: \" + result.affectedRows);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_delete.js",
        "Number of records deleted: 1",
        "{\nfieldCount: 0,\naffectedRows: 1,\ninsertId: 0,\nserverStatus: 34,\nwarningCount: 0,\nmessage: '',\nprotocol41: true,\nchangedRows: 0\n}",
        "console.log(result.affectedRows)",
        "1"
      ]
    },
    {
      "title": "Node.js MySQL Drop Table",
      "summary": "Delete a Table\nYou can delete an existing table by using the \"DROP TABLE\" statement:\nExampleGet your own Node.js Server\nDelete the table \"customers\":\nSave the code above in a file called \"demo_db_drop_table.js\" and run the file:\nRun \"demo_db_drop_table.js\"\nWhich will give you this result:\nREMOVE ADS\nDrop Only if Exist\nIf the the table you want to delete is already deleted, or for any other reason does not exist, you can use the IF EXISTS keyword to avoid getting an error.\nExample\nDelete the table \"customers\" if it exists:\nSave the code above in a file called \"demo_db_drop_table_if.js\" and run the file:\nRun \"demo_db_drop_table_if.js\"\nIf the table exist, the result object will look like this:\nIf the table does not exist, the result object will look like this:\nAs you can see the only differnce is that the warningCount property is set to 1 if the table does not exist.",
      "examples": [
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nlet sql = \"DROP TABLE customers\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(\"Table deleted\");\n});\n});",
        "C:\\Users\\Your Name>node demo_db_drop_table.js",
        "Table deleted",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nlet sql = \"DROP TABLE IF EXISTS customers\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_drop_table_if.js",
        "{\nfieldCount: 0,\naffectedRows: 0,\ninsertId: 0,\nserverstatus: 2,\nwarningCount: 0,\nmessage: '',\nprotocol41: true,\nchangedRows: 0\n}",
        "{\nfieldCount: 0,\naffectedRows: 0,\ninsertId: 0,\nserverstatus: 2,\nwarningCount: 1,\nmessage: '',\nprotocol41: true,\nchangedRows: 0\n}"
      ]
    },
    {
      "title": "Node.js MySQL Update",
      "summary": "Update Table\nYou can update existing records in a table by using the \"UPDATE\" statement:\nExampleGet your own Node.js Server\nOverwrite the address column from \"Valley 345\" to \"Canyon 123\":\nNotice the WHERE clause in the UPDATE syntax: The WHERE clause specifies which record or records that should be updated. If you omit the WHERE clause, all records will be updated!\nSave the code above in a file called \"demo_db_update.js\" and run the file:\nRun \"demo_db_update.js\"\nWhich will give you this result:\nREMOVE ADS\nThe Result Object\nWhen executing a query, a result object is returned.\nThe result object contains information about how the query affected the table.\nThe result object returned from the example above looks like this:\nThe values of the properties can be displayed like this:\nExample\nReturn the number of affected rows:\nWhich will produce this result:",
      "examples": [
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nlet sql = \"UPDATE customers SET address = 'Canyon 123' WHERE address = 'Valley 345'\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(result.affectedRows + \" record(s) updated\");\n});\n});",
        "C:\\Users\\Your Name>node demo_db_update.js",
        "1 record(s) updated",
        "{\nfieldCount: 0,\naffectedRows: 1,\ninsertId: 0,\nserverStatus: 34,\nwarningCount: 0,\nmessage: '(Rows matched: 1 Changed: 1 Warnings: 0',\nprotocol41: true,\nchangedRows: 1\n}",
        "console.log(result.affectedRows)",
        "1"
      ]
    },
    {
      "title": "Node.js MySQL Limit",
      "summary": "Limit the Result\nYou can limit the number of records returned from the query, by using the \"LIMIT\" statement:\nExampleGet your own Node.js Server\nSelect the 5 first records in the \"customers\" table:\nSave the code above in a file called \"demo_db_limit.js\" and run the file:\nRun \"demo_db_limit.js\"\nWhich will give you this result:\nREMOVE ADS\nStart From Another Position\nIf you want to return five records, starting from the third record, you can use the \"OFFSET\" keyword:\nExample\nStart from position 3, and return the next 5 records:\nNote: \"OFFSET 2\", means starting from the third position, not the second!\nSave the code above in a file called \"demo_db_offset.js\" and run the file:\nRun \"demo_db_offset.js\"\nWhich will give you this result:\nShorter Syntax\nYou can also write your SQL statement like this \"LIMIT 2, 5\" which returns the same as the offset example above:\nExample\nStart from position 3, and return the next 5 records:\nNote: The numbers are reversed: \"LIMIT 2, 5\" is the same as \"LIMIT 5 OFFSET 2\"",
      "examples": [
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nlet sql = \"SELECT * FROM customers LIMIT 5\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_limit.js",
        "[\n{ id: 1, name: 'John', address: 'Highway 71'},\n{ id: 2, name: 'Peter', address: 'Lowstreet 4'},\n{ id: 3, name: 'Amy', address: 'Apple st 652'},\n{ id: 4, name: 'Hannah', address: 'Mountain 21'},\n{ id: 5, name: 'Michael', address: 'Valley 345'}\n]",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nlet sql = \"SELECT * FROM customers LIMIT 5 OFFSET 2\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_offset.js",
        "[\n{ id: 3, name: 'Amy', address: 'Apple st 652'},\n{ id: 4, name: 'Hannah', address: 'Mountain 21'},\n{ id: 5, name: 'Michael', address: 'Valley 345'},\n{ id: 6, name: 'Sandy', address: 'Ocean blvd 2'},\n{ id: 7, name: 'Betty', address: 'Green Grass 1'}\n]",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nlet sql = \"SELECT * FROM customers LIMIT 2, 5\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});\n});"
      ]
    },
    {
      "title": "Node.js MySQL Join",
      "summary": "Join Two or More Tables\nYou can combine rows from two or more tables, based on a related column between them, by using a JOIN statement.\nConsider you have a \"users\" table and a \"products\" table:\nusersGet your own Node.js Server\nproducts\nThese two tables can be combined by using users' favorite_product field and products' id field.\nExample\nSelect records with a match in both tables:\nNote: You can use INNER JOIN instead of JOIN. They will both give you the same result.\nSave the code above in a file called \"demo_db_join.js\" and run the file:\nRun \"demo_db_join.js\"\nWhich will give you this result:\nAs you can see from the result above, only the records with a match in both tables are returned.\nREMOVE ADS\nLeft Join\nIf you want to return all users, no matter if they have a favorite product or not, use the LEFT JOIN statement:\nExample\nSelect all users and their favorite product:\nWhich will give you this result:\nRight Join\nIf you want to return all products, and the users who have them as their favorite, even if no user have them as their favorite, use the RIGHT JOIN statement:\nExample\nSelect all products and the user who have them as their favorite:\nWhich will give you this result:\nNote: Hannah and Michael, who have no favorite product, are not included in the result.",
      "examples": [
        "[\n{ id: 1, name: 'John', favorite_product: 154},\n{ id: 2, name: 'Peter', favorite_product: 154},\n{ id: 3, name: 'Amy', favorite_product: 155},\n{ id: 4, name: 'Hannah', favorite_product:},\n{ id: 5, name: 'Michael', favorite_product:}\n]",
        "[\n{ id: 154, name: 'Chocolate Heaven' },\n{ id: 155, name: 'Tasty Lemons' },\n{ id: 156, name: 'Vanilla Dreams' }\n]",
        "let mysql = require('mysql');\n\nlet con = mysql.createConnection({\nhost: \"localhost\",\nuser: \"yourusername\",\npassword: \"yourpassword\",\ndatabase: \"mydb\"\n});\n\ncon.connect(function(err) {\nif (err) throw err;\nlet sql = \"SELECT users.name AS user, products.name AS favorite FROM users JOIN products ON users.favorite_product = products.id\";\ncon.query(sql, function (err, result) {\nif (err) throw err;\nconsole.log(result);\n});\n});",
        "C:\\Users\\Your Name>node demo_db_join.js",
        "[\n{ user: 'John', favorite: 'Chocolate Heaven' },\n{ user: 'Peter', favorite: 'Chocolate Heaven' },\n{ user: 'Amy', favorite: 'Tasty Lemons' }\n]",
        "SELECT users.name AS user,\nproducts.name AS favorite\nFROM users\nLEFT JOIN products ON users.favorite_product = products.id",
        "[\n{ user: 'John', favorite: 'Chocolate Heaven' },\n{ user: 'Peter', favorite: 'Chocolate Heaven' },\n{ user: 'Amy', favorite: 'Tasty Lemons' },\n{ user: 'Hannah', favorite: null },\n{ user: 'Michael', favorite: null }\n]",
        "SELECT users.name AS user,\nproducts.name AS favorite\nFROM users\nRIGHT JOIN products ON users.favorite_product = products.id",
        "[\n{ user: 'John', favorite: 'Chocolate Heaven' },\n{ user: 'Peter', favorite: 'Chocolate Heaven' },\n{ user: 'Amy', favorite: 'Tasty Lemons' },\n{ user: null, favorite: 'Vanilla Dreams' }\n]",
        "favorite_product",
        "id"
      ]
    },
    {
      "title": "Node.js MongoDB",
      "summary": "Node.js can be used in database applications.\nOne of the most popular NoSQL database is MongoDB.\nMongoDB\nTo be able to experiment with the code examples, you will need access to a MongoDB database.\nYou can download a free MongoDB database at https://www.mongodb.com.\nOr get started right away with a MongoDB cloud service at https://www.mongodb.com/cloud/atlas.\nInstall MongoDB Driver\nLet us try to access a MongoDB database with Node.js.\nTo download and install the official MongoDB driver, open the Command Terminal and execute the following:\nDownload and install mongodb package:\nNow you have downloaded and installed a mongodb database driver.\nNode.js can use this module to manipulate MongoDB databases:",
      "examples": [
        "C:\\Users\\Your Name>npm install mongodb",
        "let mongo = require('mongodb');"
      ]
    },
    {
      "title": "Node.js MongoDB Create Database",
      "summary": "Creating a Database\nTo create a database in MongoDB, start by creating a MongoClient object, then specify a connection URL with the correct ip address and the name of the database you want to create.\nMongoDB will create the database if it does not exist, and make a connection to it.\nExampleGet your own Node.js Server\nCreate a database called \"mydb\":\nSave the code above in a file called \"demo_create_mongo_db.js\" and run the file:\nRun \"demo_create_mongo_db.js\"\nWhich will give you this result:\nImportant: In MongoDB, a database is not created until it gets content!\nMongoDB waits until you have created a collection (table), with at least one document (record) before it actually creates the database (and collection).",
      "examples": [
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/mydb\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nconsole.log(\"Database created!\");\ndb.close();\n});",
        "C:\\Users\\Your Name>node demo_create_mongo_db.js",
        "Database created!"
      ]
    },
    {
      "title": "Node.js MongoDB Create Collection",
      "summary": "A collection in MongoDB is the same as a table in MySQL\nCreating a Collection\nTo create a collection in MongoDB, use the createCollection() method:\nExampleGet your own Node.js Server\nCreate a collection called \"customers\":\nSave the code above in a file called \"demo_mongodb_createcollection.js\" and run the file:\nRun \"demo_mongodb_createcollection.js\"\nWhich will give you this result:\nImportant: In MongoDB, a collection is not created until it gets content!\nMongoDB waits until you have inserted a document before it actually creates the collection.",
      "examples": [
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.createCollection(\"customers\", function(err, res) {\nif (err) throw err;\nconsole.log(\"Collection created!\");\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_mongodb_createcollection.js",
        "Collection created!",
        "createCollection()"
      ]
    },
    {
      "title": "Node.js MongoDB Insert",
      "summary": "Insert Into Collection\nTo insert a record, or document as it is called in MongoDB, into a collection, we use the insertOne() method.\nA document in MongoDB is the same as a record in MySQL\nThe first parameter of the insertOne() method is an object containing the name(s) and value(s) of each field in the document you want to insert.\nIt also takes a callback function where you can work with any errors, or the result of the insertion:\nExampleGet your own Node.js Server\nInsert a document in the \"customers\" collection:\nSave the code above in a file called \"demo_mongodb_insert.js\" and run the file:\nRun \"demo_mongodb_insert.js\"\nWhich will give you this result:\nNote: If you try to insert documents in a collection that do not exist, MongoDB will create the collection automatically.\nREMOVE ADS\nInsert Multiple Documents\nTo insert multiple documents into a collection in MongoDB, we use the insertMany() method.\nThe first parameter of the insertMany() method is an array of objects, containing the data you want to insert.\nIt also takes a callback function where you can work with any errors, or the result of the insertion:\nExample\nInsert multiple documents in the \"customers\" collection:\nSave the code above in a file called \"demo_mongodb_insert_multiple.js\" and run the file:\nRun \"demo_mongodb_insert_multiple.js\"\nWhich will give you this result:\nThe Result Object\nWhen executing the insertMany() method, a result object is returned.\nThe result object contains information about how the insertion affected the database.\nThe object returned from the example above looked like this:\nThe values of the properties can be displayed like this:\nExample\nReturn the number of inserted documents:\nWhich will produce this result:\nThe _id Field\nIf you do not specify an _id field, then MongoDB will add one for you and assign a unique id for each document.\nIn the example above no _id field was specified, and as you can see from the result object, MongoDB assigned a unique _id for each document.\nIf you do specify the _id field, the value must be unique for each document:\nExample\nInsert three records in a \"products\" table, with specified _id fields:\nSave the code above in a file called \"demo_mongodb_insert_id.js\" and run the file:\nRun \"demo_mongodb_insert_id.js\"\nWhich will give you this result:",
      "examples": [
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet myobj = { name: \"Company Inc\", address: \"Highway 37\" };\ndbo.collection(\"customers\").insertOne(myobj, function(err, res) {\nif (err) throw err;\nconsole.log(\"1 document inserted\");\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_mongodb_insert.js",
        "1 document inserted",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet myobj = [\n{ name: 'John', address: 'Highway 71'},\n{ name: 'Peter', address: 'Lowstreet 4'},\n{ name: 'Amy', address: 'Apple st 652'},\n{ name: 'Hannah', address: 'Mountain 21'},\n{ name: 'Michael', address: 'Valley 345'},\n{ name: 'Sandy', address: 'Ocean blvd 2'},\n{ name: 'Betty', address: 'Green Grass 1'},\n{ name: 'Richard', address: 'Sky st 331'},\n{ name: 'Susan', address: 'One way 98'},\n{ name: 'Vicky', address: 'Yellow Garden 2'},\n{ name: 'Ben', address: 'Park Lane 38'},\n{ name: 'William', address: 'Central st 954'},\n{ name: 'Chuck', address: 'Main Road 989'},\n{ name: 'Viola', address: 'Sideway 1633'}\n];\ndbo.collection(\"customers\").insertMany(myobj, function(err, res) {\nif (err) throw err;\nconsole.log(\"Number of documents inserted: \" + res.insertedCount);\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_mongodb_insert_multiple.js",
        "Number of documents inserted: 14",
        "{\nresult: { ok: 1, n: 14 },\nops: [\n{ name: 'John', address: 'Highway 71', _id: 58fdbf5c0ef8a50b4cdd9a84 },\n{ name: 'Peter', address: 'Lowstreet 4', _id: 58fdbf5c0ef8a50b4cdd9a85 },\n{ name: 'Amy', address: 'Apple st 652', _id: 58fdbf5c0ef8a50b4cdd9a86 },\n{ name: 'Hannah', address: 'Mountain 21', _id: 58fdbf5c0ef8a50b4cdd9a87 },\n{ name: 'Michael', address: 'Valley 345', _id: 58fdbf5c0ef8a50b4cdd9a88 },\n{ name: 'Sandy', address: 'Ocean blvd 2', _id: 58fdbf5c0ef8a50b4cdd9a89 },\n{ name: 'Betty', address: 'Green Grass 1', _id: 58fdbf5c0ef8a50b4cdd9a8a },\n{ name: 'Richard', address: 'Sky st 331', _id: 58fdbf5c0ef8a50b4cdd9a8b },\n{ name: 'Susan', address: 'One way 98', _id: 58fdbf5c0ef8a50b4cdd9a8c },\n{ name: 'Vicky', address: 'Yellow Garden 2', _id: 58fdbf5c0ef8a50b4cdd9a8d },\n{ name: 'Ben', address: 'Park Lane 38', _id: 58fdbf5c0ef8a50b4cdd9a8e },\n{ name: 'William', address: 'Central st 954', _id: 58fdbf5c0ef8a50b4cdd9a8f },\n{ name: 'Chuck', address: 'Main Road 989', _id: 58fdbf5c0ef8a50b4cdd9a90 },\n{ name: 'Viola', address: 'Sideway 1633', _id: 58fdbf5c0ef8a50b4cdd9a91 } ],\ninsertedCount: 14,\ninsertedIds: [\n58fdbf5c0ef8a50b4cdd9a84,\n58fdbf5c0ef8a50b4cdd9a85,\n58fdbf5c0ef8a50b4cdd9a86,\n58fdbf5c0ef8a50b4cdd9a87,\n58fdbf5c0ef8a50b4cdd9a88,\n58fdbf5c0ef8a50b4cdd9a89,\n58fdbf5c0ef8a50b4cdd9a8a,\n58fdbf5c0ef8a50b4cdd9a8b,\n58fdbf5c0ef8a50b4cdd9a8c,\n58fdbf5c0ef8a50b4cdd9a8d,\n58fdbf5c0ef8a50b4cdd9a8e,\n58fdbf5c0ef8a50b4cdd9a8f\n58fdbf5c0ef8a50b4cdd9a90,\n58fdbf5c0ef8a50b4cdd9a91 ]\n}",
        "console.log(res.insertedCount)",
        "14",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet myobj = [\n{ _id: 154, name: 'Chocolate Heaven'},\n{ _id: 155, name: 'Tasty Lemon'},\n{ _id: 156, name: 'Vanilla Dream'}\n];\ndbo.collection(\"products\").insertMany(myobj, function(err, res) {\nif (err) throw err;\nconsole.log(res);\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_mongodb_insert_id.js",
        "{\nresult: { ok: 1, n: 3 },\nops: [\n{ _id: 154, name: 'Chocolate Heaven },\n{ _id: 155, name: 'Tasty Lemon },\n{ _id: 156, name: 'Vanilla Dream } ],\ninsertedCount: 3,\ninsertedIds: [\n154,\n155,\n156 ]\n}",
        "insertOne()",
        "insertMany()",
        "_id"
      ]
    },
    {
      "title": "Node.js MongoDB Find",
      "summary": "In MongoDB we use the find and findOne methods to find data in a collection.\nJust like the SELECT statement is used to find data in a table in a MySQL database.\nFind One\nTo select data from a collection in MongoDB, we can use the findOne() method.\nThe findOne() method returns the first occurrence in the selection.\nThe first parameter of the findOne() method is a query object. In this example we use an empty query object, which selects all documents in a collection (but returns only the first document).\nExampleGet your own Node.js Server\nFind the first document in the customers collection:\nSave the code above in a file called \"demo_mongodb_findone.js\" and run the file:\nRun \"demo_mongodb_findone.js\"\nWhich will give you this result:\nREMOVE ADS\nFind All\nTo select data from a table in MongoDB, we can also use the find() method.\nThe find() method returns all occurrences in the selection.\nThe first parameter of the find() method is a query object. In this example we use an empty query object, which selects all documents in the collection.\nNo parameters in the find() method gives you the same result as SELECT * in MySQL.\nExample\nFind all documents in the customers collection:\nSave the code above in a file called \"demo_mongodb_find.js\" and run the file:\nRun \"demo_mongodb_find.js\"\nWhich will give you this result:\nFind Some\nThe second parameter of the find() method is the projection object that describes which fields to include in the result.\nThis parameter is optional, and if omitted, all fields will be included in the result.\nExample\nReturn the fields \"name\" and \"address\" of all documents in the customers collection:\nSave the code above in a file called \"demo_mongodb_find_fields.js\" and run the file:\nRun \"demo_mongodb_find_fields.js\"\nWhich will give you this result:\nYou are not allowed to specify both 0 and 1 values in the same object (except if one of the fields is the _id field). If you specify a field with the value 0, all other fields get the value 1, and vice versa:\nExample\nThis example will exclude \"address\" from the result:\nTo exclude the _id field, you must set its value to 0:\nExample\nThis example will return only the \"name\" field:\nExample\nThis example will give you the same result as the first example; return all fields except the _id field:\nExample\nYou get an error if you specify both 0 and 1 values in the same object (except if one of the fields is the _id field):\nThe Result Object\nAs you can see from the result of the example above, the result can be converted into an array containing each document as an object.\nTo return e.g. the address of the third document, just refer to the third array object's address property:\nExample\nReturn the address of the third document:\nWhich will produce this result:",
      "examples": [
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.collection(\"customers\").findOne({}, function(err, result) {\nif (err) throw err;\nconsole.log(result.name);\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_mongodb_findone.js",
        "Company Inc.",
        "C:\\Users\\Your Name>node demo_mongodb_find.js",
        "[\n{ _id: 58fdbf5c0ef8a50b4cdd9a84 , name: 'John', address: 'Highway 71'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a85 , name: 'Peter', address: 'Lowstreet 4'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a86 , name: 'Amy', address: 'Apple st 652'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a87 , name: 'Hannah', address: 'Mountain 21'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a88 , name: 'Michael', address: 'Valley 345'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a89 , name: 'Sandy', address: 'Ocean blvd 2'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8a , name: 'Betty', address: 'Green Grass 1'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8b , name: 'Richard', address: 'Sky st 331'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8c , name: 'Susan', address: 'One way 98'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8d , name: 'Vicky', address: 'Yellow Garden 2'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8e , name: 'Ben', address: 'Park Lane 38'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8f , name: 'William', address: 'Central st 954'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a90 , name: 'Chuck', address: 'Main Road 989'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a91 , name: 'Viola', address: 'Sideway 1633'}\n]",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.collection(\"customers\").find({}, { projection: { _id: 0, name: 1, address: 1 } }).toArray(function(err, result) {\nif (err) throw err;\nconsole.log(result);\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_mongodb_find_fields.js",
        "[\n{ name: 'John', address: 'Highway 71'},\n{ name: 'Peter', address: 'Lowstreet 4'},\n{ name: 'Amy', address: 'Apple st 652'},\n{ name: 'Hannah', address: 'Mountain 21'},\n{ name: 'Michael', address: 'Valley 345'},\n{ name: 'Sandy', address: 'Ocean blvd 2'},\n{ name: 'Betty', address: 'Green Grass 1'},\n{ name: 'Richard', address: 'Sky st 331'},\n{ name: 'Susan', address: 'One way 98'},\n{ name: 'Vicky', address: 'Yellow Garden 2'},\n{ name: 'Ben', address: 'Park Lane 38'},\n{ name: 'William', address: 'Central st 954'},\n{ name: 'Chuck', address: 'Main Road 989'},\n{ name: 'Viola', address: 'Sideway 1633'}\n]",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.collection(\"customers\").find({}, { projection: { address: 0 } }).toArray(function(err, result) {\nif (err) throw err;\nconsole.log(result);\ndb.close();\n});\n});",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.collection(\"customers\").find({}, { projection: { _id: 0, name: 1 } }).toArray(function(err, result) {\nif (err) throw err;\nconsole.log(result);\ndb.close();\n});\n});",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.collection(\"customers\").find({}, { projection: { _id: 0 } }).toArray(function(err, result) {\nif (err) throw err;\nconsole.log(result);\ndb.close();\n});\n});",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.collection(\"customers\").find({}, { projection: { name: 1, address: 0 } }).toArray(function(err, result) {\nif (err) throw err;\nconsole.log(result);\ndb.close();\n});\n});",
        "console.log(result[2].address);",
        "Apple st 652",
        "findOne()",
        "find()",
        "projection"
      ]
    },
    {
      "title": "Node.js MongoDB Query",
      "summary": "Filter the Result\nWhen finding documents in a collection, you can filter the result by using a query object.\nThe first argument of the find() method is a query object, and is used to limit the search.\nExampleGet your own Node.js Server\nFind documents with the address \"Park Lane 38\":\nSave the code above in a file called \"demo_mongodb_query.js\" and run the file:\nRun \"demo_mongodb_query.js\"\nWhich will give you this result:\nREMOVE ADS\nFilter With Regular Expressions\nYou can write regular expressions to find exactly what you are searching for.\nRegular expressions can only be used to query strings.\nTo find only the documents where the \"address\" field starts with the letter \"S\", use the regular expression /^S/:\nExample\nFind documents where the address starts with the letter \"S\":\nSave the code above in a file called \"demo_mongodb_query_s.js\" and run the file:\nRun \"demo_mongodb_query_s.js\"\nWhich will give you this result:",
      "examples": [
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet query = { address: \"Park Lane 38\" };\ndbo.collection(\"customers\").find(query).toArray(function(err, result) {\nif (err) throw err;\nconsole.log(result);\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_mongodb_query.js",
        "[\n{ _id: 58fdbf5c0ef8a50b4cdd9a8e , name: 'Ben', address: 'Park Lane 38' }\n]",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet query = { address: /^S/ };\ndbo.collection(\"customers\").find(query).toArray(function(err, result) {\nif (err) throw err;\nconsole.log(result);\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_mongodb_query_s.js",
        "[\n{ _id: 58fdbf5c0ef8a50b4cdd9a8b , name: 'Richard', address: 'Sky st 331' },\n{ _id: 58fdbf5c0ef8a50b4cdd9a91 , name: 'Viola', address: 'Sideway 1633' }\n]",
        "find()",
        "/^S/"
      ]
    },
    {
      "title": "Node.js MongoDB Sort",
      "summary": "Sort the Result\nUse the sort() method to sort the result in ascending or descending order.\nThe sort() method takes one parameter, an object defining the sorting order.\nExampleGet your own Node.js Server\nSort the result alphabetically by name:\nSave the code above in a file called \"demo_sort.js\" and run the file:\nRun \"demo_sort.js\"\nWhich will give you this result:\nREMOVE ADS\nSort Descending\nUse the value -1 in the sort object to sort descending.\n{ name: 1 } // ascending\n{ name: -1 } // descending\nExample\nSort the result reverse alphabetically by name:\nSave the code above in a file called \"demo_sort_desc.js\" and run the file:\nRun \"demo_sort_desc.js\"\nWhich will give you this result:",
      "examples": [
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet mysort = { name: 1 };\ndbo.collection(\"customers\").find().sort(mysort).toArray(function(err, result) {\nif (err) throw err;\nconsole.log(result);\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_sort.js",
        "[\n{ _id: 58fdbf5c0ef8a50b4cdd9a86, name: 'Amy', address: 'Apple st 652'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8e, name: 'Ben', address: 'Park Lane 38'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8a, name: 'Betty', address: 'Green Grass 1'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a90, name: 'Chuck', address: 'Main Road 989'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a87, name: 'Hannah', address: 'Mountain 21'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a84, name: 'John', address: 'Highway 71'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a88, name: 'Michael', address: 'Valley 345'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a85, name: 'Peter', address: 'Lowstreet 4'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8b, name: 'Richard', address: 'Sky st 331'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a89, name: 'Sandy', address: 'Ocean blvd 2'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8c, name: 'Susan', address: 'One way 98'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8d, name: 'Vicky', address: 'Yellow Garden 2'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a91, name: 'Viola', address: 'Sideway 1633'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8f, name: 'William', address: 'Central st 954'}\n]",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet mysort = { name: -1 };\ndbo.collection(\"customers\").find().sort(mysort).toArray(function(err, result) {\nif (err) throw err;\nconsole.log(result);\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_sort_desc.js",
        "[\n{ _id: 58fdbf5c0ef8a50b4cdd9a8f, name: 'William', address: 'Central st 954'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a91, name: 'Viola', address: 'Sideway 1633'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8d, name: 'Vicky', address: 'Yellow Garden 2'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8c, name: 'Susan', address: 'One way 98'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a89, name: 'Sandy', address: 'Ocean blvd 2'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8b, name: 'Richard', address: 'Sky st 331'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a85, name: 'Peter', address: 'Lowstreet 4'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a88, name: 'Michael', address: 'Valley 345'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a84, name: 'John', address: 'Highway 71'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a87, name: 'Hannah', address: 'Mountain 21'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a90, name: 'Chuck', address: 'Main Road 989'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8a, name: 'Betty', address: 'Green Grass 1'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8e, name: 'Ben', address: 'Park Lane 38'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a86, name: 'Amy', address: 'Apple st 652'}\n]",
        "sort()"
      ]
    },
    {
      "title": "Node.js MongoDB Delete",
      "summary": "Delete Document\nTo delete a record, or document as it is called in MongoDB, we use the deleteOne() method.\nThe first parameter of the deleteOne() method is a query object defining which document to delete.\nNote: If the query finds more than one document, only the first occurrence is deleted.\nExampleGet your own Node.js Server\nDelete the document with the address \"Mountain 21\":\nSave the code above in a file called \"demo_delete.js\" and run the file:\nRun \"demo_delete.js\"\nWhich will give you this result:\nREMOVE ADS\nDelete Many\nTo delete more than one document, use the deleteMany() method.\nThe first parameter of the deleteMany() method is a query object defining which documents to delete.\nExample\nDelete all documents were the address starts with the letter \"O\":\nSave the code above in a file called \"demo_delete_many.js\" and run the file:\nRun \"demo_delete_many.js\"\nWhich will give you this result:\nThe Result Object\nThe deleteMany() method returns an object which contains information about how the execution affected the database.\nMost of the information is not important to understand, but one object inside the object is called \"result\" which tells us if the execution went OK, and how many documents were affected.\nThe result object looks like this:\nYou can use this object to return the number of deleted documents:\nExample\nReturn the number of deleted documents:\nWhich will produce this result:",
      "examples": [
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet myquery = { address: 'Mountain 21' };\ndbo.collection(\"customers\").deleteOne(myquery, function(err, obj) {\nif (err) throw err;\nconsole.log(\"1 document deleted\");\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_delete.js",
        "1 document deleted",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet myquery = { address: /^O/ };\ndbo.collection(\"customers\").deleteMany(myquery, function(err, obj) {\nif (err) throw err;\nconsole.log(obj.result.n + \" document(s) deleted\");\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_delete_many.js",
        "2 document(s) deleted",
        "{ n: 2, ok: 1 }",
        "console.log(obj.result.n);",
        "2",
        "deleteOne()",
        "deleteMany()"
      ]
    },
    {
      "title": "Node.js MongoDB Drop",
      "summary": "Drop Collection\nYou can delete a table, or collection as it is called in MongoDB, by using the drop() method.\nThe drop() method takes a callback function containing the error object and the result parameter which returns true if the collection was dropped successfully, otherwise it returns false.\nExampleGet your own Node.js Server\nDelete the \"customers\" table:\nSave the code above in a file called \"demo_drop.js\" and run the file:\nRun \"demo_drop.js\"\nWhich will give you this result:\nREMOVE ADS\ndb.dropCollection\nYou can also use the dropCollection() method to delete a table (collection).\nThe dropCollection() method takes two parameters: the name of the collection and a callback function.\nExample\nDelete the \"customers\" collection, using dropCollection():\nSave the code above in a file called \"demo_dropcollection.js\" and run the file:\nRun \"demo_dropcollection.js\"\nWhich will give you this result:",
      "examples": [
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.collection(\"customers\").drop(function(err, delOK) {\nif (err) throw err;\nif (delOK) console.log(\"Collection deleted\");\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_drop.js",
        "Collection deleted",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.dropCollection(\"customers\", function(err, delOK) {\nif (err) throw err;\nif (delOK) console.log(\"Collection deleted\");\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_dropcollection.js",
        "drop()",
        "dropCollection()"
      ]
    },
    {
      "title": "Node.js MongoDB Update",
      "summary": "Update Document\nYou can update a record, or document as it is called in MongoDB, by using the updateOne() method.\nThe first parameter of the updateOne() method is a query object defining which document to update.\nNote: If the query finds more than one record, only the first occurrence is updated.\nThe second parameter is an object defining the new values of the document.\nExampleGet your own Node.js Server\nUpdate the document with the address \"Valley 345\" to name=\"Mickey\" and address=\"Canyon 123\":\nSave the code above in a file called \"demo_update_one.js\" and run the file:\nRun \"demo_update_one.js\"\nWhich will give you this result:\nREMOVE ADS\nUpdate Only Specific Fields\nWhen using the $set operator, only the specified fields are updated:\nExample\nUpdate the address from \"Valley 345\" to \"Canyon 123\":\nUpdate Many Documents\nTo update all documents that meets the criteria of the query, use the updateMany() method.\nExample\nUpdate all documents where the name starts with the letter \"S\":\nSave the code above in a file called \"demo_update_many.js\" and run the file:\nRun \"demo_update_many.js\"\nWhich will give you this result:\nThe Result Object\nThe updateOne() and the updateMany() methods return an object which contains information about how the execution affected the database.\nMost of the information is not important to understand, but one object inside the object is called \"result\" which tells us if the execution went OK, and how many documents were affected.\nThe result object looks like this:\nYou can use this object to return the number of updated documents:\nExample\nReturn the number of updated documents:\nWhich will produce this result:",
      "examples": [
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://127.0.0.1:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet myquery = { address: \"Valley 345\" };\nlet newvalues = { $set: {name: \"Mickey\", address: \"Canyon 123\" } };\ndbo.collection(\"customers\").updateOne(myquery, newvalues, function(err, res) {\nif (err) throw err;\nconsole.log(\"1 document updated\");\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_update_one.js",
        "1 document updated",
        "...\nlet myquery = { address: \"Valley 345\" };\nlet newvalues = { $set: { address: \"Canyon 123\" } };\ndbo.collection(\"customers\").updateOne(myquery, newvalues, function(err, res) {\n...",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://127.0.0.1:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\nlet myquery = { address: /^S/ };\nlet newvalues = {$set: {name: \"Minnie\"} };\ndbo.collection(\"customers\").updateMany(myquery, newvalues, function(err, res) {\nif (err) throw err;\nconsole.log(res.result.nModified + \" document(s) updated\");\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_update_many.js",
        "2 document(s) updated",
        "{ n: 1, nModified: 2, ok: 1 }",
        "console.log(res.result.nModified);",
        "2",
        "updateOne()",
        "$set",
        "updateMany()"
      ]
    },
    {
      "title": "Node.js MongoDB Limit",
      "summary": "Limit the Result\nTo limit the result in MongoDB, we use the limit() method.\nThe limit() method takes one parameter, a number defining how many documents to return.\nConsider you have a \"customers\" collection:\ncustomersGet your own Node.js Server\nExample\nLimit the result to only return 5 documents:\nSave the code above in a file called \"demo_mongodb_limit.js\" and run the file:\nRun \"demo_mongodb_limit.js\"\nWhich will give you this result:\ncustomers\nAs you can see from the result above, only the 5 first documents were returned.",
      "examples": [
        "[\n{ _id: 58fdbf5c0ef8a50b4cdd9a84 , name: 'John', address: 'Highway 71'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a85 , name: 'Peter', address: 'Lowstreet 4'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a86 , name: 'Amy', address: 'Apple st 652'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a87 , name: 'Hannah', address: 'Mountain 21'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a88 , name: 'Michael', address: 'Valley 345'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a89 , name: 'Sandy', address: 'Ocean blvd 2'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8a , name: 'Betty', address: 'Green Grass 1'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8b , name: 'Richard', address: 'Sky st 331'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8c , name: 'Susan', address: 'One way 98'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8d , name: 'Vicky', address: 'Yellow Garden 2'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8e , name: 'Ben', address: 'Park Lane 38'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a8f , name: 'William', address: 'Central st 954'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a90 , name: 'Chuck', address: 'Main Road 989'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a91 , name: 'Viola', address: 'Sideway 1633'}\n]",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://localhost:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.collection(\"customers\").find().limit(5).toArray(function(err, result) {\nif (err) throw err;\nconsole.log(result);\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_mongodb_limit.js",
        "[\n{ _id: 58fdbf5c0ef8a50b4cdd9a84 , name: 'John', address: 'Highway 71'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a85 , name: 'Peter', address: 'Lowstreet 4'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a86 , name: 'Amy', address: 'Apple st 652'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a87 , name: 'Hannah', address: 'Mountain 21'},\n{ _id: 58fdbf5c0ef8a50b4cdd9a88 , name: 'Michael', address: 'Valley 345'}\n]",
        "limit()"
      ]
    },
    {
      "title": "Node.js MongoDB Join",
      "summary": "Join Collections\nMongoDB is not a relational database, but you can perform a left outer join by using the $lookup stage.\nThe $lookup stage lets you specify which collection you want to join with the current collection, and which fields that should match.\nConsider you have a \"orders\" collection and a \"products\" collection:\nordersGet your own Node.js Server\nproducts\nExample\nJoin the matching \"products\" document(s) to the \"orders\" collection:\nSave the code above in a file called \"demo_mongodb_join.js\" and run the file:\nRun \"demo_mongodb_join.js\"\nWhich will give you this result:\nAs you can see from the result above, the matching document from the products collection is included in the orders collection as an array.",
      "examples": [
        "[\n{ _id: 1, product_id: 154, status: 1 }\n]",
        "[\n{ _id: 154, name: 'Chocolate Heaven' },\n{ _id: 155, name: 'Tasty Lemons' },\n{ _id: 156, name: 'Vanilla Dreams' }\n]",
        "let MongoClient = require('mongodb').MongoClient;\nlet url = \"mongodb://127.0.0.1:27017/\";\n\nMongoClient.connect(url, function(err, db) {\nif (err) throw err;\nlet dbo = db.db(\"mydb\");\ndbo.collection('orders').aggregate([\n{ $lookup:\n{\nfrom: 'products',\nlocalField: 'product_id',\nforeignField: '_id',\nas: 'orderdetails'\n}\n}\n]).toArray(function(err, res) {\nif (err) throw err;\nconsole.log(JSON.stringify(res));\ndb.close();\n});\n});",
        "C:\\Users\\Your Name>node demo_mongodb_join.js",
        "[\n{ \"_id\": 1, \"product_id\": 154, \"status\": 1, \"orderdetails\": [\n{ \"_id\": 154, \"name\": \"Chocolate Heaven\" } ]\n}\n]",
        "$lookup"
      ]
    },
    {
      "title": "Node.js GraphQL",
      "summary": "What is GraphQL?\nGraphQL is a query language for APIs and a runtime for executing those queries against your data. It was developed by Facebook in 2012 and publicly released in 2015.\nKey Features\nClient-specified queries: Request exactly what you need, nothing more\nSingle endpoint: Access all resources through one endpoint\nStrongly typed: Clear schema defines available data and operations\nHierarchical: Queries match the shape of your data\nSelf-documenting: Schema serves as documentation\nNote: Unlike REST, GraphQL lets clients specify exactly what data they need, reducing over-fetching and under-fetching of data.\nGetting Started with GraphQL in Node.js\nPrerequisites\nNode.js installed (v14 or later recommended)\nBasic knowledge of JavaScript and Node.js\nnpm or yarn package manager\nStep 1: Set Up a New Project\nCreate a new directory and initialize a Node.js project:\nStep 2: Install Required Packages\nInstall the necessary dependencies:\nThis installs:\nexpress: Web framework for Node.js\nexpress-graphql: Middleware for creating a GraphQL HTTP server\ngraphql: The JavaScript reference implementation of GraphQL\nStep 3: Create a Basic GraphQL Server\nCreate a new file server.js and start by defining your data model using GraphQL's Schema Definition Language (SDL):\nAdd the schema definition to your server.js file:\nAdd resolver functions to fetch the actual data:\nComplete the server setup:\nStep 4: Run and Test Your GraphQL Server\nRun your server with Node.js:\nYou should see the message: Server running at http://localhost:4000/graphql\nOpen your browser and navigate to http://localhost:4000/graphql to access the GraphiQL interface.\nHandling Mutations\nMutations are used to modify data on the server. Let's add the ability to add, update, and delete books.\n1. Update the Schema\nAdd the Mutation type to your schema:\n2. Implement Mutation Resolvers\nUpdate your root resolver object to include the mutation resolvers:\n3. Testing Mutations\nBest Practices\n1. Error Handling\nAlways handle errors properly in your resolvers:\n2. Data Validation\nValidate input data before processing:\n3. N+1 Problem\nUse DataLoader to batch and cache database queries:\nNext Steps\nConnect to a real database (MongoDB, PostgreSQL, etc.)\nImplement authentication and authorization\nAdd subscriptions for real-time updates\nExplore Apollo Server for more advanced features\nLearn about schema stitching and federation for microservices\nTip: Always use variables in your GraphQL operations for better reusability and security.\nGraphQL Schemas and Types\nGraphQL schemas define the structure of your API and the types of data that can be requested.\nType System\nGraphQL uses a type system to define the shape of your data. Here are the basic scalar types:",
      "examples": [
        "mkdir graphql-server\ncd graphql-server\nnpm init -y",
        "npm install express express-graphql graphql",
        "const express = require('express');\nconst { graphqlHTTP } = require('express-graphql');\nconst { buildSchema } = require('graphql');\n\n// Sample data\nconst books = [\n{\nid: '1',\ntitle: 'The Great Gatsby',\nauthor: 'F. Scott Fitzgerald',\nyear: 1925,\ngenre: 'Novel'\n},\n{\nid: '2',\ntitle: 'To Kill a Mockingbird',\nauthor: 'Harper Lee',\nyear: 1960,\ngenre: 'Southern Gothic'\n}\n];",
        "// Define the schema using GraphQL schema language\nconst schema = buildSchema(`\n# A book has a title, author, and publication year\ntype Book {\nid: ID!\ntitle: String!\nauthor: String!\nyear: Int\ngenre: String\n}\n\n# The \"Query\" type is the root of all GraphQL queries\ntype Query {\n# Get all books\nbooks: [Book!]!\n# Get a specific book by ID\nbook(id: ID!): Book\n# Search books by title or author\nsearchBooks(query: String!): [Book!]!\n}\n`);",
        "// Define resolvers for the schema fields\nconst root = {\n// Resolver for fetching all books\nbooks: () => books,\n\n// Resolver for fetching a single book by ID\nbook: ({ id }) => books.find(book => book.id === id),\n\n// Resolver for searching books\nsearchBooks: ({ query }) => {\nconst searchTerm = query.toLowerCase();\nreturn books.filter(\nbook =>\nbook.title.toLowerCase().includes(searchTerm) ||\nbook.author.toLowerCase().includes(searchTerm)\n);\n}\n};",
        "// Create an Express app\nconst app = express();\n\n// Set up the GraphQL endpoint\napp.use('/graphql', graphqlHTTP({\nschema: schema,\nrootValue: root,\n// Enable the GraphiQL interface for testing\ngraphiql: true,\n}));\n\n// Start the server\nconst PORT = 4000;\napp.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/graphql`);\n});",
        "node server.js",
        "{\nbooks {\nid\ntitle\nauthor\nyear\n}\n}",
        "{\nbook(id: \"1\") {\ntitle\nauthor\ngenre\n}\n}",
        "{\nsearchBooks(query: \"Gatsby\") {\ntitle\nauthor\nyear\n}\n}",
        "const schema = buildSchema(`\n# ... (previous types remain the same) ...\n\n# Input type for adding/updating books\ninput BookInput {\ntitle: String\nauthor: String\nyear: Int\ngenre: String\n}\n\ntype Mutation {\n# Add a new book\naddBook(input: BookInput!): Book!\n# Update an existing book\nupdateBook(id: ID!, input: BookInput!): Book\n# Delete a book\ndeleteBook(id: ID!): Boolean\n}\n`);",
        "const root = {\n// ... (previous query resolvers remain the same) ...\n\n// Mutation resolvers\naddBook: ({ input }) => {\nconst newBook = {\nid: String(books.length + 1),\n...input\n}\nbooks.push(newBook);\nreturn newBook;\n},\n\nupdateBook: ({ id, input }) => {\nconst bookIndex = books.findIndex(book => book.id === id);\nif (bookIndex === -1) return null;\n\nconst updatedBook = {\n...books[bookIndex],\n...input\n}\nbooks[bookIndex] = updatedBook;\nreturn updatedBook;\n},\n\ndeleteBook: ({ id }) => {\nconst bookIndex = books.findIndex(book => book.id === id);\nif (bookIndex === -1) return false;\n\nbooks.splice(bookIndex, 1);\nreturn true;\n}\n};",
        "mutation {\naddBook(input: {\ntitle: \"1984\"\nauthor: \"George Orwell\"\nyear: 1949\ngenre: \"Dystopian\"\n}) {\nid\ntitle\nauthor\n}\n}",
        "mutation {\nupdateBook(\nid: \"1\"\ninput: { year: 1926 }\n) {\ntitle\nyear\n}\n}",
        "mutation {\ndeleteBook(id: \"2\")\n}",
        "const root = {\nbook: ({ id }) => {\nconst book = books.find(book => book.id === id);\nif (!book) {\nthrow new Error('Book not found');\n}\nreturn book;\n},\n// ... other resolvers\n}",
        "const { GraphQLError } = require('graphql');\n\nconst root = {\naddBook: ({ input }) => {\nif (input.year && (input.year < 0 || input.year > new Date().getFullYear() + 1)) {\nthrow new GraphQLError('Invalid publication year', {\nextensions: { code: 'BAD_USER_INPUT' }\n}\n}\n// ... rest of the resolver\n}\n};",
        "npm install dataloader",
        "const DataLoader = require('dataloader');\n\n// Create a loader for books\nconst bookLoader = new DataLoader(async (ids) => {\n// This would be a database query in a real app\nreturn ids.map(id => books.find(book => book.id === id));\n});\n\nconst root = {\nbook: ({ id }) => bookLoader.load(id),\n// ... other resolvers\n};",
        "express",
        "express-graphql",
        "graphql",
        "server.js",
        "Server running at http://localhost:4000/graphql",
        "http://localhost:4000/graphql",
        "42",
        "3.14",
        "\"Hello, GraphQL!\"",
        "true",
        "false",
        "\"5f8a8d8e8f8c8d8b8a8e8f8c\""
      ]
    },
    {
      "title": "Node.js Socket.IO",
      "summary": "What is Socket.IO?\nSocket.IO is a powerful JavaScript library that enables real-time, bidirectional, and event-based communication between web clients and servers. It's designed to work on every platform, browser, or device, focusing equally on reliability and speed.\nKey Features\nReal-time bidirectional communication - Enables instant data transfer between clients and servers\nAutomatic reconnection - Handles disconnections and reconnections automatically\nRoom support - Easily create channels for group communication\nBinary support - Send and receive binary data (ArrayBuffer, Blob, File, etc.)\nMultiplexing - Handle multiple sockets with namespaces\nFallback options - Automatically falls back to HTTP long-polling if WebSockets aren't available\nUse Cases\nReal-time chat applications\nLive notifications\nCollaborative tools\nOnline gaming\nLive analytics\nDocument collaboration\nReal-time dashboards\nIoT applications\nSocket.IO consists of two parts:\nA client-side library that runs in the browser\nA server-side library for Node.js\nInstalling Socket.IO\nServer-Side Installation\nInstall Socket.IO in your Node.js project using npm or yarn:\nClient-Side Setup\nChoose one of the following methods to include the client library:\nVersion Compatibility\nNote: For production, it's recommended to use the same version on both client and server.\nSimple Chat Application with Socket.IO\nLet's build a simple real-time chat application using Node.js and Socket.IO.\nThis example doesn't require any login and demonstrates the basic functionality.\nCreate the Server (app.js)\nCreate a new file named app.js with the following content:\nCreate the Client (public/index.html)\nCreate a public directory and add an index.html file with this content:\nRun the Application\nStart the server:\nnode app.js\nOpen your browser and navigate to http://localhost:3000\nOpen multiple browser windows to see the real-time updates\nHow It Works\nThe server uses Express to serve the static files and handle the Socket.IO connection\nWhen a client connects, they can send messages that get broadcast to all connected clients\nThe client-side JavaScript handles sending and receiving messages in real-time\nNext Steps\nOnce you have this basic version working, you might want to add:\nUsernames for each message\nUser join/leave notifications\nDifferent chat rooms\nMessage persistence\nUser authentication\nNote: This is a basic example for demonstration purposes. In a production environment, you would want to add proper error handling, input validation, and security measures.\nAdding Usernames\nLet's enhance our chat by adding usernames to messages. First, modify the server to handle usernames:\nNow, update the client to handle usernames:\nAdding Chat Rooms\nLet's add the ability to create and join different chat rooms. First, update the server:\nUpdate the client to handle rooms:\nAdding User List and Typing Indicators\nLet's enhance our chat with a user list and typing indicators. First, update the server to track users and typing status:\nUpdate the client to show the user list and handle typing indicators:\nClient-Side API Overview\nThe client-side Socket.IO API provides methods for:\nio() - Connects to the server\nsocket.emit() - Sends an event to the server\nsocket.on() - Listens for events from the server\nsocket.disconnect() - Disconnects from the server\nSocket.IO Events\nSocket.IO uses an event-based architecture for communication. Here are some key events:\nBuilt-in Events\nconnect - Fired upon connection\ndisconnect - Fired upon disconnection\nerror - Fired upon an error\nreconnect - Fired upon successful reconnection\nreconnect_attempt - Fired upon reconnection attempt\nSocket.IO Middleware\nSocket.IO allows you to define middleware functions for authentication and other purposes:\nSocket.IO vs Native WebSockets\nSocket.IO is preferred when you need reliability, compatibility, and higher-level features, while native WebSockets are more lightweight and have less overhead.",
      "examples": [
        "# Using npm\nnpm install socket.io\n\n# Or using Yarn\nyarn add socket.io",
        "<script src=\"https://cdn.socket.io/4.5.0/socket.io.min.js\"></script>",
        "# Install the client library\nnpm install socket.io-client\n\n# Or using Yarn\nyarn add socket.io-client",
        "import { io } from 'socket.io-client';",
        "const express = require('express');\nconst http = require('http');\nconst { Server } = require('socket.io');\nconst path = require('path');\n\nconst app = express();\nconst server = http.createServer(app);\nconst io = new Server(server);\n\n// Serve static files\napp.use(express.static(path.join(__dirname, 'public')));\n\n// Simple route\napp.get('/', (req, res) => {\n;  res.sendFile(path.join(__dirname, 'public', 'index.html'));\n});\n\n// Socket.IO connection handler\nio.on('connection', (socket) => {\nconsole.log('A user connected');\n\n// Handle new messages\nsocket.on('chat message', (msg) => {\nconsole.log('Message received:', msg);\n// Broadcast the message to all connected clients\nio.emit('chat message', msg);\n});\n\n// Handle disconnection\nsocket.on('disconnect', () => {\nconsole.log('A user disconnected');\n});\n});\n\nconst PORT = process.env.PORT || 3000;\nserver.listen(PORT, () => {\nconsole.log(`Server running on port ${PORT}`);\n});",
        "<!DOCTYPE html>\n<html>\n<head>\n<title>Simple Chat</title>\n<style>\nbody {\nmargin: 0;\npadding: 20px;\nfont-family: Arial, sans-serif;\n}\n#messages {\nlist-style-type: none;\nmargin: 0;\npadding: 0;\nmargin-bottom: 20px;\nborder: 1px solid #ddd;\npadding: 10px;\nheight: 400px;\noverflow-y: auto;\n}\n#messages li {\npadding: 8px 16px;\nborder-bottom: 1px solid #eee;\n}\n#messages li:last-child {\nborder-bottom: none;\n}\n#form {\ndisplay: flex;\nmargin-top: 10px;\n}\n#input {\nflex-grow: 1;\npadding: 10px;\nfont-size: 16px;\n}\nbutton {\npadding: 10px 20px;\nbackground: #4CAF50;\ncolor: white;\nborder: none;\ncursor: pointer;\nmargin-left: 10px;\n}\nbutton:hover {\nbackground: #45a049;\n}\n</style>\n</head>\n<body>\n<h1>Simple Chat</h1>\n<ul id=\"messages\"></ul>\n<form id=\"form\" action=\"#\">\n<input id=\"input\" autocomplete=\"off\" placeholder=\"Type your message...\" />\n<button>Send</button>\n</form>\n\n<script src=\"/socket.io/socket.io.js\"></script>\n<script>\nconst socket = io();\nconst form = document.getElementById('form');\nconst input = document.getElementById('input');\nconst messages = document.getElementById('messages');\n\n// Handle form submission\nform.addEventListener('submit', (e) => {\ne.preventDefault();\nconst message = input.value.trim();\nif (message) {\n// Emit the message to the server\nsocket.emit('chat message', message);\n// Clear the input\ninput.value = '';\n}\n});\n\n// Listen for incoming messages\nsocket.on('chat message', (msg) => {\nconst item = document.createElement('li');\nitem.textContent = msg;\nmessages.appendChild(item);\n// Scroll to the bottom\nmessages.scrollTop = messages.scrollHeight;\n});\n</script>\n</body>\n</html>",
        "node app.js",
        "// In app.js, modify the connection handler\nio.on('connection', (socket) => {\nconsole.log('A user connected');\n\n// Store username with socket\nsocket.username = 'Anonymous';\n// Handle new messages with username\nsocket.on('chat message', (msg) => {\nio.emit('chat message', {\nusername: socket.username,\nmessage: msg,\ntimestamp: new Date().toISOString()\n});\n});\n// Handle username change\nsocket.on('set username', (username) => {\nconst oldUsername = socket.username;\nsocket.username = username || 'Anonymous';\nio.emit('user joined', {\noldUsername: oldUsername,\nnewUsername: socket.username\n});\n});\n\n// Handle disconnection\nsocket.on('disconnect', () => {\nconsole.log('A user disconnected');\nio.emit('user left', { username: socket.username });\n});\n});",
        "<!-- Add username input at the top of the chat -->\n<div id=\"username-container\">\n<input type=\"text\" id=\"username-input\" placeholder=\"Enter your username\" />\n<button id=\"set-username\">Set Username</button>\n</div>\n\n<script>\n// Add username handling\nconst usernameInput = document.getElementById('username-input');\nconst setUsernameBtn = document.getElementById('set-username');\nlet currentUsername = 'Anonymous';\n\nsetUsernameBtn.addEventListener('click', () => {\nconst newUsername = usernameInput.value.trim();\nif (newUsername) {\nsocket.emit('set username', newUsername);\ncurrentUsername = newUsername;\nusernameInput.value = '';\n}\n});\n\n// Update message display to show usernames\nsocket.on('chat message', (data) => {\nconst item = document.createElement('li');\nitem.innerHTML = `<strong>${data.username}:</strong> ${data.message}`;\nmessages.appendChild(item);\nmessages.scrollTop = messages.scrollHeight;\n});\n\n// Handle user join notifications\nsocket.on('user joined', (data) => {\nconst item = document.createElement('li');\nitem.className = 'system-message';\nif (data.oldUsername === 'Anonymous') {\nitem.textContent = `${data.newUsername} has joined the chat`;\n} else {\nitem.textContent = `${data.oldUsername} is now known as ${data.newUsername}`;\n}\nmessages.appendChild(item);\nmessages.scrollTop = messages.scrollHeight;\n});\n\n// Handle user leave notifications\nsocket.on('user left', (data) => {\nconst item = document.createElement('li');\nitem.className = 'system-message';\nitem.textContent = `${data.username} has left the chat`;\nmessages.appendChild(item);\nmessages.scrollTop = messages.scrollHeight;\n});\n</script>\n\n<style>\n.system-message {\ncolor: #666;\nfont-style: italic;\nfont-size: 0.9em;\n}\n</style>",
        "// In app.js, add room handling\nconst rooms = new Set(['general', 'random']);\n\nio.on('connection', (socket) => {\n// ... existing code ...\n\n// Join a room\nsocket.on('join room', (room) => {\n// Leave all rooms except the default one\nsocket.rooms.forEach(r => {\nif (r !== socket.id) {\nsocket.leave(r);\nsocket.emit('left room', r);\n}\n});\n\n// Join the new room\nsocket.join(room);\nsocket.emit('joined room', room);\n\n// Notify others in the room\nsocket.to(room).emit('room message', {\nusername: 'System',\nmessage: `${socket.username} has joined the room`,\ntimestamp: new Date().toISOString()\n});\n});\n\n// Handle room creation\nsocket.on('create room', (roomName) => {\nif (!rooms.has(roomName)) {\nrooms.add(roomName);\nio.emit('room created', roomName);\n}\n});\n\n// Modify message handler to send to room\nsocket.on('chat message', (data) => {\nconst room = Array.from(socket.rooms).find(r => r !== socket.id) || 'general';\nio.to(room).emit('chat message', {\nusername: socket.username,\nmessage: data.message,\ntimestamp: new Date().toISOString(),\nroom: room\n});\n});\n});",
        "<div id=\"chat-container\">\n<div id=\"sidebar\">\n<h3>Rooms</h3>\n<ul id=\"room-list\">\n<li class=\"room active\" data-room=\"general\">General</li>\n<li class=\"room\" data-room=\"random\">Random</li>\n</ul>\n<div id=\"create-room\">\n<input type=\"text\" id=\"new-room\" placeholder=\"New room name\" />\n<button id=\"create-room-btn\">Create Room</button>\n</div>\n</div>\n<div id=\"chat-area\">\n<div id=\"messages\"></div>\n<form id=\"form\">\n<input id=\"input\" autocomplete=\"off\" />\n<button>Send</button>\n</form>\n</div>\n</div>\n\n<script>\n// Room handling\nconst roomList = document.getElementById('room-list');\nconst newRoomInput = document.getElementById('new-room');\nconst createRoomBtn = document.getElementById('create-room-btn');\nlet currentRoom = 'general';\n\n// Join room when clicking on room in the list\nroomList.addEventListener('click', (e) => {\nif (e.target.classList.contains('room')) {\nconst room = e.target.dataset.room;\nsocket.emit('join room', room);\ncurrentRoom = room;\ndocument.querySelectorAll('.room').forEach(r => r.classList.remove('active'));\ne.target.classList.add('active');\n}\n});\n\n// Create new room\ncreateRoomBtn.addEventListener('click', () => {\nconst roomName = newRoomInput.value.trim();\nif (roomName && !document.querySelector(`[data-room=\"${roomName}\"]`)) {\nsocket.emit('create room', roomName);\nnewRoomInput.value = '';\n}\n});\n\n// Handle new room creation\nsocket.on('room created', (roomName) => {\nconst roomItem = document.createElement('li');\nroomItem.className = 'room';\nroomItem.dataset.room = roomName;\nroomItem.textContent = roomName;\nroomList.appendChild(roomItem);\n});\n\n// Handle room join confirmation\nsocket.on('joined room', (room) => {\nconst item = document.createElement('li');\nitem.className = 'system-message';\nitem.textContent = `You joined ${room}`;\nmessages.appendChild(item);\ncurrentRoom = room;\nmessages.scrollTop = messages.scrollHeight;\n});\n\n// Handle room messages\nsocket.on('room message', (data) => {\nconst item = document.createElement('li');\nitem.className = 'system-message';\nitem.textContent = data.message;\nmessages.appendChild(item);\nmessages.scrollTop = messages.scrollHeight;\n});\n</script>\n\n<style>\n#chat-container {\ndisplay: flex;\nmax-width: 1200px;\nmargin: 0 auto;\n}\n\n#sidebar {\nwidth: 250px;\npadding: 20px;\nbackground-color: #f5f5f5;\nborder-right: 1px solid #ddd;\n}\n\n#chat-area {\nflex: 1;\npadding: 20px;\n}\n\n.room {\npadding: 8px;\ncursor: pointer;\nborder-radius: 4px;\nmargin: 4px 0;\n}\n\n.room:hover {\nbackground-color: #e9e9e9;\n}\n\n.room.active {\nbackground-color: #4CAF50;\ncolor: white;\n}\n\n#create-room {\nmargin-top: 20px;\n}\n\n#new-room {\nwidth: 100%;\npadding: 8px;\nmargin-bottom: 8px;\n}\n\n#create-room-btn {\nwidth: 100%;\npadding: 8px;\nbackground-color: #4CAF50;\ncolor: white;\nborder: none;\nborder-radius: 4px;\ncursor: pointer;\n}\n\n#create-room-btn:hover {\nbackground-color: #45a049;\n}\n</style>",
        "// In app.js, track users and typing status\nconst usersInRooms = new Map();\nconst typingUsers = new Map();\n\nio.on('connection', (socket) => {\n// ... existing code ...\n\n// Initialize user data\nsocket.on('join room', (room) => {\n// ... existing join room code ...\n\n// Initialize user data for the room\nif (!usersInRooms.has(room)) {\nusersInRooms.set(room, new Map());\ntypingUsers.set(room, new Set());\n}\n\n// Add user to room\nusersInRooms.get(room).set(socket.id, {\nusername: socket.username,\nid: socket.id\n});\n\n// Send updated user list to room\nupdateUserList(room);\n});\n\n// Handle typing status\nsocket.on('typing', (isTyping) => {\nconst room = Array.from(socket.rooms).find(r => r !== socket.id);\nif (!room) return;\n\nif (isTyping) {\ntypingUsers.get(room).add(socket.username);\n} else {\ntypingUsers.get(room).delete(socket.username);\n}\n\n// Notify room about typing users\nio.to(room).emit('typing users', Array.from(typingUsers.get(room)));\n});\n\n// Handle disconnection\nsocket.on('disconnect', () => {\n// Remove from all rooms\nArray.from(usersInRooms.entries()).forEach(([room, users]) => {\nif (users.has(socket.id)) {\nusers.delete(socket.id);\ntypingUsers.get(room)?.delete(socket.username);\nupdateUserList(room);\n}\n}\n});\n});\n\n// Helper function to update user list for a room\nfunction updateUserList(room) {\nconst users = Array.from(usersInRooms.get(room)?.values() || []);\nio.to(room).emit('user list', {\nroom: room,\nusers: users.map(u => ({\nusername: u.username,\nisTyping: typingUsers.get(room)?.has(u.username) || false\n}))\n});\n}\n});\n});",
        "<div id=\"chat-container\">\n<div id=\"sidebar\">\n<h3>Rooms</h3>\n<ul id=\"room-list\">\n<!-- Room list will be populated here -->\n</ul>\n<div id=\"create-room\">\n<input type=\"text\" id=\"new-room\" placeholder=\"New room name\" />\n<button id=\"create-room-btn\">Create Room</button>\n</div>\n<h3>Users in Room</h3>\n<ul id=\"user-list\">\n<!-- User list will be populated here -->\n</ul>\n</div>\n<div id=\"chat-area\">\n<div id=\"typing-indicator\"></div>\n<div id=\"messages\"></div>\n<form id=\"form\">\n<input id=\"input\" autocomplete=\"off\" placeholder=\"Type a message...\" />\n<button>Send</button>\n</form>\n</div>\n</div>\n\n<script>\n// ... existing code ...\n\nconst userList = document.getElementById('user-list');\nconst typingIndicator = document.getElementById('typing-indicator');\nconst messageInput = document.getElementById('input');\nlet typingTimeout;\n\n// Handle typing events\nmessageInput.addEventListener('input', () => {\n// User is typing\nif (!typingTimeout) {\nsocket.emit('typing', true);\n}\n\n// Clear previous timeout\nclearTimeout(typingTimeout);\n\n// Set a timeout to indicate user stopped typing\ntypingTimeout = setTimeout(() => {\nsocket.emit('typing', false);\ntypingTimeout = null;\n}, 1000);\n});\n\n// Handle form submission\nform.addEventListener('submit', (e) => {\ne.preventDefault();\nif (messageInput.value.trim()) {\nsocket.emit('chat message', {\nmessage: messageInput.value,\nroom: currentRoom\n});\nmessageInput.value = '';\n\n// Clear typing status\nif (typingTimeout) {\nclearTimeout(typingTimeout);\ntypingTimeout = null;\nsocket.emit('typing', false);\n}\n}\n});\n\n// Update user list\nsocket.on('user list', (data) => {\nif (data.room === currentRoom) {\nuserList.innerHTML = '';\ndata.users.forEach(user => {\nconst userItem = document.createElement('li');\nuserItem.textContent = user.username;\nif (user.isTyping) {\nuserItem.innerHTML += ' <span class=\"typing\">typing...</span>';\n}\nuserList.appendChild(userItem);\n});\n}\n});\n\n// Update typing indicator\nsocket.on('typing users', (usernames) => {\nconst typingUsers = usernames.filter(u => u !== currentUsername);\nif (typingUsers.length > 0) {\ntypingIndicator.textContent = `${typingUsers.join(', ')} ${typingUsers.length > 1 ? 'are' : 'is'} typing...`;\ntypingIndicator.style.display = 'block';\n} else {\ntypingIndicator.style.display = 'none';\n}\n});\n</script>\n\n<style>\n/* Add to existing styles */\n#typing-indicator {\ncolor: #666;\nfont-style: italic;\nfont-size: 0.9em;\npadding: 5px 10px;\ndisplay: none;\n}\n\n.typing {\ncolor: #666;\nfont-size: 0.8em;\nfont-style: italic;\n}\n\n#user-list {\nlist-style: none;\npadding: 0;\nmargin: 10px 0;\n}\n\n#user-list li {\npadding: 5px 10px;\nborder-radius: 3px;\nmargin: 2px 0;\n}\n\n#user-list li:hover {\nbackground-color: #f0f0f0;\n}\n</style>",
        "const io = new Server(server);\n\n// Middleware for authentication\nio.use((socket, next) => {\nconst token = socket.handshake.auth.token;\n\nif (!token) {\nreturn next(new Error('Authentication error: Token missing'));\n}\n\n// Verify token (example with JWT)\ntry {\nconst user = jwt.verify(token, 'your-secret-key');\nsocket.user = user;\nnext();\n} catch (error) {\nnext(new Error('Authentication error: Invalid token'));\n}\n});\n\nio.on('connection', (socket) => {\nconsole.log(`Authenticated user connected: ${socket.user.username}`);\n});",
        "app.js",
        "public",
        "index.html",
        "http://localhost:3000",
        "io()",
        "socket.emit()",
        "socket.on()",
        "socket.disconnect()",
        "connect",
        "disconnect",
        "error",
        "reconnect",
        "reconnect_attempt"
      ]
    },
    {
      "title": "Node.js WebSockets",
      "summary": "Introduction to WebSockets\nWebSockets provide a persistent connection between client and server, allowing for real-time, bidirectional communication.\nThis is different from traditional HTTP, which follows a request-response model.\nReal-time updates: Instantly push data to clients\nEfficient: No need for repeated HTTP requests\nBidirectional: Both client and server can send messages\nLow latency: Messages are sent immediately\nWebSockets vs HTTP\nUnderstanding the difference between WebSockets and HTTP is crucial for building real-time applications effectively.\nPro Tip: WebSockets begin with an HTTP handshake (status code 101) before upgrading to the WebSocket protocol (ws:// or wss://).\nREMOVE ADS\nSetting Up WebSockets\n1. Install the ws Module\nFirst, create a new directory for your project and initialize it:\nThen, install the ws package:\nNote: The ws module is a simple, fast, and thoroughly tested WebSocket client and server implementation.\nCreating a WebSocket Server\nLet's create a simple WebSocket server that echoes back any message it receives.\nCreate a new file called server.js:\nExample: WebSocket Echo ServerGet your own Node.js Server\nUnderstanding the Code\nWe import the ws module\nCreate a new WebSocket server on port 8080\nSet up event handlers for connections, messages, and disconnections\nEcho back any received messages to the client\n1. Save the code above as server.js\n2. Run the server: node server.js\n3. The server will start and listen on ws://localhost:8080\nCreating a WebSocket Client\nNow that we have a WebSocket server, let's create clients to connect to it. We'll create both a Node.js client and a browser client.\n1. Node.js Client\nCreate a new file called client.js:\nSave the code above as client.js\nMake sure the WebSocket server is running\nRun the client: node client.js\nType messages and press Enter to send them to the server\nType \"exit\" to quit\n2. Browser Client\nLet's create a simple HTML page with JavaScript to connect to our WebSocket server.\nCreate a file named index.html:\nSave the code above as index.html\nMake sure the WebSocket server is running\nOpen the HTML file in a web browser\nType messages in the input field and click Send or press Enter\nNote: For the browser client to work, you'll need to serve the HTML file through a web server (like http-server or live-server) due to browser security restrictions.\n3. Testing the Application\nStart the WebSocket server: node server.js\nOpen multiple browser windows with the client HTML page\nSend messages from different clients and see them appear in real-time\nYou can also run the Node.js client alongside the browser clients\nThe server maintains a set of all connected clients\nWhen a message is received from one client, it's broadcast to all others\nThe client handles connection, disconnection, and error events\nMessages are displayed in real-time as they're received\nWebSocket Events\nWebSockets use an event-driven model. Here are the key events:\nReal-world Applications\nWebSockets are used in a variety of real-world applications:\nChat Applications: Instant message delivery\nLive Dashboards: Real-time updates of metrics and data\nCollaborative Tools: Multiple users editing the same document\nGaming: Multiplayer online games requiring fast interactions\nFinancial Platforms: Real-time stock tickers and trading platforms\nIoT Applications: Monitoring and controlling connected devices\nAdvanced WebSocket Features\n1. Binary Data Transfer\nWebSockets support sending binary data, which is more efficient for certain types of data:\n2. Heartbeats and Connection Monitoring\nImplement heartbeats to detect and handle disconnections:\nSecurity Considerations\n1. Authentication\nAlways authenticate WebSocket connections:\n2. Rate Limiting\nPrevent abuse with rate limiting:\n3. Input Validation\nAlways validate incoming messages:\nPerformance Optimization\nCompression\nEnable per-message deflate to reduce bandwidth usage:\nBest Practice: For production applications, consider using libraries like Socket.IO which provides additional features like fallbacks for browsers that don't support WebSockets.",
      "examples": [
        "mkdir websocket-demo\ncd websocket-demo\nnpm init -y",
        "npm install ws",
        "const WebSocket = require('ws');\n\n// Create a WebSocket server on port 8080\nconst wss = new WebSocket.Server({ port: 8080 });\n\nconsole.log('WebSocket server is running on ws://localhost:8080');\n\n// Connection event handler\nwss.on('connection', (ws) => {\nconsole.log('New client connected');\n\n// Send a welcome message to the client\nws.send('Welcome to the WebSocket server!');\n\n// Message event handler\nws.on('message', (message) => {\nconsole.log(`Received: ${message}`);\n// Echo the message back to the client\nws.send(`Server received: ${message}`);\n});\n\n// Close event handler\nws.on('close', () => {\nconsole.log('Client disconnected');\n});\n});",
        "const WebSocket = require('ws');\nconst readline = require('readline');\n\n// Create readline interface for user input\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\n// Connect to the WebSocket server\nconst ws = new WebSocket('ws://localhost:8080');\n\n// Connection opened\nws.on('open', () => {\nconsole.log('Connected to the WebSocket server');\npromptForMessage();\n});\n\n// Listen for messages from the server\nws.on('message', (message) => {\nconsole.log(`Server: ${message}`);\n});\n\n// Handle errors\nws.on('error', (error) => {\nconsole.error('WebSocket error:', error);\n});\n\n// Handle connection close\nws.on('close', () => {\nconsole.log('Disconnected from the server');\nprocess.exit(0);\n});\n\n// Function to prompt user for messages\nfunction promptForMessage() {\nrl.question('Enter a message (or \"exit\" to quit): ', (message) => {\nif (message.toLowerCase() === 'exit') {\nws.close();\nrl.close();\nreturn;\n}\nws.send(message);\npromptForMessage();\n});\n}",
        "<!DOCTYPE html>\n<html>\n<head>\n<title>WebSocket Client</title>\n<style>\nbody {\nfont-family: Arial, sans-serif;\nmax-width: 600px;\nmargin: 0 auto;\npadding: 20px;\n}\n#messages {\nheight: 300px;\nborder: 1px solid #ccc;\noverflow-y: auto;\npadding: 10px;\nmargin-bottom: 10px;\n}\n.message { margin: 5px 0; }\n</style>\n</head>\n<body>\n<h1>WebSocket Client</h1>\n<div id=\"status\">Connecting to server...</div>\n<div id=\"messages\"></div>\n<div>\n<input type=\"text\" id=\"messageInput\" placeholder=\"Type your message\">\n<button onclick=\"sendMessage()\">Send</button>\n</div>\n\n<script>\nconst status = document.getElementById('status');\nconst messages = document.getElementById('messages');\nconst messageInput = document.getElementById('messageInput');\n\n// Connect to the WebSocket server\nconst ws = new WebSocket('ws://localhost:8080');\n\n// Connection opened\nws.onopen = () => {\nstatus.textContent = 'Connected to server';\nstatus.style.color = 'green';\n};\n\n// Listen for messages\nws.onmessage = (event) => {\nconst message = document.createElement('div');\nmessage.className = 'message';\nmessage.textContent = event.data;\nmessages.appendChild(message);\nmessages.scrollTop = messages.scrollHeight;\n};\n\n// Handle errors\nws.onerror = (error) => {\nstatus.textContent = 'Error: ' + error.message;\nstatus.style.color = 'red';\n};\n\n// Handle connection close\nws.onclose = () => {\nstatus.textContent = 'Disconnected from server';\nstatus.style.color = 'red';\n};\n\n// Function to send a message\nfunction sendMessage() {\nconst message = messageInput.value.trim();\nif (message) {\nws.send(message);\nmessageInput.value = '';\n}\n}\n\n// Send message on Enter key\nmessageInput.addEventListener('keypress', (e) => {\nif (e.key === 'Enter') {\nsendMessage();\n}\n});\n</script>\n</body>\n</html>",
        "// Sending binary data (server-side)\nconst buffer = Buffer.from([0x48, 0x65, 0x6c, 0x6c, 0x6f]); // 'Hello' in binary\nws.send(buffer, { binary: true });\n\n// Receiving binary data (client-side)\nws.binaryType = 'arraybuffer';\nws.onmessage = (event) => {\nif (event.data instanceof ArrayBuffer) {\nconst view = new Uint8Array(event.data);\nconsole.log('Received binary data:', view);\n}\n};",
        "// Server-side heartbeat\nfunction setupHeartbeat(ws) {\nws.isAlive = true;\nws.on('pong', () => { ws.isAlive = true; });\n}\n\n// Ping all clients every 30 seconds\nconst interval = setInterval(() => {\nwss.clients.forEach((ws) => {\nif (ws.isAlive === false) return ws.terminate();\nws.isAlive = false;\nws.ping();\n});\n}, 30000);\n\n// Clean up on server close\nwss.on('close', () => {\nclearInterval(interval);\n});",
        "const http = require('http');\nconst WebSocket = require('ws');\nconst jwt = require('jsonwebtoken');\n\nconst server = http.createServer();\nconst wss = new WebSocket.Server({ noServer: true });\n\n// Handle upgrade with authentication\nserver.on('upgrade', (request, socket, head) => {\ntry {\nconst token = request.url.split('token=')[1];\nif (!token) throw new Error('No token provided');\n\n// Verify JWT token\njwt.verify(token, 'your-secret-key', (err, decoded) => {\nif (err) {\nsocket.write('HTTP/1.1 401 Unauthorized\\r\\n\\r\\n');\nsocket.destroy();\nreturn;\n}\n\n// Proceed with WebSocket handshake\nwss.handleUpgrade(request, socket, head, (ws) => {\nws.user = decoded; // Attach user data to WebSocket\nwss.emit('connection', ws, request);\n});\n});\n} catch (error) {\nsocket.write('HTTP/1.1 401 Unauthorized\\r\\n\\r\\n');\nsocket.destroy();\n}\n});",
        "const rateLimit = require('ws-rate-limit');\n\n// Limit to 100 messages per minute per connection\nconst limiter = rateLimit({\nwindowMs: 60 * 1000, // 1 minute\nmax: 100,\nmessage: 'Too many messages, please slow down!',\n});\n\nwss.on('connection', (ws) => {\nlimiter(ws);\n// ... rest of your connection handler\n});",
        "const Joi = require('joi');\n\nconst messageSchema = Joi.object({\ntype: Joi.string().valid('chat', 'join', 'leave').required(),\nusername: Joi.string().alphanum().min(3).max(30),\nmessage: Joi.string().max(1000),\nroom: Joi.string().alphanum().max(50),\n});\n\nws.on('message', (data) => {\ntry {\nconst message = JSON.parse(data);\nconst { error, value } = messageSchema.validate(message);\nif (error) {\nthrow new Error(`Invalid message: ${error.details[0].message}`);\n}\n// Process valid message...\n} catch (err) {\nws.send(JSON.stringify({ error: err.message }));\n}\n});",
        "const WebSocket = require('ws');\n\nconst wss = new WebSocket.Server({\nport: 8080,\nperMessageDeflate: {\nzlibDeflateOptions: {\nchunkSize: 1024,\nmemLevel: 7,\nlevel: 3\n},\nzlibInflateOptions: {\nchunkSize: 10 * 1024\n},\n// Other options\nclientNoContextTakeover: true,\nserverNoContextTakeover: true,\nconcurrencyLimit: 10,\n}\n});",
        "ws",
        "server.js",
        "node server.js",
        "ws://localhost:8080",
        "client.js",
        "node client.js",
        "index.html",
        "http-server",
        "live-server",
        "connection",
        "open",
        "message",
        "error",
        "close"
      ]
    },
    {
      "title": "Node.js Advanced Debugging",
      "summary": "Introduction to Advanced Debugging\nEffective debugging is a critical skill for Node.js developers.\nWhile console.log() is useful for basic debugging, advanced techniques allow you to diagnose complex issues like memory leaks, performance bottlenecks, and race conditions.\nThis tutorial covers advanced debugging techniques and tools to help you solve challenging problems in your Node.js applications.\nAdvanced debugging tools provide capabilities like:\nSetting breakpoints and stepping through code execution\nInspecting variable values at runtime\nVisualizing memory consumption and finding leaks\nProfiling CPU usage to identify performance bottlenecks\nAnalyzing asynchronous call stacks\nDebugging with Chrome DevTools\nNode.js includes built-in support for the Chrome DevTools debugging protocol, allowing you to use the powerful Chrome DevTools interface to debug your Node.js applications.\nStarting Node.js in Debug Mode\nThere are several ways to start your application in debug mode:\nStandard Debug ModeGet your own Node.js Server\nThis starts your app normally but enables the inspector on port 9229.\nBreak on Start\nThis pauses execution at the first line of code, allowing you to set up breakpoints before execution begins.\nCustom Port\nThis uses a custom port for the inspector.\nConnecting to the Debugger\nAfter starting your Node.js application with the inspect flag, you can connect to it in several ways:\nChrome DevTools: Open Chrome and navigate to chrome://inspect.\nYou should see your Node.js application listed under \"Remote Target.\"\nClick \"inspect\" to open DevTools connected to your application:\nDevTools URL: Open the URL shown in the terminal\n(usually something like devtools://devtools/bundled/js_app.html?experiments=true&v8only=true&ws=127.0.0.1:9229/...).\nUsing DevTools for Debugging\nOnce connected, you can use the full power of Chrome DevTools:\nSources Panel: Set breakpoints, step through code, and watch variables\nCall Stack: View the current execution stack, including async call chains\nScope Variables: Inspect local and global variables at each breakpoint\nConsole: Evaluate expressions in the current context\nMemory Panel: Take heap snapshots and analyze memory usage\nPro Tip: Use the Sources panel's \"Pause on caught exceptions\" feature (the pause button with curved lines) to automatically break when an error occurs.\nDebugging in VS Code\nVisual Studio Code provides excellent built-in debugging capabilities for Node.js applications.\nSetting Up Node.js Debugging in VS Code\nYou can start debugging your Node.js application in VS Code in several ways:\nlaunch.json Configuration: Create a .vscode/launch.json file to define how VS Code should launch or attach to your application.\nAuto-Attach: Enable auto-attach in VS Code settings to automatically debug any Node.js process started with the --inspect flag.\nJavaScript Debug Terminal: Use the JavaScript Debug Terminal in VS Code to automatically debug any Node.js process started from that terminal.\nExample launch.json Configuration\nVS Code Debugging Features\nVS Code provides powerful debugging capabilities:\nBreakpoints: Set, disable, and enable breakpoints by clicking in the gutter of your code editor.\nConditional Breakpoints: Right-click on a breakpoint to set a condition that must be true for the breakpoint to trigger.\nLogpoints: Add logging without modifying code by setting logpoints that print messages to the console when hit.\nWatch Expressions: Monitor the value of variables and expressions as you step through code.\nCall Stack: View and navigate the call stack, including asynchronous frames.\nNote: VS Code can also debug TypeScript files directly, with source maps enabling debugging of the original TypeScript code rather than the transpiled JavaScript.\nUsing the Debug Module\nThe debug module is a lightweight debugging utility that allows you to add conditional logging to your Node.js applications without cluttering your code with console.log statements.\nInstalling the Debug Module\nBasic Usage of Debug\nThe debug module lets you create namespaced debug functions that can be enabled or disabled via environment variables:\nExample: Using the Debug Module\nEnabling Debug Output\nTo see the debug output, set the DEBUG environment variable to a comma-separated list of namespace patterns:\nEnable All Debug Output\nEnable Specific Namespaces\nEnable All but Exclude Some\nDebug Output Features\nEach namespace has a unique color for easy visual identification\nTimestamps show when each message was logged\nSupports formatted output similar to console.log\nShows the difference in milliseconds from the previous log of the same namespace\nBest Practice: Use specific namespaces for different components of your application to make it easier to filter debug output based on what you're currently troubleshooting.\nFinding and Fixing Memory Leaks\nMemory leaks in Node.js applications can cause performance degradation and eventual crashes.\nDetecting and fixing memory leaks is a crucial debugging skill.\nCommon Causes of Memory Leaks in Node.js\nGlobal Variables: Objects stored in global scope that are never cleaned up\nClosures: Functions that maintain references to large objects or variables\nEvent Listeners: Listeners that are added but never removed\nCaches: In-memory caches that grow without bounds\nTimers: Timers (setTimeout/setInterval) that aren't cleared\nPromises: Unhandled promises or promise chains that never resolve\nDetecting Memory Leaks\nSeveral approaches can help you detect memory leaks:\nHeap snapshots provide a detailed view of memory allocation:\nStart your app with node --inspect app.js\nConnect with Chrome DevTools\nGo to the Memory tab\nTake heap snapshots at different points\nCompare snapshots to find objects that are growing in number or size\nclinic doctor: Identify memory issues in your application\nclinic heap: Visualize heap memory usage\nmemwatch-next: Library to detect memory leaks\nExample: Memory Leak in a Node.js Server\nHere's an example showing a common memory leak pattern in a Node.js server:\nFixing the Memory Leak\nHere's how to fix the memory leak in the example above:\nImportant: Always implement proper cleanup routines for resources like event listeners, timers, and cached objects.\nConsider using weak references or implementing time-based expiration for cached items.\nCPU Profiling and Performance\nCPU profiling helps identify performance bottlenecks in your Node.js application by showing which functions consume the most CPU time.\nCPU Profiling Methods\nNode.js includes a built-in V8 profiler that you can use to generate CPU profiles:\nUsing the Built-in V8 Profiler\nThe processed output shows where time is spent in your application, sorted by the percentage of total program execution time.\nStart your app with node --inspect app.js\nConnect with Chrome DevTools\nGo to the Performance tab\nClick Record\nPerform the actions you want to profile\nStop the recording\nAnalyze the flame chart\nclinic flame: Generate flame graphs for CPU profiling\n0x: Flamegraph generation tool\nv8-profiler: Programmatically collect V8 CPU profiles\nExample: Identifying CPU Bottlenecks\nThis example demonstrates how to identify inefficient code patterns:\nOptimizing CPU-Intensive Code\nCommon techniques for optimizing CPU-intensive Node.js code include:\nAvoid Recursion: Use iterative approaches for better performance\nMemoization: Cache results of expensive function calls\nOffload to Worker Threads: Move CPU-intensive work to separate threads\nUse Native Modules: For very performance-critical code, consider C++ addons\nAvoid Blocking the Event Loop: Break large tasks into smaller chunks\nDebugging Asynchronous Code\nAsynchronous code can be challenging to debug due to its non-linear execution flow and complex error propagation.\nCommon Challenges in Async Debugging\nLost Error Context: Errors thrown in callbacks may lose their stack trace\nCallback Hell: Nested callbacks make it hard to trace execution flow\nPromise Chains: Errors may be swallowed if not properly caught\nRace Conditions: Timing-dependent bugs that are hard to reproduce\nUnhandled Rejections: Promises that reject without catch handlers\nAsync Debugging Techniques\nAsync/await makes asynchronous code easier to debug by allowing you to use traditional try/catch blocks:\nWhen debugging in Chrome DevTools or VS Code, you can set breakpoints inside async functions and promise callbacks.\nThe debugger will pause execution at those points, allowing you to inspect the current state.\nModern debuggers can capture and display async stack traces, showing the complete chain of asynchronous operations:\nIn Chrome DevTools, enable \"Async\" in the call stack pane\nIn VS Code, this is enabled by default\nExample: Debugging Async Code\nHere's an example demonstrating async debugging techniques:\nDebugging Tips for Async Code:\nUse async/await for more linear, debuggable code\nAdd correlation IDs to track operations across async boundaries\nListen for unhandledRejection and uncaughtException events\nUse console.trace() to log stack traces at specific points\nSet NODE_DEBUG=* to see internal Node.js debug logs",
      "examples": [
        "node --inspect app.js",
        "node --inspect-brk app.js",
        "node --inspect=127.0.0.1:9222 app.js",
        "{\n\"version\": \"0.2.0\",\n\"configurations\": [\n{\n\"type\": \"node\",\n\"request\": \"launch\",\n\"name\": \"Launch Program\",\n\"program\": \"${workspaceFolder}/app.js\",\n\"skipFiles\": [\"<node_internals>/**\"]\n},\n{\n\"type\": \"node\",\n\"request\": \"attach\",\n\"name\": \"Attach to Process\",\n\"port\": 9229\n}\n]\n}",
        "npm install debug",
        "// Create namespaced debuggers for different parts of your application\nconst debug = require('debug');\n\nconst debugServer = debug('app:server');\nconst debugDatabase = debug('app:database');\nconst debugAuth = debug('app:auth');\n\n// Use the debuggers in your code\ndebugServer('Server starting on port %d', 8080);\ndebugDatabase('Connected to database: %s', 'mongodb://localhost');\ndebugAuth('User %s authenticated', 'john@example.com');\n\n// By default, these debug messages won't appear in the output",
        "DEBUG=app:* node app.js",
        "DEBUG=app:server,app:auth node app.js",
        "DEBUG=app:*,-app:database node app.js",
        "// Monitor memory usage\nfunction logMemoryUsage() {\nconst memoryUsage = process.memoryUsage();\nconsole.log('Memory usage:');\nconsole.log(`RSS: ${Math.round(memoryUsage.rss / 1024 / 1024)} MB`);\nconsole.log(`Heap Total: ${Math.round(memoryUsage.heapTotal / 1024 / 1024)} MB`);\nconsole.log(`Heap Used: ${Math.round(memoryUsage.heapUsed / 1024 / 1024)} MB`);\n}\n\n// Log memory usage every 30 seconds\nsetInterval(logMemoryUsage, 30000);",
        "const http = require('http');\n\n// This object will store data for each request (memory leak!)\nconst requestData = {};\n\nconst server = http.createServer((req, res) => {\n// Generate a unique request ID\nconst requestId = Date.now() + Math.random().toString(36).substring(2, 15);\n\n// Store data in the global object (THIS IS THE MEMORY LEAK)\nrequestData[requestId] = {\nurl: req.url,\nmethod: req.method,\nheaders: req.headers,\ntimestamp: Date.now(),\n// Create a large object to make the leak more obvious\npayload: Buffer.alloc(1024 * 1024) // Allocate 1MB per request\n};\n\n// Log memory usage after each request\nconst memoryUsage = process.memoryUsage();\nconsole.log(`Memory usage after request ${requestId}:`);\nconsole.log(`- Heap Used: ${Math.round(memoryUsage.heapUsed / 1024 / 1024)} MB`);\nconsole.log(`- Request count: ${Object.keys(requestData).length}`);\n\nres.end('Request processed');\n});\n\nserver.listen(8080);",
        "const http = require('http');\n\n// This object will store data for each request\nconst requestData = {};\n\nconst server = http.createServer((req, res) => {\nconst requestId = Date.now() + Math.random().toString(36).substring(2, 15);\n\n\n// Store data in the global object\nrequestData[requestId] = {\nurl: req.url,\nmethod: req.method,\ntimestamp: Date.now()\n};\n\n// Clean up after the response is sent (FIX FOR THE MEMORY LEAK)\nres.on('finish', () => {\ndelete requestData[requestId];\nconsole.log(`Cleaned up request ${requestId}`);\n});\n\nres.end('Request processed');\n});\n\nserver.listen(8080);",
        "# Generate CPU profile\nnode --prof app.js\n\n# Convert the generated log file to a readable format\nnode --prof-process isolate-0xnnnnnnnnnnnn-v8.log > processed.txt",
        "// Inefficient recursive Fibonacci function\nfunction inefficientFibonacci(n) {\nif (n <= 1) return n;\nreturn inefficientFibonacci(n - 1) + inefficientFibonacci(n - 2);\n}\n\n// More efficient iterative Fibonacci function\nfunction efficientFibonacci(n) {\nif (n <= 1) return n;\n\nlet a = 0, b = 1, temp;\nfor (let i = 2; i <= n; i++) {\ntemp = a + b;\na = b;\nb = temp;\n}\n\nreturn b;\n}\n\n// Compare the performance\nfunction comparePerformance(n) {\nconsole.log(`Calculating Fibonacci(${n})`);\n\n// Time the inefficient version\nconst inefficientStart = process.hrtime.bigint();\nconst inefficientResult = inefficientFibonacci(n);\nconst inefficientEnd = process.hrtime.bigint();\nconst inefficientTime = Number(inefficientEnd - inefficientStart) / 1_000_000; // in ms\n\n// Time the efficient version\nconst efficientStart = process.hrtime.bigint();\nconst efficientResult = efficientFibonacci(n);\nconst efficientEnd = process.hrtime.bigint();\nconst efficientTime = Number(efficientEnd - efficientStart) / 1_000_000; // in ms\n\nconsole.log(`Inefficient: ${inefficientResult} (${inefficientTime.toFixed(2)} ms)`);\nconsole.log(`Efficient: ${efficientResult} (${efficientTime.toFixed(2)} ms)`);\nconsole.log(`Speedup: ${Math.round(inefficientTime / efficientTime)}x`);\n}\n\n// Run the comparison\ncomparePerformance(30);",
        "// Hard to debug\nfetch('https://api.example.com/data')\n.then(response => response.json())\n.then(data => processData(data))\n.catch(error => console.error('Error:', error));\n\n// Easier to debug\nasync function fetchData() {\ntry {\nconst response = await fetch('https://api.example.com/data');\nconst data = await response.json();\nreturn processData(data);\n} catch (error) {\nconsole.error('Error:', error);\nthrow error; // Re-throw for upper layers to handle\n}\n}",
        "const util = require('util');\nconst fs = require('fs');\n\n// Convert callbacks to promises\nconst readFile = util.promisify(fs.readFile);\n\n// Function with a nested chain of async operations\nasync function processUserData(userId) {\ntry {\nconsole.log(`Processing data for user ${userId}...`);\n\n// Fetch user data\nconst userData = await fetchUserData(userId);\nconsole.log(`User data retrieved: ${userData.name}`);\n\n// Get user posts\nconst posts = await getUserPosts(userId);\nconsole.log(`Retrieved ${posts.length} posts for user`);\n\n// Process posts (this will cause an error for userId = 3)\nconst processedPosts = posts.map(post => {\nreturn {\nid: post.id,\ntitle: post.title.toUpperCase(),\ncontentLength: post.content.length, // Will fail if content is undefined\n};\n});\nreturn { user: userData, posts: processedPosts };\n} catch (error) {\nconsole.error('Error processing user data:', error);\nthrow error;\n}\n}\n\n// Simulated API call\nfunction fetchUserData(userId) {\nreturn new Promise((resolve, reject) => {\nsetTimeout(() => {\nif (userId <= 0) {\nreject(new Error('Invalid user ID'));\n} else {\nresolve({ id: userId, name: `User ${userId}` });\n}\n}, 500);\n});\n}\n\n// Simulated database query\nfunction getUserPosts(userId) {\nreturn new Promise((resolve) => {\nsetTimeout(() => {\n// Bug: post with undefined content for userId 3\nif (userId === 3) {\nresolve([\n{ id: 1, title: 'First Post', content: 'Content' },\n{ id: 2, title: 'Second Post', content: undefined }\n]);\n} else {\nresolve([\n{ id: 1, title: 'First Post', content: 'Content' },\n{ id: 2, title: 'Second Post', content: 'More content' }\n]);\n}\n}, 300);\n});\n}\n\n// Usage\nprocessUserData(3).catch(err => console.log('Caught at top level:', err.message));",
        "console.log()",
        "chrome://inspect",
        "devtools://devtools/bundled/js_app.html?experiments=true&v8only=true&ws=127.0.0.1:9229/...",
        ".vscode/launch.json",
        "--inspect",
        "debug",
        "console.log",
        "DEBUG",
        "clinic doctor",
        "clinic heap",
        "memwatch-next",
        "clinic flame",
        "0x",
        "v8-profiler",
        "unhandledRejection",
        "uncaughtException",
        "console.trace()",
        "NODE_DEBUG=*"
      ]
    },
    {
      "title": "Node.js Testing",
      "summary": "Why Test Your Node.js Applications?\nTesting is an essential part of software development that provides numerous benefits:\nBug Detection: Find and fix errors before they reach production\nCode Quality: Enforce code quality standards and prevent regressions\nDocumentation: Tests serve as executable documentation for your code\nConfidence: Build confidence in making changes and refactoring code\nCollaboration: Help team members understand how code should work\nCI/CD: Enable continuous integration and deployment pipelines\nTypes of Testing in Node.js\nUnit Testing\nUnit tests verify that individual components (functions, methods, classes) work as expected in isolation, typically using mocks for dependencies.\ncalculator.js\ntest/calculator.test.js\nIntegration Testing\nIntegration tests verify that multiple components work together correctly, such as testing database operations, API endpoints, or third-party service interactions.\nExample: Testing a Simple API EndpointGet your own Node.js Server\napp.js\ntest.js\nEnd-to-End Testing\nEnd-to-end tests verify the entire application flow from start to finish, simulating real user scenarios and interactions.\nThese tests typically use tools like Playwright, Cypress, or WebdriverIO to automate browser interactions.\nNote: End-to-end tests are more complex to set up and maintain but provide the most thorough validation of your application's functionality.\nTest-Driven Development (TDD)\nTest-Driven Development is a software development approach where you:\nWrite a test that defines a function or improvement\nRun the test, which should fail because the function doesn't exist yet\nWrite the simplest code to make the test pass\nRefactor the code to meet quality standards\nRepeat for each new feature or improvement\nTDD Example: Developing a Password Validator\npassword-validator.test.js\npassword-validator.js\nTesting Best Practices\nWrite Testable Code\nSingle Responsibility Principle: Each function should do one thing well\nPure Functions: Functions that produce the same output for the same input without side effects are easier to test\nDependency Injection: Pass dependencies to functions rather than creating them inside\nTest Organization\nGroup Related Tests: Keep tests for related functionality together\nDescriptive Test Names: Use clear names that explain what the test verifies\nSetup and Teardown: Properly set up test data and clean up after tests\nTest Coverage\nAim for high test coverage, but prioritize critical paths and edge cases:\nHappy Path: Test the expected normal flow\nEdge Cases: Test boundary conditions and unusual inputs\nError Handling: Verify that errors are handled correctly\nTest Runtime Considerations\nMocking\nReplace real dependencies with test doubles to isolate the code being tested:\nExample: Mocking a Database Connection\nuser-service.js\nuser-service.test.js\nTesting Asynchronous Code\nNode.js applications often involve asynchronous operations.\nMake sure your tests properly handle async code.\nExample: Testing Asynchronous Functions\nasync-service.js\nasync-service.test.js\nContinuous Integration (CI)\nAutomating your tests with continuous integration ensures they run regularly:\nConfigure your test suite to run on every code push or pull request\nPrevent merging code that fails tests\nTrack test coverage over time\nLearn more about setting up CI/CD pipelines in our Node.js CI/CD tutorial.\nSummary\nTesting is crucial for building reliable Node.js applications\nDifferent testing types (unit, integration, end-to-end) serve different purposes\nTest-driven development (TDD) can improve code quality and design\nWrite testable code by following good software design practices\nUse appropriate testing tools and frameworks for your project's needs\nAutomate testing with continuous integration",
      "examples": [
        "function add(a, b) {\nif (typeof a !== 'number' || typeof b !== 'number') {\nthrow new Error('Both arguments must be numbers');\n}\nreturn a + b;\n}\nfunction subtract(a, b) {\nif (typeof a !== 'number' || typeof b !== 'number') {\nthrow new Error('Both arguments must be numbers');\n}\nreturn a - b;\n}\nmodule.exports = { add, subtract };",
        "const assert = require('assert');\nconst { add, subtract } = require('./calculator');\n\n// Test the add function\nassert.strictEqual(add(1, 2), 3, 'Addition not working correctly');\nassert.strictEqual(add(-1, 1), 0, 'Addition with negative numbers not working');\n\n// Test the subtract function\nassert.strictEqual(subtract(5, 2), 3, 'Subtraction not working correctly');\nassert.strictEqual(subtract(2, 5), -3, 'Subtraction resulting in negative not working');\n\nconsole.log('All tests passed!');",
        "const express = require('express');\nconst app = express();\n\napp.get('/users', (req, res) => {\nres.json([\n{ id: 1, name: 'Alice' },\n{ id: 2, name: 'Bob' }\n]);\n});\n\nmodule.exports = app;",
        "const assert = require('assert');\nconst http = require('http');\nconst app = require('./app');\n\n// Start the server\nconst server = app.listen(8080);\n\n// Make a request to the API\nhttp.get('http://localhost:8080/users', (res) => {\nlet data = '';\n\nres.on('data', (chunk) => {\ndata += chunk;\n});\n\nres.on('end', () => {\nconst users = JSON.parse(data);\n\n// Verify the response\nassert.strictEqual(res.statusCode, 200, 'Status code should be 200');\nassert.strictEqual(users.length, 2, 'Should return two users');\nassert.strictEqual(users[0].name, 'Alice', 'First user should be Alice');\nassert.strictEqual(users[1].name, 'Bob', 'Second user should be Bob');\n\nconsole.log('API test passed!');\n\n// Close the server\nserver.close();\n});\n}).on('error', (err) => {\nconsole.error('Test failed:', err);\nserver.close();\n});",
        "// 1. Write the test first\nconst assert = require('assert');\nconst validatePassword = require('./password-validator');\n\n// Test for password length\nassert.strictEqual(validatePassword('abc12'), false, 'Should reject passwords shorter than 8 characters');\nassert.strictEqual(validatePassword('abcdef123'), true, 'Should accept passwords 8+ characters long');\n\n// Test for number requirement\nassert.strictEqual(validatePassword('abcdefgh'), false, 'Should reject passwords without numbers');\nassert.strictEqual(validatePassword('abcdefg1'), true, 'Should accept passwords with numbers');\n\nconsole.log('All password validation tests passed!');\n\n// 2. Run the test - it will fail because validatePassword doesn't exist yet",
        "// 3. Write the simplest code to pass the tests\nfunction validatePassword(password) {\n// Check length (at least 8 characters)\nif (password.length < 8) {\nreturn false;\n}\n\n// Check if it contains at least one number\nif (!/\\d/.test(password)) {\nreturn false;\n}\n\nreturn true;\n}\n\nmodule.exports = validatePassword;\n\n// 4. Run the tests again - they should pass now\n\n// 5. Refactor if needed, then repeat for new requirements",
        "class UserService {\nconstructor(database) {\nthis.database = database;\n}\nasync getUserById(id) {\nconst user = await this.database.findById(id);\nif (!user) {\nthrow new Error('User not found');\n}\nreturn user;\n}\n}\n\nmodule.exports = UserService;",
        "const assert = require('assert');\nconst UserService = require('./user-service');\n\n// Create a mock database\nconst mockDatabase = {\nfindById: async (id) => {\n// Mock implementation returns test data\nif (id === 1) {\nreturn { id: 1, name: 'Alice', email: 'alice@example.com' };\n}\nreturn null;\n}\n};\n\nasync function testUserService() {\nconst userService = new UserService(mockDatabase);\n\n// Test successful retrieval\nconst user = await userService.getUserById(1);\nassert.strictEqual(user.name, 'Alice', 'Should retrieve correct user name');\n\n// Test error handling\ntry {\nawait userService.getUserById(999);\nassert.fail('Should have thrown an error for non-existent user');\n} catch (error) {\nassert.strictEqual(error.message, 'User not found', 'Should throw user not found error');\n}\n\nconsole.log('UserService tests passed!');\n}\n\ntestUserService().catch(err => {\nconsole.error('Test failed:', err);\n});",
        "class AsyncService {\nasync fetchData() {\nreturn new Promise((resolve) => {\nsetTimeout(() => {\nresolve({ status: 'success', data: [1, 2, 3] });\n}, 100);\n});\n}\n\nasync processData() {\nconst result = await this.fetchData();\nreturn result.data.map(num => num * 2);\n}\n}\n\nmodule.exports = AsyncService;",
        "const assert = require('assert');\nconst AsyncService = require('./async-service');\n\nasync function testAsyncService() {\nconst service = new AsyncService();\n\n// Test fetchData\nconst fetchResult = await service.fetchData();\nassert.strictEqual(fetchResult.status, 'success', 'Should return success status');\nassert.deepStrictEqual(fetchResult.data, [1, 2, 3], 'Should return correct data array');\n\n// Test processData\nconst processResult = await service.processData();\nassert.deepStrictEqual(processResult, [2, 4, 6], 'Should double each value in the array');\n\nconsole.log('AsyncService tests passed!');\n}\n\ntestAsyncService().catch(err => {\nconsole.error('Test failed:', err);\n});"
      ]
    },
    {
      "title": "Node.js Testing Frameworks",
      "summary": "Introduction to Node.js Testing Frameworks\nTesting is a critical part of the development process that helps ensure your Node.js applications are reliable and maintainable.\nThis page introduces the most popular testing frameworks and tools in the Node.js ecosystem, helping you choose the right one for your project.\nNote: A good testing framework should be fast, provide helpful error messages, support different types of tests (unit, integration, e2e), and integrate well with your development workflow.\nPopular Testing Frameworks\nHere are the most popular and widely-used testing frameworks in the Node.js ecosystem:\nJest\nJest is a delightful JavaScript Testing Framework with a focus on simplicity, developed by Facebook.\nIt's a zero-configuration testing platform that works out of the box for most JavaScript projects.\nBest for: Full-featured testing with minimal setup, great for both frontend and backend testing\nInstallation\nExample Test\nKey Features\nZero Configuration: Works out of the box with minimal setup\nFast and Parallel: Runs tests in parallel for better performance\nBuilt-in Coverage: Comes with built-in code coverage reporting\nGreat Mocking: Powerful mocking capabilities\nSnapshot Testing: Great for UI testing with React and other frameworks\nWatch Mode: Automatically re-runs tests on file changes\nRunning Tests\nZero configuration required\nBuilt-in code coverage\nSnapshot testing\nGreat TypeScript support\nMocking support\nMocha\nMocha is a feature-rich JavaScript test framework running on Node.js and in the browser, making asynchronous testing simple and fun.\nBest for: Flexible testing with a wide range of plugins and integrations\nInstallation\nExample Test\nKey Features\nFlexible: Works with any assertion library (Chai, should.js, etc.)\nBrowser Support: Can run tests in the browser\nAsync Support: Excellent support for testing asynchronous code\nExtensible: Large ecosystem of plugins and extensions\nTest Coverage: Works well with tools like nyc for coverage\nRunning Tests\nVitest\nVitest is a blazing fast unit test framework powered by Vite, designed to be compatible with Jest but much faster.\nBest for: Projects already using Vite, or those needing faster test execution\nInstallation\nExample Test\nKey Features\nBlazing Fast: Uses Vite's native ESM for fast test execution\nJest Compatible: Uses the same API as Jest for easy migration\nFirst-class TypeScript Support: Works great with TypeScript out of the box\nESM First: Native support for ES Modules\nWatch Mode: Super fast watch mode with smart test filtering\nComparison Table",
      "examples": [
        "npm install --save-dev jest",
        "// utils/math.js\nfunction sum(a, b) {\nif (typeof a !== 'number' || typeof b !== 'number') {\nthrow new Error('Both arguments must be numbers');\n}\nreturn a + b;\n}\n\nfunction divide(a, b) {\nif (b === 0) {\nthrow new Error('Division by zero');\n}\nreturn a / b;\n}\n\nmodule.exports = { sum, divide };\n\n// __tests__/math.test.js\nconst { sum, divide } = require('../utils/math');\n\ndescribe('Math utilities', () => {\ndescribe('sum()', () => {\nit('should add two numbers correctly', () => {\nexpect(sum(1, 2)).toBe(3);\nexpect(sum(-1, 1)).toBe(0);\n});\n\nit('should throw error for non-number inputs', () => {\nexpect(() => sum('1', 2)).toThrow('Both arguments must be numbers');\n});\n});\n\ndescribe('divide()', () => {\nit('should divide two numbers correctly', () => {\nexpect(divide(10, 2)).toBe(5);\n});\n\nit('should throw error when dividing by zero', () => {\nexpect(() => divide(10, 0)).toThrow('Division by zero');\n});\n});\n});",
        "# Run all tests\nnpx jest\n\n# Run tests in watch mode\nnpx jest --watch\n\n# Run tests matching a specific pattern\nnpx jest -t \"math utilities\"\n\n# Generate coverage report\nnpx jest --coverage",
        "npm install --save-dev mocha chai",
        "// test/math.test.js\nconst { expect } = require('chai');\nconst { sum, divide } = require('../utils/math');\n\ndescribe('Math Utilities', () => {\ndescribe('sum()', () => {\nit('should return the sum of two numbers', () => {\nexpect(sum(1, 2)).to.equal(3);\nexpect(sum(-1, 1)).to.equal(0);\n});\n\nit('should throw error for non-number inputs', () => {\nexpect(() => sum('1', 2)).to.throw('Both arguments must be numbers');\n});\n});\n\ndescribe('divide()', () => {\nit('should divide two numbers correctly', () => {\nexpect(divide(10, 2)).to.equal(5);\n});\n\nit('should throw error when dividing by zero', () => {\nexpect(() => divide(10, 0)).to.throw('Division by zero');\n});\n});\n});",
        "# Add to package.json\n\"scripts\": {\n\"test\": \"mocha\"\n}\n\n# Run tests\nnpm test\n\n# Run with specific reporter\nnpx mocha --reporter nyan\n\n# Run with coverage\nnpx nyc mocha",
        "npm install -D vitest",
        "// math.test.js\nimport { describe, it, expect } from 'vitest';\nimport { sum, divide } from './math.js';\n\ndescribe('Math Utilities', () => {\nit('should add numbers', () => {\nexpect(sum(1, 2)).toBe(3);\n});\n\nit('should throw error for invalid inputs', () => {\nexpect(() => sum('1', 2)).toThrow('Both arguments must be numbers');\n});\n});"
      ]
    },
    {
      "title": "Node.js Test Runner",
      "summary": "Introduction to Node.js Test Runner\nThe built-in node:test module provides a lightweight, no-dependency framework for writing and running JavaScript tests directly in Node.js.\nIntroduced as a stable API in Node.js 20, it's designed to be a fast, modern alternative to external testing frameworks.\nNote: The Node.js Test Runner is stable as of Node.js v20.\nSome advanced features may be experimental in earlier versions.\nKey Features\nZero Configuration: Works out of the box with no setup\nDual Module Support: Native ESM and CommonJS compatibility\nParallel Execution: Tests run concurrently by default\nTest Isolation: Each test runs in its own context\nAsync Support: First-class async/await handling\nTest Hooks: Before/After hooks for setup/teardown\nMocking: Built-in test doubles and spies\nCode Coverage: Integration with Node.js coverage tools\nGetting Started\nWriting Your First Test\nLet's create and run a basic test using the Node.js Test Runner.\nYou'll need Node.js 16.17.0 or later installed.\nTest Structure and Organization\nFor larger projects, organize your tests in a structured way:\nTest Hooks\nUse hooks to set up and clean up test environments:\nRunning Tests\nRun tests using the --test flag:\nYou can also run all test files in a directory:\nThis will run all files with names matching these patterns:\n**/*.test.js\n**/*.spec.js\n**/test-*.js\n**/test/*.js\nREMOVE ADS\nWriting Tests\nAsynchronous Tests\nFor asynchronous code, use an async test function:\nSubtests (Nested Tests)\nYou can organize related tests using subtests:\nSetup and Teardown (Test Fixtures)\nFor tests that need setup and teardown, use the t.before() and t.after() hooks:\nSkipping and Todo Tests\nYou can mark tests to be skipped or as todos:\nAssertions\nThe Node.js Test Runner works with the built-in assert module. For stricter equality checks, use assert/strict.\nWorking with Mocks\nThe Node.js Test Runner doesn't include built-in mocking, but you can:\nUse dependency injection to provide test doubles\nCreate simple mock functions and objects\nIntegrate with third-party mocking libraries if needed\nTesting Real Examples\nTesting a Utility Function\nTesting an API Endpoint\nAdvanced Configuration\nCustom Reporters\nYou can specify different output formats for test results:\nAvailable reporters include:\nspec - Detailed hierarchical view\ndot - Minimal dots output\ntap - Test Anything Protocol format\njunit - JUnit XML format\nFiltering Tests\nYou can filter which tests to run using patterns:\nThis runs only tests with \"user\" in their name.\nWatch Mode\nFor development, you can run tests in watch mode to automatically rerun when files change:\nComparison with Other Testing Frameworks\nNote: The Node.js Test Runner is ideal for projects that want a lightweight, zero-dependency testing solution that's built into Node.js itself.\nFor more complex testing needs, Jest or Mocha might be better choices.",
      "examples": [
        "// Load the test module\nconst test = require('node:test');\n// Use strict assertion mode for better error messages\nconst assert = require('node:assert/strict');\n\n// Simple synchronous test\ntest('basic arithmetic', (t) => {\n// Assert that 1 + 1 equals 2\nassert.equal(1 + 1, 2, '1 + 1 should equal 2');\n\n// Deep equality check for objects/arrays\nassert.deepEqual(\n{ a: 1, b: { c: 2 } },\n{ a: 1, b: { c: 2 } }\n);\n});\n// Asynchronous test with async/await\ntest('async test', async (t) => {\nconst result = await Promise.resolve('async result');\nassert.strictEqual(result, 'async result');\n});",
        "# Run all test files in the test directory\nnode --test\n\n# Run a specific test file\nnode --test test/example.test.js\n\n# Run with coverage reporting\nNODE_V8_COVERAGE=coverage node --test",
        "project/\n├── src/\n│ ├── math.js\n│ └── utils.js\n└── test/\n├── unit/\n│ ├── math.test.js\n│ └── utils.test.js\n└── integration/\n└── api.test.js",
        "const { test, describe, before, after, beforeEach, afterEach } = require('node:test');\nconst assert = require('node:assert/strict');\n\ndescribe('Test Suite with Hooks', (t) => {\nlet testData = [];\n\n// Runs once before all tests\nbefore(() => {\nconsole.log('Running before all tests');\ntestData = [1, 2, 3];\n});\n\n// Runs before each test\nbeforeEach((t) => {\nconsole.log('Running before each test');\n});\n\ntest('array length', () => {\nassert.strictEqual(testData.length, 3);\n});\n\n// Runs after each test\nafterEach(() => {\nconsole.log('Running after each test');\n});\n\n// Runs once after all tests\nafter(() => {\nconsole.log('Running after all tests');\ntestData = [];\n});\n});",
        "// simple-test.js\nconst test = require('node:test');\nconst assert = require('node:assert/strict');\n\ntest('basic test', () => {\nassert.equal(1 + 1, 2);\n});",
        "node --test simple-test.js",
        "node --test",
        "import test from 'node:test';\nimport assert from 'node:assert/strict';\n\n// Using async/await\ntest('async test', async () => {\n// Simulate async operation\nconst result = await Promise.resolve(42);\nassert.equal(result, 42);\n});\n\n// Using callbacks with done (older style)\ntest('callback test', (t, done) => {\nsetTimeout(() => {\nassert.equal(1 + 1, 2);\ndone();\n}, 100);\n});",
        "import test from 'node:test';\nimport assert from 'node:assert/strict';\n\ntest('math operations', async (t) => {\nawait t.test('addition', () => {\nassert.equal(1 + 1, 2);\n});\n\nawait t.test('multiplication', () => {\nassert.equal(2 * 3, 6);\n});\n\nawait t.test('division', () => {\nassert.equal(10 / 2, 5);\n});\n});",
        "import test from 'node:test';\nimport assert from 'node:assert/strict';\n\ntest('using test fixtures', async (t) => {\n// Setup - runs before the test\nt.before(() => {\nconsole.log('Setting up test resources');\n// Example: Create test database, mock services, etc.\n});\n\n// Actual test\nawait t.test('my test with fixtures', () => {\nassert.equal(1 + 1, 2);\n});\n\n// Teardown - runs after the test\nt.after(() => {\nconsole.log('Cleaning up test resources');\n// Example: Delete test database, restore mocks, etc.\n});\n});",
        "import test from 'node:test';\n\n// Skip this test\ntest('skipped test', { skip: true }, () => {\n// This won't run\n});\n\n// Skip with a reason\ntest('skipped with reason', { skip: 'working on this later' }, () => {\n// This won't run\n});\n\n// Mark as TODO\ntest('todo test', { todo: true }, () => {\n// This won't run, but will be reported as TODO\n});\n\n// Conditional skip\ntest('conditional skip', { skip: process.platform === 'win32' }, () => {\n// This will be skipped on Windows\n});",
        "import assert from 'node:assert/strict';\n\n// Equality checks\nassert.equal(1, 1);                 // Loose equality (==)\nassert.strictEqual(1, 1);           // Strict equality (===)\nassert.deepEqual({a: 1}, {a: 1});   // Deep equality for objects\nassert.deepStrictEqual({a: 1}, {a: 1}); // Strict deep equality\n\n// Truthiness checks\nassert.ok(true);                    // Checks if value is truthy\nassert.ok(1);                       // Also truthy\n\n// Comparing values\nassert.notEqual(1, 2);              // Check inequality\nassert.notStrictEqual(1, '1');      // Check strict inequality\n\n// Throwing errors\nassert.throws(() => { throw new Error('Boom!'); }); // Check if function throws\nassert.doesNotThrow(() => { return 42; });         // Check if no error thrown\n\n// Async assertions\nawait assert.rejects(               // Check if Promise rejects\nasync () => { throw new Error('Async boom!'); }\n);",
        "import test from 'node:test';\nimport assert from 'node:assert/strict';\n\n// Function we want to test\nfunction processUser(user, logger) {\nif (!user.name) {\nlogger.error('User has no name');\nreturn false;\n}\nlogger.info(`Processing user: ${user.name}`);\nreturn true;\n}\n\n// Test with a mock logger\ntest('processUser logs correctly', () => {\n// Create a mock logger\nconst mockCalls = [];\nconst mockLogger = {\nerror: (msg) => mockCalls.push(['error', msg]),\ninfo: (msg) => mockCalls.push(['info', msg])\n};\n\n// Test with valid user\nconst validResult = processUser({name: 'Alice'}, mockLogger);\nassert.strictEqual(validResult, true);\nassert.deepStrictEqual(mockCalls[0], ['info', 'Processing user: Alice']);\n\n// Reset mock calls\nmockCalls.length = 0;\n\n// Test with invalid user\nconst invalidResult = processUser({}, mockLogger);\nassert.strictEqual(invalidResult, false);\nassert.deepStrictEqual(mockCalls[0], ['error', 'User has no name']);\n});",
        "// utils.js\nexports.formatPrice = function(price) {\nif (typeof price !== 'number' || isNaN(price)) {\nthrow new Error('Price must be a valid number');\n}\nreturn `$${price.toFixed(2)}`;\n};\n\n// utils.test.js\nconst test = require('node:test');\nconst assert = require('node:assert/strict');\nconst { formatPrice } = require('./utils');\n\n// Test cases\ntest('formatPrice formats numbers as currency strings', (t) => {\nassert.equal(formatPrice(10), '$10.00');\nassert.equal(formatPrice(10.5), '$10.50');\nassert.equal(formatPrice(0), '$0.00');\n});\n\n// Test for error\ntest('formatPrice throws error for invalid inputs', (t) => {\nassert.throws(() => formatPrice('not a number'), {\nmessage: 'Price must be a valid number'\n});\nassert.throws(() => formatPrice(NaN));\nassert.throws(() => formatPrice());\n});",
        "// userService.js\nconst express = require('express');\nconst app = express();\napp.use(express.json());\n\napp.get('/users/:id', (req, res) => {\nconst userId = parseInt(req.params.id);\n// Simplified - in real app would fetch from database\nif (userId === 1) {\nres.json({ id: 1, name: 'John Doe', email: 'john@example.com' });\n} else {\nres.status(404).json({ error: 'User not found' });\n}\n});\n\nmodule.exports = app;\n\n// userService.test.js\nconst test = require('node:test');\nconst assert = require('node:assert/strict');\nconst http = require('node:http');\nconst app = require('./userService');\n\ntest('GET /users/:id returns correct user', async (t) => {\n// Start the server\nconst server = http.createServer(app);\nawait new Promise(resolve => server.listen(0, resolve));\nconst port = server.address().port;\n\ntry {\n// Make request to our API\nconst response = await fetch(`http://localhost:${port}/users/1`);\nassert.equal(response.status, 200, 'Status should be 200');\n\nconst user = await response.json();\nassert.deepStrictEqual(user, {\nid: 1,\nname: 'John Doe',\nemail: 'john@example.com'\n});\n\n// Test not found case\nconst notFoundResponse = await fetch(`http://localhost:${port}/users/999`);\nassert.equal(notFoundResponse.status, 404, 'Status should be 404');\n} finally {\n// Clean up - close the server\nawait new Promise(resolve => server.close(resolve));\n}\n});",
        "node --test --test-reporter=spec",
        "node --test --test-name-pattern=\"user\"",
        "node --test --watch",
        "node:test",
        "--test",
        "**/*.test.js",
        "**/*.spec.js",
        "**/test-*.js",
        "**/test/*.js",
        "t.before()",
        "t.after()",
        "assert",
        "assert/strict",
        "spec",
        "dot",
        "tap",
        "junit"
      ]
    },
    {
      "title": "Node.js Environment Variables",
      "summary": "What are Environment Variables?\nEnvironment variables are dynamic named values that can affect how running processes behave on a computer.\nThey are part of the environment in which a process runs and are used to configure applications without changing the code.\nKey Benefits:\nStore configuration separate from code\nKeep sensitive information out of version control\nConfigure applications differently across environments\nChange application behavior without code changes\nCommon Use Cases\nDatabase connection strings\nAPI keys and secrets\nExternal service URLs\nFeature flags\nLogging verbosity\nPort numbers\nTimeouts and limits\nEnvironment-specific settings\nAccessing Environment Variables in Node.js\nNode.js provides the process.env object to access environment variables.\nThis object contains all the environment variables available to the current process.\nBasic Usage\nCommon Built-in Environment Variables\nNote: Always provide default values when accessing environment variables to prevent undefined values in your application.\nSetting Environment Variables\nThere are several ways to set environment variables for your Node.js application, depending on your development workflow and deployment environment.\n1. Command Line (Temporary)\nSet variables directly in the command line when starting your application:\n2. Using .env Files with dotenv\nFor development, use a .env file to store environment variables locally:\nImportant: Never commit .env files to version control. Add .env to your .gitignore file.\n3. Production Environment Variables\nIn production, set environment variables using your hosting provider's configuration:\nUsing dotenv for Local Development\nThe dotenv package lets you load environment variables from a .env file:\nLoad the variables in your app:\nInstall dotenv with:\nSummary\nEnvironment variables help you keep sensitive data and configuration out of your code.\nUse process.env and tools like dotenv to manage them easily in Node.js.",
      "examples": [
        "// Access a single environment variable\nconst nodeEnv = process.env.NODE_ENV || 'development';\nconsole.log(`Running in ${nodeEnv} mode`);\n\n// Access multiple variables with destructuring\nconst { PORT = 3000, HOST = 'localhost' } = process.env;\nconsole.log(`Server running at http://${HOST}:${PORT}`);\n\n// Check if running in production\nif (process.env.NODE_ENV === 'production') {\nconsole.log('Production optimizations enabled');\n// Enable production features\n}",
        "set PORT=3000\nset NODE_ENV=development\nset DB_HOST=localhost\nnode app.js",
        "$env:PORT=3000\n$env:NODE_ENV=\"development\"\nnode app.js",
        "PORT=3000 NODE_ENV=development DB_HOST=localhost node app.js",
        "export PORT=3000\nexport NODE_ENV=development\nnode app.js",
        "npm install dotenv",
        "# .env\nPORT=3000\nNODE_ENV=development\nDB_HOST=localhost\nDB_USER=admin\nDB_PASS=your_secure_password\nAPI_KEY=your_api_key_here",
        "// Load environment variables from .env file\nrequire('dotenv').config();\n\nconst port = process.env.PORT || 3000;\nconst dbConfig = {\nhost: process.env.DB_HOST,\nuser: process.env.DB_USER,\npassword: process.env.DB_PASS\n};\n\nconsole.log(`Server running on port ${port}`);",
        "heroku config:set NODE_ENV=production DATABASE_URL=your_database_url",
        "docker run -e NODE_ENV=production -e PORT=3000 your-image",
        "# /etc/systemd/system/your-app.service\n[Service]\nEnvironment=\"NODE_ENV=production\"\nEnvironment=\"PORT=3000\"",
        "# .env file\nAPI_KEY=abcdef12345",
        "require('dotenv').config();\nconsole.log(process.env.API_KEY);",
        "process.env",
        "NODE_ENV",
        "production",
        "PORT",
        "3000",
        "PATH",
        "/usr/local/bin:/usr/bin",
        "HOME",
        "/Users/username",
        "undefined",
        ".env",
        ".gitignore"
      ]
    },
    {
      "title": "Node.js: Development vs Production",
      "summary": "Differences between Development and Production\nThis page covers the key differences between development and production environments in Node.js applications and best practices for managing both effectively.\nKey Differences at a Glance\nVerbose logging\nDetailed error messages\nHot-reloading enabled\nUnminified code\nMock data/stubs\nMinimal logging\nGeneric error messages\nOptimized performance\nMinified and bundled code\nReal data/services\nThe NODE_ENV Environment Variable\nIn Node.js, the NODE_ENV environment variable is a convention used to determine the environment in which an application is running.\nIt's commonly set to either 'development' or 'production', though other values like 'test' or 'staging' are also used.\nNote: Many Node.js frameworks and libraries (like Express, React, Vue, etc.) use NODE_ENV to enable or disable certain features and optimizations.\nSetting NODE_ENV\nUsing NODE_ENV in Your Application\nNote: Setting NODE_ENV=production can improve application performance by up to 35%, as some packages apply optimizations based on this setting.\nConfiguration Management\nDifferent environments typically require different configurations for databases, APIs, logging, and other services.\nEnvironment-Specific Configuration\nConfiguration with dotenvGet your own Node.js Server\nConfiguration Files\nCommon approaches to configuration management include:\nEnvironment files: Using .env files with the dotenv package\nConfiguration objects: Creating environment-specific configuration objects\nConfiguration services: Using external services like AWS Parameter Store, Vault, or Consul\nSecurity Warning: Never commit sensitive information like API keys, database credentials, or secrets to version control. Always use environment variables or secure configuration services for sensitive data.\nError Handling\nError handling strategies should differ between development and production environments:\nDisplay detailed error messages and stack traces\nUse verbose logging to aid debugging\nCrash early on errors to identify issues quickly\nEnable source maps for better debugging\nProvide interactive debugging tools\nHide implementation details from error responses\nLog errors for internal use but return generic error messages\nImplement proper error recovery mechanisms\nUse structured logging for better analysis\nImplement circuit breakers for external services\nEnvironment-Specific Error Handling\nLogging Strategies\nLogging requirements differ significantly between development and production:\nVerbose logging with detailed information\nHuman-readable format with colors\nConsole output for immediate feedback\nDebug and trace level logging enabled\nNo log rotation needed\nStructured logging (JSON format)\nAppropriate log levels (warn/error)\nLog rotation and retention policies\nCentralized log aggregation\nPerformance monitoring integration\nEnvironment-Specific Logging with Winston\nFor more details on logging, see the Node.js Logging tutorial.\nPerformance Optimizations\nProduction environments should be optimized for performance and reliability:\nFast refresh and hot module replacement\nSource maps for debugging\nDetailed error overlays\nUnminified code\nDevelopment tools integration\nCode minification and tree-shaking\nAsset optimization and compression\nContent Delivery Network (CDN) usage\nBrowser caching headers\nPerformance monitoring\nPerformance Considerations\nOptimized code bundling and minification\nCaching strategies\nCluster mode to utilize multiple CPU cores\nMemory and CPU optimizations\nContent compression\nRunning in Cluster Mode in Production\nSecurity Considerations\nSecurity practices should be more stringent in production environments:\nProduction Security Measures\nHelmet: Set security-related HTTP headers\nRate limiting: Protect against brute force and DoS attacks\nCSRF protection: Prevent cross-site request forgery\nInput validation: Sanitize all user inputs\nHTTPS: Encrypt all communications\nDependency scanning: Check for vulnerabilities in dependencies\nSecurity Middleware for Production\nBuild Process\nFor applications using TypeScript, Babel, or other build tools, the build process differs between environments:\nDevelopment Build\nSource maps for debugging\nIncremental compilation\nHot module replacement\nLess aggressive optimizations\nProduction Build\nMinification and tree shaking\nBundling and code splitting\nAhead-of-time compilation\nNo source maps (or external source maps)\nwebpack.config.js for Different Environments\nPackage.json Scripts\nDeployment Considerations\nDevelopment\nLocal development server\nDocker containers for dependencies\nIntegrated development environment (IDE) tools\nProduction\nProcess managers (PM2, Forever)\nContainer orchestration (Kubernetes, Docker Swarm)\nLoad balancing\nHealth checks and monitoring\nAutomated deployment pipelines\nRollback strategies\nPM2 Ecosystem File for Production\nFor more details on deployment, see the Node.js Deployment tutorial.\nTesting Environments\nDifferent environments have different testing requirements:\nDevelopment Testing\nUnit tests during development\nIntegration tests\nFast feedback loops\nMocking external dependencies\nStaging/QA Environment\nEnd-to-end tests\nPerformance testing\nConfiguration similar to production\nMock data or sanitized production data\nProduction Testing\nSmoke tests\nCanary deployments\nReal user monitoring\nLoad testing (during off-peak hours)\nBest Practices\n1. Use Environment Variables\nStore environment-specific configuration in environment variables, not in code.\n2. Automate Environment Setup\nUse tools like Docker, Vagrant, or cloud templates to create consistent environments.\n3. Implement Feature Flags\nUse feature flags to enable features selectively in different environments.\n4. Implement Continuous Integration/Continuous Deployment (CI/CD)\nAutomate testing and deployment across environments to ensure consistency.\n5. Monitor and Alert\nSet up comprehensive monitoring and alerting in production environments.\n6. Document Environment Differences\nMaintain clear documentation of environment-specific configurations and requirements.\nSummary\nUse the NODE_ENV environment variable to distinguish between development and production environments\nImplement environment-specific configuration management\nHandle errors differently in development (verbose) and production (secure)\nAdjust logging strategies based on the environment\nApply performance optimizations and security measures in production\nUse different build and deployment processes for each environment\nFollow best practices for environment management, including automation and documentation",
      "examples": [
        "# Windows Command Prompt\nset NODE_ENV=production\nnode app.js\n\n# Windows PowerShell\n$env:NODE_ENV=\"production\"\nnode app.js\n\n# Linux/macOS\nexport NODE_ENV=production\nnode app.js",
        "{\n\"scripts\": {\n\"start\": \"NODE_ENV=production node app.js\",\n\"dev\": \"NODE_ENV=development nodemon app.js\",\n\"test\": \"NODE_ENV=test jest\"\n}\n}",
        "npm install --save-dev cross-env",
        "{\n\"scripts\": {\n\"start\": \"cross-env NODE_ENV=production node app.js\"\n}\n}",
        "// Simple environment check\nconst isProduction = process.env.NODE_ENV === 'production';\nconst isDevelopment = !isProduction;\n\n// Environment-specific configuration\nconst config = {\nport: process.env.PORT || 3000,\ndb: {\nhost: isProduction ? 'prod-db.example.com' : 'localhost',\nname: isProduction ? 'myapp_prod' : 'myapp_dev'\n},\nlogging: {\nlevel: isProduction ? 'warn' : 'debug',\nprettyPrint: !isProduction\n}\n};\n\n// Express.js example\nconst express = require('express');\nconst app = express();",
        "// Install dotenv: npm install dotenv\nrequire('dotenv').config(); // Loads .env file contents into process.env\n\n// config.js\nmodule.exports = {\ndevelopment: {\nport: 8080,\ndatabase: 'mongodb://localhost:27017/myapp_dev',\nlogLevel: 'debug',\napiKeys: {\nthirdPartyService: process.env.DEV_API_KEY\n}\n},\ntest: {\nport: 3001,\ndatabase: 'mongodb://localhost:27017/myapp_test',\nlogLevel: 'info',\napiKeys: {\nthirdPartyService: process.env.TEST_API_KEY\n}\n},\nproduction: {\nport: process.env.PORT || 8080,\ndatabase: process.env.DATABASE_URL,\nlogLevel: 'error',\napiKeys: {\nthirdPartyService: process.env.PROD_API_KEY\n}\n}\n};\n\nconst env = process.env.NODE_ENV || 'development';\nmodule.exports.current = module.exports[env];",
        "const express = require('express');\nconst app = express();\n\napp.get('/api/data', (req, res) => {\ntry {\n// Some operation that might fail\nthrow new Error('Something went wrong');\n} catch (error) {\n// Log the error internally (always do this)\nconsole.error('Error occurred:', error);\n\n// Provide different responses based on environment\nif (process.env.NODE_ENV === 'production') {\n// In production: generic error message\nreturn res.status(500).json({\nerror: 'An unexpected error occurred'\n});\n} else {\n// In development: detailed error information\nreturn res.status(500).json({\nerror: error.message,\nstack: error.stack,\ndetails: 'This detailed error is only shown in development'\n});\n}\n}\n});\n\napp.listen(8080);",
        "const winston = require('winston');\n\n// Define different logging configurations per environment\nconst logger = winston.createLogger({\nlevel: process.env.NODE_ENV === 'production' ? 'info' : 'debug',\nformat: process.env.NODE_ENV === 'production'\n? winston.format.json()\n: winston.format.combine(\nwinston.format.colorize(),\nwinston.format.simple()\n),\ndefaultMeta: { service: 'user-service' },\ntransports: [\n// Always log errors to a file\nnew winston.transports.File({\nfilename: 'error.log',\nlevel: 'error'\n}),\n\n// In production, save all logs to a file\n...(process.env.NODE_ENV === 'production'\n? [new winston.transports.File({ filename: 'combined.log' })]\n: []),\n\n// In development, log to the console\n...(process.env.NODE_ENV !== 'production'\n? [new winston.transports.Console()]\n: [])\n],\n});\n\nlogger.info('Application started');\nlogger.debug('This debug message appears only in development');",
        "const cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;\n\nif (process.env.NODE_ENV === 'production' && cluster.isMaster) {\nconsole.log(`Master ${process.pid} is running`);\n\n// Fork workers\nfor (let i = 0; i < numCPUs; i++) {\ncluster.fork();\n}\n\ncluster.on('exit', (worker, code, signal) => {\nconsole.log(`Worker ${worker.process.pid} died`);\n// Replace the dead worker\ncluster.fork();\n});\n} else {\n// Workers can share a TCP connection\nhttp.createServer((req, res) => {\nres.writeHead(200);\nres.end('Hello World\\n');\n}).listen(8000);\n\nconsole.log(`Worker ${process.pid} started`);\n}",
        "const express = require('express');\nconst helmet = require('helmet');\nconst rateLimit = require('express-rate-limit');\nconst app = express();\n\n// Apply security middleware in production\nif (process.env.NODE_ENV === 'production') {\n// Set security headers\napp.use(helmet());\n\n// Enable rate limiting\nconst limiter = rateLimit({\nwindowMs: 15 * 60 * 1000, // 15 minutes\nmax: 100, // limit each IP to 100 requests per windowMs\nmessage: 'Too many requests from this IP, please try again later'\n});\napp.use('/api/', limiter);\n\n// Force HTTPS\napp.use((req, res, next) => {\nif (req.header('x-forwarded-proto') !== 'https') {\nres.redirect(`https://${req.header('host')}${req.url}`);\n} else {\nnext();\n}\n});\n}\n\napp.get('/', (req, res) => {\nres.send('Hello World');\n});\n\napp.listen(8080);",
        "const path = require('path');\nconst TerserPlugin = require('terser-webpack-plugin');\n\nmodule.exports = (env, argv) => {\nconst isProduction = argv.mode === 'production';\n\nreturn {\nentry: './src/index.js',\noutput: {\npath: path.resolve(__dirname, 'dist'),\nfilename: isProduction\n? 'bundle.[contenthash].js'\n: 'bundle.js'\n},\nmode: isProduction ? 'production' : 'development',\n// Generate source maps in development but not production\ndevtool: isProduction ? false : 'eval-source-map',\noptimization: {\nminimize: isProduction,\nminimizer: isProduction ? [\nnew TerserPlugin({\nterserOptions: {\ncompress: true,\nmangle: true\n}\n})\n] : [],\n},\n// Add development server configuration for non-production\n...(isProduction ? {} : {\ndevServer: {\ncontentBase: './dist',\nhot: true\n}\n})\n};\n};",
        "{\n\"scripts\": {\n\"start\": \"node dist/server.js\",\n\"dev\": \"nodemon src/server.ts\",\n\"build\": \"tsc\",\n\"build:prod\": \"tsc && webpack --mode=production\",\n\"lint\": \"eslint src/**/*.ts\",\n\"test\": \"jest\"\n}\n}",
        "// ecosystem.config.js\nmodule.exports = {\napps: [{\nname: \"my-app\",\nscript: \"./dist/server.js\",\ninstances: \"max\",\nexec_mode: \"cluster\",\nenv_development: {\nNODE_ENV: \"development\",\nPORT: 8080\n},\nenv_production: {\nNODE_ENV: \"production\",\nPORT: 8080\n}\n}]\n};",
        "const featureFlags = {\ndevelopment: {\nnewUserInterface: true,\nexperimentalFeature: true,\nbetaAnalytics: true\n},\nproduction: {\nnewUserInterface: false,\nexperimentalFeature: false,\nbetaAnalytics: true\n}\n};\n\nconst env = process.env.NODE_ENV || 'development';\nconst features = featureFlags[env];\n\nif (features.newUserInterface) {\n// Enable the new UI\n}",
        "NODE_ENV",
        "NODE_ENV=production",
        ".env",
        "dotenv"
      ]
    },
    {
      "title": "Node.js CI/CD",
      "summary": "Understanding CI/CD\nContinuous Integration (CI) and Continuous Deployment (CD) are essential practices that automates the software development lifecycle, enabling teams to deliver code changes more frequently and reliably.\nThe key components are:\nAutomatically building and testing code changes whenever a developer pushes code to version control.\nBenefits: Early bug detection, reduced integration issues, faster feedback cycles.\nEnsuring that code is always in a deployable state, with automated testing and release processes.\nBenefits: Lower risk releases, faster time to market, reduced deployment pain.\nAutomatically deploying every change that passes automated tests to production.\nBenefits: Faster delivery of features, reduced manual work, more frequent releases.\nNote: While these practices are often mentioned together, they represent different levels of automation maturity.\nMany teams start with CI, then progress to continuous delivery, and eventually implement continuous deployment.\nCI/CD Tools for Node.js\nChoosing the right CI/CD tool depends on your project requirements, team size, and infrastructure. Here are the most popular options for Node.js applications:\nTip: For most Node.js projects, GitHub Actions or GitLab CI/CD provide the best balance of features and ease of use, especially if you're already using GitHub or GitLab for version control.\nGitHub Actions for Node.js\nGitHub Actions provides a powerful, flexible platform for automating your development workflows directly within GitHub.\nIt's particularly well-suited for Node.js projects due to its native integration with GitHub repositories and extensive marketplace of pre-built actions.\nKey Features\nNative GitHub Integration: Direct access to your repository's code, issues, and pull requests\nMatrix Builds: Test across multiple Node.js versions and operating systems\nCaching: Speed up builds by caching dependencies\nContainer Support: Run jobs in containers for consistent environments\nArtifacts: Store build outputs and test results\nDeployment Environments: Manage deployments with protection rules and secrets\nBasic CI Workflow\nThis workflow runs tests on every push to the repository and on pull requests targeting the main branch. It includes caching for faster builds and handles both Linux and Windows environments.\nAdvanced CI/CD Pipeline\nThis example demonstrates a complete CI/CD pipeline that includes:\nCode checkout\nDependency installation with caching\nLinting and type checking (for TypeScript projects)\nRunning tests with coverage\nBuilding the application\nDeploying to a staging environment on push to main\nManual approval for production deployment\nNote: This is a more complex workflow that includes multiple jobs and deployment environments. You can customize it based on your project's specific needs.\nREMOVE ADS\nCI/CD Best Practices for Node.js\nTip: A well-configured CI/CD pipeline can reduce deployment errors by up to 90% and improve team productivity by 50% or more.\nKeep Builds Fast: Aim for builds under 10 minutes\nUse Parallel Jobs: Run independent tests in parallel\nImplement Caching: Cache node_modules and build artifacts\nUse Specific Node.js Versions: Pin versions in .nvmrc or package.json\nClean Up: Remove temporary files after builds\nScan Dependencies: Use npm audit or Snyk\nStore Secrets Securely: Use secret management\nRun Linters: Enforce code quality standards\nTest in Isolation: Use containers or VMs\nMonitor Performance: Track build times and success rates\nEnvironment Strategy\nImplement a clear environment strategy with proper promotion gates:\nDevelopment: Latest changes, frequent deployments\nTesting: Automated tests, code quality checks\nStaging: Mirrors production, final verification\nProduction: Stable releases, monitored closely\nNode.js Pipeline Stages\nDocker in CI/CD\nDocker is a powerful tool for creating consistent environments across development, testing, and production.\nWhen combined with CI/CD, it ensures your application runs the same way everywhere.\nConsistency: Identical environments from development to production\nIsolation: Dependencies are contained within the container\nReproducibility: Same image runs the same way everywhere\nScalability: Easy to scale horizontally with container orchestration\nMulti-stage Builds: Create optimized production images\nUse specific version tags (e.g., node:20-alpine)\nLeverage multi-stage builds to reduce image size\nRun as non-root user for security\nUse .dockerignore to exclude unnecessary files\nScan images for vulnerabilities\nDocker Compose for Local Development\nMonitoring and Optimization\nTip: Continuously monitor and optimize your CI/CD pipeline to maintain efficiency and catch issues early.\nKey Metrics to Monitor\nBuild Time: Track duration of each pipeline stage\nSuccess Rate: Percentage of successful builds\nTest Coverage: Code coverage metrics\nDeployment Frequency: How often you deploy\nLead Time: Time from commit to production\nMTTR: Mean Time To Recover from failures\nOptimization Techniques\nParallelize independent jobs\nCache dependencies and build artifacts\nUse smaller base images\nImplement incremental builds\nRun only affected tests\nUse self-hosted runners for large projects\nConclusion\nImplementing a robust CI/CD pipeline is essential for modern Node.js development. By following the practices outlined in this guide, you can achieve:\nFaster and more reliable releases\nHigher code quality through automated testing\nBetter collaboration among team members\nReduced risk of deployment failures\nFaster feedback cycles for developers\nRemember: CI/CD is not a one-time setup but an ongoing process of improvement. Regularly review and update your pipeline to incorporate new tools and practices.",
      "examples": [
        "name: Node.js CI\non: [push]\njobs:\nbuild:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v2\n- name: Use Node.js\nuses: actions/setup-node@v2\nwith:\nnode-version: '20'\n- run: npm install\n- run: npm test",
        "name: Node.js CI/CD\n\non:\npush:\nbranches: [ main ]\npull_request:\nbranches: [ main ]\n\njobs:\ntest:\nruns-on: ubuntu-latest\nstrategy:\nmatrix:\nnode-version: [16.x, 18.x, 20.x]\n\nsteps:\n- uses: actions/checkout@v3\n\n- name: Use Node.js ${{ matrix.node-version }}\nuses: actions/setup-node@v3\nwith:\nnode-version: ${{ matrix.node-version }}\ncache: 'npm'\n\n- name: Install dependencies\nrun: npm ci\n\n- name: Run linting\nrun: npm run lint\n\n- name: Run tests\nrun: npm test\n\ndeploy-staging:\nneeds: test\nif: github.ref == 'refs/heads/main' && github.event_name == 'push'\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n- name: Deploy to staging\nuses: some-deployment-action@v1\nwith:\nenvironment: staging",
        "Development → Testing → Staging → Production",
        "# Build stage\nFROM node:20-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build\n\n# Production stage\nFROM node:20-alpine\nWORKDIR /app\n\n# Install production dependencies only\nCOPY package*.json ./\nRUN npm ci --only=production\n\n# Copy built assets from builder\nCOPY --from=builder /app/dist ./dist\n\n# Run as non-root user\nRUN chown -R node:node /app\nUSER node\nEXPOSE 3000\nCMD [\"node\", \"dist/server.js\"]",
        "version: '3.8'\nservices:\napp:\nbuild: .\nports:\n- '3000:3000'\nvolumes:\n- .:/app\n- /app/node_modules\nenvironment:\n- NODE_ENV=development\ncommand: npm run dev\n\n# Add other services like databases, caches, etc.\n# redis:\n# image: redis:alpine\n# ports:\n# - '6379:6379'",
        "actions/checkout@v3",
        "npm ci",
        "npm run lint",
        "npm test",
        "npm run build",
        "npm audit",
        "node:20-alpine",
        ".dockerignore"
      ]
    },
    {
      "title": "Node.js Security",
      "summary": "Why Security Matters in Node.js\nSecurity is critically important for Node.js applications for several reasons:\nJavaScript Ecosystem Size: The npm registry contains over 1.5 million packages, making it difficult to verify the security of all dependencies\nServer-Side Execution: Unlike client-side JavaScript, Node.js has access to file systems, networks, and other sensitive resources\nDefault Permissiveness: Node.js has few security restrictions by default, making secure coding practices essential\nEvent-Driven Architecture: Asynchronous operations can create complex execution flows that may hide security flaws\nWhen Node.js applications are compromised, attackers might:\nAccess sensitive user data\nManipulate application behavior\nUse your server for cryptocurrency mining\nLaunch attacks against other systems\nDamage your organization's reputation\nCommon Security Vulnerabilities in Node.js\nEssential Security Best Practices\n1. Input Validation and Sanitization\nNever trust user input. Always validate and sanitize all data that comes from outside your application.\n2. Protection Against Injection Attacks\nPrevent SQL, NoSQL, command injection, and similar attacks by using parameterized queries and avoiding direct concatenation of user input.\n3. Cross-Site Scripting (XSS) Prevention\nProtect against XSS by properly encoding output and using Content Security Policy (CSP).\n4. Keep Dependencies Up-to-Date\nRegularly check for and update vulnerable dependencies using npm audit and other security tools.\n5. Secure Authentication Practices\nImplement authentication securely with proper password hashing, account lockouts, and multi-factor authentication.\n6. Use Security Headers\nImplement HTTP security headers to protect against various attacks. Use packages like Helmet.js to simplify this.\n7. Use HTTPS\nAlways use HTTPS in production environments to encrypt data in transit.\n8. Protect Sensitive Data\nStore sensitive data securely using environment variables and dedicated secret management solutions.\nImportant: Never commit sensitive data to version control. Use .gitignore to exclude .env files.\nDependency Vulnerability Management\nNode.js applications typically have numerous dependencies, each potentially introducing security vulnerabilities.\nProper dependency management is essential for maintaining application security.\nUsing npm audit\nThe npm audit command scans your dependency tree and identifies packages with known vulnerabilities:\nThe output of npm audit includes:\nVulnerability severity (low, moderate, high, critical)\nAffected package and vulnerable version range\nDescription of the vulnerability\nPath to the vulnerable dependency\nRecommended actions to fix the issue\nVulnerability Prevention Strategies\nLock Dependencies: Use package-lock.json or yarn.lock to lock dependency versions\nSet Minimum Versions: Use version ranges with minimum bounds (e.g., \"express\": \"^4.17.1\")\nAutomated Scanning: Integrate security scanning into your CI/CD pipeline\nConsider Alternatives: For problematic packages, research alternatives with better security records\nThird-Party Security Tools\nAdvanced Security Practices\nRate Limiting\nProtect your API from abuse or brute force attacks by implementing rate limiting:\nCSRF Protection\nPrevent Cross-Site Request Forgery attacks by implementing CSRF tokens:\nContent Security Policy (CSP)\nCSP helps prevent XSS and data injection attacks by controlling which resources can be loaded by the browser:\nSecurity Logging and Monitoring\nImplement comprehensive logging to detect and respond to security incidents:\nSecure Development Lifecycle (SDLC)\nBuilding secure Node.js applications requires integrating security throughout the entire development process.\nFollow these SDLC best practices:\n1. Requirements & Design Phase\nDefine security requirements and compliance needs\nPerform threat modeling to identify potential risks\nDesign with security principles in mind (least privilege, defense in depth)\nChoose secure frameworks and libraries\n2. Development Phase\nUse secure coding standards and linters\nImplement input validation and output encoding\nUse parameterized queries for database access\nFollow the principle of least privilege\n3. Testing Phase\nConduct static application security testing (SAST)\nPerform dynamic application security testing (DAST)\nRun dependency vulnerability scans\nConduct penetration testing\n4. Deployment & Maintenance\nUse secure configuration management\nImplement continuous security monitoring\nEstablish an incident response plan\nSchedule regular security audits\nExample: Secure Development Checklist\nTip: Integrate security checks into your CI/CD pipeline to automatically catch security issues before they reach production.\nSummary\nSecurity is a continuous process, not a one-time implementation.\nFollow these best practices to protect your Node.js applications:\nValidate and sanitize all input\nProtect against common attacks (XSS, CSRF, injections)\nKeep dependencies updated and regularly audit them\nImplement secure authentication and session management\nUse HTTPS and proper security headers\nStore sensitive data securely\nImplement rate limiting and monitoring\nFollow established security guidelines (OWASP)\nRemember that security is only as strong as the weakest link in your application.\nRegular security reviews and penetration testing are recommended for all production applications.",
      "examples": [
        "const express = require('express');\nconst { body, validationResult } = require('express-validator');\nconst app = express();\n\napp.use(express.json());\n\n// Define validation rules\nconst userValidationRules = [\nbody('email').isEmail().normalizeEmail(),\nbody('password').isLength({ min: 8 }),\nbody('age').isInt({ min: 18 }).toInt(),\nbody('name').trim().escape().notEmpty()\n];\n\n// Apply validation\napp.post('/register', userValidationRules, (req, res) => {\n// Check for validation errors\nconst errors = validationResult(req);\n\nif (!errors.isEmpty()) {\nreturn res.status(400).json({ errors: errors.array() });\n}\n\n// Process validated data\nconst { email, password, age, name } = req.body;\n// ... safe to use validated data\n\nres.status(201).json({ message: 'User registered successfully' });\n});",
        "// VULNERABLE - DO NOT USE\nfunction searchUsersUnsafe(name) {\n// Direct string concatenation - VULNERABLE TO INJECTION\nreturn db.query(`SELECT * FROM users WHERE name LIKE '%${name}%'`);\n}\n\n// SAFE - USE THIS APPROACH\nfunction searchUsersSafe(name) {\n// Parameterized query - PROTECTED AGAINST INJECTION\nreturn db.query('SELECT * FROM users WHERE name LIKE ?', [`%${name}%`]);\n}",
        "const express = require('express');\nconst app = express();\n\n// VULNERABLE - Direct insertion of user input into HTML\napp.get('/unsafe', (req, res) => {\nconst userInput = req.query.message || '';\nres.send(`<div>Your message: ${userInput}</div>`);\n});\n\n// SAFE - Encoding user input\napp.get('/safe', (req, res) => {\nconst userInput = req.query.message || '';\n\n// Encode HTML special characters\nconst safeInput = userInput\n.replace(/&/g, '&')\n.replace(/</g, '<')\n.replace(/>/g, '>')\n.replace(/\"/g, '\"')\n.replace(/'/g, ''');\n\nres.send(`<div>Your message: ${safeInput}</div>`);\n});",
        "# Check for vulnerable dependencies\nnpm audit\n\n# Automatically fix vulnerabilities when possible\nnpm audit fix\n\n# Check for vulnerable dependencies in production only\nnpm audit --production\n\n# Generate a detailed report\nnpm audit --json > audit-report.json",
        "const crypto = require('crypto');\n\n// Generate a random salt\nfunction generateSalt() {\nreturn crypto.randomBytes(16).toString('hex');\n}\n\n// Hash password with PBKDF2\nfunction hashPassword(password, salt) {\nreturn crypto.pbkdf2Sync(password, salt, 10000, 64, 'sha512').toString('hex');\n}\n\n// Register a new user with secure password storage\nfunction registerUser(username, password) {\n// Generate unique salt for this user\nconst salt = generateSalt();\n\n// Hash the password with the salt\nconst hashedPassword = hashPassword(password, salt);\n\n// Store username, hashedPassword, and salt in database\n// NEVER store plaintext passwords\nreturn { username, hashedPassword, salt };\n}\n\n// Verify a login attempt\nfunction verifyUser(username, password, storedHash, storedSalt) {\n// Hash the provided password with the stored salt\nconst hashedAttempt = hashPassword(password, storedSalt);\n\n// Time-constant comparison to prevent timing attacks\nreturn crypto.timingSafeEqual(\nBuffer.from(hashedAttempt, 'hex'),\nBuffer.from(storedHash, 'hex')\n);\n}",
        "const express = require('express');\nconst helmet = require('helmet');\nconst app = express();\n\n// Apply all security headers with default settings\napp.use(helmet());\n\n// Or customize specific headers\napp.use(helmet({\ncontentSecurityPolicy: {\ndirectives: {\ndefaultSrc: [\"'self'\"],\nscriptSrc: [\"'self'\", \"'unsafe-inline'\", 'trusted-cdn.com']\n}\n},\n// Prevent clickjacking\nframeguard: { action: 'deny' },\n// Strict-Transport-Security\nhsts: { maxAge: 15552000, includeSubDomains: true }\n}));",
        "const https = require('https');\nconst fs = require('fs');\nconst express = require('express');\n\nconst app = express();\n\n// Your Express routes here\napp.get('/', (req, res) => {\nres.send('Secure HTTPS Server');\n});\n\n// HTTPS configuration\nconst options = {\nkey: fs.readFileSync('path/to/private-key.pem'),\ncert: fs.readFileSync('path/to/certificate.pem'),\n// Modern, secure TLS options\nminVersion: 'TLSv1.2',\nciphers: 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256'\n};\n\n// Create HTTPS server\nhttps.createServer(options, app).listen(443, () => {\nconsole.log('HTTPS server running on port 443');\n});",
        "// Load environment variables from .env file in development\nif (process.env.NODE_ENV !== 'production') {\nrequire('dotenv').config();\n}\n\n// Access environment variables\nconst dbConnection = {\nhost: process.env.DB_HOST,\nusername: process.env.DB_USER,\npassword: process.env.DB_PASSWORD,\ndatabase: process.env.DB_NAME\n};\n\n// Never log sensitive information\nconsole.log('Connected to database:', dbConnection.host);\n// DON'T DO THIS: console.log('Database connection:', dbConnection);",
        "# Run a basic audit\nnpm audit\n\n# Fix vulnerabilities automatically (when possible)\nnpm audit fix\n\n# Fix vulnerabilities that might require major version updates\nnpm audit fix --force",
        "const express = require('express');\nconst rateLimit = require('express-rate-limit');\nconst app = express();\n\n// Basic rate limiter: max 100 requests per 15 minutes per IP\nconst limiter = rateLimit({\nwindowMs: 15 * 60 * 1000, // 15 minutes\nmax: 100, // limit each IP to 100 requests per windowMs\nstandardHeaders: true, // Return rate limit info in the `RateLimit-*` headers\nmessage: 'Too many requests from this IP, please try again after 15 minutes'\n});\n\n// Apply rate limiting to all requests\napp.use(limiter);\n\n// Or apply to specific routes\nconst loginLimiter = rateLimit({\nwindowMs: 60 * 60 * 1000, // 1 hour\nmax: 5, // 5 failed attempts per hour\nmessage: 'Too many login attempts, please try again after an hour'\n});\n\napp.post('/login', loginLimiter, (req, res) => {\n// Login logic here\n});",
        "const express = require('express');\nconst cookieParser = require('cookie-parser');\nconst csrf = require('csurf');\nconst app = express();\n\n// Setup middleware\napp.use(express.urlencoded({ extended: false }));\napp.use(cookieParser());\n\n// Initialize CSRF protection\nconst csrfProtection = csrf({ cookie: true });\n\n// Form display route with CSRF token\napp.get('/form', csrfProtection, (req, res) => {\nres.send(`\n<form action=\"/process\" method=\"POST\">\n<input type=\"hidden\" name=\"_csrf\" value=\"${req.csrfToken()}\">\n<input type=\"text\" name=\"data\">\n<button type=\"submit\">Submit</button>\n</form>\n`);\n});\n\n// Form submission route with CSRF validation\napp.post('/process', csrfProtection, (req, res) => {\n// If we get here, CSRF token was valid\nres.send('Data processed successfully');\n});\n\n// CSRF errors will be caught here\napp.use((err, req, res, next) => {\nif (err.code === 'EBADCSRFTOKEN') {\n// Handle CSRF token errors\nres.status(403).send('CSRF token validation failed');\n} else {\nnext(err);\n}\n});",
        "const express = require('express');\nconst helmet = require('helmet');\nconst app = express();\n\n// Detailed CSP configuration\napp.use(helmet.contentSecurityPolicy({\ndirectives: {\ndefaultSrc: [\"'self'\"], // Only allow resources from same origin\nscriptSrc: [\"'self'\", \"'unsafe-inline'\", 'trusted-cdn.com'],\nstyleSrc: [\"'self'\", \"'unsafe-inline'\", 'trusted-cdn.com'],\nimgSrc: [\"'self'\", 'data:', 'trusted-cdn.com', 'another-trusted-cdn.com'],\nconnectSrc: [\"'self'\", 'api.example.com'], // API endpoints\nfontSrc: [\"'self'\", 'fonts.googleapis.com', 'fonts.gstatic.com'],\nobjectSrc: [\"'none'\"], // Prevent object, embed, and applet elements\nmediaSrc: [\"'self'\"], // Audio and video sources\nframeSrc: [\"'self'\"], // Frames\nsandbox: ['allow-forms', 'allow-scripts', 'allow-same-origin'],\nreportUri: '/csp-violation-report'\n}\n}));\n\n// Route to handle CSP violation reports\napp.post('/csp-violation-report', (req, res) => {\n// Log CSP violations\nconsole.log('CSP Violation:', req.body);\nres.status(204).end();\n});",
        "const winston = require('winston');\nconst express = require('express');\nconst app = express();\n\n// Create a security logger\nconst securityLogger = winston.createLogger({\nlevel: 'info',\nformat: winston.format.combine(\nwinston.format.timestamp(),\nwinston.format.json()\n),\ndefaultMeta: { service: 'security-service' },\ntransports: [\nnew winston.transports.File({ filename: 'security-events.log' })\n]\n});\n\n// Log authentication attempts\napp.post('/login', (req, res) => {\nconst { username } = req.body;\nconst ip = req.ip;\n\n// Authentication logic here...\nconst success = true; // Replace with actual auth logic\n\n// Log the authentication attempt\nsecurityLogger.info({\nevent: 'authentication_attempt',\nusername,\nip,\nsuccess,\nuserAgent: req.get('User-Agent')\n});\n\n// Continue with login response...\n});\n\n// Log access to sensitive resources\napp.get('/admin', (req, res) => {\nsecurityLogger.info({\nevent: 'admin_access',\nuser: req.user?.id,\nip: req.ip,\nmethod: req.method,\npath: req.path\n});\n\n// Continue with admin page response...\n});",
        "// package.json example with security-related scripts\n{\n\"name\": \"secure-node-app\",\n\"version\": \"1.0.0\",\n\"scripts\": {\n\"start\": \"node app.js\",\n\"test\": \"jest\",\n\"lint\": \"eslint . --ext .js\",\n\"audit\": \"npm audit --production --audit-level=high\",\n\"check-vuln\": \"npx snyk test\",\n\"security-check\": \"npm-run-all --parallel lint audit check-vuln\",\n\"precommit\": \"npm run security-check\"\n},\n\"dependencies\": {\n// Production dependencies\n},\n\"devDependencies\": {\n\"eslint\": \"^8.0.0\",\n\"eslint-plugin-security\": \"^1.5.0\",\n\"jest\": \"^29.0.0\",\n\"npm-run-all\": \"^4.1.5\",\n\"snyk\": \"^1.1000.0\"\n},\n\"husky\": {\n\"hooks\": {\n\"pre-commit\": \"npm run security-check\"\n}\n}\n}",
        "npm audit",
        ".gitignore",
        ".env",
        "\"express\": \"^4.17.1\""
      ]
    },
    {
      "title": "Node.js Deployment",
      "summary": "Introduction to Deployment\nDeployment strategies focus on how to deploy and manage your Node.js applications in production.\nKey aspects of modern Node.js deployment include:\nContainerization: Package your app and dependencies into a container that runs consistently across environments.\nOrchestration: Automate container management with tools like Kubernetes or Docker Swarm.\nCI/CD: Automate testing and deployment pipelines.\nCloud-native: Use cloud services and serverless functions.\nIaC: Define infrastructure as code for reproducible deployments.\nObservability: Monitor your application's performance and health.\nContainerization with Docker\nContainers package your application and its dependencies into a standardized unit, ensuring consistent behavior across different environments.\nDocker is the most popular containerization platform for Node.js applications.\nBenefits of Docker for Node.js\nEnvironment consistency across development, testing, and production\nIsolation from the host system and other applications\nEfficient resource utilization compared to virtual machines\nSimplified scaling and orchestration\nEasy integration with CI/CD pipelines\nDockerizing a Node.js Application\nExample: Basic Dockerfile for Node.jsGet your own Node.js Server\nThis basic Dockerfile:\nSpecifies a base image (Alpine Linux with Node.js 20)\nSets the working directory\nCopies and installs dependencies\nCopies application code\nExposes a port\nDefines the startup command\nBuilding and Running Your Docker Container\nMulti-Stage Builds for Optimized Images\nMulti-stage builds create smaller, more secure images by separating the build environment from the runtime environment:\nExample: Multi-Stage Dockerfile\nWhy Multi-Stage Builds?\nSmaller images (no build tools or dev dependencies)\nBetter security (fewer potential vulnerabilities)\nFaster container startup and deployment\nDocker Compose for Multi-Container Applications\nFor applications with multiple services (e.g., Node.js app + database), use Docker Compose to define and run multi-container applications:\nExample: docker-compose.yml\nKubernetes for Orchestration\nFor production-grade orchestration of containerized applications, Kubernetes provides powerful features:\nAutomatic scaling of containers based on load\nSelf-healing (restarting failed containers)\nService discovery and load balancing\nRolling updates and rollbacks\nStorage orchestration\nBasic Kubernetes Deployment for Node.js\nExample: deployment.yaml\nKubernetes Service for Node.js\nExample: service.yaml\nTo learn more about Kubernetes, check out the Kubernetes documentation.\nCloud Platform Deployment\nCloud platforms provide ready-to-use infrastructure and services for deploying Node.js applications with minimal configuration. These platforms abstract away much of the complexity of infrastructure management.\nPopular Cloud Platforms for Node.js\nExample: Deploying to Heroku\nHeroku offers one of the simplest deployment workflows for Node.js applications:\nPrerequisites\nCreate a Procfile in your project root to tell Heroku how to run your app:\nProcfile\nDeploy your application:\nEnvironment-Specific Configuration\nFor any cloud deployment, ensure your app is configured for production:\nExample: app.js with environment configuration\nServerless Deployment\nServerless computing allows you to build and run applications without thinking about servers.\nIt provides automatic scaling, built-in high availability, and a pay-for-use billing model.\nBenefits of Serverless for Node.js\nNo server management required\nAutomatic scaling based on demand\nOnly pay for what you use (no idle costs)\nBuilt-in high availability and fault tolerance\nFocus on code, not infrastructure\nPopular Serverless Platforms\nAWS Lambda\nAzure Functions\nGoogle Cloud Functions\nVercel Functions\nNetlify Functions\nExample: AWS Lambda Function\nSimple AWS Lambda Function (handler.js)\nExample: Serverless Framework Configuration\nUsing the Serverless Framework makes it easier to deploy and manage serverless applications:\nserverless.yml\nServerless Considerations:\nCold starts: Initial request latency when function hasn't been used recently\nTimeout limits: Functions have maximum execution duration (e.g., 15 min on AWS Lambda)\nStatelessness: Each invocation is isolated; use external services for state\nLimited local resources: Memory and disk space constraints\nCI/CD for Node.js Applications\nContinuous Integration and Continuous Deployment (CI/CD) pipelines automate the testing and deployment process, ensuring reliable and consistent deployments.\nKey Components of a CI/CD Pipeline\nSource control integration (e.g., GitHub, GitLab)\nAutomated testing (unit, integration, end-to-end)\nStatic code analysis and linting\nSecurity scanning\nBuild and packaging\nDeployment to staging and production\nPost-deployment verification\nExample: GitHub Actions Workflow\n.github/workflows/deploy.yml\nInfrastructure as Code (IaC)\nIaC tools allow you to define your infrastructure in code files, providing version-controlled, reproducible deployments.\nPopular IaC Tools\nTerraform: Cloud-agnostic IaC tool\nAWS CloudFormation: AWS-specific IaC service\nAzure Resource Manager: Azure-specific IaC service\nPulumi: IaC using familiar programming languages\nExample: Terraform Configuration\nmain.tf\nBest Practices for Modern Deployment\nZero-downtime deployments: Use blue-green or canary deployment strategies\nContainer security: Scan images, use minimal base images, and non-root users\nEnvironment variables: Use environment variables for all configuration\nSecret management: Use dedicated secret management solutions (HashiCorp Vault, AWS Secrets Manager, etc.)\nHealth checks: Implement comprehensive health and readiness checks\nMonitoring and logging: Set up thorough monitoring and centralized logging\nAuto-scaling: Configure appropriate scaling policies based on load metrics\nDatabase migrations: Automate and version database schema changes\nFeature flags: Use feature flags to control feature rollout\nBackup and disaster recovery: Implement robust backup and recovery procedures\nEdge Computing with Node.js\nEdge computing brings computation and data storage closer to the location where it's needed, improving response times and reducing bandwidth usage.\nNode.js is well-suited for edge computing due to its lightweight nature and non-blocking I/O model.\nEdge Computing Platforms for Node.js\nExample: Cloudflare Worker with Node.js\nworker.js\nExample: Vercel Edge Middleware\nmiddleware.js\nEdge Computing Use Cases\nReduced latency for global users\nFaster content delivery\nImproved Time to First Byte (TTFB)\nEfficient caching strategies\nPersonalized content delivery\nA/B testing and feature flags\nBot protection and security\nAuthentication and authorization\nEdge vs Serverless: While both run on-demand, edge functions are optimized for ultra-low latency and run at the network edge, closer to users, while traditional serverless functions might run in centralized regions.\nSummary\nModern Node.js deployment encompasses containerization, orchestration, cloud platforms, serverless computing, and DevOps practices.\nBy adopting these approaches, you can achieve:\nFaster and more reliable deployments\nBetter resource utilization and cost efficiency\nImproved scalability and resilience\nGreater development velocity through automation\nChoose the deployment strategy that best fits your application requirements, team expertise, and business needs.",
      "examples": [
        "FROM node:20-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm install\n\nCOPY . .\n\nEXPOSE 8080\n\nCMD [\"node\", \"app.js\"]",
        "# Build the image\ndocker build -t my-nodejs-app .\n\n# Run the container\ndocker run -p 8080:8080 my-nodejs-app",
        "# Build stage\nFROM node:20-alpine AS build\n\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\n\n# Production stage\nFROM node:20-alpine\n\nWORKDIR /app\nCOPY --from=build /app/node_modules ./node_modules\nCOPY . .\n\n# Set NODE_ENV\nENV NODE_ENV=production\n\n# Non-root user for security\nUSER node\n\nEXPOSE 8080\nCMD [\"node\", \"app.js\"]",
        "version: '3.8'\n\nservices:\n# Node.js application\napp:\nbuild: .\nports:\n- \"8080:8080\"\nenvironment:\n- NODE_ENV=production\n- DB_HOST=db\n- DB_USER=user\n- DB_PASSWORD=password\n- DB_NAME=myapp\ndepends_on:\n- db\nrestart: unless-stopped\n\n# Database\ndb:\nimage: postgres:14\nvolumes:\n- postgres_data:/var/lib/postgresql/data\nenvironment:\n- POSTGRES_USER=user\n- POSTGRES_PASSWORD=password\n- POSTGRES_DB=myapp\nrestart: unless-stopped\n\nvolumes:\npostgres_data:",
        "# Start all services\ndocker-compose up\n\n# Start in detached mode\ndocker-compose up -d\n\n# Stop all services\ndocker-compose down",
        "apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: nodejs-app\nspec:\nreplicas: 3\nselector:\nmatchLabels:\napp: nodejs-app\ntemplate:\nmetadata:\nlabels:\napp: nodejs-app\nspec:\ncontainers:\n- name: nodejs-app\nimage: your-registry/nodejs-app:latest\nports:\n- containerPort: 8080\nenv:\n- name: NODE_ENV\nvalue: \"production\"\nresources:\nlimits:\ncpu: \"500m\"\nmemory: \"512Mi\"\nrequests:\ncpu: \"200m\"\nmemory: \"256Mi\"\nlivenessProbe:\nhttpGet:\npath: /health\nport: 8080\ninitialDelaySeconds: 30\nperiodSeconds: 10",
        "apiVersion: v1\nkind: Service\nmetadata:\nname: nodejs-service\nspec:\nselector:\napp: nodejs-app\nports:\n- port: 80\ntargetPort: 8080\ntype: LoadBalancer",
        "# Install Heroku CLI\nnpm install -g heroku\n\n# Login to Heroku\nheroku login",
        "web: node app.js",
        "# Initialize Git if needed\ngit init\ngit add .\ngit commit -m \"Initial commit\"\n\n# Create a Heroku app\nheroku create my-nodejs-app\n\n# Deploy to Heroku\ngit push heroku main\n\n# Scale your app (optional)\nheroku ps:scale web=1\n\n# Open your app in browser\nheroku open",
        "const express = require('express');\nconst app = express();\n\n// Environment variables with fallbacks\nconst PORT = process.env.PORT || 8080;\nconst NODE_ENV = process.env.NODE_ENV || 'development';\nconst DB_URI = process.env.DB_URI || 'mongodb://localhost:27017/myapp';\n\napp.get('/', (req, res) => {\nres.send(`Hello from ${NODE_ENV} environment!`);\n});\n\napp.listen(PORT, () => {\nconsole.log(`Server running on port ${PORT} in ${NODE_ENV} mode`);\n});",
        "module.exports.hello = async (event) => {\nconst name = event.queryStringParameters?.name || 'World';\n\nreturn {\nstatusCode: 200,\nheaders: {\n'Content-Type': 'application/json'\n},\nbody: JSON.stringify(\n{\nmessage: `Hello, ${name}!`,\ntimestamp: new Date().toISOString(),\n},\n),\n};\n};",
        "service: my-nodejs-api\n\nprovider:\nname: aws\nruntime: nodejs16.x\nregion: us-east-1\nenvironment:\nNODE_ENV: production\n\nfunctions:\nhello:\nhandler: handler.hello\nevents:\n- http:\npath: hello\nmethod: get\ncors: true\n\ngetUser:\nhandler: users.getUser\nevents:\n- http:\npath: users/{id}\nmethod: get\ncors: true",
        "name: Deploy Node.js Application\n\non:\npush:\nbranches: [ main ]\n\njobs:\ntest:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n- name: Use Node.js\nuses: actions/setup-node@v3\nwith:\nnode-version: '16.x'\n- name: Install dependencies\nrun: npm ci\n- name: Run tests\nrun: npm test\n- name: Run linting\nrun: npm run lint\n\ndeploy:\nneeds: test\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n- name: Deploy to production\nuses: some-action/deploy-to-cloud@v1\nwith:\napi-key: ${{ secrets.DEPLOY_API_KEY }}\napp-name: my-nodejs-app\nenvironment: production",
        "provider \"aws\" {\nregion = \"us-east-1\"\n}\n\nresource \"aws_instance\" \"nodejs_server\" {\nami = \"ami-0c55b159cbfafe1f0\"\ninstance_type = \"t3.micro\"\n\ntags = {\nName = \"nodejs-app-server\"\n}\n\nuser_data = <<-EOF\n#!/bin/bash\ncurl -sL https://deb.nodesource.com/setup_16.x | sudo -E bash -\nsudo apt-get install -y nodejs\nmkdir -p /app\ncd /app\necho 'console.log(\"Hello from Node.js\");' > app.js\nnode app.js\nEOF\n}\n\nresource \"aws_security_group\" \"app_sg\" {\nname = \"app-security-group\"\ndescription = \"Allow web traffic\"\n\ningress {\nfrom_port = 80\nto_port = 80\nprotocol = \"tcp\"\ncidr_blocks = [\"0.0.0.0/0\"]\n}\n\ningress {\nfrom_port = 22\nto_port = 22\nprotocol = \"tcp\"\ncidr_blocks = [\"0.0.0.0/0\"]\n}\n\negress {\nfrom_port = 0\nto_port = 0\nprotocol = \"-1\"\ncidr_blocks = [\"0.0.0.0/0\"]\n}\n}",
        "// Handle incoming requests addEventListener('fetch', event => {\nevent.respondWith(handleRequest(event.request));\n});\n\nasync function handleRequest(request) {\n// Get visitor's country from Cloudflare headers\nconst country = request.cf.country || 'unknown';\n\n// Custom response based on location\nconst html = `\n<!DOCTYPE html>\n<html>\n<head>\n<title>Edge Computing Demo</title>\n</head>\n<body>\n<h1>Hello from ${country}!</h1>\n<p>Served from ${new Date().toISOString()}</p>\n</body>\n</html>`;\n\nreturn new Response(html, {\nheaders: { 'content-type': 'text/html;charset=UTF-8' },\n});\n}",
        "import { NextResponse } from 'next/server';\n\n// Runs on every request to your site\nexport function middleware(request) {\n// Get the user's country from the request\nconst country = request.geo.country || 'US';\n\n// Rewrite to a country-specific page if needed\nif (country === 'GB') {\nreturn NextResponse.rewrite('/uk-home');\n}\n\n// Add a custom header\nconst response = NextResponse.next();\nresponse.headers.set('x-edge-runtime', 'true');\n\nreturn response;\n}\n\n// Only run on specific paths\nexport const config = {\nmatcher: ['/', '/about/:path*'],\n};"
      ]
    },
    {
      "title": "Node.js Logging",
      "summary": "Why Logging Matters\nEffective logging is essential for several reasons:\nDebugging: Understand what's happening inside your application\nTroubleshooting: Diagnose issues in production environments\nMonitoring: Track application health and performance\nAuditing: Record important events for compliance and security\nAnalytics: Gather data about application usage and behavior\nBasic Logging with Console\nNode.js provides built-in console methods for basic logging:\nConsole Limitations\nWhile the console is convenient, it has significant limitations for production use:\nNo built-in log levels for filtering\nNo log rotation or file management\nNo structured output formats like JSON\nLimited integration with monitoring systems\nNote: Console methods are synchronous when outputting to terminals/files and can impact performance if used frequently in production.\nStructured Logging\nStructured logging formats log messages as data objects (typically JSON) rather than plain text, making them easier to parse, search, and analyze.\nBenefits of Structured Logging\nConsistent format for machine readability\nBetter searchability and filtering\nSimplified integration with log aggregation tools\nEnhanced context with metadata\nExample of a Structured Log Entry (JSON)Get your own Node.js Server\nPopular Node.js Logging Libraries\nWinston\nWinston is a versatile logging library with support for multiple transports (outputs):\nBasic Winston Setup\nCustom Winston Formats\nPino\nPino is designed to be a low-overhead logger with optimal performance:\nBasic Pino Setup\nPino with Express\nBunyan\nBunyan is a structured logging library with a CLI for viewing logs:\nBasic Bunyan Setup\nApplication Logging Best Practices\nLog Levels\nUse appropriate log levels to categorize the importance and urgency of log messages:\nerror: Runtime errors, exceptions, and failures that require attention\nwarn: Warning conditions that don't stop the application but indicate potential issues\ninfo: Informational messages about application events and milestones\ndebug: Detailed diagnostic information useful during development\ntrace: Very detailed debugging information (method entry/exit, variable values)\nWhat to Log\nDO LOG:\nApplication startup/shutdown events\nAuthentication and authorization events\nAPI requests and responses\nDatabase operations and performance metrics\nErrors and exceptions with context\nResource usage and performance metrics\nConfiguration changes\nDON'T LOG:\nPasswords, tokens, API keys, or other credentials\nPersonally identifiable information (PII) without proper safeguards\nCredit card numbers, social security numbers, or other sensitive data\nSession IDs or cookies\nEncryption keys\nContextual Logging\nInclude relevant context with each log entry to make troubleshooting easier:\nLog Management and Analysis\nLog Rotation\nPrevent log files from growing too large by implementing log rotation:\nWinston with rotating file transport\nCentralized Logging\nFor applications running across multiple servers or containers, centralize your logs for easier analysis:\nWinston with Elasticsearch transport\nPopular Log Management Systems\nELK Stack (Elasticsearch, Logstash, Kibana): Comprehensive logging stack\nGraylog: Centralized log management with a focus on security\nFluentd/Fluent Bit: Log collection and forwarding\nLoki: Lightweight log aggregation system\nCommercial options: Datadog, New Relic, Splunk, LogDNA, Loggly\nLogging in Production\nPerformance Considerations\nUse asynchronous logging to avoid blocking the event loop\nBuffer logs for better performance\nAdjust log levels to reduce volume in production\nSample high-volume logs rather than logging every occurrence\nSecurity Considerations\nSanitize sensitive data before logging\nProtect log files with appropriate permissions\nUse encryption when transmitting logs\nImplement retention policies for log data\nVerify compliance with relevant regulations (GDPR, HIPAA, etc.)\nData Sanitization Example\nDebugging with Logs\nDebug Module\nThe debug module provides a lightweight way to add conditional debug logging:\nCorrelation IDs\nTrack requests across multiple services using correlation IDs:\nSummary\nEffective logging is crucial for debugging, monitoring, and troubleshooting Node.js applications\nUse structured logging with JSON format for better searchability and analysis\nChoose appropriate logging libraries like Winston, Pino, or Bunyan based on your needs\nApply best practices: use proper log levels, include context, and protect sensitive data\nImplement log rotation and centralized logging for production environments\nConsider performance and security implications when designing your logging strategy\nUse correlation IDs to track requests through distributed systems",
      "examples": [
        "// Basic logging\nconsole.log('Info message');\nconsole.error('Error message');\nconsole.warn('Warning message');\nconsole.debug('Debug message');\n\n// Log objects\nconst user = { id: 1, name: 'John', roles: ['admin', 'user'] };\nconsole.log('User object:', user);\n\n// Table output for arrays or objects\nconsole.table([\n{ name: 'John', age: 30, role: 'admin' },\n{ name: 'Jane', age: 25, role: 'user' },\n{ name: 'Bob', age: 40, role: 'guest' }\n]);\n\n// Timing operations\nconsole.time('operation');\n// Perform some operations...\nfor (let i = 0; i < 1000000; i++) {\n// Do something\n}\nconsole.timeEnd('operation'); // Outputs: operation: 4.269ms\n\n// Grouping related logs\nconsole.group('User Processing');\nconsole.log('Loading user data...');\nconsole.log('Validating user...');\nconsole.log('Updating user profile...');\nconsole.groupEnd();\n\n// Stack trace\nconsole.trace('Trace message');",
        "{\n\"timestamp\": \"2023-11-28T15:24:39.123Z\",\n\"level\": \"error\",\n\"message\": \"Failed to connect to database\",\n\"service\": \"user-service\",\n\"context\": {\n\"requestId\": \"req-123-456\",\n\"userId\": \"user-789\",\n\"databaseHost\": \"db.example.com\"\n},\n\"error\": {\n\"name\": \"ConnectionError\",\n\"message\": \"Connection refused\",\n\"stack\": \"...\"\n}\n}",
        "const winston = require('winston');\n\n// Create a logger\nconst logger = winston.createLogger({\nlevel: 'info',\nformat: winston.format.json(),\ndefaultMeta: { service: 'user-service' },\ntransports: [\n// Write logs to a file\nnew winston.transports.File({ filename: 'error.log', level: 'error' }),\nnew winston.transports.File({ filename: 'combined.log' }),\n],\n});\n\n// If not in production, also log to the console\nif (process.env.NODE_ENV !== 'production') {\nlogger.add(new winston.transports.Console({\nformat: winston.format.simple(),\n}));\n}\n\n// Usage\nlogger.log('info', 'Hello distributed log files!');\nlogger.info('Hello again distributed logs');\nlogger.error('Something went wrong', { additionalInfo: 'error details' });",
        "const winston = require('winston');\nconst { format } = winston;\nconst { combine, timestamp, label, printf } = format;\n\n// Custom format\nconst myFormat = printf(({ level, message, label, timestamp }) => {\nreturn `${timestamp} [${label}] ${level}: ${message}`;\n});\n\nconst logger = winston.createLogger({\nformat: combine(\nlabel({ label: 'API Service' }),\ntimestamp(),\nmyFormat\n),\ntransports: [\nnew winston.transports.Console(),\nnew winston.transports.File({ filename: 'combined.log' })\n]\n});\n\nlogger.info('Application started');",
        "const pino = require('pino');\n\n// Create a logger\nconst logger = pino({\nlevel: 'info',\ntimestamp: pino.stdTimeFunctions.isoTime,\nbase: { pid: process.pid, hostname: require('os').hostname() }\n});\n\n// Usage\nlogger.info('Application started');\nlogger.info({ user: 'john' }, 'User logged in');\nlogger.error({ err: new Error('Connection failed') }, 'Database connection error');",
        "const express = require('express');\nconst pino = require('pino');\nconst pinoHttp = require('pino-http');\n\nconst app = express();\nconst logger = pino();\nconst httpLogger = pinoHttp({ logger });\n\n// Add request logging middleware\napp.use(httpLogger);\n\napp.get('/', (req, res) => {\nreq.log.info('User accessed homepage');\nres.send('Hello World!');\n});\n\napp.get('/error', (req, res) => {\nreq.log.error('Something went wrong');\nres.status(500).send('Error!');\n});\n\napp.listen(8080, () => {\nlogger.info('Server started on port 8080');\n});",
        "const bunyan = require('bunyan');\n\n// Create a logger\nconst logger = bunyan.createLogger({\nname: 'myapp',\nstreams: [\n{\nlevel: 'info',\nstream: process.stdout\n},\n{\nlevel: 'error',\npath: 'error.log'\n}\n],\nserializers: bunyan.stdSerializers\n});\n\n// Usage\nlogger.info('Application started');\nlogger.info({ user: 'john' }, 'User logged in');\nlogger.error({ err: new Error('Connection failed') }, 'Database connection error');",
        "const winston = require('winston');\n\n// Create a base logger\nconst logger = winston.createLogger({\nlevel: 'info',\nformat: winston.format.json(),\ntransports: [new winston.transports.Console()]\n});\n\n// Create a child logger with request context\nfunction createRequestLogger(req) {\nreturn logger.child({\nrequestId: req.id,\nmethod: req.method,\nurl: req.url,\nip: req.ip,\nuserId: req.user ? req.user.id : 'anonymous'\n});\n}\n\n// Usage in Express middleware\napp.use((req, res, next) => {\nreq.id = generateRequestId();\nreq.logger = createRequestLogger(req);\nreq.logger.info('Request received');\n\nconst start = Date.now();\n\nres.on('finish', () => {\nconst duration = Date.now() - start;\nreq.logger.info({\nstatusCode: res.statusCode,\nduration: duration\n}, 'Request completed');\n});\n\nnext();\n});\n\nfunction generateRequestId() {\nreturn Date.now().toString(36) + Math.random().toString(36).substring(2);\n}",
        "const winston = require('winston');\nrequire('winston-daily-rotate-file');\n\nconst transport = new winston.transports.DailyRotateFile({\nfilename: 'application-%DATE%.log',\ndatePattern: 'YYYY-MM-DD',\nzippedArchive: true,\nmaxSize: '20m',\nmaxFiles: '14d'\n});\n\nconst logger = winston.createLogger({\nlevel: 'info',\nformat: winston.format.json(),\ntransports: [\ntransport,\nnew winston.transports.Console()// Optional console transport\n]\n});\n\nlogger.info('Hello rotated logs');",
        "const winston = require('winston');\nrequire('winston-elasticsearch');\n\nconst esTransportOpts = {\nlevel: 'info',\nclientOpts: {\nnode: 'http://localhost:9200'\n},\nindexPrefix: 'app-logs'\n};\n\nconst logger = winston.createLogger({\ntransports: [\nnew winston.transports.Elasticsearch(esTransportOpts),\nnew winston.transports.Console()// Optional console transport\n]\n});\n\nlogger.info('This log will go to Elasticsearch');",
        "const winston = require('winston');\n\n// Custom format to sanitize sensitive data\nconst sanitizeFormat = winston.format((info) => {\nif (info.user && info.user.password) {\ninfo.user.password = '[REDACTED]';\n}\n\nif (info.user && info.user.creditCard) {\ninfo.user.creditCard = '[REDACTED]';\n}\n\nif (info.headers && info.headers.authorization) {\ninfo.headers.authorization = '[REDACTED]';\n}\n\nreturn info;\n});\n\nconst logger = winston.createLogger({\nformat: winston.format.combine(\nsanitizeFormat(),\nwinston.format.json()\n),\ntransports: [\nnew winston.transports.Console()\n]\n});\n\n// This sensitive data will be sanitized in the logs\nlogger.info({\nmessage: 'User registered',\nuser: {\nname: 'John',\nemail: 'john@example.com',\npassword: 'secret123',\ncreditCard: '4111-1111-1111-1111'\n},\nheaders: {\nauthorization: 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...'\n}\n});",
        "const debug = require('debug');\n\n// Create named debuggers\nconst dbDebug = debug('app:db');\nconst apiDebug = debug('app:api');\nconst authDebug = debug('app:auth');\n\n// Usage\ndbDebug('Connected to database');\napiDebug('API request received at /users');\nauthDebug('User authenticated: %o', { id: 123, roles: ['admin'] });\n\n// Enable with environment variable:\n// DEBUG=app:* node app.js\n// or\n// DEBUG=app:db,app:auth node app.js",
        "const express = require('express');\nconst { v4: uuidv4 } = require('uuid');\nconst winston = require('winston');\nconst app = express();\n\n// Create a logger\nconst logger = winston.createLogger({\ntransports: [new winston.transports.Console()],\nformat: winston.format.combine(\nwinston.format.timestamp(),\nwinston.format.json()\n)\n});\n\n// Correlation ID middleware\napp.use((req, res, next) => {\n// Extract correlation ID from the request header or generate a new one\nconst correlationId = req.headers['x-correlation-id'] || uuidv4();\n\n// Add it to the response headers\nres.setHeader('x-correlation-id', correlationId);\n\n// Add it to the request object\nreq.correlationId = correlationId;\n\n// Create a request-specific logger\nreq.logger = logger.child({ correlationId });\n\nreq.logger.info({\nmessage: 'Request received',\nmethod: req.method,\nurl: req.url\n});\n\nnext();\n});\n\n// Routes\napp.get('/', (req, res) => {\nreq.logger.info('Processing home request');\nres.send('Hello World');\n});\n\napp.get('/error', (req, res) => {\nreq.logger.error('Error occurred in request');\nres.status(500).send('Error');\n});\n\napp.listen(8080, () => {\nlogger.info('Server started on port 8080');\n});",
        "debug"
      ]
    },
    {
      "title": "Node.js Monitoring & Observability",
      "summary": "Introduction to Observability\nObservability in Node.js applications involves collecting and analyzing metrics and logs to understand system behavior.\nKey Pillars of Observability: Metrics, Logs, and Traces (often called the \"three pillars of observability\") provide different but complementary views of your system's health and performance.\nApplication Metrics Collection\nUsing Prometheus Client\nBasic Metrics CollectionGet your own Node.js Server\nKey Metrics to Monitor\nCPU Usage\nMemory Usage (Heap & RSS)\nEvent Loop Lag\nGarbage Collection\nActive Handles/Requests\nRequest Rate & Duration\nError Rates\nDatabase Query Performance\nCache Hit/Miss Ratios\nQueue Lengths\nDistributed Tracing\nDistributed tracing helps track requests as they flow through multiple services in a microservices architecture.\nOpenTelemetry Setup\nLogging Best Practices\nStructured Logging with Pino\nLog Enrichment\nAlerting and Visualization\nGrafana Dashboard Example\nVisualize your metrics with Grafana dashboards. Example queries for common metrics:\nAlerting Rules (Prometheus)\nProduction Monitoring Tools\nOpen Source\nPrometheus + Grafana\nElasticsearch + Fluentd + Kibana (EFK)\nJaeger\nLoki\nCommercial\nDatadog\nNew Relic\nDynatrace\nAppDynamics\nCloud Native\nAWS CloudWatch\nGoogle Cloud Operations\nAzure Monitor\nOpenTelemetry Collector\nBest Practices\nUse structured logging with consistent formats\nMonitor both system and application metrics\nSet up alerts based on SLOs (Service Level Objectives)\nUse distributed tracing for microservices\nDon't log sensitive information\nAvoid high-cardinality labels in metrics\nDon't rely solely on logs for debugging\nAvoid alert fatigue - focus on actionable alerts",
      "examples": [
        "const express = require('express');\nconst client = require('prom-client');\n\n// Create a Registry to register the metrics\nconst register = new client.Registry();\n\n// Add a default label which is added to all metrics\nregister.setDefaultLabels({\napp: 'nodejs-monitoring-demo'\n});\n\n// Enable collection of default metrics\nclient.collectDefaultMetrics({ register });\n\n// Create a custom metric\nconst httpRequestDurationMicroseconds = new client.Histogram({\nname: 'http_request_duration_seconds',\nhelp: 'Duration of HTTP requests in seconds',\nlabelNames: ['method', 'route', 'code'],\nbuckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10] // buckets for response time\n});\n\nconst app = express();\n\n// Custom middleware to track request duration\napp.use((req, res, next) => {\nconst end = httpRequestDurationMicroseconds.startTimer();\nres.on('finish', () => {\nend({ method: req.method, route: req.path, code: res.statusCode });\n});\nnext();\n});\n\n// Expose metrics endpoint\napp.get('/metrics', async (req, res) => {\nres.set('Content-Type', register.contentType);\nres.end(await register.metrics());\n});\n\n// Example route\napp.get('/', (req, res) => {\nres.send('Hello, Observability!');\n});\n\nconst PORT = process.env.PORT || 3000;\napp.listen(PORT, () => {\nconsole.log(`Server running on port ${PORT}`);\n});",
        "// Install required packages\n// npm install @opentelemetry/sdk-node @opentelemetry/auto-instrumentations-http\n// npm install @opentelemetry/exporter-trace-otlp-http\n\nconst { NodeSDK } = require('@opentelemetry/sdk-node');\nconst { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');\nconst { OTLPTraceExporter } = require('@opentelemetry/exporter-trace-otlp-http');\nconst { Resource } = require('@opentelemetry/resources');\nconst { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions');\n\nconst sdk = new NodeSDK({\nresource: new Resource({\n[SemanticResourceAttributes.SERVICE_NAME]: 'my-service',\n[SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',\n}),\ntraceExporter: new OTLPTraceExporter({\nurl: 'http://collector:4318/v1/traces',\n}),\ninstrumentations: [getNodeAutoInstrumentations()],\n});\n\nsdk.start()\n.then(() => console.log('Tracing initialized'))\n.catch((error) => console.log('Error initializing tracing', error));",
        "const pino = require('pino');\nconst express = require('express');\nconst pinoHttp = require('pino-http');\n\nconst logger = pino({\nlevel: process.env.LOG_LEVEL || 'info',\nformatters: {\nlevel: (label) => ({ level: label.toUpperCase() }),\n},\n});\n\nconst app = express();\n\n// HTTP request logging middleware\napp.use(pinoHttp({\nlogger,\ncustomLogLevel: function (res, err) {\nif (res.statusCode >= 400 && res.statusCode < 500) {\nreturn 'warn';\n} else if (res.statusCode >= 500 || err) {\nreturn 'error';\n}\nreturn 'info';\n},\n}));\n\napp.get('/', (req, res) => {\nreq.log.info('Processing request');\nres.json({ status: 'ok' });\n});\n\napp.listen(3000, () => {\nlogger.info('Server started on port 3000');\n});",
        "// Add context to logs\napp.use((req, res, next) => {\nconst childLogger = logger.child({\nrequestId: req.id,\nuserId: req.user?.id || 'anonymous',\npath: req.path,\nmethod: req.method\n});\nreq.log = childLogger;\nnext();\n});",
        "# Node.js Memory Usage (RSS in MB)\nprocess_resident_memory_bytes{job=\"nodejs\"} / 1024 / 1024\n\n# Request Duration (p99 in ms)\nhistogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) * 1000\n\n# Error Rate\nsum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m]))",
        "groups:\n- name: nodejs\nrules:\n- alert: HighErrorRate\nexpr: rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m]) > 0.05\nfor: 10m\nlabels:\nseverity: critical\nannotations:\nsummary: \"High error rate on {{ $labels.instance }}\""
      ]
    },
    {
      "title": "Node.js Performance Diagnostics",
      "summary": "Why Performance Matters\nNode.js offers various tools and techniques for diagnosing performance issues.\nThis guide covers built-in tools, and popular third-party solutions, for comprehensive performance analysis.\nPerformance Tip: Always measure before optimizing.\nUse the techniques in this guide to identify actual bottlenecks rather than guessing where performance issues might be.\nUnderstanding Node.js Performance\nPerformance in Node.js applications can be affected by several factors:\nCPU-intensive operations that block the event loop\nMemory leaks and excessive garbage collection\nI/O bottlenecks (database queries, file operations, network requests)\nInefficient code and algorithms\nEvent loop congestion\nDiagnosing these issues requires a methodical approach and the right tools.\nBuilt-in Diagnostic Tools\nconsole.time() and console.timeEnd()\nThe simplest way to measure how long an operation takes:\nProcess Statistics\nNode.js provides access to process statistics through the process global object:\nNode.js Performance Hooks\nSince Node.js 8.5.0, the perf_hooks module provides tools for measuring performance:\nAdvanced CPU Profiling\nIdentifying hot functions consuming excessive CPU time\nFinding optimization opportunities in synchronous code\nAnalyzing event loop blocking operations\nComparing performance before and after optimizations\n1. V8 Profiler with Source Maps\nFor applications using TypeScript or transpiled JavaScript, source maps are essential for meaningful profiling results:\nNode.js allows accessing the V8 profiler directly for CPU profiling:\nTo use the above example, you need to install the v8-profiler package:\nThe generated .cpuprofile file can be loaded in Chrome DevTools for visualization.\n2. Node.js Built-in Profiling\nNode.js has built-in profiling capabilities that can be accessed through command-line flags:\nAdvanced Memory Profiling\nMemory Leak Detection Tip: Compare multiple heap snapshots taken at different times to identify objects that aren't being garbage collected as expected.\nHeap Snapshots with Chrome DevTools\nHeap snapshots can help identify memory leaks by capturing the memory state at a specific moment:\nTo use the above example, you need to install the heapdump package:\nHeap snapshots can be analyzed in Chrome DevTools to identify memory leaks.\nEvent Loop and Latency Analysis\nEvent loop lag (time between event loop ticks)\nActive handles and requests\nPending async operations\nGarbage collection pauses\nThe event loop is central to Node.js performance. Blocking it causes performance degradation:\nTo use the above example, you need to install the toobusy-js package:\nFlame Graphs\nFlame graphs provide a visual representation of CPU sampling, helping to identify where time is spent in your application:\nBenchmarking\nBenchmarking helps compare different implementations to choose the most efficient one:\nTo use the above example, you need to install the benchmark package:\nNode.js Inspector\nNode.js has an integrated debugger and profiler accessible through Chrome DevTools:\nOpen Chrome and navigate to chrome://inspect to access DevTools for your Node.js application. This provides access to:\nCPU profiler\nMemory heap snapshots\nMemory allocation timeline\nDebugger\nClinic.js Suite\nClinic.js is a collection of tools for diagnosing performance issues in Node.js applications:\nPractical Performance Diagnosis\nStep 1: Establish Baseline Metrics\nBefore optimizing, establish baseline metrics for your application:\nStep 2: Identify Bottlenecks\nUse profiling to identify bottlenecks:\nCPU profiling for compute-intensive operations\nMemory snapshots for memory leaks\nFlame graphs for call stack analysis\nEvent loop monitoring for I/O and callback delays\nStep 3: Fix and Verify\nAfter applying optimizations, verify improvements against your baseline.\nCommon Performance Issues and Solutions\n1. Memory Leaks\nSigns: Increasing memory usage over time that doesn't plateau.\nSolutions:\nTake heap snapshots at intervals and compare\nCheck for global variables, event listeners, and closures that retain references\nImplement proper cleanup when objects are no longer needed\n2. Long-Running Operations\nSigns: High event loop lag, inconsistent response times.\nSolutions:\nMove CPU-intensive work to worker threads\nBreak long tasks into smaller chunks using setImmediate/process.nextTick\nConsider offloading to dedicated services\n3. Inefficient Database Queries\nSigns: Slow response times, high latency.\nSolutions:\nProfile database operations\nOptimize queries with proper indexing\nUse connection pooling\nImplement caching for frequently accessed data",
      "examples": [
        "// Measure execution time\nconsole.time('operation');\n\n// Some operation to measure\nconst array = Array(1000000).fill().map((_, i) => i);\narray.sort((a, b) => b - a);\n\nconsole.timeEnd('operation');\n// Output: operation: 123.45ms",
        "// Memory usage\nconst memoryUsage = process.memoryUsage();\nconsole.log('Memory Usage:');\nconsole.log(` RSS: ${Math.round(memoryUsage.rss / 1024 / 1024)} MB`);\nconsole.log(` Heap Total: ${Math.round(memoryUsage.heapTotal / 1024 / 1024)} MB`);\nconsole.log(` Heap Used: ${Math.round(memoryUsage.heapUsed / 1024 / 1024)} MB`);\nconsole.log(` External: ${Math.round(memoryUsage.external / 1024 / 1024)} MB`);\n\n// CPU usage\nconst startUsage = process.cpuUsage();\n\n// Simulate CPU work\nconst now = Date.now();\nwhile (Date.now() - now < 500); // Busy wait for 500ms\n\nconst endUsage = process.cpuUsage(startUsage);\nconsole.log('CPU Usage:');\nconsole.log(` User: ${endUsage.user / 1000}ms`);\nconsole.log(` System: ${endUsage.system / 1000}ms`);\n\n// Uptime\nconsole.log(`Process uptime: ${process.uptime().toFixed(2)} seconds`);",
        "const { performance, PerformanceObserver } = require('perf_hooks');\n\n// Create a performance observer\nconst obs = new PerformanceObserver((items) => {\nitems.getEntries().forEach((entry) => {\nconsole.log(`${entry.name}: ${entry.duration.toFixed(2)}ms`);\n});\n});\n\n// Subscribe to performance events\nobs.observe({ entryTypes: ['measure'] });\n\n// Mark the beginning of an operation\nperformance.mark('start');\n\n// Simulate some work\nconst data = [];\nfor (let i = 0; i < 1000000; i++) {\ndata.push(i * i);\n}\n\n// Mark the end and measure\nperformance.mark('end');\nperformance.measure('Data processing time', 'start', 'end');\n\n// Clean up marks\nperformance.clearMarks();",
        "const v8Profiler = require('v8-profiler-node8');\nconst fs = require('fs');\nconst path = require('path');\n\n// Enable source map support for accurate profiling\nrequire('source-map-support').install();\n\n// Start CPU profiling with source map support\nv8Profiler.setGenerateType(1); // Include type information\nconst profile = v8Profiler.startProfiling('CPU profile', true);\n\n// Run code to profile\nfunction fibonacci(n) {\nif (n <= 1) return n;\nreturn fibonacci(n - 1) + fibonacci(n - 2);\n}\n\n// Simulate both CPU and I/O work\nfunction processData() {\nconst start = Date.now();\nfibonacci(35);\nconsole.log(`CPU work took: ${Date.now() - start}ms`);\n\n// Simulate async work\nsetImmediate(() => {\nconst asyncStart = Date.now();\nfibonacci(30);\nconsole.log(`Async work took: ${Date.now() - asyncStart}ms`);\n});\n}\n\nprocessData();\n\n// Stop profiling after async work completes\nsetTimeout(() => {\nconst profile = v8Profiler.stopProfiling('CPU profile');\nprofile.export((error, result) => {\nconst filename = path.join(__dirname, 'profile.cpuprofile');\nfs.writeFileSync(filename, result);\nconsole.log(`CPU profile saved to ${filename}`);\nprofile.delete();\n});\n}, 1000);",
        "npm install v8-profiler-node8",
        "# Start a Node.js application with profiling enabled\nnode --prof app.js\n\n# Process the generated log file\nnode --prof-process isolate-0xNNNNNNNN-NNNN-v8.log > processed.txt",
        "const heapdump = require('heapdump');\nconst fs = require('fs');\nconst path = require('path');\n\n// Generate some data that might leak\nlet leakyData = [];\nfunction potentiallyLeaky() {\nconst data = {\nid: Date.now(),\ncontent: Array(1000).fill('potentially leaky data'),\ntimestamp: new Date().toISOString()\n};\nleakyData.push(data);\n}\n\n// Simulate a memory leak with different retention patterns\nsetInterval(() => {\npotentiallyLeaky();\n// Keep only the last 100 items to simulate a partial leak\nif (leakyData.length > 100) {\nleakyData = leakyData.slice(-100);\n}\n}, 100);\n// Take heap snapshots at intervals\nfunction takeHeapSnapshot(prefix) {\nconst filename = path.join(__dirname, `${prefix}-${Date.now()}.heapsnapshot`);\nheapdump.writeSnapshot(filename, (err, filename) => {\nif (err) {\nconsole.error('Failed to take heap snapshot:', err);\n} else {\nconsole.log(`Heap snapshot saved to ${filename}`);\n}\n});\n}\n// Initial snapshot takeHeapSnapshot('heap-initial');\n// Take periodic snapshots\nsetInterval(() => {   takeHeapSnapshot('heap-periodic');\n}, 10000);\n// Force garbage collection before final snapshot\nsetTimeout(() => {\nif (global.gc) {\nglobal.gc();\nconsole.log('Garbage collection forced');\n}\ntakeHeapSnapshot('heap-final');\n}, 30000);",
        "npm install heapdump",
        "const toobusy = require('toobusy-js');\nconst http = require('http');\n\n// Configure thresholds (in milliseconds)\ntoobusy.maxLag(100); // Maximum allowed lag before considering server too busy\ntoobusy.interval(500); // Check interval for event loop lag\n\n// Create HTTP server with event loop monitoring\nconst server = http.createServer((req, res) => {\n// Check if event loop is overloaded\nif (toobusy()) {\nres.statusCode = 503; // Service Unavailable\nres.setHeader('Retry-After', '10');\nreturn res.end(JSON.stringify({\nerror: 'Server is too busy',\nmessage: 'Please try again later',\nstatus: 503\n}));\n}\n// Simulate some work based on URL\nif (req.url === '/compute') {\n// CPU-intensive work\nlet sum = 0;\nfor (let i = 0; i < 1e7; i++) {\nsum += Math.random();\n}\nres.end(`Computed: ${sum}`);\n} else {\n// Normal response\nres.end('OK');\n}\n});\n// Add error handling\nserver.on('error', (err) => {\nconsole.error('Server error:', err);\n});\n// Start server\nconst PORT = process.env.PORT || 3000;\nserver.listen(PORT, () => {\nconsole.log(`Server running on port ${PORT}`);\n});\n// Monitor event loop lag and memory usage\nsetInterval(() => {\nconst lag = toobusy.lag();\nconst mem = process.memoryUsage();\nconsole.log(`Event loop lag: ${lag}ms`);\nconsole.log(`Memory usage: ${Math.round(mem.heapUsed / 1024 / 1024)}MB / ${Math.round(mem.heapTotal / 1024 / 1024)}MB`);\n}, 1000);\n// Graceful shutdown\nprocess.on('SIGINT', () => {\nconsole.log('Shutting down...');\nserver.close(() => {\nprocess.exit(0);\n});\n});",
        "npm install toobusy-js",
        "# Using 0x for flame graphs (install globally)\nnpm install -g 0x\n\n# Run your application with 0x\n0x app.js\n\n# A browser will open with the flame graph visualization when the process exits",
        "const Benchmark = require('benchmark');\nconst suite = new Benchmark.Suite;\n\n// Add tests\nsuite\n.add('RegExp#test', function() {\n/o/.test('Hello World!');\n})\n.add('String#indexOf', function() {\n'Hello World!'.indexOf('o') > -1;\n})\n.add('String#includes', function() {\n'Hello World!'.includes('o');\n})\n// Add listeners\n.on('cycle', function(event) {\nconsole.log(String(event.target));\n})\n.on('complete', function() {\nconsole.log('Fastest is ' + this.filter('fastest').map('name'));\n})\n// Run benchmarks\n.run({ 'async': true });",
        "npm install benchmark",
        "# Start an application with the inspector\nnode --inspect app.js\n\n# Start and immediately break (for debugging)\nnode --inspect-brk app.js",
        "# Install the Clinic.js suite\nnpm install -g clinic\n\n# Use Doctor to identify issues\nclinic doctor -- node app.js\n\n# Use Flame to generate CPU flame graphs\nclinic flame -- node app.js\n\n# Use Bubbleprof for async operations analysis\nclinic bubbleprof -- node app.js",
        "const autocannon = require('autocannon');\nconst { writeFileSync } = require('fs');\n\n// Run a benchmark against your application\nconst result = autocannon({\nurl: 'http://localhost:8080',\nconnections: 100,\nduration: 10\n});\n\n// Save the results\nresult.on('done', (results) => {\nconsole.log('Baseline performance metrics:');\nconsole.log(` Requests/sec: ${results.requests.average}`);\nconsole.log(` Latency: ${results.latency.average}ms`);\n\nwriteFileSync('baseline-metrics.json', JSON.stringify(results, null, 2));\n});",
        "process",
        "perf_hooks",
        ".cpuprofile",
        "chrome://inspect"
      ]
    },
    {
      "title": "Node.js Child Process Module",
      "summary": "What is the Child Process Module?\nThe Child Process module is a built-in Node.js module that allows you to create and manage child processes.\nIt provides several ways to execute external commands and communicate with subprocess instances.\nThis capability is essential for tasks like:\nRunning system commands from your Node.js application\nExecuting CPU-intensive tasks in separate processes\nRunning multiple processes in parallel to utilize multiple CPU cores\nInterfacing with external programs and scripts\nImporting the Child Process Module\nThe Child Process module is included in Node.js by default.\nYou can use it by requiring it in your script:\nMethods for Creating Child Processes\nThe Child Process module provides four primary methods for creating and managing child processes, each with different behaviors and use cases:\nThe exec() Method\nThe exec() method creates a shell and executes a command within that shell.\nIt buffers the entire output and provides it via a callback when the command completes.\nWarning: Never pass unsanitized user input to exec() as it runs commands with full shell syntax, which can lead to command injection attacks.\nexec() with Promise\nUsing a promise wrapper to handle the callback:\nThe execFile() Method\nThe execFile() method is similar to exec(), but it doesn't spawn a shell.\nIt's more efficient for executing external binaries.\nNote: execFile() is more secure than exec() for running commands with user input, as it doesn't process shell metacharacters.\nThe spawn() Method\nThe spawn() method launches a new process with the given command.\nUnlike exec(), it doesn't buffer the output, instead providing stream-based access to stdout and stderr.\nWhen to Use spawn()\nspawn() is especially useful for:\nLong-running processes (like server processes or watchers)\nProcesses that produce large amounts of output\nWhen you need to process data as it's generated, rather than waiting for completion\nUsing spawn() with stdin\nThe fork() Method\nThe fork() method is a special case of spawn() specifically for creating Node.js processes. It sets up an IPC channel that allows sending messages between the parent and child processes.\nBenefits of fork()\nEach forked process gets its own V8 instance and memory\nIsolates CPU-intensive work from the main event loop\nAllows communication between processes via messages\nHelps utilize multiple CPU cores\nInterprocess Communication (IPC)\nChild processes created with fork() can communicate with the parent process through a built-in IPC channel using send() and the message event.\nSending Complex Data\nNote: The messages are serialized using JSON, so you can only send JSON-compatible data (objects, arrays, strings, numbers, booleans, and null).\nManaging Child Processes\nKilling a Child Process\nDetached Processes\nYou can create detached child processes that continue running independently of the parent:\nPractical Examples\nCreating a Simple Task Queue\nRunning External Applications\nBest Practices\nInput Sanitization: Always sanitize user inputs to prevent command injection attacks, especially with exec()\nResource Management: Monitor and handle the resources (memory, file descriptors) used by child processes\nError Handling: Always have proper error handling for child processes\nChoose the Right Method:\nUse exec() for simple commands with limited output\nUse spawn() for long-running processes or large outputs\nUse fork() for CPU-intensive Node.js operations\nUse exec() for simple commands with limited output\nUse spawn() for long-running processes or large outputs\nUse fork() for CPU-intensive Node.js operations\nCleanup: Properly kill child processes when they're no longer needed\nLimit Concurrency: Control the number of concurrent child processes to avoid system overload\nWarning: Running too many child processes can quickly exhaust system resources. Always implement rate limiting and concurrency control.\nSecurity Considerations\nCommand Injection: Never pass unsanitized user input directly to exec() or spawn()\nEnvironment Variables: Be careful with passing environment variables to child processes\nFile Access: Understand the permissions that child processes may have\nResource Limits: Consider implementing timeouts and memory limits for child processes",
      "examples": [
        "const childProcess = require('child_process');\n\n// Or using destructuring to access specific methods\nconst { exec, spawn, fork } = require('child_process');",
        "const { exec } = require('child_process');\n\n// Execute the 'ls -la' command (or 'dir' on Windows)\nconst command = process.platform === 'win32' ? 'dir' : 'ls -la';\n\nexec(command, (error, stdout, stderr) => {\nif (error) {\nconsole.error(`Error executing command: ${error.message}`);\nreturn;\n}\n\nif (stderr) {\nconsole.error(`Command stderr: ${stderr}`);\n}\n\nconsole.log(`Command output:\\n${stdout}`);\n});\n\n// With options\nexec('echo $HOME', {\nenv: { HOME: '/custom/home/directory' }\n}, (error, stdout, stderr) => {\nconsole.log(`Custom home directory: ${stdout.trim()}`);\n});",
        "const { exec } = require('child_process');\nconst util = require('util');\n\n// Convert exec to a promise-based function\nconst execPromise = util.promisify(exec);\n\nasync function executeCommand(command) {\ntry {\nconst { stdout, stderr } = await execPromise(command);\n\nif (stderr) {\nconsole.error(`Command stderr: ${stderr}`);\n}\n\nconsole.log(`Command output:\\n${stdout}`);\nreturn stdout;\n} catch (error) {\nconsole.error(`Error executing command: ${error.message}`);\nthrow error;\n}\n}\n\n// Using the promise-based function\nexecuteCommand('node --version')\n.then(version => console.log(`Node.js version: ${version.trim()}`))\n.catch(err => console.error('Failed to get Node.js version'));",
        "const { execFile } = require('child_process');\n\n// Execute 'node' with arguments\nexecFile('node', ['--version'], (error, stdout, stderr) => {\nif (error) {\nconsole.error(`Error executing file: ${error.message}`);\nreturn;\n}\n\nconsole.log(`Node.js version: ${stdout.trim()}`);\n});\n\n// On Windows, execute a batch file\nif (process.platform === 'win32') {\nexecFile('C:\\\\Windows\\\\System32\\\\cmd.exe', ['/c', 'echo Hello from batch!'], (error, stdout, stderr) => {\nif (error) {\nconsole.error(`Error: ${error.message}`);\nreturn;\n}\n\nconsole.log(`Output: ${stdout.trim()}`);\n});\n}",
        "const { spawn } = require('child_process');\n\n// Spawn a process to list files\nconst ls = process.platform === 'win32'\n? spawn('cmd', ['/c', 'dir'])\n: spawn('ls', ['-la']);\n\n// Handle process output streams\nls.stdout.on('data', (data) => {\nconsole.log(`stdout: ${data}`);\n});\n\nls.stderr.on('data', (data) => {\nconsole.error(`stderr: ${data}`);\n});\n\nls.on('close', (code) => {\nconsole.log(`Child process exited with code ${code}`);\n});\n\n// Spawn with options\nconst grep = spawn('grep', ['hello', 'input.txt'], {\ncwd: '/tmp', // Working directory\nenv: { ...process.env, CUSTOM_ENV: 'value' },\nstdio: 'pipe', // Configure stdio\ndetached: false, // Process group behavior\nshell: false // Whether to run in a shell\n});\n\n// Handling errors\ngrep.on('error', (err) => {\nconsole.error(`Failed to start subprocess: ${err.message}`);\n});",
        "const { spawn } = require('child_process');\n\n// Spawn a process that reads from stdin\nconst process = spawn('wc', ['-w']); // Word count\n\n// Send data to the process's stdin\nprocess.stdin.write('Hello world from Node.js!');\nprocess.stdin.end(); // Signal the end of input\n\n// Capture output\nprocess.stdout.on('data', (data) => {\nconsole.log(`Number of words: ${data}`);\n});",
        "// In the main file (parent.js)\nconst { fork } = require('child_process');\n\n// Fork a child process\nconst child = fork('child.js');\n\n// Send a message to the child\nchild.send({ message: 'Hello from parent' });\n\n// Receive messages from the child\nchild.on('message', (message) => {\nconsole.log('Message from child:', message);\n});\n\n// Handle child process exit\nchild.on('close', (code) => {\nconsole.log(`Child process exited with code ${code}`);\n});",
        "// In the child file (child.js)\nconsole.log('Child process started', process.pid);\n\n// Listen for messages from the parent\nprocess.on('message', (message) => {\nconsole.log('Message from parent:', message);\n\n// Send a message back to the parent\nprocess.send({ response: 'Hello from child' });\n\n// After 3 seconds, exit the process\nsetTimeout(() => {\nprocess.exit(0);\n}, 8080);\n});",
        "// In parent.js\nconst { fork } = require('child_process');\nconst child = fork('worker.js');\n\n// Send different types of data\nchild.send({\ncommand: 'compute',\ndata: [1, 2, 3, 4, 5],\noptions: {\nmultiply: 2,\nsubtract: 1\n}\n});\n\n// Receive the result\nchild.on('message', (result) => {\nconsole.log('Computation result:', result);\nchild.disconnect(); // Clean up the IPC channel\n});",
        "// In worker.js\nprocess.on('message', (msg) => {\nif (msg.command === 'compute') {\nconst result = msg.data.map(num => num * msg.options.multiply - msg.options.subtract);\n\n// Send the result back to the parent\nprocess.send({ result });\n}\n});",
        "const { spawn } = require('child_process');\n\n// Spawn a long-running process\nconst child = spawn('node', ['-e', `\nsetInterval(() => {\nconsole.log('Still running...', Date.now());\n}, 1000);\n`]);\n\n// Output from the process\nchild.stdout.on('data', (data) => {\nconsole.log(`stdout: ${data}`);\n});\n\n// Kill the process after 5 seconds\nsetTimeout(() => {\nconsole.log('Killing the child process...');\n\n// Send a SIGTERM signal\nchild.kill('SIGTERM');\n\n// Alternative: child.kill() - uses SIGTERM by default\n}, 5000);\n\n// Handle the exit event\nchild.on('exit', (code, signal) => {\nconsole.log(`Child process exited with code ${code} and signal ${signal}`);\n});",
        "const { spawn } = require('child_process');\nconst fs = require('fs');\n\n// Create a detached process\nconst child = spawn('node', ['long_running_script.js'], {\ndetached: true,\nstdio: ['ignore',\nfs.openSync('output.log', 'w'),\nfs.openSync('error.log', 'w')\n]\n});\n\n// Unref the child to allow the parent to exit independently\nchild.unref();\n\nconsole.log(`Started detached process with PID: ${child.pid}`);\nconsole.log('Parent will exit while child continues running.');\n\n// The parent can now exit, and the child will continue running",
        "// In tasks.js (parent)\nconst { fork } = require('child_process');\nconst numCPUs = require('os').cpus().length;\n\nclass TaskQueue {\nconstructor() {\nthis.tasks = [];\nthis.workers = [];\nthis.maxWorkers = numCPUs;\n}\n\naddTask(task) {\nthis.tasks.push(task);\nthis.runNext();\n}\n\nrunNext() {\n// If we have tasks and available workers\nif (this.tasks.length > 0 && this.workers.length < this.maxWorkers) {\nconst task = this.tasks.shift();\nconst worker = fork('worker.js');\n\nconsole.log(`Starting worker for task ${task.id}`);\nthis.workers.push(worker);\n\nworker.send(task);\n\nworker.on('message', (result) => {\nconsole.log(`Task ${task.id} completed with result:`, result);\n\n// Remove this worker from our workers list\nthis.workers = this.workers.filter(w => w !== worker);\n\n// Run the next task if we have one\nthis.runNext();\n});\n\nworker.on('error', (err) => {\nconsole.error(`Worker for task ${task.id} had an error:`, err);\nthis.workers = this.workers.filter(w => w !== worker);\nthis.runNext();\n});\n\nworker.on('exit', (code) => {\nif (code !== 0) {\nconsole.error(`Worker for task ${task.id} exited with code ${code}`);\n}\n});\n}\n}\n\n// Usage\nconst queue = new TaskQueue();\n\n// Add some tasks\nfor (let i = 1; i <= 10; i++) {\nqueue.addTask({\nid: i,\ntype: 'calculation',\ndata: Array.from({ length: 1000000 }, () => Math.random())\n});\n}",
        "// In worker.js\nprocess.on('message', (task) => {\nconsole.log(`Worker ${process.pid} received task ${task.id}`);\n\n// Simulate CPU-intensive work\nlet result;\n\nif (task.type === 'calculation') {\n// For example, find sum and average\nconst sum = task.data.reduce((acc, val) => acc + val, 0);\nconst avg = sum / task.data.length;\n\nresult = { sum, avg };\n}\n\n// Send result back to parent\nprocess.send({ taskId: task.id, result });\n\n// Exit this worker\nprocess.exit(0);\n});",
        "const { spawn } = require('child_process');\nconst path = require('path');\nconst fs = require('fs');\n\n// Function to convert a video using ffmpeg\nfunction convertVideo(inputFile, outputFile, options = {}) {\nreturn new Promise((resolve, reject) => {\n// Make sure input file exists\nif (!fs.existsSync(inputFile)) {\nreturn reject(new Error(`Input file ${inputFile} does not exist`));\n}\n\n// Prepare ffmpeg arguments\nconst args = ['-i', inputFile];\n\nif (options.scale) {\nargs.push('-vf', `scale=${options.scale}`);\n}\n\nif (options.format) {\nargs.push('-f', options.format);\n}\n\nargs.push(outputFile);\n\n// Spawn ffmpeg process\nconst ffmpeg = spawn('ffmpeg', args);\n\n// Collect output for logging\nlet stdoutData = '';\nlet stderrData = '';\n\nffmpeg.stdout.on('data', (data) => {\nstdoutData += data;\n});\n\nffmpeg.stderr.on('data', (data) => {\nstderrData += data;\n});\n\n// Handle process completion\nffmpeg.on('close', (code) => {\nif (code === 0) {\nresolve({\ninputFile,\noutputFile,\nstdout: stdoutData,\nstderr: stderrData\n});\n} else {\nreject(new Error(`ffmpeg exited with code ${code}\\n${stderrData}`));\n}\n});\n\n// Handle process errors\nffmpeg.on('error', reject);\n});\n}\n\n// Example usage (commented out)\n/*\nconvertVideo('input.mp4', 'output.webm', {\nscale: '640:480',\nformat: 'webm'\n})\n.then(result => {\nconsole.log('Video conversion successful!');\nconsole.log(`Output file: ${result.outputFile}`)\n;   })\n.catch(error => {\nconsole.error('Video conversion failed:', error.message);\n});\n*/",
        "exec()",
        "execFile()",
        "spawn()",
        "fork()",
        "send()",
        "message"
      ]
    },
    {
      "title": "Node.js Cluster Module",
      "summary": "What is the Cluster Module?\nThe Cluster module provides a way to create multiple worker processes that share the same server port.\nSince Node.js is single-threaded by default, the Cluster module helps your application utilize multiple CPU cores, significantly improving performance on multi-core systems.\nEach worker runs in its own process with its own event loop and memory space, but they all share the same server port.\nThe master process is responsible for creating workers and distributing incoming connections among them.\nImporting the Cluster Module\nThe Cluster module is included in Node.js by default.\nYou can use it by requiring it in your script:\nHow Clustering Works\nThe Cluster module works by creating a master process that spawns multiple worker processes.\nThe master process doesn't execute the application code but manages the workers.\nEach worker process is a new Node.js instance that runs your application code independently.\nNote: Under the hood, the Cluster module uses the Child Process module's fork() method to create new workers.\nCreating and managing worker processes\nMonitoring worker health\nRestarting crashed workers\nLoad balancing (distributing connections)\nRunning the actual application code\nHandling incoming requests\nProcessing data\nExecuting business logic\nCreating a Basic Cluster\nHere's a simple example of creating a cluster with worker processes for each CPU:\nIn this example:\nThe master process detects the number of CPU cores\nIt forks one worker per CPU\nEach worker creates an HTTP server on the same port (8000)\nThe cluster module automatically load balances the incoming connections\nIf a worker crashes, the master creates a new one\nWorker Communication\nYou can communicate between master and worker processes using the send() method and message events, similar to how IPC works in the Child Process module.\nZero-Downtime Restart\nOne of the main benefits of clustering is the ability to restart workers without downtime. This is useful for deploying updates to your application.\nThis example demonstrates:\nCreating an initial set of workers\nReplacing each worker one by one\nEnsuring a new worker is listening before disconnecting the old one\nGracefully handling unexpected worker deaths\nLoad Balancing\nThe Cluster module has built-in load balancing for distributing incoming connections among worker processes.\nThere are two primary strategies:\nRound-Robin (default)\nBy default on all platforms except Windows, Node.js distributes connections using a round-robin approach, where the master accepts connections and distributes them across workers in a circular sequence.\nNote: On Windows, the load distribution behaves differently due to how Windows handles ports. In Windows, the workers compete to accept connections.\nPrimary Worker\nYou can also let each worker accept connections directly by setting cluster.schedulingPolicy:\nShared State\nSince each worker runs in its own process with its own memory space, they cannot directly share state via variables. Instead, you can:\nUse IPC messaging (as shown in the communication example)\nUse external storage like Redis, MongoDB, or a file system\nUse sticky load balancing for session management\nSticky Sessions Example\nSticky sessions ensure that requests from the same client always go to the same worker process:\nThis is a simplified example showing the concept of sticky sessions. In production, you'd typically:\nUse a more sophisticated hashing algorithm\nUse cookies or other session identifiers instead of IP addresses\nHandle socket connections more carefully\nWorker Lifecycle\nUnderstanding the worker lifecycle is important for properly managing your cluster:\nGraceful Shutdown\nA graceful shutdown is important to allow your worker processes to finish handling existing requests before they exit.\nBest Practices\nNumber of Workers: In most cases, create one worker per CPU core\nStateless Design: Design your application to be stateless to work effectively with clusters\nGraceful Shutdown: Implement proper shutdown handling to avoid dropping connections\nWorker Monitoring: Monitor and replace crashed workers promptly\nDatabase Connections: Each worker has its own connection pool, so configure database connections appropriately\nShared Resources: Be careful with resources shared between workers (e.g., file locks)\nKeep Workers Lean: Avoid unnecessary memory usage in worker processes\nWarning: Be careful with file-based locking and other shared resources when using multiple workers. Operations that were safe in a single-process application may cause race conditions with multiple workers.\nAlternatives to the Cluster Module\nWhile the Cluster module is powerful, there are alternatives for running Node.js applications on multiple cores:\nAdvanced Load Balancing Strategies\nWhile the Cluster module's default round-robin load balancing works well for many applications, you might need more sophisticated strategies for specific use cases.\n1. Weighted Round-Robin\n2. Least Connections\nPerformance Monitoring and Metrics\nMonitoring your cluster's performance is crucial for maintaining a healthy application. Here's how to implement basic metrics collection:\nKey Metrics to Monitor\nRequest Rate: Requests per second per worker\nError Rate: Error responses per second\nResponse Time: P50, P90, P99 response times\nCPU Usage: Per-worker CPU utilization\nMemory Usage: Heap and RSS memory per worker\nEvent Loop Lag: Delay in the event loop\nContainer Integration\nWhen running in containerized environments like Docker and Kubernetes, consider these best practices:\n1. Process Management\n2. Kubernetes Deployment\nCommon Pitfalls and Solutions\n1. Memory Leaks in Workers\nProblem: Memory leaks in worker processes can cause gradual memory growth.\nSolution: Implement worker recycling based on memory usage.\n2. Thundering Herd Problem\nProblem: All workers accepting connections simultaneously after a restart.\nSolution: Implement staggered startup.\n3. Worker Starvation\nProblem: Some workers get more load than others.\nSolution: Implement proper load balancing and monitoring.\nSummary\nThe Node.js Cluster module provides an efficient way to scale your application across multiple CPU cores:\nCreates a master process that manages multiple worker processes\nWorkers share the same server port, allowing load balancing\nImproves application performance and resilience\nEnables zero-downtime restarts and graceful shutdowns\nUses IPC for communication between master and workers\nBy understanding and properly implementing clustering, you can build high-performance, reliable Node.js applications that efficiently utilize all available CPU resources.",
      "examples": [
        "const cluster = require('cluster');\nconst os = require('os');\n\n// Check if this is the master process\nif (cluster.isMaster) {\nconsole.log(`Master process ${process.pid} is running`);\n} else {\nconsole.log(`Worker process ${process.pid} started`);\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;\n\nif (cluster.isMaster) {\n// This is the master process\n\nconsole.log(`Master ${process.pid} is running`);\n\n// Fork workers for each CPU core\nfor (let i = 0; i < numCPUs; i++) {\ncluster.fork();\n}\n\n// Listen for worker exits\ncluster.on('exit', (worker, code, signal) => {\nconsole.log(`Worker ${worker.process.pid} died`);\n// You can fork a new worker to replace the dead one\nconsole.log('Forking a new worker...');\ncluster.fork();\n});\n} else {\n// This is a worker process\n\n// Create an HTTP server\nhttp.createServer((req, res) => {\nres.writeHead(200);\nres.end(`Hello from Worker ${process.pid}\\n`);\n\n// Simulate CPU work\nlet i = 1e7;\nwhile (i > 0) { i--; }\n\n}).listen(8000);\n\nconsole.log(`Worker ${process.pid} started`);\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;\n\nif (cluster.isMaster) {\nconsole.log(`Master ${process.pid} is running`);\n\n// Track request count for each worker\nconst requestCounts = {};\n\n// Fork workers\nfor (let i = 0; i < numCPUs; i++) {\nconst worker = cluster.fork();\nrequestCounts[worker.id] = 0;\n\n// Listen for messages from this worker\nworker.on('message', (msg) => {\nif (msg.cmd === 'incrementRequestCount') {\nrequestCounts[worker.id]++;\nconsole.log(`Worker ${worker.id} (pid ${worker.process.pid}) has handled ${requestCounts[worker.id]} requests`);\n}\n});\n}\n\n// Every 10 seconds, send the request count to each worker\nsetInterval(() => {\nfor (const id in cluster.workers) {\ncluster.workers[id].send({\ncmd: 'requestCount',\nrequestCount: requestCounts[id]\n});\n}\nconsole.log('Total request counts:', requestCounts);\n}, 10000);\n\n// Handle worker exit\ncluster.on('exit', (worker, code, signal) => {\nconsole.log(`Worker ${worker.process.pid} died`);\n// Fork a new worker to replace it\nconst newWorker = cluster.fork();\nrequestCounts[newWorker.id] = 0;\n});\n} else {\n// Worker process\nconsole.log(`Worker ${process.pid} started`);\n\nlet localRequestCount = 0;\n\n// Handle messages from the master\nprocess.on('message', (msg) => {\nif (msg.cmd === 'requestCount') {\nconsole.log(`Worker ${process.pid} has handled ${msg.requestCount} requests according to master`);\n}\n});\n\n// Create an HTTP server\nhttp.createServer((req, res) => {\n// Notify the master that we handled a request\nprocess.send({ cmd: 'incrementRequestCount' });\n\n// Increment local count\nlocalRequestCount++;\n\n// Send response\nres.writeHead(200);\nres.end(`Hello from Worker ${process.pid}, I've handled ${localRequestCount} requests locally\\n`);\n}).listen(8000);\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;\n\nif (cluster.isMaster) {\nconsole.log(`Master ${process.pid} is running`);\n\n// Store workers\nconst workers = [];\n\n// Fork initial workers\nfor (let i = 0; i < numCPUs; i++) {\nworkers.push(cluster.fork());\n}\n\n// Function to restart workers one by one\nfunction restartWorkers() {\nconsole.log('Starting zero-downtime restart...');\n\nlet i = 0;\nfunction restartWorker() {\nif (i >= workers.length) {\nconsole.log('All workers restarted successfully!');\nreturn;\n}\n\nconst worker = workers[i++];\nconsole.log(`Restarting worker ${worker.process.pid}...`);\n\n// Create a new worker\nconst newWorker = cluster.fork();\nnewWorker.on('listening', () => {\n// Once the new worker is listening, kill the old one\nworker.disconnect();\n\n// Replace the old worker in our array\nworkers[workers.indexOf(worker)] = newWorker;\n\n// Continue with the next worker\nsetTimeout(restartWorker, 1000);\n});\n}\n\n// Start the recursive process\nrestartWorker();\n}\n\n// Simulate a restart after 20 seconds\nsetTimeout(restartWorkers, 20000);\n\n// Handle normal worker exit\ncluster.on('exit', (worker, code, signal) => {\nif (worker.exitedAfterDisconnect !== true) {\nconsole.log(`Worker ${worker.process.pid} died unexpectedly, replacing it...`);\nconst newWorker = cluster.fork();\nworkers[workers.indexOf(worker)] = newWorker;\n}\n});\n} else {\n// Worker process\n\n// Create an HTTP server\nhttp.createServer((req, res) => {\nres.writeHead(200);\nres.end(`Worker ${process.pid} responding, uptime: ${process.uptime().toFixed(2)} seconds\\n`);\n}).listen(8000);\n\nconsole.log(`Worker ${process.pid} started`);\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;\n\n// Set the scheduling policy to SCHED_NONE (let workers accept connections themselves)\ncluster.schedulingPolicy = cluster.SCHED_NONE;\n\nif (cluster.isMaster) {\nconsole.log(`Master ${process.pid} is running`);\n\n// Fork workers\nfor (let i = 0; i < numCPUs; i++) {\ncluster.fork();\n}\n\ncluster.on('exit', (worker, code, signal) => {\nconsole.log(`Worker ${worker.process.pid} died`);\ncluster.fork();\n});\n} else {\n// Worker process\nhttp.createServer((req, res) => {\nres.writeHead(200);\nres.end(`Hello from Worker ${process.pid}\\n`);\n}).listen(8000);\n\nconsole.log(`Worker ${process.pid} started`);\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;\n\nif (cluster.isMaster) {\nconsole.log(`Master ${process.pid} is running`);\n\n// Fork workers\nfor (let i = 0; i < numCPUs; i++) {\ncluster.fork();\n}\n\n// Store worker references by id\nconst workers = {};\nfor (const id in cluster.workers) {\nworkers[id] = cluster.workers[id];\n}\n\n// Create a server to route connections to workers\nconst server = http.createServer((req, res) => {\n// Get client IP\nconst clientIP = req.connection.remoteAddress || req.socket.remoteAddress;\n\n// Simple hash function to determine which worker to use\nconst workerIndex = clientIP.split('.').reduce((a, b) => a + parseInt(b), 0) % numCPUs;\nconst workerIds = Object.keys(workers);\nconst workerId = workerIds[workerIndex];\n\n// Send the request to the selected worker\nworkers[workerId].send('sticky-session:connection', req.connection);\n\nres.end(`Request routed to worker ${workerId}`);\n}).listen(8000);\n\nconsole.log('Master server listening on port 8000');\n\n// Handle worker exit\ncluster.on('exit', (worker, code, signal) => {\nconsole.log(`Worker ${worker.process.pid} died`);\n\n// Remove the dead worker\ndelete workers[worker.id];\n\n// Create a replacement\nconst newWorker = cluster.fork();\nworkers[newWorker.id] = newWorker;\n});\n} else {\n// Worker process - just demonstrates the concept\n// In a real implementation, you'd need more socket handling\n\nprocess.on('message', (msg, socket) => {\nif (msg === 'sticky-session:connection' && socket) {\nconsole.log(`Worker ${process.pid} received sticky connection`);\n\n// In a real implementation, you'd handle the socket here\n// socket.end(`Handled by worker ${process.pid}\\n`);\n}\n});\n\n// Workers would also run their own server\nhttp.createServer((req, res) => {\nres.writeHead(200);\nres.end(`Direct request to Worker ${process.pid}\\n`);\n}).listen(8001);\n\nconsole.log(`Worker ${process.pid} started`);\n}",
        "const cluster = require('cluster');\nconst http = require('http');\n\nif (cluster.isMaster) {\nconsole.log(`Master ${process.pid} is running`);\n\n// Fork a worker\nconst worker = cluster.fork();\n\n// Listen for all worker lifecycle events\nworker.on('fork', () => {\nconsole.log(`Worker ${worker.process.pid} is being forked`);\n});\n\nworker.on('online', () => {\nconsole.log(`Worker ${worker.process.pid} is online`);\n});\n\nworker.on('listening', (address) => {\nconsole.log(`Worker ${worker.process.pid} is listening on port ${address.port}`);\n});\n\nworker.on('disconnect', () => {\nconsole.log(`Worker ${worker.process.pid} has disconnected`);\n});\n\nworker.on('exit', (code, signal) => {\nconsole.log(`Worker ${worker.process.pid} exited with code ${code} and signal ${signal}`);\n\nif (signal) {\nconsole.log(`Worker was killed by signal: ${signal}`);\n} else if (code !== 0) {\nconsole.log(`Worker exited with error code: ${code}`);\n} else {\nconsole.log('Worker exited successfully');\n}\n});\n\n// After 10 seconds, gracefully disconnect the worker\nsetTimeout(() => {\nconsole.log('Gracefully disconnecting worker...');\nworker.disconnect();\n}, 10000);\n\n} else {\n// Worker process\nconsole.log(`Worker ${process.pid} started`);\n\n// Create an HTTP server\nhttp.createServer((req, res) => {\nres.writeHead(200);\nres.end(`Hello from Worker ${process.pid}\\n`);\n}).listen(8000);\n\n// If worker is disconnected, close the server\nprocess.on('disconnect', () => {\nconsole.log(`Worker ${process.pid} disconnected, closing server...`);\n// In a real application, you'd want to close all connections and clean up resources\nprocess.exit(0);\n});\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;\n\nif (cluster.isMaster) {\nconsole.log(`Master ${process.pid} is running`);\n\n// Fork workers\nfor (let i = 0; i < numCPUs; i++) {\ncluster.fork();\n}\n\n// Handle termination signals\nprocess.on('SIGTERM', () => {\nconsole.log('Master received SIGTERM, initiating graceful shutdown...');\n\n// Notify all workers to finish their work and exit\nObject.values(cluster.workers).forEach(worker => {\nconsole.log(`Sending SIGTERM to worker ${worker.process.pid}`);\nworker.send('shutdown');\n});\n\n// Set a timeout to force-kill workers if they don't exit gracefully\nsetTimeout(() => {\nconsole.log('Some workers did not exit gracefully, forcing shutdown...');\nObject.values(cluster.workers).forEach(worker => {\nif (!worker.isDead()) {\nconsole.log(`Killing worker ${worker.process.pid}`);\nworker.process.kill('SIGKILL');\n}\n});\n\n// Exit the master\nconsole.log('All workers terminated, exiting master...');\nprocess.exit(0);\n}, 5000);\n});\n\n// Handle worker exits\ncluster.on('exit', (worker, code, signal) => {\nconsole.log(`Worker ${worker.process.pid} exited (${signal || code})`);\n\n// If all workers have exited, exit the master\nif (Object.keys(cluster.workers).length === 0) {\nconsole.log('All workers have exited, shutting down master...');\nprocess.exit(0);\n}\n});\n\n// Log to show the master is ready\nconsole.log(`Master ${process.pid} is ready with ${Object.keys(cluster.workers).length} workers`);\nconsole.log('Send SIGTERM to the master process to initiate graceful shutdown');\n\n} else {\n// Worker process\nconsole.log(`Worker ${process.pid} started`);\n\n// Track if we're shutting down\nlet isShuttingDown = false;\nlet activeConnections = 0;\n\n// Create HTTP server\nconst server = http.createServer((req, res) => {\n// Track active connection\nactiveConnections++;\n\n// Simulate a slow response\nsetTimeout(() => {\nres.writeHead(200);\nres.end(`Hello from Worker ${process.pid}\\n`);\n\n// Connection complete\nactiveConnections--;\n\n// If we're shutting down and no active connections, close the server\nif (isShuttingDown && activeConnections === 0) {\nconsole.log(`Worker ${process.pid} has no active connections, closing server...`);\nserver.close(() => {\nconsole.log(`Worker ${process.pid} closed server, exiting...`);\nprocess.exit(0);\n});\n}\n}, 2000);\n});\n\n// Start server\nserver.listen(8000);\n\n// Handle shutdown message from master\nprocess.on('message', (msg) => {\nif (msg === 'shutdown') {\nconsole.log(`Worker ${process.pid} received shutdown message, stopping new connections...`);\n\n// Set shutdown flag\nisShuttingDown = true;\n\n// Stop accepting new connections\nserver.close(() => {\nconsole.log(`Worker ${process.pid} closed server`);\n\n// If no active connections, exit immediately\nif (activeConnections === 0) {\nconsole.log(`Worker ${process.pid} has no active connections, exiting...`);\nprocess.exit(0);\n} else {\nconsole.log(`Worker ${process.pid} waiting for ${activeConnections} connections to finish...`);\n}\n});\n}\n});\n\n// Also handle direct termination signal\nprocess.on('SIGTERM', () => {\nconsole.log(`Worker ${process.pid} received SIGTERM directly`);\n// Use the same shutdown logic\nisShuttingDown = true;\nserver.close(() => process.exit(0));\n});\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nconst os = require('os');\nif (cluster.isMaster) {\nconsole.log(`Master ${process.pid} is running`);\n\n// Create workers with different weights\nconst workerWeights = [3, 2, 1]; // First worker gets 3x more load than the last\nconst workers = [];\n\n// Create workers based on weights\nworkerWeights.forEach((weight, index) => {\nfor (let i = 0; i < weight; i++) {\nconst worker = cluster.fork({ WORKER_WEIGHT: weight });\nworker.weight = weight;\nworkers.push(worker);\n}\n});\n\n// Track the next worker to use\nlet workerIndex = 0;\n\n// Create a load balancer server\nhttp.createServer((req, res) => {\n// Simple round-robin with weights\nconst worker = workers[workerIndex++ % workers.length];\nworker.send('handle-request', req.socket);\n}).listen(8000);\n\n} else {   // Worker code\nprocess.on('message', (message, socket) => {\nif (message === 'handle-request' && socket) {\n// Handle the request\nsocket.end(`Handled by worker ${process.pid}\\n`);\n}\n});\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nif (cluster.isMaster) {\nconsole.log(`Master ${process.pid} is running`);\n\n// Create workers and track their connection counts\nconst workers = [];\nconst numCPUs = require('os').cpus().length;\n\nfor (let i = 0; i < numCPUs; i++) {\nconst worker = cluster.fork();\nworker.connectionCount = 0;\nworkers.push(worker);\n\n// Track worker connections\nworker.on('message', (msg) => {       if (msg.type === 'connection') {         worker.connectionCount = msg.count;       }     });\n}\n// Create load balancer\nhttp.createServer((req, res) => {\n// Find worker with least connections\nlet minConnections = Infinity;\nlet selectedWorker = null;\n\nfor (const worker of workers) {\nif (worker.connectionCount < minConnections) {\nminConnections = worker.connectionCount;\nselectedWorker = worker;\n}\n}\n\nif (selectedWorker) {\nselectedWorker.send('handle-request', req.socket);\n}\n}).listen(8000);\n}",
        "const cluster = require('cluster');\nconst os = require('os');\nconst promClient = require('prom-client');\nif (cluster.isMaster) {\n// Create metrics registry\nconst register = new promClient.Registry();\npromClient.collectDefaultMetrics({ register });\n\n// Custom metrics\nconst workerRequests = new promClient.Counter({\nname: 'worker_requests_total',\nhelp: 'Total requests handled by worker',\nlabelNames: ['worker_pid']\n});\nregister.registerMetric(workerRequests);\n\n// Fork workers\nfor (let i = 0; i < os.cpus().length; i++) {\nconst worker = cluster.fork();\nworker.on('message', (msg) => {\nif (msg.type === 'request_processed') {\nworkerRequests.inc({ worker_pid: worker.process.pid });\n}\n});\n}\n\n// Expose metrics endpoint\nrequire('http').createServer(async (req, res) => {\nif (req.url === '/metrics') {\nres.setHeader('Content-Type', register.contentType);\nres.end(await register.metrics());\n}\n}).listen(9090);\n} else {\n// Worker code\nlet requestCount = 0;\n\nrequire('http').createServer((req, res) => {\nrequestCount++;\nprocess.send({ type: 'request_processed' });\nres.end(`Request ${requestCount} handled by worker ${process.pid}\\n`);\n}).listen(8000);\n}",
        "// Dockerfile example for a Node.js cluster app\nFROM node:16-slim\n\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install --production\n\n# Copy application code\nCOPY . .\n\n# Use the node process as PID 1 for proper signal handling\nCMD [\"node\", \"cluster.js\"]\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=3s \\\nCMD curl -f http://localhost:8080/health || exit 1",
        "# k8s-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: node-cluster-app\nspec:\nreplicas: 3 # Number of pods\nselector:\nmatchLabels:\napp: node-cluster\ntemplate:\nmetadata:\nlabels:\napp: node-cluster\nspec:\ncontainers:\n- name: node-app\nimage: your-image:latest\nports:\n- containerPort: 8000\nresources:\nrequests:\ncpu: \"500m\"\nmemory: \"512Mi\"\nlimits:\ncpu: \"1000m\"\nmemory: \"1Gi\"\nlivenessProbe:\nhttpGet:\npath: /health\nport: 8000\ninitialDelaySeconds: 5\nperiodSeconds: 10\nreadinessProbe:\nhttpGet:\npath: /ready\nport: 8000\ninitialDelaySeconds: 5\nperiodSeconds: 10",
        "// In worker process\nconst MAX_MEMORY_MB = 500; // Max memory in MB before recycling\n\nfunction checkMemory() {\nconst memoryUsage = process.memoryUsage();\nconst memoryMB = memoryUsage.heapUsed / 1024 / 1024;\n\nif (memoryMB > MAX_MEMORY_MB) {\nconsole.log(`Worker ${process.pid} memory ${memoryMB.toFixed(2)}MB exceeds limit, exiting...`);\nprocess.exit(1); // Let cluster restart the worker\n}\n}\n\n// Check memory every 30 seconds\nsetInterval(checkMemory, 30000);",
        "// In master process\nif (cluster.isMaster) {\nconst numWorkers = require('os').cpus().length;\n\nfunction forkWorker(delay) {\nsetTimeout(() => {\nconst worker = cluster.fork();\nconsole.log(`Worker ${worker.process.pid} started after ${delay}ms delay`);\n}, delay);\n}\n\n// Stagger worker starts by 1 second\nfor (let i = 0; i < numWorkers; i++) {\nforkWorker(i * 1000);\n}\n}",
        "// Track request distribution\nconst requestDistribution = new Map();\n\n// In master process\nif (cluster.isMaster) {\n// ...\n\n// Monitor request distribution\nsetInterval(() => {\nconsole.log('Request distribution:');\nrequestDistribution.forEach((count, pid) => {\nconsole.log(` Worker ${pid}: ${count} requests`);\n});\n}, 60000);\n\n// Track requests per worker\ncluster.on('message', (worker, message) => {\nif (message.type === 'request_handled') {\nconst count = requestDistribution.get(worker.process.pid) || 0;\nrequestDistribution.set(worker.process.pid, count + 1);\n}\n});\n}",
        "fork()",
        "send()",
        "message",
        "cluster.schedulingPolicy",
        "fork",
        "online",
        "listening",
        "disconnect",
        "exit"
      ]
    },
    {
      "title": "Node.js Worker Threads Module",
      "summary": "What are Worker Threads?\nWorker Threads are a feature introduced in Node.js (initially in v10.5.0 as an experimental feature and stabilized in v12) that allows JavaScript code to run in parallel across multiple CPU cores.\nUnlike the child_process or cluster modules, which create separate Node.js processes, Worker Threads can share memory and run true parallel JavaScript code.\nThe Node.js Worker Threads module addresses the limitations of Node.js's single-threaded nature for CPU-intensive tasks.\nWhile Node.js excels at I/O-bound operations thanks to its asynchronous event loop, it can struggle with CPU-bound tasks that can block the main thread and affect application performance.\nNote: Worker Threads are different from Web Workers in browsers, although they share similar concepts. Node.js Worker Threads are specifically designed for the Node.js runtime environment.\nWhen to Use Worker Threads\nWorker Threads are most useful for:\nCPU-intensive operations (large calculations, data processing)\nParallel processing of data\nOperations that would otherwise block the main thread\nThey are not necessary for:\nI/O-bound operations (file system, network)\nOperations that already use asynchronous APIs\nSimple tasks that complete quickly\nImporting the Worker Threads Module\nThe Worker Threads module is included in Node.js by default. You can use it by requiring it in your script:\nKey Components\nCreating Your First Worker Thread\nLet's create a simple example where the main thread creates a worker to perform a CPU-intensive task:\nIn this example:\nThe main thread creates a worker with some initial data\nThe worker performs a CPU-intensive calculation\nThe worker sends the result back to the main thread\nThe main thread receives and processes the result\nKey Concepts in the Example\nThe Worker constructor takes the path to the worker script and an options object\nThe workerData option is used to pass initial data to the worker\nThe worker communicates back to the main thread using parentPort.postMessage()\nEvent handlers (message, error, exit) are used to manage the worker lifecycle\nCommunication Between Threads\nWorker threads communicate by passing messages.\nThe communication is bidirectional, meaning both the main thread and workers can send and receive messages.\nMain Thread to Worker\nNote: Messages passed between threads are copied by value (serialized), not shared by reference.\nThis means that when you send an object from one thread to another, changes to the object in one thread will not affect the copy in the other thread.\nCPU-Intensive Task Example\nHere's a more practical example that demonstrates the advantage of using worker threads for CPU-intensive tasks:\nThis example calculates Fibonacci numbers using both a single-threaded approach and a multi-threaded approach with worker threads.\nOn a multi-core CPU, the worker threads version should be significantly faster because it can utilize multiple CPU cores to calculate the Fibonacci numbers in parallel.\nWarning: While worker threads can significantly improve performance for CPU-bound tasks, they do come with overhead for creation and communication. For very small tasks, this overhead might outweigh the benefits.\nSharing Data with Worker Threads\nThere are several ways to share data between threads:\nPassing copies: The default behavior when using postMessage()\nTransferring ownership: Using the transferList parameter of postMessage()\nSharing memory: Using SharedArrayBuffer\nTransferring ArrayBuffers\nWhen you transfer an ArrayBuffer, you're transferring ownership of the buffer from one thread to another, without copying the data. This is more efficient for large data:\nNote: After transferring an ArrayBuffer, the original buffer becomes unusable (its byteLength becomes 0).\nThe receiving thread gains full access to the buffer.\nSharing Memory with SharedArrayBuffer\nFor scenarios where you need to share data between threads without copying or transferring, the SharedArrayBuffer provides a way to access the same memory from multiple threads.\nWarning: SharedArrayBuffer may be disabled in some Node.js versions due to security considerations related to Spectre vulnerabilities. Check your Node.js version documentation for details on how to enable it if needed.\nSynchronizing Access with Atomics\nWhen multiple threads access shared memory, you need a way to synchronize access to prevent race conditions.\nThe Atomics object provides methods for atomic operations on shared memory arrays.\nNote: The Atomics object provides methods like load, store, add, wait, and notify for synchronizing access to shared memory and implementing coordination patterns between threads.\nCreating a Worker Pool\nFor most applications, you'll want to create a pool of workers to handle multiple tasks concurrently.\nHere's an implementation of a simple worker pool:\nUsing the worker pool:\nNote: This worker pool implementation handles task scheduling, worker errors, and automatic worker replacement.\nIt's a good starting point for real-world applications but can be expanded with features like worker timeouts and prioritized tasks.\nPractical Application: Image Processing\nImage processing is a perfect use case for worker threads as it's both CPU-intensive and easily parallelizable.\nHere's an example of parallel image processing:\nWorker Threads vs. Child Process and Cluster\nIt's important to understand when to use Worker Threads versus other Node.js concurrency mechanisms:\nWhen to Use Worker Threads\nCPU-bound tasks like number crunching, image processing, or compression\nWhen shared memory is needed for better performance\nWhen you need to run parallel JavaScript code within a single Node.js instance\nWhen to Use Child Process\nRunning external programs or commands\nExecuting tasks in different languages\nWhen you need stronger isolation between the main process and the spawned processes\nWhen to Use Cluster\nScaling an HTTP server across multiple cores\nLoad balancing incoming connections\nImproving application resilience and uptime\nBest Practices\nDon't overuse threads: Only use worker threads for CPU-intensive tasks that would otherwise block the main thread.\nConsider the overhead: Creating threads has overhead. For very short tasks, this overhead might outweigh the benefits.\nUse a worker pool: Reuse workers for multiple tasks instead of creating and destroying them for each task.\nMinimize data transfer: Transfer ownership with ArrayBuffer or use SharedArrayBuffer when working with large amounts of data.\nHandle errors properly: Always catch errors from workers and have a strategy for worker failures.\nMonitor worker lifecycles: Keep track of worker health and restart them if they crash.\nUse appropriate synchronization: Use Atomics for coordinating access to shared memory.\nBenchmark your solution: Always measure the performance improvement to ensure threads are actually helping.\nWarning: Threading adds complexity to your code. Only use worker threads when you have a genuine need for parallel execution. For I/O-bound operations, Node.js's built-in asynchronous APIs are usually more efficient.\nSummary\nThe Worker Threads module provides true multithreading capabilities in Node.js, enabling CPU-intensive tasks to run in parallel without blocking the main event loop.\nIn this tutorial, we've covered:\nSharing data between threads using SharedArrayBuffer\nSynchronizing thread access with Atomics\nCreating a reusable worker pool for efficient task management\nPractical applications like parallel image processing\nComparison with other Node.js concurrency models\nBest practices for using worker threads effectively",
      "examples": [
        "const {\nWorker,\nisMainThread,\nparentPort,\nworkerData\n} = require('worker_threads');",
        "// main.js\nconst { Worker } = require('worker_threads');\n\n// Function to create a new worker\nfunction runWorker(workerData) {\nreturn new Promise((resolve, reject) => {\n// Create a new worker\nconst worker = new Worker('./worker.js', { workerData });\n\n// Listen for messages from the worker\nworker.on('message', resolve);\n\n// Listen for errors\nworker.on('error', reject);\n\n// Listen for worker exit\nworker.on('exit', (code) => {\nif (code !== 0) {\nreject(new Error(`Worker stopped with exit code ${code}`));\n}\n});\n});\n}\n\n// Run the worker\nasync function run() {\ntry {\n// Send data to the worker and get the result\nconst result = await runWorker('Hello from main thread!');\nconsole.log('Worker result:', result);\n} catch (err) {\nconsole.error('Worker error:', err);\n}\n}\n\nrun().catch(err => console.error(err));",
        "// worker.js\nconst { parentPort, workerData } = require('worker_threads');\n\n// Receive message from the main thread\nconsole.log('Worker received:', workerData);\n\n// Simulate CPU-intensive task\nfunction performCPUIntensiveTask() {\n// Simple example: Sum up to a large number\nlet result = 0;\nfor (let i = 0; i < 1_000_000; i++) {\nresult += i;\n}\nreturn result;\n}\n\n// Perform the task\nconst result = performCPUIntensiveTask();\n\n// Send the result back to the main thread\nparentPort.postMessage({\nreceivedData: workerData,\ncalculatedSum: result\n});",
        "// main.js\nconst { Worker } = require('worker_threads');\n\n// Create a worker\nconst worker = new Worker('./message_worker.js');\n\n// Send messages to the worker\nworker.postMessage('Hello worker!');\nworker.postMessage({ type: 'task', data: [1, 2, 3, 4, 5] });\n\n// Receive messages from the worker\nworker.on('message', (message) => {\nconsole.log('Main thread received:', message);\n});\n\n// Handle worker completion\nworker.on('exit', (code) => {\nconsole.log(`Worker exited with code ${code}`);\n});",
        "// message_worker.js\nconst { parentPort } = require('worker_threads');\n\n// Receive messages from the main thread\nparentPort.on('message', (message) => {\nconsole.log('Worker received:', message);\n\n// Process different message types\nif (typeof message === 'object' && message.type === 'task') {\nconst result = processTask(message.data);\nparentPort.postMessage({ type: 'result', data: result });\n} else {\n// Echo the message back\nparentPort.postMessage(`Worker echoing: ${message}`);\n}\n});\n\n// Example task processor\nfunction processTask(data) {\nif (Array.isArray(data)) {\nreturn data.map(x => x * 2);\n}\nreturn null;\n}",
        "// fibonacci.js\nconst { Worker, isMainThread, parentPort, workerData } = require('worker_threads');\n\n// Recursive Fibonacci function (deliberately inefficient to simulate CPU load)\nfunction fibonacci(n) {\nif (n <= 1) return n;\nreturn fibonacci(n - 1) + fibonacci(n - 2);\n}\n\nif (isMainThread) {\n// This code runs in the main thread\n\n// Function to run a worker\nfunction runFibonacciWorker(n) {\nreturn new Promise((resolve, reject) => {\nconst worker = new Worker(__filename, { workerData: n });\nworker.on('message', resolve);\nworker.on('error', reject);\nworker.on('exit', (code) => {\nif (code !== 0) {\nreject(new Error(`Worker stopped with exit code ${code}`));\n}\n});\n});\n}\n\n// Measure execution time with and without workers\nasync function run() {\nconst numbers = [40, 41, 42, 43];\n\n// Using a single thread (blocking)\nconsole.time('Single thread');\nfor (const n of numbers) {\nconsole.log(`Fibonacci(${n}) = ${fibonacci(n)}`);\n}\nconsole.timeEnd('Single thread');\n\n// Using worker threads (parallel)\nconsole.time('Worker threads');\nconst results = await Promise.all(\nnumbers.map(n => runFibonacciWorker(n))\n);\nfor (let i = 0; i < numbers.length; i++) {\nconsole.log(`Fibonacci(${numbers[i]}) = ${results[i]}`);\n}\nconsole.timeEnd('Worker threads');\n}\n\nrun().catch(err => console.error(err));\n} else {\n// This code runs in worker threads\n\n// Calculate Fibonacci number\nconst result = fibonacci(workerData);\n\n// Send the result back to the main thread\nparentPort.postMessage(result);\n}",
        "// transfer_main.js\nconst { Worker } = require('worker_threads');\n\n// Create a large buffer\nconst buffer = new ArrayBuffer(100 * 1024 * 1024); // 100MB\nconst view = new Uint8Array(buffer);\n\n// Fill with data\nfor (let i = 0; i < view.length; i++) {\nview[i] = i % 256;\n}\n\nconsole.log('Buffer created in main thread');\nconsole.log('Buffer byteLength before transfer:', buffer.byteLength);\n\n// Create a worker and transfer the buffer\nconst worker = new Worker('./transfer_worker.js');\nworker.on('message', (message) => {\nconsole.log('Message from worker:', message);\n\n// After transfer, the buffer is no longer usable in main thread\nconsole.log('Buffer byteLength after transfer:', buffer.byteLength);\n});\n\n// Transfer ownership of the buffer to the worker\nworker.postMessage({ buffer }, [buffer]);",
        "// transfer_worker.js\nconst { parentPort } = require('worker_threads');\n\nparentPort.on('message', ({ buffer }) => {\nconst view = new Uint8Array(buffer);\n\n// Calculate sum to verify data\nlet sum = 0;\nfor (let i = 0; i < view.length; i++) {\nsum += view[i];\n}\n\nconsole.log('Buffer received in worker');\nconsole.log('Buffer byteLength in worker:', buffer.byteLength);\nconsole.log('Sum of all values:', sum);\n\n// Send confirmation back\nparentPort.postMessage('Buffer processed successfully');\n});",
        "// shared_main.js\nconst { Worker } = require('worker_threads');\n\n// Create a shared buffer\nconst sharedBuffer = new SharedArrayBuffer(4 * 10); // 10 Int32 values\nconst sharedArray = new Int32Array(sharedBuffer);\n\n// Initialize the shared array\nfor (let i = 0; i < sharedArray.length; i++) {\nsharedArray[i] = i;\n}\n\nconsole.log('Initial shared array in main thread:', [...sharedArray]);\n\n// Create a worker that will update the shared memory\nconst worker = new Worker('./shared_worker.js', {\nworkerData: { sharedBuffer }\n});\n\nworker.on('message', (message) => {\nconsole.log('Message from worker:', message);\nconsole.log('Updated shared array in main thread:', [...sharedArray]);\n\n// The changes made in the worker are visible here\n// because we're accessing the same memory\n});",
        "// shared_worker.js\nconst { parentPort, workerData } = require('worker_threads');\nconst { sharedBuffer } = workerData;\n\n// Create a new view on the shared buffer\nconst sharedArray = new Int32Array(sharedBuffer);\n\nconsole.log('Initial shared array in worker:', [...sharedArray]);\n\n// Modify the shared memory\nfor (let i = 0; i < sharedArray.length; i++) {\n// Double each value\nsharedArray[i] = sharedArray[i] * 2;\n}\n\nconsole.log('Updated shared array in worker:', [...sharedArray]);\n\n// Notify the main thread\nparentPort.postMessage('Shared memory updated');",
        "// atomics_main.js\nconst { Worker } = require('worker_threads');\n\n// Create a shared buffer with control flags and data\nconst sharedBuffer = new SharedArrayBuffer(4 * 10);\nconst sharedArray = new Int32Array(sharedBuffer);\n\n// Initialize values\nsharedArray[0] = 0; // Control flag: 0 = main thread's turn, 1 = worker's turn\nsharedArray[1] = 0; // Data value to increment\n\n// Create workers\nconst workerCount = 4;\nconst workerIterations = 10;\nconst workers = [];\n\nconsole.log(`Creating ${workerCount} workers with ${workerIterations} iterations each`);\n\nfor (let i = 0; i < workerCount; i++) {\nconst worker = new Worker('./atomics_worker.js', {\nworkerData: { sharedBuffer, id: i, iterations: workerIterations }\n});\n\nworkers.push(worker);\n\nworker.on('exit', () => {\nconsole.log(`Worker ${i} exited`);\n\n// If all workers have exited, show final value\nif (workers.every(w => w.threadId === -1)) {\nconsole.log(`Final value: ${sharedArray[1]}`);\nconsole.log(`Expected value: ${workerCount * workerIterations}`);\n}\n});\n}\n\n// Signal to the first worker to start\nAtomics.store(sharedArray, 0, 1);\nAtomics.notify(sharedArray, 0);",
        "// atomics_worker.js\nconst { parentPort, workerData } = require('worker_threads');\nconst { sharedBuffer, id, iterations } = workerData;\n\n// Create a typed array from the shared memory\nconst sharedArray = new Int32Array(sharedBuffer);\n\nfor (let i = 0; i < iterations; i++) {\n// Wait for this worker's turn\nwhile (Atomics.load(sharedArray, 0) !== id + 1) {\n// Wait for notification\nAtomics.wait(sharedArray, 0, Atomics.load(sharedArray, 0));\n}\n\n// Increment the shared counter\nconst currentValue = Atomics.add(sharedArray, 1, 1);\nconsole.log(`Worker ${id} incremented counter to ${currentValue + 1}`);\n\n// Signal to the next worker\nconst nextWorkerId = (id + 1) % (iterations === 0 ? 1 : iterations);\nAtomics.store(sharedArray, 0, nextWorkerId + 1);\nAtomics.notify(sharedArray, 0);\n}\n\n// Exit the worker\nparentPort.close();",
        "// worker_pool.js\nconst { Worker } = require('worker_threads');\nconst os = require('os');\nconst path = require('path');\n\nclass WorkerPool {\nconstructor(workerScript, numWorkers = os.cpus().length) {\nthis.workerScript = workerScript;\nthis.numWorkers = numWorkers;\nthis.workers = [];\nthis.freeWorkers = [];\nthis.tasks = [];\n\n// Initialize workers\nthis._initialize();\n}\n\n_initialize() {\n// Create all workers\nfor (let i = 0; i < this.numWorkers; i++) {\nthis._createWorker();\n}\n}\n\n_createWorker() {\nconst worker = new Worker(this.workerScript);\n\nworker.on('message', (result) => {\n// Get the current task\nconst { resolve } = this.tasks.shift();\n\n// Resolve the task with the result\nresolve(result);\n\n// Add this worker back to the free workers pool\nthis.freeWorkers.push(worker);\n\n// Process the next task if any\nthis._processQueue();\n});\n\nworker.on('error', (err) => {\n// If a worker errors, terminate it and create a new one\nconsole.error(`Worker error: ${err}`);\nthis._removeWorker(worker);\nthis._createWorker();\n\n// Process the next task\nif (this.tasks.length > 0) {\nconst { reject } = this.tasks.shift();\nreject(err);\nthis._processQueue();\n}\n});\n\nworker.on('exit', (code) => {\nif (code !== 0) {\nconsole.error(`Worker exited with code ${code}`);\nthis._removeWorker(worker);\nthis._createWorker();\n}\n});\n\n// Add to free workers\nthis.workers.push(worker);\nthis.freeWorkers.push(worker);\n}\n\n_removeWorker(worker) {\n// Remove from the workers arrays\nthis.workers = this.workers.filter(w => w !== worker);\nthis.freeWorkers = this.freeWorkers.filter(w => w !== worker);\n}\n\n_processQueue() {\n// If there are tasks and free workers, process the next task\nif (this.tasks.length > 0 && this.freeWorkers.length > 0) {\nconst { taskData } = this.tasks[0];\nconst worker = this.freeWorkers.pop();\nworker.postMessage(taskData);\n}\n}\n\n// Run a task on a worker\nrunTask(taskData) {\nreturn new Promise((resolve, reject) => {\nconst task = { taskData, resolve, reject };\nthis.tasks.push(task);\nthis._processQueue();\n});\n}\n\n// Close all workers when done\nclose() {\nfor (const worker of this.workers) {\nworker.terminate();\n}\n}\n}\n\nmodule.exports = WorkerPool;",
        "// pool_usage.js\nconst WorkerPool = require('./worker_pool');\nconst path = require('path');\n\n// Create a worker pool with the worker script\nconst pool = new WorkerPool(path.resolve(__dirname, 'pool_worker.js'));\n\n// Function to run tasks on the pool\nasync function runTasks() {\nconst tasks = [\n{ type: 'fibonacci', data: 40 },\n{ type: 'factorial', data: 15 },\n{ type: 'prime', data: 10000000 },\n{ type: 'fibonacci', data: 41 },\n{ type: 'factorial', data: 16 },\n{ type: 'prime', data: 20000000 },\n{ type: 'fibonacci', data: 42 },\n{ type: 'factorial', data: 17 },\n];\n\nconsole.time('All tasks');\n\ntry {\n// Run all tasks in parallel\nconst results = await Promise.all(\ntasks.map(task => {\nconsole.time(`Task: ${task.type}(${task.data})`);\nreturn pool.runTask(task)\n.then(result => {\nconsole.timeEnd(`Task: ${task.type}(${task.data})`);\nreturn result;\n});\n})\n);\n\n// Log results\nfor (let i = 0; i < tasks.length; i++) {\nconsole.log(`${tasks[i].type}(${tasks[i].data}) = ${results[i].result}`);\n}\n} catch (err) {\nconsole.error('Error running tasks:', err);\n} finally {\nconsole.timeEnd('All tasks');\npool.close();\n}\n}\n\nrunTasks().catch(console.error);",
        "// pool_worker.js\nconst { parentPort } = require('worker_threads');\n\n// Fibonacci function\nfunction fibonacci(n) {\nif (n <= 1) return n;\nreturn fibonacci(n - 1) + fibonacci(n - 2);\n}\n\n// Factorial function\nfunction factorial(n) {\nif (n <= 1) return 1;\nreturn n * factorial(n - 1);\n}\n\n// Prime count function\nfunction countPrimes(max) {\nconst sieve = new Uint8Array(max);\nlet count = 0;\n\nfor (let i = 2; i < max; i++) {\nif (!sieve[i]) {\ncount++;\nfor (let j = i * 2; j < max; j += i) {\nsieve[j] = 1;\n}\n}\n}\n\nreturn count;\n}\n\n// Handle messages from the main thread\nparentPort.on('message', (task) => {\nconst { type, data } = task;\nlet result;\n\n// Perform different calculations based on task type\nswitch (type) {\ncase 'fibonacci':\nresult = fibonacci(data);\nbreak;\ncase 'factorial':\nresult = factorial(data);\nbreak;\ncase 'prime':\nresult = countPrimes(data);\nbreak;\ndefault:\nthrow new Error(`Unknown task type: ${type}`);\n}\n\n// Send the result back\nparentPort.postMessage({ result });\n});",
        "// image_main.js\nconst { Worker } = require('worker_threads');\nconst path = require('path');\nconst fs = require('fs');\n\n// Function to process an image in a worker\nfunction processImageInWorker(imagePath, options) {\nreturn new Promise((resolve, reject) => {\nconst worker = new Worker('./image_worker.js', {\nworkerData: {\nimagePath,\noptions\n}\n});\n\nworker.on('message', resolve);\nworker.on('error', reject);\nworker.on('exit', (code) => {\nif (code !== 0) {\nreject(new Error(`Worker stopped with exit code ${code}`));\n}\n});\n});\n}\n\n// Main function to process multiple images in parallel\nasync function processImages() {\nconst images = [\n{ path: 'image1.jpg', options: { grayscale: true } },\n{ path: 'image2.jpg', options: { blur: 5 } },\n{ path: 'image3.jpg', options: { sharpen: 10 } },\n{ path: 'image4.jpg', options: { resize: { width: 800, height: 600 } } }\n];\n\nconsole.time('Image processing');\n\ntry {\n// Process all images in parallel\nconst results = await Promise.all(\nimages.map(img => processImageInWorker(img.path, img.options))\n);\n\nconsole.log('All images processed successfully');\nconsole.log('Results:', results);\n} catch (err) {\nconsole.error('Error processing images:', err);\n}\n\nconsole.timeEnd('Image processing');\n}\n\n// Note: This is a conceptual example.\n// In a real application, you would use an image processing library like sharp or jimp\n// and provide actual image files.\n// processImages().catch(console.error);\nconsole.log('Image processing example (not actually running)');",
        "// image_worker.js\nconst { parentPort, workerData } = require('worker_threads');\nconst { imagePath, options } = workerData;\n\n// In a real application, you would import an image processing library here\n// const sharp = require('sharp');\n\n// Simulate image processing\nfunction processImage(imagePath, options) {\nconsole.log(`Processing image: ${imagePath} with options:`, options);\n\n// Simulate processing time based on options\nlet processingTime = 500; // Base time in ms\n\nif (options.grayscale) processingTime += 200;\nif (options.blur) processingTime += options.blur * 50;\nif (options.sharpen) processingTime += options.sharpen * 30;\nif (options.resize) processingTime += 300;\n\n// Simulate the actual processing\nreturn new Promise(resolve => {\nsetTimeout(() => {\n// Return simulated result\nresolve({\nimagePath,\noutputPath: `processed_${imagePath}`,\nprocessing: options,\ndimensions: options.resize || { width: 1024, height: 768 },\nsize: Math.floor(Math.random() * 1000000) + 500000 // Random file size\n});\n}, processingTime);\n});\n}\n\n// Process the image and send the result back\nprocessImage(imagePath, options)\n.then(result => {\nparentPort.postMessage(result);\n})\n.catch(err => {\nthrow err;\n});",
        "child_process",
        "cluster",
        "Worker",
        "isMainThread",
        "parentPort",
        "workerData",
        "MessageChannel",
        "MessagePort",
        "threadId",
        "parentPort.postMessage()",
        "message",
        "error",
        "exit",
        "postMessage()",
        "transferList",
        "SharedArrayBuffer",
        "Atomics",
        "load",
        "store",
        "add",
        "wait",
        "notify"
      ]
    },
    {
      "title": "Node.js Microservices",
      "summary": "Introduction to Microservices\nMicroservices is an architectural style that structures an application as a collection of small, loosely coupled services. Each service is:\nFocused on a single business capability\nIndependently deployable\nIndependently scalable\nPotentially written in different programming languages\nPotentially using different data storage technologies\nMicroservices architecture enables faster development cycles, better scalability, and improved resilience compared to traditional monolithic applications.\nMonoliths vs Microservices\nREMOVE ADS\nKey Principles\nSingle Responsibility - Each microservice should focus on doing one thing well - implementing a single business capability.\nDecentralization - Decentralize everything: governance, data management, and architecture decisions.\nAutonomous Services - Services should be able to change and deploy independently without affecting others.\nDomain-Driven Design - Design services around business domains rather than technical functions.\nResilience - Services should be designed to handle failure of other services.\nObservability - Implement comprehensive monitoring, logging, and tracing across services.\nBest Practice: Start with a clear domain model and identify bounded contexts before splitting an application into microservices.\nNode.js for Microservices\nNode.js is particularly well-suited for microservices architecture for several reasons:\nLightweight and Fast - Node.js has a small footprint and starts quickly, making it ideal for microservices that need to scale rapidly.\nAsynchronous and Event-Driven - Node.js's non-blocking I/O model makes it efficient for handling many concurrent connections between services.\nJSON Support - First-class JSON support makes data exchange between microservices straightforward.\nNPM Ecosystem - The vast package ecosystem provides libraries for service discovery, API gateways, monitoring, and more.\nExample: Simple Node.js MicroserviceGet your own Node.js Server\nService Communication\nMicroservices need ways to communicate with each other.\nThere are two fundamental approaches:\nSynchronous Communication\nServices directly call each other's APIs, creating a real-time request-response flow:\nREST: Simple, widely used, stateless communication\nGraphQL: Flexible queries with a single endpoint\ngRPC: High-performance RPC framework using Protocol Buffers\nExample: REST Communication Between Services\nNote: Synchronous communication creates direct dependencies between services.\nIf the called service is down or slow, it affects the calling service, potentially causing cascading failures.\nAsynchronous Communication\nServices communicate through message brokers or event buses without waiting for immediate responses:\nMessage Queues: RabbitMQ, ActiveMQ for point-to-point messaging\nPub/Sub: Kafka, Redis Pub/Sub for publishing messages to multiple subscribers\nEvent Streaming: Kafka, AWS Kinesis for handling data streams\nExample: Event-Driven Communication with an Event Bus\nHandling Service Failures\nIn microservices, you need strategies for handling communication failures:\nExample: Circuit Breaker Implementation\nAsynchronous Communication\nServices communicate through message brokers or event buses:\nMessage Queues: RabbitMQ, ActiveMQ\nStreaming Platforms: Apache Kafka, AWS Kinesis\nEvent Buses: Redis Pub/Sub, NATS\nExample: Asynchronous Communication with RabbitMQ\nBest Practice: For operations that don't need immediate responses, use asynchronous messaging to improve resilience and reduce coupling between services.\nAPI Gateway Pattern\nAn API Gateway acts as a single entry point for all client requests to a microservices architecture.\nResponsibilities of an API Gateway\nRequest Routing: Directs client requests to appropriate services\nAPI Composition: Aggregates responses from multiple services\nProtocol Translation: Converts between protocols (e.g., HTTP to gRPC)\nAuthentication & Authorization: Handles security concerns\nRate Limiting: Prevents abuse of the API\nMonitoring & Logging: Provides visibility into API usage\nExample: API Gateway Implementation\nBest Practice: Use a dedicated API Gateway like Kong, Netflix Zuul, or cloud solutions like AWS API Gateway in production environments instead of building your own.\nService Discovery\nService discovery enables microservices to find and communicate with each other dynamically without hardcoded endpoints.\nService Discovery Methods\nExample: Client-Side Service Discovery\nPopular Service Discovery Tools\nConsul: Service discovery and configuration\netcd: Distributed key-value store\nZooKeeper: Centralized service for configuration and synchronization\nEureka: REST-based service discovery for the AWS cloud\nKubernetes Service Discovery: Built-in service discovery for Kubernetes\nData Management Strategies\nManaging data in a microservices architecture requires different approaches than monolithic applications.\nDatabase Per Service\nEach microservice has its own dedicated database, ensuring loose coupling and independent scaling.\nNote: The Database Per Service pattern allows each service to choose the most appropriate database technology for its needs (SQL, NoSQL, Graph DB, etc.).\nDistributed Transactions\nMaintaining data consistency across services without ACID transactions requires special patterns:\nA sequence of local transactions where each transaction updates data within a single service. Each local transaction publishes an event that triggers the next transaction.\nExample: Saga Pattern Implementation\nEvent Sourcing stores all changes to application state as a sequence of events. Command Query Responsibility Segregation (CQRS) separates read and write operations.\nExample: Event Sourcing\nMicroservice Patterns\nSeveral design patterns help solve common challenges in microservices architectures:\nAPI Gateway\nA single entry point for all client requests that routes to the appropriate services.\nCircuit Breaker\nPrevents cascading failures by failing fast when a service is unresponsive.\nService Discovery\nAllows services to find and communicate with each other without hardcoded locations.\nSaga Pattern\nManages distributed transactions across multiple services.\nCQRS (Command Query Responsibility Segregation)\nSeparates read and write operations for better performance and scalability.\nBulkhead Pattern\nIsolates failures to prevent them from cascading throughout the system.\nAdvanced Tip: Consider using a service mesh like Istio or Linkerd to handle service-to-service communication, including traffic management, security, and observability.\nDeployment Strategies\nMicroservices benefit from modern deployment approaches:\nContainerization\nDocker containers provide consistent environments for each microservice.\nExample Dockerfile for a Node.js Microservice\nOrchestration\nTools like Kubernetes automate deployment, scaling, and management of containerized services.\nExample Kubernetes Deployment\nContinuous Deployment\nCI/CD pipelines automate testing and deployment of individual services.\nInfrastructure as Code\nTools like Terraform or AWS CloudFormation define infrastructure in a declarative way.\nBest Practice: Use blue-green or canary deployment strategies to minimize downtime and risk when updating microservices.\nAdvanced Microservice Patterns\n1. Circuit Breaker Pattern\nPrevent cascading failures when services are down:\n2. Saga Pattern\nManage distributed transactions across microservices:\nMicroservices Security\n1. Service-to-Service Authentication\n2. Rate Limiting\nMonitoring and Observability\n1. Distributed Tracing with OpenTelemetry\n2. Structured Logging",
      "examples": [
        "// user-service.js\nconst express = require('express');\nconst app = express();\n\napp.use(express.json());\n\n// In-memory user database for demonstration\nconst users = [\n{ id: 1, name: 'John Doe', email: 'john@example.com' },\n{ id: 2, name: 'Jane Smith', email: 'jane@example.com' }\n];\n\n// Get all users\napp.get('/users', (req, res) => {\nres.json(users);\n});\n\n// Get user by ID\napp.get('/users/:id', (req, res) => {\nconst user = users.find(u => u.id === parseInt(req.params.id));\nif (!user) return res.status(404).json({ message: 'User not found' });\nres.json(user);\n});\n\n// Create a new user\napp.post('/users', (req, res) => {\nconst newUser = {\nid: users.length + 1,\nname: req.body.name,\nemail: req.body.email\n};\nusers.push(newUser);\nres.status(201).json(newUser);\n});\n\nconst PORT = process.env.PORT || 8080;\napp.listen(PORT, () => {\nconsole.log(`User service running on port ${PORT}`);\n});",
        "// order-service.js calling the user-service\nconst axios = require('axios');\n\nasync function getUserDetails(userId) {\ntry {\nconst response = await axios.get(`http://user-service:3001/users/${userId}`);\nreturn response.data;\n} catch (error) {\nconsole.error(`Error fetching user ${userId}:`, error.message);\nthrow new Error('User service unavailable');\n}\n}\n\n// Route handler in order service\napp.post('/orders', async (req, res) => {\nconst { userId, products } = req.body;\n\ntry {\n// Get user data from user service\nconst user = await getUserDetails(userId);\n\n// Check product availability from product service\nconst productStatus = await checkProductAvailability(products);\n\nif (!productStatus.allAvailable) {\nreturn res.status(400).json({ error: 'Some products are unavailable' });\n}\n\n// Create the order\nconst order = await createOrder(userId, products, user.shippingAddress);\n\nres.status(201).json(order);\n} catch (error) {\nconsole.error('Order creation failed:', error);\nres.status(500).json({ error: 'Failed to create order' });\n}\n});",
        "// order-service.js publishing an event\nconst axios = require('axios');\n\nasync function publishEvent(eventType, data) {\ntry {\nawait axios.post('http://event-bus:3100/events', {\ntype: eventType,\ndata: data,\nsource: 'order-service',\ntimestamp: new Date().toISOString()\n});\nconsole.log(`Published event: ${eventType}`);\n} catch (error) {\nconsole.error(`Failed to publish event ${eventType}:`, error.message);\n// Store failed events for retry\nstoreFailedEvent(eventType, data, error);\n}\n}\n\n// Create an order and publish event\napp.post('/orders', async (req, res) => {\ntry {\nconst order = await createOrder(req.body);\n\n// Publish event for other services\nawait publishEvent('order.created', order);\n\nres.status(201).json(order);\n} catch (error) {\nres.status(500).json({ error: 'Order creation failed' });\n}\n});",
        "const CircuitBreaker = require('opossum');\n\n// Configure the circuit breaker\nconst options = {\nfailureThreshold: 50,        // Open after 50% of requests fail\nresetTimeout: 10000,         // Try again after 10 seconds\ntimeout: 8080,               // Time before request is considered failed\nerrorThresholdPercentage: 50 // Error percentage to open circuit\n};\n\n// Create a circuit breaker for the user service\nconst getUserDetailsBreaker = new CircuitBreaker(getUserDetails, options);\n\n// Add listeners for circuit state changes\ngetUserDetailsBreaker.on('open', () => {\nconsole.log('Circuit OPEN - User service appears to be down');\n});\n\ngetUserDetailsBreaker.on('halfOpen', () => {\nconsole.log('Circuit HALF-OPEN - Testing user service');\n});\n\ngetUserDetailsBreaker.on('close', () => {\nconsole.log('Circuit CLOSED - User service restored');\n});\n\n// Use the circuit breaker in the route handler\napp.get('/orders/:orderId', async (req, res) => {\nconst orderId = req.params.orderId;\nconst order = await getOrderById(orderId);\n\ntry {\n// Call the user service through the circuit breaker\nconst user = await getUserDetailsBreaker.fire(order.userId);\nres.json({ order, user });\n} catch (error) {\n// If the circuit is open or the call fails, return fallback data\nconsole.error('Could not fetch user details:', error.message);\nres.json({\norder,\nuser: { id: order.userId, name: 'User details unavailable' }\n});\n}\n});\ntry {\nconst response = await axios.get(`http://user-service:8080/users/${userId}`);\nreturn response.data;\n} catch (error) {\nconsole.error('Error fetching user details:', error.message);\nthrow new Error('User service unavailable');\n}\n}\n\n// Process an order\napp.post('/orders', async (req, res) => {\ntry {\nconst { userId, products } = req.body;\n\n// Get user details from the user service\nconst user = await getUserDetails(userId);\n\n// Create the order\nconst order = {\nid: generateOrderId(),\nuserId: userId,\nuserEmail: user.email,\nproducts: products,\ntotal: calculateTotal(products),\ncreatedAt: new Date()\n};\n\n// Save order (simplified)\nsaveOrder(order);\n\nres.status(201).json(order);\n} catch (error) {\nres.status(500).json({ error: error.message });\n}\n});",
        "// order-service.js publishing an event\nconst amqp = require('amqplib');\n\nasync function publishOrderCreated(order) {\ntry {\nconst connection = await amqp.connect('amqp://localhost');\nconst channel = await connection.createChannel();\n\nconst exchange = 'order_events';\nawait channel.assertExchange(exchange, 'topic', { durable: true });\n\nconst routingKey = 'order.created';\nconst message = JSON.stringify(order);\n\nchannel.publish(exchange, routingKey, Buffer.from(message));\nconsole.log(`Published order created event for order ${order.id}`);\n\nsetTimeout(() => connection.close(), 500);\n} catch (error) {\nconsole.error('Error publishing event:', error);\n}\n}\n\n// notification-service.js consuming the event\nasync function setupOrderCreatedConsumer() {\nconst connection = await amqp.connect('amqp://localhost');\nconst channel = await connection.createChannel();\n\nconst exchange = 'order_events';\nawait channel.assertExchange(exchange, 'topic', { durable: true });\n\nconst queue = 'notification_service_orders';\nawait channel.assertQueue(queue, { durable: true });\nawait channel.bindQueue(queue, exchange, 'order.created');\n\nchannel.consume(queue, (msg) => {\nif (msg) {\nconst order = JSON.parse(msg.content.toString());\nconsole.log(`Sending order confirmation email for order ${order.id}`);\nsendOrderConfirmationEmail(order);\nchannel.ack(msg);\n}\n});\n}",
        "const express = require('express');\nconst { createProxyMiddleware } = require('http-proxy-middleware');\nconst rateLimit = require('express-rate-limit');\nconst helmet = require('helmet');\n\nconst app = express();\nconst PORT = 8080;\n\n// Add security headers\napp.use(helmet());\n\n// Apply rate limiting\nconst apiLimiter = rateLimit({\nwindowMs: 15 * 60 * 1000, // 15 minutes\nmax: 100,                // limit each IP to 100 requests per windowMs\nmessage: 'Too many requests from this IP, please try again later'\n});\napp.use('/api/', apiLimiter);\n\n// Authentication middleware\nfunction authenticate(req, res, next) {\nconst token = req.headers.authorization;\nif (!token) {\nreturn res.status(401).json({ error: 'Unauthorized' });\n}\n// Verify token logic would go here\nnext();\n}\n\n// Service registry (hardcoded for simplicity)\nconst serviceRegistry = {\nuserService: 'http://localhost:3001',\nproductService: 'http://localhost:3002',\norderService: 'http://localhost:3003'\n};\n\n// Define proxy middleware for each service\nconst userServiceProxy = createProxyMiddleware({\ntarget: serviceRegistry.userService,\nchangeOrigin: true,\npathRewrite: { '^/api/users': '/users' }\n});\n\nconst productServiceProxy = createProxyMiddleware({\ntarget: serviceRegistry.productService,\nchangeOrigin: true,\npathRewrite: { '^/api/products': '/products' }\n});\n\nconst orderServiceProxy = createProxyMiddleware({\ntarget: serviceRegistry.orderService,\nchangeOrigin: true,\npathRewrite: { '^/api/orders': '/orders' }\n});\n\n// Route requests to appropriate services\napp.use('/api/users', authenticate, userServiceProxy);\napp.use('/api/products', productServiceProxy);\napp.use('/api/orders', authenticate, orderServiceProxy);\n\napp.listen(PORT, () => console.log(`API Gateway running on port ${PORT}`));",
        "const axios = require('axios');\n\n// Simple service registry client\nclass ServiceRegistry {\nconstructor(registryUrl) {\nthis.registryUrl = registryUrl;\nthis.servicesCache = {};\nthis.cacheTimeout = 60000; // 1 minute\n}\n\nasync getService(name) {\n// Check cache first\nconst cachedService = this.servicesCache[name];\nif (cachedService && cachedService.expiresAt > Date.now()) {\nreturn this._selectInstance(cachedService.instances);\n}\n\n// Fetch from registry if not in cache or expired\ntry {\nconst response = await axios.get(`${this.registryUrl}/services/${name}`);\nconst instances = response.data.instances;\n\nif (!instances || instances.length === 0) {\nthrow new Error(`No instances found for service: ${name}`);\n}\n\n// Update cache\nthis.servicesCache[name] = {\ninstances,\nexpiresAt: Date.now() + this.cacheTimeout\n};\n\nreturn this._selectInstance(instances);\n} catch (error) {\nconsole.error(`Error fetching service ${name}:`, error.message);\nthrow new Error(`Service discovery failed for ${name}`);\n}\n}\n\n// Simple round-robin load balancing\n_selectInstance(instances) {\nif (!instances._lastIndex) {\ninstances._lastIndex = 0;\n} else {\ninstances._lastIndex = (instances._lastIndex + 1) % instances.length;\n}\n\nreturn instances[instances._lastIndex];\n}\n}\n\n// Usage example\nconst serviceRegistry = new ServiceRegistry('http://registry:8500/v1');\n\nasync function callUserService(userId) {\ntry {\nconst serviceInstance = await serviceRegistry.getService('user-service');\nconst response = await axios.get(`${serviceInstance.url}/users/${userId}`);\nreturn response.data;\n} catch (error) {\nconsole.error('Error calling user service:', error.message);\nthrow error;\n}\n}",
        "// In order-service.js\n\nasync function createOrder(orderData) {\ntry {\n// Start the saga - create order\nconst order = await orderRepository.create(orderData);\n\n// Publish event to trigger the next step in the saga\nawait eventBus.publish('order.created', { orderId: order.id, ...orderData });\n\nreturn order;\n} catch (error) {\nconsole.error('Failed to create order:', error);\nthrow error;\n}\n}\n\n// In payment-service.js\nasync function processPayment(event) {\nconst { orderId, userId, amount } = event.data;\n\ntry {\n// Process payment\nconst payment = await paymentProcessor.charge(userId, amount, `Order ${orderId}`);\n\n// Publish success event\nawait eventBus.publish('payment.succeeded', {\norderId,\npaymentId: payment.id\n});\n} catch (error) {\n// Publish failure event to trigger compensation\nawait eventBus.publish('payment.failed', {\norderId,\nreason: error.message\n});\n}\n}\n\n// Compensating transaction in order-service.js\nasync function handlePaymentFailure(event) {\nconst { orderId, reason } = event.data;\n\n// Update order status to 'payment-failed'\nawait orderRepository.updateStatus(orderId, 'payment-failed', reason);\n\n// Notify customer about payment failure\nconst order = await orderRepository.findById(orderId);\nawait notificationService.notifyCustomer(order.userId, `Payment failed for order ${orderId}: ${reason}`);\n}",
        "// Event store\nclass EventStore {\nconstructor() {\nthis.events = [];\n}\n\nappend(aggregateId, eventType, eventData) {\nconst event = {\nid: this.events.length + 1,\ntimestamp: new Date().toISOString(),\naggregateId,\ntype: eventType,\ndata: eventData\n};\n\nthis.events.push(event);\nthis.publishEvent(event);\nreturn event;\n}\n\ngetEventsForAggregate(aggregateId) {\nreturn this.events.filter(event => event.aggregateId === aggregateId);\n}\n\npublishEvent(event) {\n// Publish to subscribers/event bus\nconsole.log(`Event published: ${event.type}`);\n}\n}\n\n// Order aggregate\nclass Order {\nconstructor(eventStore) {\nthis.eventStore = eventStore;\n}\n\ncreateOrder(orderId, userId, items) {\nthis.eventStore.append(orderId, 'OrderCreated', {\nuserId,\nitems,\nstatus: 'created'\n});\n}\n\naddItem(orderId, item) {\nthis.eventStore.append(orderId, 'ItemAdded', { item });\n}\n\nremoveItem(orderId, itemId) {\nthis.eventStore.append(orderId, 'ItemRemoved', { itemId });\n}\n\nsubmitOrder(orderId) {\nthis.eventStore.append(orderId, 'OrderSubmitted', {\nstatus: 'submitted',\nsubmittedAt: new Date().toISOString()\n});\n}\n\n// Rebuild the current state from events\ngetOrder(orderId) {\nconst events = this.eventStore.getEventsForAggregate(orderId);\nif (events.length === 0) return null;\n\nlet order = { id: orderId, items: [] };\n\nfor (const event of events) {\nswitch (event.type) {\ncase 'OrderCreated':\norder = { ...order, ...event.data };\nbreak;\ncase 'ItemAdded':\norder.items.push(event.data.item);\nbreak;\ncase 'ItemRemoved':\norder.items = order.items.filter(item => item.id !== event.data.itemId);\nbreak;\ncase 'OrderSubmitted':\norder.status = event.data.status;\norder.submittedAt = event.data.submittedAt;\nbreak;\n}\n}\n\nreturn order;\n}\n}",
        "// Basic API Gateway with Express\nconst express = require('express');\nconst { createProxyMiddleware } = require('http-proxy-middleware');\n\nconst app = express();\n\n// Authentication middleware\napp.use('/api', (req, res, next) => {\nconst authHeader = req.headers.authorization;\nif (!authHeader) {\nreturn res.status(401).json({ message: 'Authentication required' });\n}\n// Validate token (simplified)\nnext();\n});\n\n// Route to services\napp.use('/api/users', createProxyMiddleware({\ntarget: 'http://user-service:8080',\npathRewrite: { '^/api/users': '/users' }\n}));\n\napp.use('/api/orders', createProxyMiddleware({\ntarget: 'http://order-service:3001',\npathRewrite: { '^/api/orders': '/orders' }\n}));\n\napp.listen(8000, () => {\nconsole.log('API Gateway running on port 8000');\n});",
        "FROM node:16-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm ci --only=production\n\nCOPY . .\n\nEXPOSE 8080\n\nCMD [\"node\", \"user-service.js\"]",
        "apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: user-service\nspec:\nreplicas: 3\nselector:\nmatchLabels:\napp: user-service\ntemplate:\nmetadata:\nlabels:\napp: user-service\nspec:\ncontainers:\n- name: user-service\nimage: my-registry/user-service:latest\nports:\n- containerPort: 8080\nenv:\n- name: DB_HOST\nvalue: mongodb-service\nresources:\nlimits:\ncpu: \"0.5\"\nmemory: \"512Mi\"\nrequests:\ncpu: \"0.2\"\nmemory: \"256Mi\"",
        "// circuit-breaker.js\nclass CircuitBreaker {\nconstructor(request, options = {}) {\nthis.request = request;\nthis.state = 'CLOSED';\nthis.failureCount = 0;\nthis.successCount = 0;\nthis.nextAttempt = Date.now();\n\n// Configurable thresholds\nthis.failureThreshold = options.failureThreshold || 5;\nthis.successThreshold = options.successThreshold || 2;\nthis.timeout = options.timeout || 10000; // 10 seconds\n}\n\nasync fire() {\nif (this.state === 'OPEN') {\nif (this.nextAttempt <= Date.now()) {\nthis.state = 'HALF';\n} else {\nthrow new Error('Circuit is OPEN');\n}\n}\n\ntry {\nconst response = await this.request();\nreturn this.success(response);\n} catch (err) {\nreturn this.fail(err);\n}\n}\n\nsuccess(response) {\nif (this.state === 'HALF') {\nthis.successCount++;\nif (this.successCount > this.successThreshold) {\nthis.close();\n}\n}\nthis.failureCount = 0;\nreturn response;\n}\n\nfail(err) {\nthis.failureCount++;\nif (this.failureCount >= this.failureThreshold) {\nthis.open();\n}\nreturn err;\n}\n\nopen() {\nthis.state = 'OPEN';\nthis.nextAttempt = Date.now() + this.timeout;\n}\n\nclose() {\nthis.state = 'CLOSED';\nthis.failureCount = 0;\nthis.successCount = 0;\nthis.nextAttempt = 0;\n}\n}\n\nmodule.exports = CircuitBreaker;",
        "// order-saga.js\nclass OrderSaga {\nconstructor(orderId) {\nthis.orderId = orderId;\nthis.steps = [];\nthis.compensations = [];\n}\n\naddStep(execute, compensate) {\nthis.steps.push(execute);\nthis.compensations.unshift(compensate);\nreturn this;\n}\n\nasync execute() {\nconst executedSteps = [];\n\ntry {\nfor (const [index, step] of this.steps.entries()) {\nawait step();\nexecutedSteps.push(index);\n}\nreturn { success: true };\n} catch (error) {\nconsole.error('Saga execution failed, compensating...', error);\nawait this.compensate(executedSteps);\nreturn { success: false, error };\n}\n}\n\nasync compensate(executedSteps) {\nfor (const stepIndex of executedSteps) {\ntry {\nawait this.compensations[stepIndex]();\n} catch (compError) {\nconsole.error('Compensation failed:', compError);\n}\n}\n}\n}\n\n// Example usage\nconst orderSaga = new OrderSaga('order-123')\n.addStep(\n() => orderService.createOrder({ id: 'order-123', items: ['item1', 'item2'] }),\n() => orderService.cancelOrder('order-123')\n)\n.addStep(\n() => paymentService.processPayment('order-123', 100.00),\n() => paymentService.refundPayment('order-123')\n);\n\norderSaga.execute();",
        "// auth-middleware.js\nconst jwt = require('jsonwebtoken');\nconst authenticateService = (req, res, next) => {\nconst authHeader = req.headers.authorization;\nif (!authHeader) {\nreturn res.status(401).json({ message: 'No token provided' });\n}\n\nconst token = authHeader.split(' ')[1];\n\ntry {\nconst decoded = jwt.verify(token, process.env.JWT_SECRET);\nif (decoded.iss !== 'auth-service') {\nreturn res.status(403).json({ message: 'Invalid token issuer' });\n}\n\n// Attach service info to request\nreq.service = {\nid: decoded.sub,\nname: decoded.serviceName,\npermissions: decoded.permissions || []\n};\n\nnext();\n} catch (error) {\nreturn res.status(401).json({ message: 'Invalid or expired token' });\n}\n};\n\nmodule.exports = authenticateService;",
        "// rate-limiter.js\nconst rateLimit = require('express-rate-limit');\nconst RedisStore = require('rate-limit-redis');\nconst { createClient } = require('redis');\n// Create Redis client\n\nconst redisClient = createClient({\nurl: process.env.REDIS_URL\n});\n\n// Initialize rate limiter\nconst apiLimiter = rateLimit({\nwindowMs: 15 * 60 * 1000, // 15 minutes\nmax: 100, // Limit each IP to 100 requests per window\nstandardHeaders: true, // Return rate limit info in the `RateLimit-*` headers\nstore: new RedisStore({\nsendCommand: (...args) => redisClient.sendCommand(args)\n}),\nhandler: (req, res) => {\nres.status(429).json({\nmessage: 'Too many requests, please try again later.'\n});\n}\n});\n\nmodule.exports = apiLimiter;",
        "// tracing.js\nconst { NodeTracerProvider } = require('@opentelemetry/sdk-trace-node');\nconst { Resource } = require('@opentelemetry/resources');\nconst { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions');\nconst { BatchSpanProcessor } = require('@opentelemetry/sdk-trace-base');\nconst { JaegerExporter } = require('@opentelemetry/exporter-jaeger');\nconst { registerInstrumentations } = require('@opentelemetry/instrumentation');\nconst { HttpInstrumentation } = require('@opentelemetry/instrumentation-http');\nconst { ExpressInstrumentation } = require('@opentelemetry/instrumentation-express');\n\n\n// Configure the tracer provider\nconst provider = new NodeTracerProvider({\nresource: new Resource({\n[SemanticResourceAttributes.SERVICE_NAME]: 'user-service',\n'service.version': '1.0.0',\n}),\n});\n\n// Configure Jaeger exporter\nconst exporter = new JaegerExporter({\nendpoint: process.env.JAEGER_ENDPOINT || 'http://localhost:14268/api/traces',\n});\n\n// Add the exporter to the provider\nprovider.addSpanProcessor(new BatchSpanProcessor(exporter));\n\n// Initialize the OpenTelemetry APIs to use the NodeTracerProvider\nprovider.register();\n\n// Register instrumentations\nregisterInstrumentations({\ninstrumentations: [\nnew HttpInstrumentation(),\nnew ExpressInstrumentation(),\n],\ntracerProvider: provider,\n});\n\nconsole.log('Tracing initialized');",
        "// logger.js\nconst winston = require('winston');\nconst { combine, timestamp, json } = winston.format;\n\nconst logger = winston.createLogger({\nlevel: process.env.LOG_LEVEL || 'info',\nformat: combine(\ntimestamp(),\njson()\n),\ndefaultMeta: {\nservice: 'user-service',\nenvironment: process.env.NODE_ENV || 'development',\n},\ntransports: [\nnew winston.transports.Console(),\n// Add other transports like file, ELK, etc.\n],\n});\n\n// Add request ID to logs\nlogger.child = function(opts) {\nreturn new Proxy(logger, {\nget(target, property, receiver) {\nif (property === 'write') {\nreturn (...args) => {\nconst originalMeta = args[args.length - 1] || {};\nargs[args.length - 1] = { ...opts, ...originalMeta };\nreturn logger[property](...args);\n};\n}\nreturn Reflect.get(target, property, receiver);\n},\n});\n};\n\nmodule.exports = logger;"
      ]
    },
    {
      "title": "Node.js WebAssembly",
      "summary": "What is WebAssembly?\nWebAssembly (Wasm) is a binary instruction format designed as a portable compilation target for high-level languages like C, C++, and Rust.\nKey characteristics of WebAssembly include:\nBinary format - Compact size that loads and executes faster than JavaScript\nNear-native performance - Executes at speeds close to native machine code\nPlatform independent - Runs on browsers, Node.js, and other environments\nSafety - Executes in a sandboxed environment with a strong security model\nUnlike JavaScript, WebAssembly is a low-level binary format that isn't meant to be written by hand.\nInstead, you compile code from other languages into WebAssembly.\nWebAssembly Support in Node.js\nNode.js provides built-in support for WebAssembly through the global WebAssembly object (just like in browsers).\nTo check if your Node.js version supports WebAssembly:\nExample: Check WebAssembly SupportGet your own Node.js Server\nNote: WebAssembly support was first added in Node.js v8.0.0 and has improved in subsequent versions.\nREMOVE ADS\nUsing WebAssembly in Node.js\nThe WebAssembly API in Node.js provides several methods for working with WebAssembly modules:\nHere's a basic example of loading and running a WebAssembly module:\nExample: Running WebAssembly in Node.js\nNote: The simple.wasm file in this example would be a compiled WebAssembly module that exports an add function.\nYou would typically create this by compiling C, C++, or Rust code.\nWorking with Different Languages\nYou can compile various languages to WebAssembly for use in Node.js:\nC/C++ with Emscripten\nEmscripten is a compiler toolchain for C/C++ that outputs WebAssembly.\nRust with wasm-pack\nwasm-pack is a tool for building Rust-generated WebAssembly.\nAdvanced WebAssembly Usage\n1. Working with Complex Data Structures\nPassing complex data between JavaScript and WebAssembly requires careful memory management:\n2. Multithreading with WebAssembly\nWebAssembly supports multithreading through Web Workers and SharedArrayBuffer:\n3. Debugging WebAssembly\nDebugging WebAssembly can be challenging, but modern tools can help:\nOpen Chrome DevTools (F12)\nGo to the \"Sources\" tab\nFind your WebAssembly file in the file tree\nSet breakpoints and inspect variables as with JavaScript\nReal-World WebAssembly Examples\n1. Image Processing with WebAssembly\nWebAssembly excels at CPU-intensive tasks like image processing:\n2. Cryptography\nHigh-performance cryptographic operations with WebAssembly:\nResources and Next Steps\nWebAssembly in Node.js offers several advantages:\nPerformance - Near-native execution speed for computationally intensive tasks\nLanguage choice - Use languages like C, C++, Rust, Go, and others in your Node.js apps\nCode reuse - Reuse existing libraries and codebases from other languages\nIsomorphic code - Share WebAssembly modules between browser and server\nCommon use cases include:\nImage and video processing\nReal-time audio processing\nCryptography and encryption\nScientific computing and simulations\nGame development\nMachine learning algorithms\nPerformance Comparison\nTo demonstrate the performance benefits, let's compare JavaScript and WebAssembly implementations of a recursive Fibonacci function:\nThe WebAssembly version uses an iterative algorithm that is much faster than the recursive approach.\nEven with identical algorithms, WebAssembly typically performs better for CPU-intensive operations due to its compiled nature.\nReal-World Applications\nHere are some popular libraries that use WebAssembly with Node.js:\nMemory Management\nWebAssembly modules operate on a linear memory, which is a contiguous, mutable array of bytes that is accessible from both WebAssembly and JavaScript.\nUnderstanding WebAssembly Memory\nWebAssembly memory is organized into pages, where each page is 64KB (65,536 bytes).\nThe memory can be created either by JavaScript or by the WebAssembly module itself.\ninitial: The initial number of pages (minimum size)\nmaximum: Optional maximum number of pages the memory can grow to\nshared: Whether the memory can be shared between workers (for multithreading)\nCreating and Accessing WebAssembly Memory\nWarning: When WebAssembly memory grows, the underlying ArrayBuffer is detached and a new one is created.\nThis means any JavaScript TypedArray views of the memory must be recreated after growing memory.\nUsing Different TypedArray Views\nYou can create different views of the same memory to interpret the data in various ways:\nWorking with Different Data Types\nImage Processing Example\nHere's a practical example of using WebAssembly memory for image processing:\nWebAssembly C Code for Grayscale Conversion\nNode.js Code to Use the WebAssembly Module\nIntegration with JavaScript\nWebAssembly and JavaScript can work together seamlessly in Node.js:\nExample: JavaScript and WebAssembly Integration\nBest Practice: Use WebAssembly for performance-critical parts of your application while keeping the application logic in JavaScript for better developer experience.\nSummary\nWebAssembly extends Node.js capabilities by allowing you to:\nRun code compiled from languages like C, C++, and Rust\nAchieve near-native performance for computationally intensive tasks\nReuse existing codebases and libraries from other languages\nShare code between browser and server environments\nThis makes Node.js a more versatile platform for a wider range of applications, especially those requiring high performance.",
      "examples": [
        "console.log(typeof WebAssembly === 'object');\nconsole.log(WebAssembly);",
        "const fs = require('fs');\n\n// Read the WebAssembly binary file\nconst wasmBuffer = fs.readFileSync('./simple.wasm');\n\n// Compile and instantiate the module\nWebAssembly.instantiate(wasmBuffer).then(result => {\nconst instance = result.instance;\n\n// Call the exported 'add' function\nconst sum = instance.exports.add(2, 3);\nconsole.log('2 + 3 =', sum); // Output: 2 + 3 = 5\n});",
        "#include <emscripten.h>\n\nEMSCRIPTEN_KEEPALIVE\nint add(int a, int b) {\nreturn a + b;\n}",
        "emcc add.c -s WASM=1 -s EXPORTED_FUNCTIONS='[\"_add\"]' -o add.js",
        "use wasm_bindgen::prelude::*;\n\n#[wasm_bindgen]\npub fn add(a: i32, b: i32) -> i32 {\na + b\n}",
        "wasm-pack build --target nodejs",
        "// JavaScript code\nconst wasmModule = await WebAssembly.instantiate(wasmBuffer, {\nenv: {\nmemory: new WebAssembly.Memory({ initial: 1 })\n}\n});\n// Allocate memory for an array of 10 integers (4 bytes each)\nconst arraySize = 10;\nconst ptr = wasmModule.exports.alloc(arraySize * 4);\nconst intArray = new Int32Array(wasmModule.exports.memory.buffer, ptr, arraySize);\n// Fill array with values\nfor (let i = 0; i < arraySize; i++) {\nintArray[i] = i * 2;\n}\n// Call WebAssembly function to process the array\nconst sum = wasmModule.exports.processArray(ptr, arraySize);\nconsole.log('Sum of array:', sum);\n// Don't forget to free the memory\nwasmModule.exports.dealloc(ptr, arraySize * 4);",
        "#include <stdlib.h>\n\nint* alloc(int size) {\nreturn (int*)malloc(size);\n}\n\nvoid dealloc(int* ptr, int size) {\nfree(ptr);\n}\n\nint processArray(int* array, int length) {\nint sum = 0;\nfor (int i = 0; i < length; i++) {\nsum += array[i];\n}\nreturn sum;\n}",
        "// main.js\nconst workerCode = `\nconst wasmModule = await WebAssembly.instantiate(wasmBuffer, {\nenv: { memory: new WebAssembly.Memory({ initial: 1, shared: true }) }\n});\n\nself.onmessage = (e) => {\nconst { data, start, end } = e.data;\nconst result = wasmModule.exports.processChunk(data, start, end);\nself.postMessage({ result });\n};\n`;\n\n// Create worker pool\nconst workerCount = navigator.hardwareConcurrency || 4;\nconst workers = Array(workerCount).fill().map(() => {\nconst blob = new Blob([workerCode], { type: 'application/javascript' });\nreturn new Worker(URL.createObjectURL(blob));\n});\n\n// Process data in parallel\nasync function processInParallel(data, chunkSize) {\nconst results = [];\nlet completed = 0;\n\nreturn new Promise((resolve) => {\nworkers.forEach((worker, i) => {\nconst start = i * chunkSize;\nconst end = Math.min(start + chunkSize, data.length);\n\nworker.onmessage = (e) => {\nresults[i] = e.data.result;\ncompleted++;\n\nif (completed === workerCount) {\nresolve(results);\n}\n};\n\nworker.postMessage({ data, start, end });\n});\n});\n}",
        "# Compile with debugging information and source maps\nemcc -g4 --source-map-base http://localhost:8080/ -s WASM=1 -s EXPORTED_FUNCTIONS='[\"_main\",\"_my_function\"]' -o output.html source.c",
        "// JavaScript wrapper for WebAssembly image processing\nasync function applyFilter(imageData, filterType) {\nconst { instance } = await WebAssembly.instantiate(wasmBuffer, {\nenv: { memory: new WebAssembly.Memory({ initial: 1 }) }\n});\n\nconst { width, height, data } = imageData;\n\n// Allocate memory for image data\nconst imageDataSize = width * height * 4; // RGBA\nconst imageDataPtr = instance.exports.alloc(imageDataSize);\n\n// Copy image data to WebAssembly memory\nconst wasmMemory = new Uint8Array(instance.exports.memory.buffer);\nwasmMemory.set(new Uint8Array(data.buffer), imageDataPtr);\n\n// Apply filter\ninstance.exports.applyFilter(imageDataPtr, width, height, filterType);\n\n// Copy result back to ImageData\nconst resultData = new Uint8ClampedArray(\nwasmMemory.slice(imageDataPtr, imageDataPtr + imageDataSize)\n);\n\n// Free allocated memory\ninstance.exports.dealloc(imageDataPtr, imageDataSize);\n\nreturn new ImageData(resultData, width, height);\n}",
        "// Example: Using the Web Crypto API with WebAssembly\nasync function encryptData(data, keyMaterial) {\n// Import WebAssembly crypto module\nconst { instance } = await WebAssembly.instantiateStreaming(\nfetch('crypto.wasm'),\n{ env: { memory: new WebAssembly.Memory({ initial: 1 }) } }\n);\n\n// Generate IV (Initialization Vector)\nconst iv = window.crypto.getRandomValues(new Uint8Array(12));\n\n// Prepare data\nconst dataBytes = new TextEncoder().encode(JSON.stringify(data));\nconst dataPtr = instance.exports.alloc(dataBytes.length);\nnew Uint8Array(instance.exports.memory.buffer, dataPtr, dataBytes.length)\n.set(dataBytes);\n\n// Encrypt data using WebAssembly\nconst encryptedDataPtr = instance.exports.encrypt(dataPtr, dataBytes.length);\n\n// Get encrypted data from WebAssembly memory\nconst encryptedData = new Uint8Array(\ninstance.exports.memory.buffer,\nencryptedDataPtr,\ndataBytes.length // In real usage, you'd track the actual encrypted size\n);\n\n// Clean up\ninstance.exports.dealloc(dataPtr, dataBytes.length);\n\nreturn {\niv: Array.from(iv),\nencryptedData: Array.from(encryptedData)\n};\n}",
        "// Recursive Fibonacci in JavaScript (inefficient for demonstration)\nfunction fibonacciJS(n) {\nif (n <= 1) return n;\nreturn fibonacciJS(n - 1) + fibonacciJS(n - 2);\n}",
        "#include <emscripten.h>\n\n// WebAssembly-optimized Fibonacci function\nEMSCRIPTEN_KEEPALIVE\nint fibonacci_wasm(int n) {\nif (n <= 1) return n;\n\nint a = 0, b = 1, temp;\nfor (int i = 2; i <= n; i++) {\ntemp = a + b;\na = b;\nb = temp;\n}\n\nreturn b;\n}\nb = temp;\n}\n\nreturn b;\n}",
        "const fs = require('fs');\nconst path = require('path');\n\n// Read the WebAssembly binary file\nconst wasmBuffer = fs.readFileSync('./fibonacci.wasm');\n\n// JavaScript implementation for comparison\nfunction fibonacciJS(n) {\nif (n <= 1) return n;\nreturn fibonacciJS(n - 1) + fibonacciJS(n - 2);\n}\n\n// Compile and instantiate the WebAssembly module\nWebAssembly.instantiate(wasmBuffer).then(result => {\nconst { fibonacci_wasm } = result.instance.exports;\n\n// Test with a value that's computationally expensive\nconst n = 40;\n\n// Measure WebAssembly performance\nconst wasmStart = performance.now();\nconst wasmResult = fibonacci_wasm(n);\nconst wasmEnd = performance.now();\n\n// Measure JavaScript performance\nconst jsStart = performance.now();\nconst jsResult = fibonacciJS(n);\nconst jsEnd = performance.now();\n\nconsole.log(`Fibonacci(${n})`);\nconsole.log(`WebAssembly: ${wasmResult} (${(wasmEnd - wasmStart).toFixed(2)} ms)`);\nconsole.log(`JavaScript: ${jsResult} (${(jsEnd - jsStart).toFixed(2)} ms)`);\n});",
        "// Create a new WebAssembly Memory instance with 1 page (64KB) initially,\n// and a maximum of 10 pages (640KB)\nconst memory = new WebAssembly.Memory({\ninitial: 1,\nmaximum: 10\n});\n\n// Access the memory as a typed array in JavaScript\nlet bytes = new Uint8Array(memory.buffer);\n\n// Write data to memory\nfor (let i = 0; i < 10; i++) {\nbytes[i] = i * 10; // Write values 0, 10, 20, ..., 90\n}\n\n// Read data from memory\nconsole.log('Memory contents:', bytes.slice(0, 10));\n\n// Grow the memory by 1 page (returns the previous size in pages)\nconst previousPages = memory.grow(1);\nconsole.log(`Memory grown from ${previousPages} to ${memory.buffer.byteLength / 65536} pages`);\n\n// IMPORTANT: After growing memory, we need to create a new view\n// because the ArrayBuffer is detached when memory grows\nbytes = new Uint8Array(memory.buffer);\nconsole.log('Memory size now:', bytes.length, 'bytes');",
        "const memory = new WebAssembly.Memory({ initial: 1 });\n\n// Different views of the same memory\nconst bytes = new Uint8Array(memory.buffer); // Unsigned 8-bit integers\nconst ints = new Int32Array(memory.buffer); // Signed 32-bit integers\nconst floats = new Float32Array(memory.buffer); // 32-bit floating point\n\n// Write an integer at the beginning of memory\nints[0] = 42;\n\n// The same memory location viewed as bytes\nconsole.log('42 as bytes:', Array.from(bytes.slice(0, 4)));\n\n// Write a float\nfloats[1] = 3.14159;\n\n// View the float as bytes and as an integer\nconst floatByteOffset = 1 * Float32Array.BYTES_PER_ELEMENT;\nconst floatIntValue = ints[floatByteOffset / Int32Array.BYTES_PER_ELEMENT];\nconsole.log('3.14159 as bytes:', Array.from(bytes.slice(floatByteOffset, floatByteOffset + 4)));\nconsole.log('3.14159 as int32:', floatIntValue);",
        "#include <emscripten.h>\n#include <stdint.h>\n\n// WebAssembly optimized grayscale conversion\nEMSCRIPTEN_KEEPALIVE\nvoid grayscale_wasm(uint8_t* pixels, int length) {\n// Process each pixel (RGBA format)\nfor (int i = 0; i < length; i += 4) {\n// Calculate grayscale value using luminance formula\nuint8_t gray = (uint8_t)(\n(0.299 * pixels[i]) +     // Red\n(0.587 * pixels[i + 1]) + // Green\n(0.114 * pixels[i + 2])   // Blue\n);\n\n// Set RGB channels to gray value\npixels[i] = gray;     // Red\npixels[i + 1] = gray; // Green\npixels[i + 2] = gray; // Blue\n// Alpha channel (pixels[i + 3]) remains unchanged\n}\n}",
        "const fs = require('fs');\nconst wasmBuffer = fs.readFileSync('./image_processing.wasm');\n\n// Sample image data (RGBA format, 2x2 pixel image)\nconst imageData = new Uint8Array([\n255, 0, 0, 255,    // Red pixel\n0, 255, 0, 255,    // Green pixel\n0, 0, 255, 255,    // Blue pixel\n255, 255, 0, 255   // Yellow pixel\n]);\n\n// Instantiate the WebAssembly module\nWebAssembly.instantiate(wasmBuffer, {\nenv: {\nmemory: new WebAssembly.Memory({ initial: 1 })\n}\n}).then(result => {\nconst instance = result.instance;\nconst { grayscale_wasm } = instance.exports;\nconst memory = instance.exports.memory;\n\n// Get a view of the WebAssembly memory\nconst wasmMemory = new Uint8Array(memory.buffer);\n\n// Copy image data to WebAssembly memory\nwasmMemory.set(imageData);\n\n// Process the image (convert to grayscale)\ngrayscale_wasm(0, imageData.length);\n\n// Get processed image data from WebAssembly memory\nconst processedData = wasmMemory.slice(0, imageData.length);\n\nconsole.log('Original image:', imageData);\nconsole.log('Grayscale image:', processedData);\n});\n// Write data to memory\nbytes[0] = 123;\n\nconsole.log(bytes[0]); // Output: 123\n\n// Grow the memory by 1 page (to 128KB total)\nmemory.grow(1);\n\nconsole.log(`Memory size: ${memory.buffer.byteLength / 1024}KB`);",
        "const fs = require('fs');\nconst wasmBuffer = fs.readFileSync('./math.wasm');\n\n// JavaScript function that will use WebAssembly\nasync function calculateFactorial(n) {\n// Instantiate the module\nconst result = await WebAssembly.instantiate(wasmBuffer);\nconst wasm = result.instance.exports;\n\n// Use the WebAssembly factorial function\nreturn wasm.factorial(n);\n}\n\n// Use our mixed JS/WebAssembly function\nasync function main() {\nconsole.log('Calculating factorials:');\nfor (let i = 1; i <= 10; i++) {\nconst result = await calculateFactorial(i);\nconsole.log(`${i}! = ${result}`);\n}\n}\n\nmain().catch(console.error);",
        "WebAssembly",
        "WebAssembly.compile()",
        "WebAssembly.instantiate()",
        "WebAssembly.validate()",
        "WebAssembly.Module",
        "WebAssembly.Instance",
        "WebAssembly.Memory",
        "simple.wasm",
        "add"
      ]
    },
    {
      "title": "Node.js HTTP/2 Module",
      "summary": "What is HTTP/2?\nThe Node.js HTTP/2 module provides an implementation of the HTTP/2 protocol, offering improved performance, server push capabilities, header compression, and multiplexing over a single connection.\nHTTP/2 improves upon HTTP/1.1 with several key features:\nBinary protocol: HTTP/2 uses a binary format for data transfer rather than the text format of HTTP/1.1, making it more efficient to parse.\nMultiplexing: Multiple requests and responses can be sent over a single connection simultaneously.\nHeader compression: HTTP/2 compresses headers to reduce overhead.\nServer push: Servers can proactively send resources to clients before they request them.\nStream prioritization: Resources can be delivered with different priorities.\nUsing the HTTP/2 Module\nIn Node.js, the HTTP/2 module can be accessed using:\nThe HTTP/2 module is stable as of Node.js v10.0.0. It's important to note that HTTP/2 requires a secure connection (HTTPS) in most browsers, so most examples will use TLS/SSL.\nCreating an HTTP/2 Server\nHere's an example of creating a basic HTTP/2 server using TLS:\nThis example assumes you have TLS certificate files. For development, you can generate self-signed certificates using OpenSSL. For production, use a trusted certificate authority.\nYou can also create an HTTP/2 server without TLS (for direct HTTP/2 connections without encryption):\nMost modern browsers only support HTTP/2 over TLS, so the insecure HTTP/2 server will typically only work with dedicated HTTP/2 clients that explicitly support cleartext HTTP/2.\nHTTP/2 Client\nCreating an HTTP/2 client to connect to an HTTP/2 server:\nHTTP/2 Streams\nHTTP/2 uses streams for communication between client and server. Each stream represents an independent, bidirectional sequence of frames exchanged between the client and server.\nStream Events\nImportant stream events include:\n'headers': Emitted when headers are received\n'data': Emitted when a chunk of data is received\n'end': Emitted when the stream is finished\n'error': Emitted when an error occurs\nHTTP/2 Server Push\nServer push allows the server to proactively send resources to the client before they are explicitly requested. This can improve performance by eliminating round-trip delays.\nHTTP/2 Headers\nHTTP/2 uses a different format for headers. Notably, all headers are lowercase, and request pseudo-headers start with a colon (:).\nHTTP/2 Settings\nHTTP/2 allows configuring various protocol settings:\nCompatibility with HTTP/1.1\nHTTP/2 servers can also handle HTTP/1.1 requests, providing a seamless upgrade path:\nPerformance Considerations\nWhile HTTP/2 offers performance improvements, it's important to optimize your usage:\nConnection Reuse - With HTTP/2, you should aim to use a single connection for multiple requests, rather than creating new connections.\nProper Stream Management - Remember to close streams when they're no longer needed, and monitor the number of concurrent streams.\nServer Push Strategy - Only push resources that are likely to be needed. Excessive pushing can waste bandwidth and resources.\nHeader Compression - Take advantage of HTTP/2's header compression by minimizing the number and size of custom headers.\nHTTP/2 vs HTTP/1.1\nKey differences between HTTP/2 and HTTP/1.1:\nReal-World Example: Serving a Complete Website\nA complete example of serving a website with HTTP/2:\nThis example requires the mime-types package:\nAdvanced Stream Management\nHTTP/2's stream management capabilities allow for efficient handling of multiple concurrent requests. Here's an advanced example demonstrating stream prioritization and flow control:\nError Handling and Debugging\nProper error handling is crucial for reliable HTTP/2 applications. Here's how to implement comprehensive error handling:\nPerformance Optimization\nOptimizing HTTP/2 performance requires understanding its unique characteristics. Here are key strategies:\n1. Connection Pooling\n2. Header Compression Optimization\nHTTP/2 uses HPACK compression for headers. Optimize by:\nMinimizing cookie sizes\nUsing short but descriptive header names\nAvoiding duplicate headers\nUsing HTTP/2-specific headers when possible\nSecurity Best Practices\nWhen using HTTP/2, follow these security practices:\nReal-World Use Cases\n1. API Gateway with HTTP/2\nBuilding a high-performance API gateway with HTTP/2:\n2. Real-Time Data Streaming\nEfficient real-time data streaming with HTTP/2:",
      "examples": [
        "const http2 = require('http2');",
        "const http2 = require('http2');\nconst fs = require('fs');\nconst path = require('path');\n\n// Read the TLS certificate and key\nconst options = {\nkey: fs.readFileSync(path.join(__dirname, 'server.key')),\ncert: fs.readFileSync(path.join(__dirname, 'server.crt'))\n};\n\n// Create an HTTP/2 server\nconst server = http2.createSecureServer(options);\n\n// Handle stream events\nserver.on('stream', (stream, headers) => {\n// Get the path from headers\nconst path = headers[':path'];\n\n// Send a response\nif (path === '/') {\nstream.respond({\n'content-type': 'text/html',\n':status': 200\n});\nstream.end('<h1>Hello from HTTP/2!</h1>');\n} else {\nstream.respond({\n':status': 404\n});\nstream.end('Not found');\n}\n});\n\n// Start the server\nconst port = 8080;\nserver.listen(port, () => {\nconsole.log(`HTTP/2 server running at https://localhost:${port}`);\n});",
        "const http2 = require('http2');\n\n// Create an HTTP/2 server without TLS\nconst server = http2.createServer();\n\nserver.on('stream', (stream, headers) => {\nstream.respond({\n'content-type': 'text/html',\n':status': 200\n});\nstream.end('<h1>Hello from HTTP/2 without TLS!</h1>');\n});\n\nserver.listen(8080);",
        "const http2 = require('http2');\n\n// Create a client\nconst client = http2.connect('https://localhost:8080', {\n// For self-signed certificates in development\nrejectUnauthorized: false\n});\n\n// Error handling\nclient.on('error', (err) => {\nconsole.error('Client error:', err);\n});\n\n// Create a request\nconst req = client.request({ ':path': '/' });\n\n// Handle response data\nreq.on('response', (headers) => {\nconsole.log('Status:', headers[':status']);\nconsole.log('Headers:', headers);\n});\n\nreq.on('data', (chunk) => {\nconsole.log('Received data:', chunk.toString());\n});\n\nreq.on('end', () => {\nconsole.log('Request completed');\nclient.close();\n});\n\n// Send the request\nreq.end();",
        "const http2 = require('http2');\nconst fs = require('fs');\nconst path = require('path');\n\n// Create a server\nconst server = http2.createSecureServer({\nkey: fs.readFileSync(path.join(__dirname, 'server.key')),\ncert: fs.readFileSync(path.join(__dirname, 'server.crt'))\n});\n\nserver.on('stream', (stream, headers) => {\n// Handle stream events\nstream.on('error', (error) => {\nconsole.error('Stream error:', error);\n});\n\nstream.on('close', () => {\nconsole.log('Stream closed');\n});\n\n// Handle request\nstream.respond({\n'content-type': 'text/plain',\n':status': 200\n});\n\n// Send data in multiple chunks\nstream.write('First chunk of data\\n');\n\nsetTimeout(() => {\nstream.write('Second chunk of data\\n');\nstream.end('Final chunk of data');\n}, 1000);\n});\n\nserver.listen(8080);",
        "const http2 = require('http2');\nconst fs = require('fs');\nconst path = require('path');\n\nconst options = {\nkey: fs.readFileSync(path.join(__dirname, 'server.key')),\ncert: fs.readFileSync(path.join(__dirname, 'server.crt'))\n};\n\nconst server = http2.createSecureServer(options);\n\nserver.on('stream', (stream, headers) => {\nconst requestPath = headers[':path'];\n\nif (requestPath === '/') {\n// Push CSS and JavaScript resources\nstream.pushStream({ ':path': '/style.css' }, (err, pushStream) => {\nif (err) {\nconsole.error('Error pushing stream:', err);\nreturn;\n}\n\npushStream.respond({\n'content-type': 'text/css',\n':status': 200\n});\n\npushStream.end('body { color: blue; }');\n});\n\nstream.pushStream({ ':path': '/script.js' }, (err, pushStream) => {\nif (err) {\nconsole.error('Error pushing stream:', err);\nreturn;\n}\n\npushStream.respond({\n'content-type': 'application/javascript',\n':status': 200\n});\n\npushStream.end('console.log(\"Hello from HTTP/2 server push!\");');\n});\n\n// Send the main HTML document\nstream.respond({\n'content-type': 'text/html',\n':status': 200\n});\n\nstream.end(`\n<!DOCTYPE html>\n<html>\n<head>\n<title>HTTP/2 Server Push Example</title>\n<link rel=\"stylesheet\" href=\"/style.css\">\n<script src=\"/script.js\"></script>\n</head>\n<body>\n<h1>HTTP/2 Server Push Demo</h1>\n<p>CSS and JavaScript were pushed by the server!</p>\n</body>\n</html>\n`);\n} else {\n// Serve pushed resources if requested directly\nif (requestPath === '/style.css') {\nstream.respond({\n'content-type': 'text/css',\n':status': 200\n});\nstream.end('body { color: blue; }');\n} else if (requestPath === '/script.js') {\nstream.respond({\n'content-type': 'application/javascript',\n':status': 200\n});\nstream.end('console.log(\"Hello from HTTP/2 server push!\");');\n} else {\n// Not found\nstream.respond({ ':status': 404 });\nstream.end('Not found');\n}\n}\n});\n\nserver.listen(8080);",
        "const http2 = require('http2');\n\n// HTTP/2 pseudo-headers\nconst {\nHTTP2_HEADER_METHOD,\nHTTP2_HEADER_PATH,\nHTTP2_HEADER_AUTHORITY,\nHTTP2_HEADER_SCHEME,\nHTTP2_HEADER_STATUS\n} = http2.constants;\n\n// Create a client\nconst client = http2.connect('https://localhost:8080', {\nrejectUnauthorized: false\n});\n\n// Send a request with custom headers\nconst req = client.request({\n[HTTP2_HEADER_METHOD]: 'GET',\n[HTTP2_HEADER_PATH]: '/',\n[HTTP2_HEADER_AUTHORITY]: 'localhost:8080',\n[HTTP2_HEADER_SCHEME]: 'https',\n'user-agent': 'node-http2/client',\n'custom-header': 'custom-value'\n});\n\nreq.on('response', (headers) => {\nconsole.log('Response status:', headers[HTTP2_HEADER_STATUS]);\nconsole.log('Response headers:', headers);\n});\n\nreq.on('data', (chunk) => {\nconsole.log('Received data:', chunk.toString());\n});\n\nreq.on('end', () => {\nclient.close();\n});\n\nreq.end();",
        "const http2 = require('http2');\nconst fs = require('fs');\nconst path = require('path');\n\nconst options = {\nkey: fs.readFileSync(path.join(__dirname, 'server.key')),\ncert: fs.readFileSync(path.join(__dirname, 'server.crt')),\n\n// HTTP/2 settings\nsettings: {\n// Max concurrent streams per connection\nmaxConcurrentStreams: 100,\n\n// Initial window size for flow control\ninitialWindowSize: 1024 * 1024, // 1MB\n\n// Enable server push\nenablePush: true\n}\n};\n\nconst server = http2.createSecureServer(options);\n\nserver.on('stream', (stream, headers) => {\nstream.respond({\n'content-type': 'text/html',\n':status': 200\n});\n\nstream.end('<h1>HTTP/2 Server with Custom Settings</h1>');\n});\n\nserver.listen(8080);",
        "const http2 = require('http2');\nconst http = require('http');\nconst fs = require('fs');\nconst path = require('path');\n\n// For HTTP/2 secure server\nconst options = {\nkey: fs.readFileSync(path.join(__dirname, 'server.key')),\ncert: fs.readFileSync(path.join(__dirname, 'server.crt')),\nallowHTTP1: true // Allow HTTP/1.1 connections\n};\n\nconst server = http2.createSecureServer(options);\n\n// Handler function for both HTTP/1.1 and HTTP/2\nconst handler = (req, res) => {\nres.writeHead(200, { 'Content-Type': 'text/plain' });\nres.end(`Hello from ${req.httpVersion} server!`);\n};\n\n// HTTP/1.1 compatibility request handler\nserver.on('request', handler);\n\n// HTTP/2 specific stream handler\nserver.on('stream', (stream, headers) => {\nstream.respond({\n'content-type': 'text/plain',\n':status': 200\n});\nstream.end(`Hello from HTTP/2 stream API!`);\n});\n\nserver.listen(8080, () => {\nconsole.log('Server running at https://localhost:8080/');\n});",
        "const http2 = require('http2');\nconst fs = require('fs');\nconst path = require('path');\nconst mime = require('mime-types');\n\nconst options = {\nkey: fs.readFileSync(path.join(__dirname, 'server.key')),\ncert: fs.readFileSync(path.join(__dirname, 'server.crt'))\n};\n\nconst server = http2.createSecureServer(options);\n\n// Serve files from the public directory\nconst publicDir = path.join(__dirname, 'public');\n\nserver.on('stream', (stream, headers) => {\nconst reqPath = headers[':path'] === '/' ? '/index.html' : headers[':path'];\nconst filePath = path.join(publicDir, reqPath);\n\n// Basic security check to prevent path traversal\nif (!filePath.startsWith(publicDir)) {\nstream.respond({ ':status': 403 });\nstream.end('Forbidden');\nreturn;\n}\n\nfs.stat(filePath, (err, stats) => {\nif (err || !stats.isFile()) {\n// File not found\nstream.respond({ ':status': 404 });\nstream.end('Not found');\nreturn;\n}\n\n// Determine content type\nconst contentType = mime.lookup(filePath) || 'application/octet-stream';\n\n// Serve the file\nstream.respond({\n'content-type': contentType,\n':status': 200\n});\n\nconst fileStream = fs.createReadStream(filePath);\nfileStream.pipe(stream);\n\nfileStream.on('error', (err) => {\nconsole.error('File stream error:', err);\nstream.close(http2.constants.NGHTTP2_INTERNAL_ERROR);\n});\n});\n});\n\nserver.listen(8080, () => {\nconsole.log('HTTP/2 server running at https://localhost:8080/');\n});",
        "npm install mime-types",
        "const http2 = require('http2');\nconst fs = require('fs');\n\n// Create a server with custom settings\nconst server = http2.createSecureServer({\nkey: fs.readFileSync('server.key'),\ncert: fs.readFileSync('server.crt'),\nsettings: {\ninitialWindowSize: 65535,  // 64KB initial window\nmaxConcurrentStreams: 100,\nenablePush: true\n}\n});\n\nserver.on('stream', (stream, headers) => {\n// Get priority information\nconst weight = stream.priority && stream.priority.weight || 1;\nconst parent = stream.priority && stream.priority.parent ? 'with parent' : 'no parent';\n\nconsole.log(`New stream ${stream.id} (weight: ${weight}, ${parent})`);\n\n// Handle different priority levels\nif (headers[':path'] === '/high-priority') {\nstream.priority({ weight: 256, exclusive: true });\nstream.respond({ ':status': 200, 'content-type': 'text/plain' });\nstream.end('High priority content');\n} else {\n// Default priority\nstream.respond({ ':status': 200, 'content-type': 'text/plain' });\nstream.end('Standard priority content');\n}\n\n// Handle stream errors\nstream.on('error', (error) => {\nconsole.error(`Stream ${stream.id} error:`, error);\nstream.end();\n});\n\n// Handle stream close\nstream.on('close', () => {\nconsole.log(`Stream ${stream.id} closed`);\n});\n});\n\nserver.listen(8443);",
        "const http2 = require('http2');\nconst fs = require('fs');\nconst { promisify } = require('util');\nconst readFile = promisify(fs.readFile);\n\nasync function startServer() {\ntry {\nconst [key, cert] = await Promise.all([\nreadFile('server.key'),\nreadFile('server.crt')\n]);\n\nconst server = http2.createSecureServer({ key, cert });\n\n// Global error handler\nserver.on('error', (err) => {\nconsole.error('Server error:', err);\n// Implement proper error recovery\n});\n\n// Handle uncaught exceptions\nprocess.on('uncaughtException', (err) => {\nconsole.error('Uncaught exception:', err);\n// Graceful shutdown\nserver.close(() => process.exit(1));\n});\n\n// Handle unhandled promise rejections\nprocess.on('unhandledRejection', (reason, promise) => {\nconsole.error('Unhandled Rejection at:', promise, 'reason:', reason);\n});\n\n// Stream handler with error boundaries\nserver.on('stream', (stream, headers) => {\ntry {\n// Simulate async operation\nsetTimeout(() => {\ntry {\nif (Math.random() > 0.8) {\nthrow new Error('Random error for demonstration');\n}\nstream.respond({ ':status': 200 });\nstream.end('Success!');\n} catch (err) {\nhandleStreamError(stream, err);\n}\n}, 100);\n} catch (err) {\nhandleStreamError(stream, err);\n}\n});\n\nfunction handleStreamError(stream, error) {\nconsole.error('Stream error:', error);\nif (!stream.destroyed) {\nstream.respond({\n':status': 500,\n'content-type': 'text/plain'\n});\nstream.end('Internal Server Error');\n}\n}\n\nserver.listen(8443, () => {\nconsole.log('Server running on https://localhost:8443');\n});\n\n} catch (err) {\nconsole.error('Failed to start server:', err);\nprocess.exit(1);\n}\n}\n\nstartServer();",
        "const http2 = require('http2');\nconst { URL } = require('url');\n\nclass HTTP2ConnectionPool {\nconstructor() {\nthis.connections = new Map();\n}\n\nasync getConnection(url) {\nconst { origin } = new URL(url);\n\nif (!this.connections.has(origin)) {\nconst client = http2.connect(origin, {\nrejectUnauthorized: false // Only for development\n});\n\n// Handle connection errors\nclient.on('error', (err) => {\nconsole.error('Connection error:', err);\nthis.connections.delete(origin);\n});\n\n// Remove connection when closed\nclient.on('close', () => {\nthis.connections.delete(origin);\n});\n\nthis.connections.set(origin, {\nclient,\nlastUsed: Date.now(),\ninUse: 0\n});\n}\n\nconst conn = this.connections.get(origin);\nconn.lastUsed = Date.now();\nconn.inUse++;\n\nreturn {\nclient: conn.client,\nrelease: () => {\nconn.inUse--;\n}\n};\n}\n\n// Clean up idle connections\nstartCleanup(interval = 30000) {\nsetInterval(() => {\nconst now = Date.now();\nfor (const [origin, conn] of this.connections.entries()) {\nif (conn.inUse === 0 && (now - conn.lastUsed) > 60000) {\nconn.client.destroy();\nthis.connections.delete(origin);\n}\n}\n}, interval);\n}\n}\n\n// Usage example\nconst pool = new HTTP2ConnectionPool();\npool.startCleanup();\n\nasync function makeRequest(url) {\nconst { client, release } = await pool.getConnection(url);\nreturn new Promise((resolve, reject) => {\nconst req = client.request({ ':path': new URL(url).pathname });\nlet data = '';\n\nreq.on('response', (headers) => {\nconsole.log('Status:', headers[':status']);\n});\n\nreq.on('data', (chunk) => data += chunk);\nreq.on('end', () => {\nrelease();\nresolve(data);\n});\nreq.on('error', (err) => {\nrelease();\nreject(err);\n});\n\nreq.end();\n});\n}",
        "const http2 = require('http2');\nconst fs = require('fs');\nconst { createSecureContext } = require('tls');\n\n// Security headers middleware\nfunction securityHeaders(req, res, next) {\n// Set security headers\nres.setHeader('X-Content-Type-Options', 'nosniff');\nres.setHeader('X-Frame-Options', 'DENY');\nres.setHeader('X-XSS-Protection', '1; mode=block');\nres.setHeader('Strict-Transport-Security', 'max-age=31536000; includeSubDomains');\nres.setHeader('Content-Security-Policy', \"default-src 'self'\");\n\n// Remove server header\nres.removeHeader('X-Powered-By');\n\nnext();\n}\n\n// Create secure server with modern TLS settings\nconst options = {\nkey: fs.readFileSync('server.key'),\ncert: fs.readFileSync('server.crt'),\nsecureOptions:\nrequire('constants').SSL_OP_NO_SSLv3 |\nrequire('constants').SSL_OP_NO_TLSv1 |\nrequire('constants').SSL_OP_NO_TLSv1_1,\nciphers: [\n'TLS_AES_256_GCM_SHA384',\n'TLS_CHACHA20_POLY1305_SHA256',\n'TLS_AES_128_GCM_SHA256'\n].join(':'),\nminVersion: 'TLSv1.3',\nmaxVersion: 'TLSv1.3',\n// OCSP Stapling\nrequestCert: false,\nrejectUnauthorized: true\n};\n\nconst server = http2.createSecureServer(options);\n\n// Apply security middleware\nserver.on('request', (req, res) => {\nsecurityHeaders(req, res, () => {\n// Request handling logic\nres.setHeader('Content-Type', 'text/plain');\nres.end('Secure HTTP/2 Response');\n});\n});\n\n// Handle TLS errors\nserver.on('tlsClientError', (err, tlsSocket) => {\nconsole.error('TLS Error:', err);\ntlsSocket.destroy();\n});\n\nserver.listen(8443);",
        "const http2 = require('http2');\nconst { URL } = require('url');\nconst path = require('path');\nconst fs = require('fs');\n\n// Service registry\nconst services = {\n'/users': 'http://users-service:3000',\n'/products': 'http://products-service:3000',\n'/orders': 'http://orders-service:3000'\n};\n\n// Create HTTP/2 server\nconst server = http2.createSecureServer({\nkey: fs.readFileSync('server.key'),\ncert: fs.readFileSync('server.crt')\n});\n\n// Route requests to appropriate services\nserver.on('stream', (stream, headers) => {\nconst path = headers[':path'];\nconst method = headers[':method'];\n\ntry {\n// Find matching service\nconst servicePath = Object.keys(services).find(prefix =>\npath.startsWith(prefix)\n);\n\nif (!servicePath) {\nstream.respond({ ':status': 404 });\nreturn stream.end('Not Found');\n}\n\nconst targetUrl = new URL(path.slice(servicePath.length), services[servicePath]);\n\n// Forward request to target service\nconst client = http2.connect(targetUrl.origin);\nconst req = client.request({\n...headers,\n':path': targetUrl.pathname + targetUrl.search,\n':method': method,\n':authority': targetUrl.host\n});\n\n// Pipe the response back to client\nreq.pipe(stream);\nstream.pipe(req);\n\n// Handle errors\nreq.on('error', (err) => {\nconsole.error('Request error:', err);\nif (!stream.destroyed) {\nstream.respond({ ':status': 502 });\nstream.end('Bad Gateway');\n}\n});\n\nstream.on('error', (err) => {\nconsole.error('Stream error:', err);\nreq.destroy();\n});\n\n} catch (err) {\nconsole.error('Gateway error:', err);\nif (!stream.destroyed) {\nstream.respond({ ':status': 500 });\nstream.end('Internal Server Error');\n}\n}\n});\n\nserver.listen(443);",
        "const http2 = require('http2');\nconst fs = require('fs');\n\nconst server = http2.createSecureServer({\nkey: fs.readFileSync('server.key'),\ncert: fs.readFileSync('server.crt')\n});\n\n// In-memory storage for active streams\nconst streams = new Set();\n\n// Broadcast data to all connected clients\nfunction broadcast(data) {\nconst payload = JSON.stringify(data);\nfor (const stream of streams) {\ntry {\nstream.write(`data: ${payload}\\n\\n`);\n} catch (err) {\nconsole.error('Stream write error:', err);\nstreams.delete(stream);\n}\n}\n}\n\n// Simulate data updates\nsetInterval(() => {\nbroadcast({\ntime: new Date().toISOString(),\nvalue: Math.random() * 100\n});\n}, 1000);\n\nserver.on('stream', (stream, headers) => {\n// Only handle GET requests\nif (headers[':method'] !== 'GET') {\nstream.respond({ ':status': 405 });\nreturn stream.end();\n}\n\n// Set up Server-Sent Events headers\nstream.respond({\n'content-type': 'text/event-stream',\n'cache-control': 'no-cache',\n'connection': 'keep-alive',\n':status': 200\n});\n\n// Add to active streams\nstreams.add(stream);\n\n// Handle client disconnect\nstream.on('close', () => {\nstreams.delete(stream);\n});\n\n// Send initial data\nstream.write('event: connect\\ndata: Connected\\n\\n');\n});\n\nserver.listen(8443, () => {\nconsole.log('HTTP/2 Server running on https://localhost:8443');\n});",
        "'headers'",
        "'data'",
        "'end'",
        "'error'"
      ]
    },
    {
      "title": "Node.js Performance Hooks Module",
      "summary": "What are Performance Hooks?\nThe perf_hooks module provides a set of APIs for performance measurement based on the W3C Performance Timeline specification.\nThese tools are essential for:\nMeasuring the time taken by specific operations\nFinding performance bottlenecks\nComparing the performance of different implementations\nTracking application performance over time\nThe module includes several useful features such as high-resolution timers, performance marks, measures, observers, and histograms.\nUsing the Performance Hooks Module\nTo use the Performance Hooks module, you need to require it in your code:\nBasic Time Measurement\nThe most basic use of the performance API is to measure elapsed time with high precision:\nThe performance.now() method returns a high-resolution timestamp in milliseconds, measured from the time the current Node.js process started.\nPerformance Marks and Measures\nMarks\nPerformance marks are specific points in time that you want to track:\nMeasures\nPerformance measures calculate the time duration between two marks:\nPerformance Observer\nThe PerformanceObserver allows you to observe performance events asynchronously:\nPerformance Timeline API\nThe Performance Timeline API provides methods to retrieve performance entries:\nPerformance Timing Levels\nNode.js provides different performance timing APIs with varying levels of precision:\nEvent Loop Monitoring\nThe monitorEventLoopDelay function provides a way to monitor the delay in the event loop:\nEvent loop monitoring is particularly useful for detecting when your application might be experiencing issues with responsiveness due to long-running tasks blocking the event loop.\nPerformance Tracking in Async Operations\nTracking performance in asynchronous operations requires careful mark placement:\nTracking Promises\nMeasuring the performance of promises requires similar techniques:\nPerformance Timing Caveats\nWhen using performance APIs, be aware of certain caveats:\nTiming resolution varies between platforms\nClock drift can occur in long-running processes\nBackground activity can affect timing measurements\nJavaScript JIT compilation can cause inconsistent first-run times\nNodeJS Performance Hooks vs Browser Performance API\nThe Node.js Performance Hooks API is based on the W3C Performance Timeline specification, but there are some differences compared to the browser's Performance API:\nPractical Example: API Performance Monitoring\nA practical example of using performance hooks to monitor API endpoints:\nAdvanced Performance Monitoring\nFor production-grade applications, consider these advanced monitoring techniques:\n1. Memory Leak Detection\nDetect and analyze memory leaks using performance hooks and Node.js memory monitoring:\nNote: The memory leak detection example requires the heapdump package. Install it using npm install heapdump.\n2. Custom Performance Metrics\nCreate and track custom performance metrics with detailed timing information:\nDistributed Tracing with Performance Hooks\nImplement distributed tracing across microservices using performance hooks:\nPerformance Optimization Techniques\nAdvanced techniques for optimizing Node.js application performance:\n1. Worker Threads for CPU-Intensive Tasks\nOffload CPU-intensive operations to worker threads to prevent blocking the event loop:\n2. Efficient Data Processing\nUse streams and buffers for efficient large data processing:\nPerformance Testing Best Practices\nWhen conducting performance testing, follow these best practices:\nTest in Production-Like Environments\nUse hardware similar to production\nInclude realistic data volumes\nSimulate production traffic patterns\nUse hardware similar to production\nInclude realistic data volumes\nSimulate production traffic patterns\nUse Statistical Significance\nRun multiple test iterations\nCalculate confidence intervals\nIgnore outliers appropriately\nRun multiple test iterations\nCalculate confidence intervals\nIgnore outliers appropriately\nMonitor System Resources\nTrack CPU and memory usage\nMonitor garbage collection\nWatch for memory leaks\nTrack CPU and memory usage\nMonitor garbage collection\nWatch for memory leaks\nProfile Before Optimizing\nIdentify actual bottlenecks\nMeasure before and after changes\nFocus on high-impact optimizations\nIdentify actual bottlenecks\nMeasure before and after changes\nFocus on high-impact optimizations",
      "examples": [
        "// Import the entire module\nconst { performance, PerformanceObserver } = require('perf_hooks');\n\n// Or using destructuring for specific parts\nconst { performance } = require('perf_hooks');",
        "const { performance } = require('perf_hooks');\n\n// Get the current high-resolution time\nconst startTime = performance.now();\n\n// Perform some operation\nlet sum = 0;\nfor (let i = 0; i < 1000000; i++) {\nsum += i;\n}\n\n// Get the end time\nconst endTime = performance.now();\n\n// Calculate and display the elapsed time in milliseconds\nconsole.log(`Operation took ${(endTime - startTime).toFixed(2)} milliseconds`);",
        "const { performance } = require('perf_hooks');\n\n// Create marks at specific points in your code\nperformance.mark('startProcess');\n\n// Simulate some work\nlet result = 0;\nfor (let i = 0; i < 1000000; i++) {\nresult += Math.sqrt(i);\n}\n\n// Create another mark\nperformance.mark('endProcess');\n\n// Get all the marks\nconsole.log(performance.getEntriesByType('mark'));",
        "const { performance } = require('perf_hooks');\n\n// Create a start mark\nperformance.mark('start');\n\n// Simulate some work\nlet result = 0;\nfor (let i = 0; i < 1000000; i++) {\nresult += Math.sqrt(i);\n}\n\n// Create an end mark\nperformance.mark('end');\n\n// Create a measure between the two marks\nperformance.measure('processTime', 'start', 'end');\n\n// Get the measure\nconst measure = performance.getEntriesByName('processTime')[0];\nconsole.log(`Process took ${measure.duration.toFixed(2)} milliseconds`);\n\n// Clear marks and measures\nperformance.clearMarks();\nperformance.clearMeasures();",
        "const { performance, PerformanceObserver } = require('perf_hooks');\n\n// Create a performance observer\nconst obs = new PerformanceObserver((items) => {\n// Process all entries\nconst entries = items.getEntries();\nentries.forEach((entry) => {\nconsole.log(`Name: ${entry.name}, Type: ${entry.entryType}, Duration: ${entry.duration.toFixed(2)}ms`);\n});\n});\n\n// Subscribe to specific entry types\nobs.observe({ entryTypes: ['measure'] });\n\n// First task\nperformance.mark('task1Start');\n// Simulate work\nsetTimeout(() => {\nperformance.mark('task1End');\nperformance.measure('Task 1', 'task1Start', 'task1End');\n\n// Second task\nperformance.mark('task2Start');\nsetTimeout(() => {\nperformance.mark('task2End');\nperformance.measure('Task 2', 'task2Start', 'task2End');\n\n// Clean up\nperformance.clearMarks();\nperformance.clearMeasures();\nobs.disconnect();\n}, 1000);\n}, 1000);",
        "const { performance } = require('perf_hooks');\n\n// Create some performance entries\nperformance.mark('mark1');\nperformance.mark('mark2');\n\nlet sum = 0;\nfor (let i = 0; i < 100000; i++) {\nsum += i;\n}\n\nperformance.mark('mark3');\nperformance.measure('measure1', 'mark1', 'mark2');\nperformance.measure('measure2', 'mark2', 'mark3');\n\n// Get all performance entries\nconsole.log('All entries:');\nconsole.log(performance.getEntries());\n\n// Get entries by type\nconsole.log('\\nMarks:');\nconsole.log(performance.getEntriesByType('mark'));\n\n// Get entries by name\nconsole.log('\\nMeasure 1:');\nconsole.log(performance.getEntriesByName('measure1'));",
        "const { performance, monitorEventLoopDelay } = require('perf_hooks');\n\n// 1. Date.now() - millisecond precision\nconst dateStart = Date.now();\nconst dateEnd = Date.now();\nconsole.log(`Date.now() difference: ${dateEnd - dateStart}ms`);\n\n// 2. process.hrtime() - nanosecond precision\nconst hrStart = process.hrtime();\nconst hrEnd = process.hrtime(hrStart);\nconsole.log(`process.hrtime() difference: ${hrEnd[0]}s ${hrEnd[1]}ns`);\n\n// 3. performance.now() - microsecond precision\nconst perfStart = performance.now();\nconst perfEnd = performance.now();\nconsole.log(`performance.now() difference: ${(perfEnd - perfStart).toFixed(6)}ms`);\n\n// 4. Event loop delay monitoring (available in Node.js 12.0.0+)\nconst histogram = monitorEventLoopDelay({ resolution: 20 });\nhistogram.enable();\n\nsetTimeout(() => {\nhistogram.disable();\nconsole.log('Event loop delay metrics:');\nconsole.log(`  Min: ${histogram.min}ns`);\nconsole.log(`  Max: ${histogram.max}ns`);\nconsole.log(`  Mean: ${histogram.mean.toFixed(2)}ns`);\nconsole.log(`  Stddev: ${histogram.stddev.toFixed(2)}ns`);\nconsole.log(`  Percentiles: 50=${histogram.percentile(50).toFixed(2)}ns, 99=${histogram.percentile(99).toFixed(2)}ns`);\n}, 1000);",
        "const { monitorEventLoopDelay } = require('perf_hooks');\n\n// Create a histogram\nconst histogram = monitorEventLoopDelay({ resolution: 10 });\n\n// Enable monitoring\nhistogram.enable();\n\n// Simulate load on the event loop\nconst operations = [];\nfor (let i = 0; i < 10; i++) {\noperations.push(new Promise((resolve) => {\nsetTimeout(() => {\n// Simulate CPU-intensive work\nlet sum = 0;\nfor (let j = 0; j < 10000000; j++) {\nsum += j;\n}\nresolve(sum);\n}, 100);\n}));\n}\n\n// After all operations complete\nPromise.all(operations).then(() => {\n// Disable monitoring\nhistogram.disable();\n\n// Print statistics\nconsole.log('Event Loop Delay Statistics:');\nconsole.log(`  Min: ${histogram.min}ns`);\nconsole.log(`  Max: ${histogram.max}ns`);\nconsole.log(`  Mean: ${histogram.mean.toFixed(2)}ns`);\nconsole.log(`  Stddev: ${histogram.stddev.toFixed(2)}ns`);\n\n// Percentiles\nconsole.log('\\nPercentiles:');\n[1, 10, 50, 90, 99, 99.9].forEach((p) => {\nconsole.log(`  p${p}: ${histogram.percentile(p).toFixed(2)}ns`);\n});\n});",
        "const { performance, PerformanceObserver } = require('perf_hooks');\nconst fs = require('fs');\n\n// Create observer for the measures\nconst obs = new PerformanceObserver((items) => {\nitems.getEntries().forEach((entry) => {\nconsole.log(`${entry.name}: ${entry.duration.toFixed(2)}ms`);\n});\n});\nobs.observe({ entryTypes: ['measure'] });\n\n// Measure async file read operation\nperformance.mark('readStart');\n\nfs.readFile(__filename, (err, data) => {\nif (err) throw err;\n\nperformance.mark('readEnd');\nperformance.measure('File Read', 'readStart', 'readEnd');\n\n// Measure async processing time\nperformance.mark('processStart');\n\n// Simulate processing the file data\nsetTimeout(() => {\nconst lines = data.toString().split('\\n').length;\n\nperformance.mark('processEnd');\nperformance.measure('File Processing', 'processStart', 'processEnd');\n\nconsole.log(`File has ${lines} lines`);\n\n// Clean up\nperformance.clearMarks();\nperformance.clearMeasures();\n}, 100);\n});",
        "const { performance, PerformanceObserver } = require('perf_hooks');\n\n// Set up the observer\nconst obs = new PerformanceObserver((items) => {\nitems.getEntries().forEach((entry) => {\nconsole.log(`${entry.name}: ${entry.duration.toFixed(2)}ms`);\n});\n});\nobs.observe({ entryTypes: ['measure'] });\n\n// Function that returns a promise\nfunction fetchData(delay) {\nreturn new Promise((resolve) => {\nsetTimeout(() => {\nresolve({ data: 'Sample data' });\n}, delay);\n});\n}\n\n// Function to process data\nfunction processData(data) {\nreturn new Promise((resolve) => {\nsetTimeout(() => {\nresolve({ processed: data.data.toUpperCase() });\n}, 200);\n});\n}\n\n// Measure Promise chain\nasync function run() {\nperformance.mark('fetchStart');\n\nconst data = await fetchData(300);\n\nperformance.mark('fetchEnd');\nperformance.mark('processStart');\n\nconst processed = await processData(data);\n\nperformance.mark('processEnd');\n\n// Create measures\nperformance.measure('Fetch Data', 'fetchStart', 'fetchEnd');\nperformance.measure('Process Data', 'processStart', 'processEnd');\nperformance.measure('Total Operation', 'fetchStart', 'processEnd');\n\nconsole.log('Result:', processed);\n}\n\nrun().finally(() => {\n// Clear after execution\nperformance.clearMarks();\nperformance.clearMeasures();\n});",
        "const { performance } = require('perf_hooks');\n\n// For accurate benchmarking, perform multiple runs\nfunction benchmark(fn, iterations = 1000) {\n// Warm-up run (for JIT optimization)\nfn();\n\nconst times = [];\n\nfor (let i = 0; i < iterations; i++) {\nconst start = performance.now();\nfn();\nconst end = performance.now();\ntimes.push(end - start);\n}\n\n// Calculate statistics\ntimes.sort((a, b) => a - b);\n\nconst sum = times.reduce((a, b) => a + b, 0);\nconst avg = sum / times.length;\nconst median = times[Math.floor(times.length / 2)];\nconst min = times[0];\nconst max = times[times.length - 1];\n\nreturn {\naverage: avg,\nmedian: median,\nmin: min,\nmax: max,\nsamples: times.length\n};\n}\n\n// Example usage\nfunction testFunction() {\n// Function to benchmark\nlet x = 0;\nfor (let i = 0; i < 10000; i++) {\nx += i;\n}\nreturn x;\n}\n\nconst results = benchmark(testFunction);\nconsole.log('Benchmark Results:');\nconsole.log(`  Samples: ${results.samples}`);\nconsole.log(`  Average: ${results.average.toFixed(4)}ms`);\nconsole.log(`  Median: ${results.median.toFixed(4)}ms`);\nconsole.log(`  Min: ${results.min.toFixed(4)}ms`);\nconsole.log(`  Max: ${results.max.toFixed(4)}ms`);",
        "const { performance, PerformanceObserver } = require('perf_hooks');\nconst express = require('express');\nconst app = express();\nconst port = 8080;\n\n// Set up performance observer for logging\nconst obs = new PerformanceObserver((items) => {\nitems.getEntries().forEach((entry) => {\nconsole.log(`[${new Date().toISOString()}] ${entry.name}: ${entry.duration.toFixed(2)}ms`);\n});\n});\nobs.observe({ entryTypes: ['measure'] });\n\n// Middleware to track request processing time\napp.use((req, res, next) => {\nconst start = performance.now();\nconst requestId = `${req.method} ${req.url} ${Date.now()}`;\n\n// Mark the start of request processing\nperformance.mark(`${requestId}-start`);\n\n// Override end method to capture when response is sent\nconst originalEnd = res.end;\nres.end = function(...args) {\nperformance.mark(`${requestId}-end`);\nperformance.measure(\n`Request ${req.method} ${req.url}`,\n`${requestId}-start`,\n`${requestId}-end`\n);\n\n// Clean up marks\nperformance.clearMarks(`${requestId}-start`);\nperformance.clearMarks(`${requestId}-end`);\n\nreturn originalEnd.apply(this, args);\n};\n\nnext();\n});\n\n// API routes\napp.get('/', (req, res) => {\nres.send('Hello World!');\n});\n\napp.get('/fast', (req, res) => {\nres.send('Fast response!');\n});\n\napp.get('/slow', (req, res) => {\n// Simulate a slow API endpoint\nsetTimeout(() => {\nres.send('Slow response after delay');\n}, 500);\n});\n\napp.get('/process', (req, res) => {\n// Simulate CPU-intensive processing\nconst requestId = `process-${Date.now()}`;\nperformance.mark(`${requestId}-process-start`);\n\nlet result = 0;\nfor (let i = 0; i < 1000000; i++) {\nresult += Math.sqrt(i);\n}\n\nperformance.mark(`${requestId}-process-end`);\nperformance.measure(\n'CPU Processing',\n`${requestId}-process-start`,\n`${requestId}-process-end`\n);\n\nres.send(`Processed result: ${result}`);\n});\n\n// Start server\napp.listen(port, () => {\nconsole.log(`Performance monitoring example running at http://localhost:${port}`);\n});",
        "const { performance, PerformanceObserver } = require('perf_hooks');\nconst { performance: perf } = require('process');\n\nclass MemoryMonitor {\nconstructor() {\nthis.leakThreshold = 10 * 1024 * 1024; // 10MB\nthis.checkInterval = 10000; // 10 seconds\nthis.interval = null;\nthis.lastMemoryUsage = process.memoryUsage();\nthis.leakDetected = false;\n\n// Set up performance observer for GC events\nconst obs = new PerformanceObserver((items) => {\nitems.getEntries().forEach((entry) => {\nif (entry.name === 'gc') {\nthis.checkMemoryLeak();\n}\n});\n});\nobs.observe({ entryTypes: ['gc'] });\n}\n\nstart() {\nconsole.log('Memory monitoring started');\nthis.interval = setInterval(() => this.checkMemoryLeak(), this.checkInterval);\n}\n\nstop() {\nif (this.interval) {\nclearInterval(this.interval);\nconsole.log('Memory monitoring stopped');\n}\n}\n\ncheckMemoryLeak() {\nconst current = process.memoryUsage();\nconst heapDiff = current.heapUsed - this.lastMemoryUsage.heapUsed;\n\nif (heapDiff > this.leakThreshold) {\nthis.leakDetected = true;\nconsole.warn(`⚠️  Possible memory leak detected: Heap increased by ${(heapDiff / 1024 / 1024).toFixed(2)}MB`);\nconsole.log('Memory snapshot:', {\nrss: this.formatMemory(current.rss),\nheapTotal: this.formatMemory(current.heapTotal),\nheapUsed: this.formatMemory(current.heapUsed),\nexternal: this.formatMemory(current.external)\n});\n\n// Take a heap snapshot if needed\nif (process.env.NODE_ENV === 'development') {\nthis.takeHeapSnapshot();\n}\n}\n\nthis.lastMemoryUsage = current;\n}\n\nformatMemory(bytes) {\nreturn `${(bytes / 1024 / 1024).toFixed(2)}MB`;\n}\n\ntakeHeapSnapshot() {\nconst heapdump = require('heapdump');\nconst filename = `heapdump-${Date.now()}.heapsnapshot`;\nheapdump.writeSnapshot(filename, (err, filename) => {\nif (err) {\nconsole.error('Failed to take heap snapshot:', err);\n} else {\nconsole.log(`Heap snapshot written to ${filename}`);\n}\n});\n}\n}\n\n// Usage example\nconst monitor = new MemoryMonitor();\nmonitor.start();\n\n// Simulate a memory leak\nconst leaks = [];\nsetInterval(() => {\nfor (let i = 0; i < 1000; i++) {\nleaks.push(new Array(1000).fill('*'.repeat(100)));\n}\n}, 1000);\n\n// Stop monitoring after 1 minute\nsetTimeout(() => {\nmonitor.stop();\nconsole.log('Memory monitoring completed');\n}, 60000);",
        "const { performance, PerformanceObserver, PerformanceEntry } = require('perf_hooks');\n\nclass PerformanceTracker {\nconstructor() {\nthis.metrics = new Map();\nthis.observers = new Map();\n\n// Set up default observer for custom metrics\nthis.setupDefaultObserver();\n}\n\nsetupDefaultObserver() {\nconst obs = new PerformanceObserver((items) => {\nitems.getEntries().forEach((entry) => {\nif (!this.metrics.has(entry.name)) {\nthis.metrics.set(entry.name, []);\n}\nthis.metrics.get(entry.name).push(entry);\n\n// Log detailed metrics\nthis.logMetric(entry);\n});\n});\n\nobs.observe({ entryTypes: ['measure'] });\nthis.observers.set('default', obs);\n}\n\nstartTimer(name) {\nperformance.mark(`${name}-start`);\n}\n\nendTimer(name, attributes = {}) {\nperformance.mark(`${name}-end`);\nperformance.measure(name, {\nstart: `${name}-start`,\nend: `${name}-end`,\n...attributes\n});\n\n// Clean up marks\nperformance.clearMarks(`${name}-start`);\nperformance.clearMarks(`${name}-end`);\n}\n\nlogMetric(entry) {\nconst { name, duration, startTime, entryType, detail } = entry;\nconsole.log(`📊 [${new Date().toISOString()}] ${name}: ${duration.toFixed(2)}ms`);\n\nif (detail) {\nconsole.log('   Details:', JSON.stringify(detail, null, 2));\n}\n}\n\ngetMetrics(name) {\nreturn this.metrics.get(name) || [];\n}\n\ngetStats(name) {\nconst metrics = this.getMetrics(name);\nif (metrics.length === 0) return null;\n\nconst durations = metrics.map(m => m.duration);\nconst sum = durations.reduce((a, b) => a + b, 0);\nconst avg = sum / durations.length;\n\nreturn {\ncount: durations.length,\ntotal: sum,\naverage: avg,\nmin: Math.min(...durations),\nmax: Math.max(...durations),\np90: this.percentile(durations, 90),\np95: this.percentile(durations, 95),\np99: this.percentile(durations, 99)\n};\n}\n\npercentile(arr, p) {\nif (!arr.length) return 0;\nconst sorted = [...arr].sort((a, b) => a - b);\nconst pos = (sorted.length - 1) * p / 100;\nconst base = Math.floor(pos);\nconst rest = pos - base;\n\nif (sorted[base + 1] !== undefined) {\nreturn sorted[base] + rest * (sorted[base + 1] - sorted[base]);\n} else {\nreturn sorted[base];\n}\n}\n}\n\n// Usage example\nconst tracker = new PerformanceTracker();\n\n// Track a simple operation\ntracker.startTimer('database-query');\nsetTimeout(() => {\ntracker.endTimer('database-query', {\ndetail: {\nquery: 'SELECT * FROM users',\nparams: { limit: 100 },\nsuccess: true\n}\n});\n\n// Get statistics\nconsole.log('Stats:', tracker.getStats('database-query'));\n}, 200);",
        "const { performance, PerformanceObserver } = require('perf_hooks');\nconst crypto = require('crypto');\n\nclass Tracer {\nconstructor(serviceName) {\nthis.serviceName = serviceName;\nthis.spans = new Map();\nthis.exportInterval = setInterval(() => this.exportSpans(), 10000);\n}\n\nstartSpan(name, parentSpanId = null) {\nconst spanId = crypto.randomBytes(8).toString('hex');\nconst traceId = parentSpanId ? this.spans.get(parentSpanId)?.traceId : crypto.randomBytes(16).toString('hex');\n\nconst span = {\nid: spanId,\ntraceId,\nparentSpanId,\nname,\nservice: this.serviceName,\nstartTime: performance.now(),\nendTime: null,\nduration: null,\ntags: {},\nlogs: []\n};\n\nthis.spans.set(spanId, span);\nreturn spanId;\n}\n\nendSpan(spanId, status = 'OK') {\nconst span = this.spans.get(spanId);\nif (!span) return;\n\nspan.endTime = performance.now();\nspan.duration = span.endTime - span.startTime;\nspan.status = status;\n\n// Auto-export if this is a root span\nif (!span.parentSpanId) {\nthis.exportSpan(span);\n}\n\nreturn span;\n}\n\naddTag(spanId, key, value) {\nconst span = this.spans.get(spanId);\nif (span) {\nspan.tags[key] = value;\n}\n}\n\nlog(spanId, message, data = {}) {\nconst span = this.spans.get(spanId);\nif (span) {\nspan.logs.push({\ntimestamp: new Date().toISOString(),\nmessage,\ndata: JSON.stringify(data)\n});\n}\n}\n\nexportSpan(span) {\n// In a real application, this would send the span to a tracing backend\n// like Jaeger, Zipkin, or AWS X-Ray\nconsole.log('Exporting span:', JSON.stringify(span, null, 2));\n\n// Clean up\nthis.spans.delete(span.id);\n}\n\nexportSpans() {\n// Export any remaining spans that have ended\nfor (const [id, span] of this.spans.entries()) {\nif (span.endTime) {\nthis.exportSpan(span);\n}\n}\n}\n\ninjectContext(spanId, headers = {}) {\nconst span = this.spans.get(spanId);\nif (!span) return headers;\n\nreturn {\n...headers,\n'x-trace-id': span.traceId,\n'x-span-id': span.id,\n'x-service': this.serviceName\n};\n}\n\nextractContext(headers) {\nconst traceId = headers['x-trace-id'] || crypto.randomBytes(16).toString('hex');\nconst parentSpanId = headers['x-span-id'] || null;\n\nreturn { traceId, parentSpanId };\n}\n}\n\n// Usage example\nconst tracer = new Tracer('user-service');\n\n// Simulate a request\nfunction handleRequest(req) {\nconst { traceId, parentSpanId } = tracer.extractContext(req.headers);\nconst spanId = tracer.startSpan('handle-request', parentSpanId);\n\ntracer.addTag(spanId, 'http.method', req.method);\ntracer.addTag(spanId, 'http.url', req.url);\n\n// Simulate work\nsetTimeout(() => {\n// Call another service\nconst childSpanId = tracer.startSpan('call-auth-service', spanId);\n\nsetTimeout(() => {\ntracer.endSpan(childSpanId, 'OK');\n\n// End the request\ntracer.endSpan(spanId, 'OK');\n}, 100);\n}, 50);\n\nreturn { status: 'processing', traceId };\n}\n\n// Simulate an incoming request\nconst request = {\nmethod: 'GET',\nurl: '/api/users/123',\nheaders: {}\n};\n\nconst response = handleRequest(request);\nconsole.log('Response:', response);\n\n// Wait for spans to complete\nsetTimeout(() => {}, 200);",
        "const { Worker, isMainThread, parentPort, workerData } = require('worker_threads');\nconst { performance, PerformanceObserver } = require('perf_hooks');\n\nif (isMainThread) {\n// Main thread\nfunction runWorker(data) {\nreturn new Promise((resolve, reject) => {\nconst start = performance.now();\n\nconst worker = new Worker(__filename, {\nworkerData: data\n});\n\nworker.on('message', (result) => {\nconst duration = performance.now() - start;\nresolve({\n...result,\nduration: `${duration.toFixed(2)}ms`\n});\n});\n\nworker.on('error', reject);\nworker.on('exit', (code) => {\nif (code !== 0) {\nreject(new Error(`Worker stopped with exit code ${code}`));\n}\n});\n});\n}\n\n// Example usage\nasync function main() {\ntry {\nconst result = await runWorker({\ntask: 'processData',\ndata: Array(1000000).fill().map((_, i) => i)\n});\n\nconsole.log('Worker result:', result);\n} catch (err) {\nconsole.error('Worker error:', err);\n}\n}\n\nmain();\n} else {\n// Worker thread\nfunction processData(data) {\n// Simulate CPU-intensive work\nreturn data.map(x => Math.sqrt(x) * Math.PI);\n}\n\ntry {\nconst result = processData(workerData.data);\nparentPort.postMessage({\ntask: workerData.task,\nresultLength: result.length,\nsample: result.slice(0, 5)\n});\n} catch (err) {\nparentPort.postMessage({ error: err.message });\n}\n}",
        "const { Transform } = require('stream');\nconst { performance } = require('perf_hooks');\n\nclass ProcessingPipeline {\nconstructor() {\nthis.startTime = performance.now();\nthis.processedItems = 0;\n}\n\ncreateTransformStream(transformFn) {\nreturn new Transform({\nobjectMode: true,\ntransform(chunk, encoding, callback) {\ntry {\nconst result = transformFn(chunk);\nthis.processedItems++;\ncallback(null, result);\n} catch (err) {\ncallback(err);\n}\n}\n});\n}\n\nasync processData(data, batchSize = 1000) {\nconst batches = [];\n\n// Process in batches\nfor (let i = 0; i < data.length; i += batchSize) {\nconst batch = data.slice(i, i + batchSize);\nconst processedBatch = await this.processBatch(batch);\nbatches.push(processedBatch);\n\n// Log progress\nconst progress = ((i + batchSize) / data.length * 100).toFixed(1);\nconsole.log(`Processed ${Math.min(i + batchSize, data.length)}/${data.length} (${progress}%)`);\n}\n\nreturn batches.flat();\n}\n\nprocessBatch(batch) {\nreturn new Promise((resolve) => {\nconst results = [];\n\n// Create a transform stream for processing\nconst processor = this.createTransformStream((item) => {\n// Simulate processing\nreturn {\n...item,\nprocessed: true,\ntimestamp: new Date().toISOString()\n};\n});\n\n// Collect results\nprocessor.on('data', (data) => {\nresults.push(data);\n});\n\nprocessor.on('end', () => {\nresolve(results);\n});\n\n// Process each item in the batch\nfor (const item of batch) {\nprocessor.write(item);\n}\n\nprocessor.end();\n});\n}\n\ngetStats() {\nconst endTime = performance.now();\nconst duration = endTime - this.startTime;\n\nreturn {\nprocessedItems: this.processedItems,\nduration: `${duration.toFixed(2)}ms`,\nitemsPerSecond: (this.processedItems / (duration / 1000)).toFixed(2)\n};\n}\n}\n\n// Example usage\nasync function main() {\n// Generate test data\nconst testData = Array(10000).fill().map((_, i) => ({\nid: i,\nvalue: Math.random() * 1000\n}));\n\nconsole.log('Starting data processing...');\nconst pipeline = new ProcessingPipeline();\n\n// Process data in batches\nconst result = await pipeline.processData(testData, 1000);\n\n// Print statistics\nconsole.log('Processing complete!');\nconsole.log('Statistics:', pipeline.getStats());\nconsole.log('Sample result:', result[0]);\n}\n\nmain().catch(console.error);",
        "perf_hooks",
        "performance.now()",
        "PerformanceObserver",
        "monitorEventLoopDelay",
        "heapdump",
        "npm install heapdump"
      ]
    },
    {
      "title": "Node.js VM Module",
      "summary": "Introduction to the VM Module\nThe VM (Virtual Machine) module allows you to compile and run code within isolated contexts.\nThis is useful for:\nRunning untrusted code safely in a sandbox\nEvaluating JavaScript code dynamically\nCreating plugins and extension systems\nBuilding custom scripting environments\nTesting code in isolation\nWarning: While the VM module provides isolation from the main JavaScript environment, it is not a completely secure sandbox. It should not be used as the sole security mechanism for running untrusted code.\nImporting the VM Module\nTo use the VM module, you need to import it in your Node.js application:\nKey Concepts\nThe VM module has several key components:\nBasic Usage: Running JavaScript in a Context\nThe simplest way to use the VM module is to run code in a context:\nIn this example:\nWe create a context object with a variable x\nWe \"contextify\" this object using vm.createContext()\nWe run JavaScript code in this context that modifies x and creates y\nThe changes are reflected in the context object\nVM Module Methods\nScript Methods\nContext Methods\nCreating and Compiling Scripts\nFor better performance when executing the same code multiple times, you can pre-compile it using the Script class:\nNote: Compiling scripts separately is more efficient when you need to execute the same code multiple times, as the parsing and compilation steps happen only once.\nDifferent Ways to Run Code\n1. runInContext\nRuns code in a previously created context:\n2. runInNewContext\nCreates a new context and runs code in it:\n3. runInThisContext\nRuns code in the current V8 context (similar to eval but safer):\nNote: runInThisContext is similar to eval, but it doesn't have access to local variables in the scope it was called from. This makes it somewhat safer, as it reduces the risk of code injection affecting local variables.\nWorking with the Timeout Option\nYou can set a timeout for script execution to prevent infinite loops or long-running scripts:\nWarning: The timeout option doesn't guarantee that execution will stop exactly at the specified time. The actual timeout may vary slightly.\nControlling Access to Node.js Core Modules\nBy default, code run in VM contexts doesn't have access to Node.js core modules. You can control which modules are available:\nWarning: While you can limit access to certain modules, this approach isn't completely secure. A determined attacker might still find ways to escape the sandbox. For truly secure sandboxing, consider additional isolation techniques or specialized libraries.\nBuilding a Simple Template Engine\nThe VM module can be used to create a simple template engine:\nNote: While this example demonstrates a simple use case, production template engines like Handlebars or EJS are more robust and secure. This example is vulnerable to injection attacks if user data isn't properly escaped.\nCreating a Plugin System\nThe VM module is useful for creating plugin systems where plugins can be loaded and executed in isolation:\nBest Practices and Security Considerations\nSecurity Best Practices\nDon't rely solely on the VM module for security: Use additional security measures for untrusted code.\nLimit resources: Set timeouts and memory limits for executed code.\nControl access: Only provide necessary functionality to the sandbox.\nValidate inputs: Carefully validate all inputs before processing them in a VM.\nConsider process isolation: For highest security, run untrusted code in separate processes or containers.\nPerformance Best Practices\nCompile scripts once: Use new vm.Script() for code that will be executed multiple times.\nReuse contexts: Creating new contexts is expensive, so reuse when possible.\nLimit context size: Keep contexts small to improve performance.\nBe cautious with large data: Passing large data structures between contexts can be inefficient.\nVM Module vs. eval()\nThe VM module provides several advantages over using eval():\nLimitations of the VM Module\nNot a complete sandbox: VM contexts don't provide true isolation like separate processes.\nNo CPU or memory limits: Cannot restrict resource usage directly (only timeout is available).\nPrototype pollution risks: Code in VM contexts can still potentially modify JavaScript prototypes.\nSynchronous execution: Running code blocks the event loop (unless you run it in a worker thread).\nDebugging challenges: Debugging code running in VM contexts can be difficult.\nWarning: For critical security applications, consider using more robust sandboxing solutions like separate processes with the child_process module, containers, or specialized libraries like vm2.\nSummary\nThe Node.js VM module provides a way to execute JavaScript code in isolated V8 contexts. It's useful for:\nRunning code dynamically with some level of isolation\nCreating plugin systems that can be extended safely\nBuilding template engines and scripting environments\nTesting code in controlled contexts\nWhile not a complete security solution for running untrusted code, the VM module offers more isolation than eval() and is a valuable tool for JavaScript evaluation within Node.js applications.\nAdvanced Context Management\nLearn how to create and manage complex VM contexts with custom globals and modules:\n1. Creating a Custom Context with Global Variables\n2. Module System in VM\nImplement a simple module system within a VM context:\nSecurity Best Practices\nWhen using the VM module, security should be your top priority. Here are some best practices:\nImportant: The VM module is not a security boundary. For running truly untrusted code, consider using dedicated sandboxing solutions like Docker, AWS Lambda, or Google Cloud Functions.\nPerformance Optimization\nOptimize VM performance with these techniques:\nPerformance Tips:\nPre-compile scripts when possible to avoid recompilation overhead\nReuse contexts instead of creating new ones for each execution\nMinimize context size by only including necessary globals\nUse code caching for frequently executed scripts\nMonitor performance to identify bottlenecks\nConsider worker threads for CPU-intensive operations",
      "examples": [
        "const vm = require('vm');",
        "const vm = require('vm');\n\n// Create a context object\nconst context = { x: 2 };\n\n// Compile and run a script in the context\nvm.createContext(context);\nvm.runInContext('x = x * 2; y = 10;', context);\n\n// Inspect the modified context\nconsole.log(context); // Outputs: { x: 4, y: 10 }",
        "const vm = require('vm');\n\n// Compile the script once\nconst script = new vm.Script('x += 40; let z = 30;');\n\n// Create multiple contexts\nconst context1 = { x: 10 };\nconst context2 = { x: 20 };\n\n// Contextify the objects\nvm.createContext(context1);\nvm.createContext(context2);\n\n// Run the same script in different contexts\nscript.runInContext(context1);\nscript.runInContext(context2);\n\nconsole.log(context1); // Outputs: { x: 50, z: 30 }\nconsole.log(context2); // Outputs: { x: 60, z: 30 }",
        "const vm = require('vm');\n\nconst context = { value: 10 };\nvm.createContext(context);\n\n// Run directly\nvm.runInContext('value += 5', context);\nconsole.log(context.value); // 15\n\n// Compile then run\nconst script = new vm.Script('value *= 2');\nscript.runInContext(context);\nconsole.log(context.value); // 30",
        "const vm = require('vm');\n\n// No need to call createContext first\nconst context = { value: 10 };\nvm.runInNewContext('value += 5; result = value * 2;', context);\n\nconsole.log(context); // { value: 15, result: 30 }",
        "const vm = require('vm');\n\n// Define a variable in the current scope\nconst locallet = 20;\nlet result;\n\n// This won't have access to localVar\nvm.runInThisContext('result = (typeof locallet !== \"undefined\" ? locallet : \"not defined\")');\nconsole.log(result); // 'not defined'\n\n// But it can access globals\nglobal.globallet = 30;\nvm.runInThisContext('result = globalVar');\nconsole.log(result); // 30\n\n// Compare with eval, which CAN access local variables\neval('result = localVar');\nconsole.log(result); // 20",
        "const vm = require('vm');\n\nconst context = { result: 0 };\nvm.createContext(context);\n\ntry {\n// This should timeout after 1000ms (1 second)\nvm.runInContext(`\nlet counter = 0;\nwhile (true) {\ncounter++;\nresult = counter;\n}\n`, context, { timeout: 1000 });\n} catch (err) {\nconsole.error(`Execution timed out: ${err.message}`);\nconsole.log(`Results before timeout: counter reached ${context.result}`);\n}",
        "const vm = require('vm');\nconst fs = require('fs');\n\n// Create a sandbox with controlled access to core modules\nconst sandbox = {\n// Allow limited access to console\nconsole: {\nlog: console.log,\nerror: console.error\n},\n\n// Provide controlled access to fs module\nfs: {\nreadFileSync: fs.readFileSync\n},\n\n// Custom utility\nutil: {\nadd: (a, b) => a + b,\nmultiply: (a, b) => a * b\n},\n\n// No access to process, child_process, etc.\n};\n\nvm.createContext(sandbox);\n\n// Run code with limited access\ntry {\nvm.runInContext(`\n// We can use the allowed methods\nconsole.log('Running in sandbox');\nconsole.log('2 + 3 =', util.add(2, 3));\n\n// Try to read a safe file\ntry {\nconst content = fs.readFileSync('example.txt', 'utf8');\nconsole.log('File content:', content);\n} catch (err) {\nconsole.error('File read error:', err.message);\n}\n\n// Try to access process (should fail)\ntry {\nconsole.log('Process info:', process.version);\n} catch (err) {\nconsole.error('Cannot access process:', err.message);\n}\n`, sandbox);\n} catch (err) {\nconsole.error('Sandbox execution failed:', err);\n}",
        "const vm = require('vm');\n\nfunction renderTemplate(template, data) {\n// Create template function - replace {{ let }} with values\nconst templateScript = `\nfunction template(data) {\nlet output = \\`${template.replace(/\\{\\{\\s*(\\w+)\\s*\\}\\}/g, '${data.$1}')}\\`;\nreturn output;\n}\ntemplate(data);\n`;\n\n// Create a context with the data\nconst context = { data };\nvm.createContext(context);\n\n// Execute the template function\nreturn vm.runInContext(templateScript, context);\n}\n\n// Example usage\nconst template = `\n<!DOCTYPE html>\n<html>\n<head>\n<title>{{ title }}</title>\n</head>\n<body>\n<h1>{{ title }}</h1>\n<p>Welcome, {{ name }}!</p>\n<p>Today is {{ date }}</p>\n</body>\n</html>\n`;\n\nconst data = {\ntitle: 'My Template Page',\nname: 'User',\ndate: new Date().toLocaleDateString()\n};\n\nconst rendered = renderTemplate(template, data);\nconsole.log(rendered);",
        "const vm = require('vm');\nconst fs = require('fs');\nconst path = require('path');\n\nclass PluginSystem {\nconstructor() {\nthis.plugins = new Map();\nthis.api = {\nversion: '1.0.0',\nregisterHook: this.registerHook.bind(this),\nutils: {\nadd: (a, b) => a + b,\nmultiply: (a, b) => a * b,\nformatDate: (date) => new Date(date).toLocaleDateString()\n}\n};\n\nthis.hooks = {\ninit: [],\nprocess: [],\nshutdown: []\n};\n}\n\n// Register a plugin hook\nregisterHook(hookName, callback) {\nif (this.hooks[hookName]) {\nthis.hooks[hookName].push(callback);\nconsole.log(`Registered ${hookName} hook`);\n} else {\nconsole.error(`Invalid hook name: ${hookName}`);\n}\n}\n\n// Load a plugin from file\nloadPlugin(pluginName, pluginCode) {\ntry {\nconsole.log(`Loading plugin: ${pluginName}`);\n\n// Create a sandbox for this plugin\nconst sandbox = {\nconsole: {\nlog: (msg) => console.log(`[${pluginName}] ${msg}`),\nerror: (msg) => console.error(`[${pluginName}] ${msg}`)\n},\nsetTimeout,\nclearTimeout,\napi: this.api\n};\n\n// Create context and run the plugin code\nconst context = vm.createContext(sandbox);\nvm.runInContext(pluginCode, context);\n\n// Store the loaded plugin\nthis.plugins.set(pluginName, {\nname: pluginName,\nsandbox\n});\n\nconsole.log(`Successfully loaded plugin: ${pluginName}`);\n} catch (err) {\nconsole.error(`Error loading plugin ${pluginName}:`, err.message);\n}\n}\n\n// Run all hooks of a specific type\nasync runHooks(hookName, data) {\nconsole.log(`Running ${hookName} hooks...`);\n\nfor (const hook of this.hooks[hookName]) {\ntry {\nconst result = await hook(data);\nconsole.log(`Hook result:`, result);\n} catch (err) {\nconsole.error(`Error in ${hookName} hook:`, err.message);\n}\n}\n}\n\n// Load all plugins from a directory\nloadPluginsFromDirectory(directory) {\ntry {\nconst files = fs.readdirSync(directory);\n\nfor (const file of files) {\nif (file.endsWith('.js')) {\nconst pluginName = path.basename(file, '.js');\nconst pluginPath = path.join(directory, file);\nconst pluginCode = fs.readFileSync(pluginPath, 'utf8');\n\nthis.loadPlugin(pluginName, pluginCode);\n}\n}\n} catch (err) {\nconsole.error('Error loading plugins directory:', err.message);\n}\n}\n\n// Run the plugin system\nasync run(data) {\nawait this.runHooks('init', data);\nawait this.runHooks('process', data);\nawait this.runHooks('shutdown', data);\n}\n}\n\n// Example plugin code (normally this would be in a separate file)\nconst examplePlugin = `\n// Register initialization hook\napi.registerHook('init', async (data) => {\nconsole.log('Plugin initializing with data:', data);\nreturn 'Initialization complete';\n});\n\n// Register processing hook\napi.registerHook('process', async (data) => {\nconsole.log('Processing data');\nreturn {\nprocessed: true,\nsum: api.utils.add(data.x, data.y),\nproduct: api.utils.multiply(data.x, data.y),\ndate: api.utils.formatDate(new Date())\n};\n});\n\n// Register shutdown hook\napi.registerHook('shutdown', async () => {\nconsole.log('Plugin shutting down');\nreturn 'Shutdown complete';\n});\n\nconsole.log('Plugin loaded with API version', api.version);\n`;\n\n// Create and run the plugin system\n(async () => {\nconst system = new PluginSystem();\n\n// Load plugins\nsystem.loadPlugin('example', examplePlugin);\n\n// You could also load from a directory\n// system.loadPluginsFromDirectory('./plugins');\n\n// Run the system\nawait system.run({ x: 5, y: 10 });\n})();",
        "const vm = require('vm');\nconst util = require('util');\n\n// Create a custom context with specific global variables\nconst context = {\nconsole: {\nlog: (...args) => {\n// Custom console.log implementation\nprocess.stdout.write('Custom Log: ' + util.format(...args) + '\\n');\n},\nerror: console.error,\nwarn: console.warn,\ninfo: console.info\n},\n// Add custom utilities\nutils: {\nformatDate: () => new Date().toISOString(),\ngenerateId: () => Math.random().toString(36).substr(2, 9)\n},\n// Add a safe require function\nrequire: (moduleName) => {\nconst allowedModules = ['path', 'url', 'util'];\nif (!allowedModules.includes(moduleName)) {\nthrow new Error(`Module '${moduleName}' is not allowed`);\n}\nreturn require(moduleName);\n}\n};\n\n// Contextify the object\nvm.createContext(context);\n\n// Run code in the custom context\nconst code = `\nconsole.log('Current time:', utils.formatDate());\nconsole.log('Generated ID:', utils.generateId());\n\ntry {\nconst fs = require('fs'); // This will throw an error\n} catch (err) {\nconsole.error('Security error:', err.message);\n}\n\n// This will work as it's an allowed module\nconst path = require('path');\nconsole.log('Current directory:', path.dirname('/path/to/file.txt'));\n`;\n\ntry {\nvm.runInContext(code, context, { filename: 'custom-context.js' });\n} catch (err) {\nconsole.error('Script execution failed:', err);\n}",
        "const vm = require('vm');\nconst fs = require('fs');\nconst path = require('path');\n\nclass VMModuleSystem {\nconstructor(basePath = '.') {\nthis.basePath = path.resolve(basePath);\nthis.cache = new Map();\nthis.context = vm.createContext({\nmodule: { exports: {} },\nexports: {},\nconsole: console,\nrequire: this.require.bind(this),\n__dirname: this.basePath,\n__filename: path.join(this.basePath, 'main.js')\n});\n}\n\nrequire(modulePath) {\n// Handle core modules\nif (require.resolve.paths(modulePath) === null) {\nreturn require(modulePath);\n}\n\n// Resolve the module path\nconst resolvedPath = this.resolveModule(modulePath);\n\n// Check cache\nif (this.cache.has(resolvedPath)) {\nreturn this.cache.get(resolvedPath).exports;\n}\n\n// Create new module\nconst module = { exports: {} };\nthis.cache.set(resolvedPath, module);\n\ntry {\n// Read and execute the module\nconst code = fs.readFileSync(resolvedPath, 'utf8');\nconst wrapper = `(function(module, exports, require, __dirname, __filename) {${code}\\n})`;\n\nconst script = new vm.Script(wrapper, {\nfilename: resolvedPath,\nlineOffset: 0,\ndisplayErrors: true\n});\n\nconst localRequire = (path) => this.require(path);\nlocalRequire.resolve = (request) => this.resolveModule(request, resolvedPath);\n\nscript.runInNewContext({\nmodule: module,\nexports: module.exports,\nrequire: localRequire,\n__dirname: path.dirname(resolvedPath),\n__filename: resolvedPath\n});\n\nreturn module.exports;\n} catch (err) {\nthis.cache.delete(resolvedPath);\nthrow err;\n}\n}\n\nresolveModule(request, parentPath) {\ntry {\n// Try to resolve as a file\nif (request.startsWith('./') || request.startsWith('../')) {\nconst resolved = path.resolve(path.dirname(parentPath || this.basePath), request);\n\n// Try with .js extension\ntry {\nconst stats = fs.statSync(resolved + '.js');\nif (stats.isFile()) return resolved + '.js';\n} catch (e) {}\n\n// Try as directory with index.js\ntry {\nconst indexPath = path.join(resolved, 'index.js');\nconst stats = fs.statSync(indexPath);\nif (stats.isFile()) return indexPath;\n} catch (e) {}\n\n// Try as file without extension\ntry {\nconst stats = fs.statSync(resolved);\nif (stats.isFile()) return resolved;\n} catch (e) {}\n}\n\n// Try to resolve as a module\ntry {\nreturn require.resolve(request);\n} catch (e) {\nthrow new Error(`Cannot find module '${request}'`);\n}\n} catch (err) {\nthrow new Error(`Cannot find module '${request}': ${err.message}`);\n}\n}\n\nrunFile(filePath) {\nconst absolutePath = path.resolve(this.basePath, filePath);\nreturn this.require(absolutePath);\n}\n}\n\n// Example usage\nconst moduleSystem = new VMModuleSystem(__dirname);\n\ntry {\n// This will execute the file in the VM with the custom module system\nmoduleSystem.runFile('example-module.js');\n} catch (err) {\nconsole.error('Module execution failed:', err);\n}",
        "const vm = require('vm');\nconst { execSync } = require('child_process');\n\n// UNSAFE: Directly executing untrusted code\nfunction unsafeEval(code) {\n// This is dangerous as it has access to the entire Node.js environment\nreturn vm.runInThisContext(code);\n}\n\n// SAFER: Isolated context with limited access\nfunction safeEval(code, timeout = 1000) {\n// Create a context with only the necessary globals\nconst context = {\nconsole: {\nlog: console.log,\nerror: console.error\n},\n// Add safe utilities\nMath: Object.create(null),\nJSON: {\nparse: JSON.parse,\nstringify: JSON.stringify\n},\n// Add a safe setTimeout with limits\nsetTimeout: (fn, delay) => {\nif (delay > 1000) delay = 1000; // Cap delay at 1 second\nreturn setTimeout(fn, delay);\n}\n};\n\n// Copy safe methods from Math\nObject.getOwnPropertyNames(Math)\n.filter(prop => typeof Math[prop] === 'function')\n.forEach(prop => {\ncontext.Math[prop] = Math[prop];\n});\n\n// Create the context without prototype access\nconst sandbox = vm.createContext(context, {\nname: 'sandbox',\ncodeGeneration: {\nstrings: false,\nwasm: false\n}\n});\n\n// Run the code with a timeout\ntry {\nconst script = new vm.Script(`\n(function() {\n\"use strict\";\n${code}\n})();\n`, {\nfilename: 'sandbox.js',\nlineOffset: 0,\ndisplayErrors: true,\ntimeout: timeout,\nmicrotaskMode: 'afterEvaluate'\n});\n\nreturn script.runInContext(sandbox, { timeout });\n} catch (err) {\nconsole.error('Script execution failed:', err.message);\nthrow new Error('Script execution failed');\n}\n}\n\n// Example of safe evaluation\ntry {\nconst result = safeEval(`\nfunction add(a, b) { return a + b; }\nadd(2, 3);\n`);\nconsole.log('Safe evaluation result:', result); // Outputs: 5\n\n// This will be caught by our safe evaluator\nsafeEval('process.exit(1)');\n} catch (err) {\nconsole.error('Caught error:', err.message);\n}\n\n// Example of security risks\nconsole.log('\\nTesting security risks:');\n\ntry {\nconsole.log('1. Accessing process:');\nsafeEval('process.versions.node');\n} catch (err) {\nconsole.log('✓ Blocked access to process object');\n}\n\ntry {\nconsole.log('2. Infinite loop:');\nsafeEval('while(true){}');\n} catch (err) {\nconsole.log('✓ Caught infinite loop with timeout');\n}\n\ntry {\nconsole.log('3. Prototype pollution:');\nsafeEval('({}).constructor.prototype.polluted = true');\nconsole.log('✓ Blocked prototype pollution');\n} catch (err) {\nconsole.log('✓ Blocked prototype pollution');\n}",
        "const vm = require('vm');\nconst { performance, PerformanceObserver } = require('perf_hooks');\n\n// 1. Compile once, run many times\nconst expensiveCalculation = new vm.Script(`\nfunction calculate(n) {\nlet result = 0;\nfor (let i = 0; i < n; i++) {\nresult += Math.sqrt(i) * Math.PI;\n}\nreturn result;\n}\n\n// Return the function reference\ncalculate;\n`);\n\n// Create a context\nconst context = { Math };\nvm.createContext(context);\n\n// Run once to get the function\nconst calculate = expensiveCalculation.runInContext(context);\n\n// Now we can call the function multiple times without recompiling\nconsole.log('Result (n=1000):', calculate(1000));\nconsole.log('Result (n=2000):', calculate(2000));\n\n// 2. Use code caching for better performance\nconst cache = new Map();\n\nfunction compileWithCache(code, filename) {\nif (cache.has(code)) {\nconsole.log(`Using cached script for ${filename}`);\nreturn cache.get(code);\n}\n\nconsole.log(`Compiling script for ${filename}`);\nconst script = new vm.Script(code, {\nfilename,\ncachedData: null, // Will be populated on first run\nproduceCachedData: true\n});\n\ncache.set(code, script);\nreturn script;\n}\n\n// 3. Measure performance\nfunction measurePerformance() {\nconst obs = new PerformanceObserver((items) => {\nconst entry = items.getEntries()[0];\nconsole.log(`\\nExecution time for ${entry.name}: ${entry.duration.toFixed(2)}ms`);\nperformance.clearMarks();\n});\nobs.observe({ entryTypes: ['measure'] });\n\n// Test with different script sizes\nconst smallScript = new vm.Script('let sum = 0; for (let i = 0; i < 1000; i++) sum += i; return sum;');\nconst largeScript = new vm.Script(`\nfunction processData(data) {\nreturn data.map(x => ({\n...x,\nprocessed: true,\ntimestamp: Date.now(),\nhash: require('crypto').createHash('md5').update(JSON.stringify(x)).digest('hex')\n}));\n}\n\n// Process sample data\nconst data = Array(1000).fill(null).map((_, i) => ({ id: i, value: Math.random() }));\nreturn processData(data);\n`);\n\n// Measure execution\nperformance.mark('small-start');\nsmallScript.runInThisContext();\nperformance.mark('small-end');\n\nperformance.mark('large-start');\nlargeScript.runInThisContext();\nperformance.mark('large-end');\n\nperformance.measure('Small script execution', 'small-start', 'small-end');\nperformance.measure('Large script execution', 'large-start', 'large-end');\n}\n\n// Run performance test\nmeasurePerformance();\n\n// 4. Reuse contexts for better performance\nfunction createOptimizedContext() {\nconst context = {\n// Only include what's necessary\nconsole: {\nlog: console.log,\nerror: console.error\n},\n// Add required globals\nsetTimeout,\nclearTimeout,\n// Add custom utilities\nutils: {\nformatNumber: n => new Intl.NumberFormat().format(n),\nformatDate: d => d.toISOString()\n}\n};\n\n// Create context once\nvm.createContext(context);\nreturn context;\n}\n\n// Reuse the same context for multiple scripts\nconst sharedContext = createOptimizedContext();\n\n// Run multiple scripts with the same context\nfunction runWithSharedContext(code) {\ntry {\nconst script = new vm.Script(code);\nreturn script.runInContext(sharedContext);\n} catch (err) {\nconsole.error('Script execution failed:', err);\nthrow err;\n}\n}\n\n// Example usage\nconst script1 = 'console.log(\"Script 1:\", utils.formatNumber(1234567.89));';\nconst script2 = 'console.log(\"Script 2:\", utils.formatDate(new Date()));';\n\nrunWithSharedContext(script1);\nrunWithSharedContext(script2);",
        "Script",
        "Context",
        "ContextifiedObject",
        "x",
        "vm.createContext()",
        "y",
        "vm.Script(code[, options])",
        "script.runInContext(contextObject[, options])",
        "script.runInNewContext([contextObject][, options])",
        "script.runInThisContext([options])",
        "vm.createContext([contextObject][, options])",
        "vm.isContext(object)",
        "vm.runInContext(code, contextObject[, options])",
        "vm.runInNewContext(code[, contextObject][, options])",
        "vm.runInThisContext(code[, options])",
        "eval",
        "runInThisContext",
        "new vm.Script()",
        "eval()",
        "child_process",
        "vm2"
      ]
    },
    {
      "title": "Node.js TLS/SSL Module",
      "summary": "What is TLS/SSL?\nTransport Layer Security (TLS) and its predecessor, Secure Socket Layer (SSL), are protocols that provide secure communication over a computer network. They ensure:\nPrivacy: Communications are encrypted to prevent eavesdropping\nData integrity: Message contents cannot be modified without detection\nAuthentication: The identities of the communicating parties can be verified\nTLS/SSL is commonly used for securing:\nWeb browsing (HTTPS)\nEmail transmissions (SMTP, IMAP, POP3)\nInstant messaging\nVoice over IP (VoIP)\nAPI communication\nUsing the TLS Module\nTo use the TLS module in Node.js, you need to require it:\nTLS Server\nHere's how to create a basic TLS server:\nThis example requires certificate files (server-key.pem and server-cert.pem). For development purposes, you can generate self-signed certificates using OpenSSL.\nGenerating Self-Signed Certificates for Development\nYou can use OpenSSL to generate self-signed certificates for development and testing:\nTLS Client\nCreating a client that connects to a TLS server:\nServer and Client Options\nBoth tls.createServer() and tls.connect() accept various options to configure the TLS connection:\nCommon Options\nkey: Private key in PEM format\ncert: Certificate in PEM format\nca: Trusted CA certificates\nciphers: Cipher suite specification string\nminVersion: Minimum TLS version to allow\nmaxVersion: Maximum TLS version to allow\nServer-specific Options\nrequestCert: Whether to request a certificate from clients\nrejectUnauthorized: Whether to reject clients with invalid certificates\nSNICallback: Function to handle SNI from the client\nClient-specific Options\nservername: Server name for SNI\ncheckServerIdentity: Function to verify server hostname\nsession: A Buffer instance containing TLS session\nSecure HTTP Server (HTTPS)\nWhile the TLS module can be used directly, for HTTPS servers, Node.js provides a higher-level https module built on top of TLS:\nThe HTTPS module provides a more convenient way to create secure HTTP servers, but it uses the TLS module under the hood.\nTLS with Express\nYou can also create an HTTPS server with Express:\nCertificate Verification\nTLS uses certificates to verify the identity of servers and optionally clients. Here's an example showing how to implement custom certificate verification:\nTLS Session Resumption\nSession resumption allows clients to reconnect to a server without performing a full TLS handshake, improving performance:\nServer Name Indication (SNI)\nSNI allows a server to present different certificates for different hostnames on the same IP address and port:\nAdvanced Certificate Management\nProper certificate management is crucial for secure TLS communications. Here are some advanced techniques:\n1. Certificate Chain and Multiple CAs\n2. Certificate Revocation with CRL\n3. Automatic Certificate Management with Let's Encrypt\nNote: The Let's Encrypt example is simplified. In production, use a well-maintained ACME client library and follow Let's Encrypt's rate limits and best practices.\nSecurity Best Practices\nWhen using TLS in production applications, consider these security best practices:\n1. Use Strong TLS Versions\n2. Configure Strong Cipher Suites\n3. Use Perfect Forward Secrecy\n4. Implement OCSP Stapling (Online Certificate Status Protocol)\n5. ALPN and SNI Support\nApplication-Layer Protocol Negotiation (ALPN) and Server Name Indication (SNI) are important TLS extensions that enable protocol negotiation and virtual hosting:\n6. Use HTTP Strict Transport Security (HSTS)",
      "examples": [
        "const tls = require('tls');",
        "const tls = require('tls');\nconst fs = require('fs');\nconst path = require('path');\n\n// Server options with TLS certificates\nconst options = {\nkey: fs.readFileSync(path.join(__dirname, 'server-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'server-cert.pem')),\n// Request client certificate (optional)\nrequestCert: true,\n// Reject connections without authorized certificates (optional)\nrejectUnauthorized: false\n};\n\n// Create TLS server\nconst server = tls.createServer(options, (socket) => {\nconsole.log('Server connected',\nsocket.authorized ? 'authorized' : 'unauthorized');\n\n// Set encoding for data\nsocket.setEncoding('utf8');\n\n// Handle incoming data\nsocket.on('data', (data) => {\nconsole.log('Received:', data);\n// Echo back the data\nsocket.write(`You said: ${data}`);\n});\n\n// Handle socket closure\nsocket.on('end', () => {\nconsole.log('Socket ended');\n});\n\n// Write welcome message\nsocket.write('Welcome to the TLS server!\\n');\n});\n\n// Start TLS server\nconst port = 8000;\nserver.listen(port, () => {\nconsole.log(`TLS server running on port ${port}`);\n});",
        "# Generate CA certificate\nopenssl genrsa -out ca-key.pem 2048\nopenssl req -new -x509 -key ca-key.pem -out ca-cert.pem -days 365\n\n# Generate server certificate\nopenssl genrsa -out server-key.pem 2048\nopenssl req -new -key server-key.pem -out server-csr.pem\nopenssl x509 -req -in server-csr.pem -CA ca-cert.pem -CAkey ca-key.pem -CAcreateserial -out server-cert.pem -days 365\n\n# Generate client certificate (optional, for mutual authentication)\nopenssl genrsa -out client-key.pem 2048\nopenssl req -new -key client-key.pem -out client-csr.pem\nopenssl x509 -req -in client-csr.pem -CA ca-cert.pem -CAkey ca-key.pem -CAcreateserial -out client-cert.pem -days 365",
        "const tls = require('tls');\nconst fs = require('fs');\nconst path = require('path');\n\n// Client options\nconst options = {\n// For mutual authentication (optional)\nkey: fs.readFileSync(path.join(__dirname, 'client-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'client-cert.pem')),\n// Server name for Server Name Indication (SNI)\nservername: 'localhost',\n// CA certificate to verify the server (optional)\nca: fs.readFileSync(path.join(__dirname, 'ca-cert.pem')),\n// Reject unauthorized certificates\nrejectUnauthorized: true\n};\n\n// Connect to server\nconst client = tls.connect(8000, 'localhost', options, () => {\n// Check if authorized\nconsole.log('Client connected',\nclient.authorized ? 'authorized' : 'unauthorized');\n\nif (!client.authorized) {\nconsole.log('Reason:', client.authorizationError);\n}\n\n// Send data to server\nclient.write('Hello from TLS client!');\n});\n\n// Set encoding for received data\nclient.setEncoding('utf8');\n\n// Handle received data\nclient.on('data', (data) => {\nconsole.log('Received from server:', data);\n\n// Send another message\nclient.write('How are you?');\n});\n\n// Handle errors\nclient.on('error', (error) => {\nconsole.error('Connection error:', error);\n});\n\n// Handle connection end\nclient.on('end', () => {\nconsole.log('Server ended connection');\n});\n\n// Close connection after 5 seconds\nsetTimeout(() => {\nconsole.log('Closing connection');\nclient.end();\n}, 5000);",
        "const tls = require('tls');\nconst fs = require('fs');\n\n// Comprehensive server options\nconst serverOptions = {\n// Key and certificate\nkey: fs.readFileSync('server-key.pem'),\ncert: fs.readFileSync('server-cert.pem'),\n\n// Certificate Authority\nca: [fs.readFileSync('ca-cert.pem')],\n\n// Protocol version control\nminVersion: 'TLSv1.2',\nmaxVersion: 'TLSv1.3',\n\n// Cipher control\nciphers: 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384',\n\n// Client authentication\nrequestCert: true,\nrejectUnauthorized: true,\n\n// Server Name Indication handling\nSNICallback: (servername, cb) => {\n// Different certificates for different servernames\nif (servername === 'example.com') {\ncb(null, tls.createSecureContext({\nkey: fs.readFileSync('example-key.pem'),\ncert: fs.readFileSync('example-cert.pem')\n}));\n} else {\n// Default certificate\ncb(null, tls.createSecureContext({\nkey: fs.readFileSync('default-key.pem'),\ncert: fs.readFileSync('default-cert.pem')\n}));\n}\n}\n};\n\n// Example client options\nconst clientOptions = {\nkey: fs.readFileSync('client-key.pem'),\ncert: fs.readFileSync('client-cert.pem'),\nca: [fs.readFileSync('ca-cert.pem')],\n\nservername: 'example.com',\nminVersion: 'TLSv1.2',\n\n// Custom identity check function\ncheckServerIdentity: (hostname, cert) => {\n// Custom validation logic\nif (hostname !== cert.subject.CN) {\nreturn new Error(`Certificate CN does not match hostname: ${hostname}`);\n}\nreturn undefined; // No error\n},\n\n// Session reuse\nsession: savedTlsSession, // Previously saved session\n};",
        "const https = require('https');\nconst fs = require('fs');\nconst path = require('path');\n\n// HTTPS server options\nconst options = {\nkey: fs.readFileSync(path.join(__dirname, 'server-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'server-cert.pem'))\n};\n\n// Create HTTPS server\nhttps.createServer(options, (req, res) => {\nres.writeHead(200, { 'Content-Type': 'text/html' });\nres.end('<h1>Secure HTTPS Server</h1><p>This connection is encrypted using TLS.</p>');\n}).listen(443, () => {\nconsole.log('HTTPS server running on port 443');\n});",
        "const express = require('express');\nconst https = require('https');\nconst fs = require('fs');\nconst path = require('path');\n\n// Create Express app\nconst app = express();\n\n// Define routes\napp.get('/', (req, res) => {\nres.send('<h1>Secure Express App</h1><p>This connection is encrypted using TLS.</p>');\n});\n\napp.get('/api/data', (req, res) => {\nres.json({\nmessage: 'This is sensitive data',\ntimestamp: new Date()\n});\n});\n\n// HTTPS server options\nconst options = {\nkey: fs.readFileSync(path.join(__dirname, 'server-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'server-cert.pem'))\n};\n\n// Create HTTPS server with Express app\nconst port = 443;\nhttps.createServer(options, app).listen(port, () => {\nconsole.log(`Secure Express app running on port ${port}`);\n});",
        "const tls = require('tls');\nconst fs = require('fs');\n\n// Custom verification function\nfunction validateCertificate(cert) {\n// Basic certificate info\nconsole.log('Certificate subject:', cert.subject);\nconsole.log('Certificate issuer:', cert.issuer);\nconsole.log('Valid from:', cert.valid_from);\nconsole.log('Valid to:', cert.valid_to);\n\n// Check certificate validity period\nconst now = new Date();\nconst validFrom = new Date(cert.valid_from);\nconst validTo = new Date(cert.valid_to);\n\nif (now < validFrom || now > validTo) {\nreturn { valid: false, reason: 'Certificate is not within its validity period' };\n}\n\n// Additional checks could include:\n// - Certificate revocation status\n// - Certificate chain validation\n// - Public key strength\n\nreturn { valid: true };\n}\n\n// Create TLS client with custom validation\nconst options = {\nca: [fs.readFileSync('ca-cert.pem')],\ncheckServerIdentity: (hostname, cert) => {\n// First check the certificate against our custom rules\nconst validationResult = validateCertificate(cert);\n\nif (!validationResult.valid) {\nreturn new Error(validationResult.reason);\n}\n\n// Then verify the hostname matches the certificate\nconst certCN = cert.subject.CN;\n\nif (hostname !== certCN &&\n!cert.subjectaltname ||\n!cert.subjectaltname.includes(hostname)) {\nreturn new Error(`Certificate name mismatch: ${hostname} !== ${certCN}`);\n}\n\n// Certificate is valid\nreturn undefined;\n}\n};\n\n// Connect to server with custom verification\nconst client = tls.connect(8000, 'example.com', options, () => {\nif (client.authorized) {\nconsole.log('Connection authorized');\nclient.write('Secure message');\n} else {\nconsole.log('Connection not authorized:', client.authorizationError);\n}\n});\n\n// Handle connection events\nclient.on('error', (error) => {\nconsole.error('TLS error:', error);\n});\n\nclient.on('end', () => {\nconsole.log('Connection ended');\n});",
        "const tls = require('tls');\nconst fs = require('fs');\nconst path = require('path');\n\n// Server options\nconst serverOptions = {\nkey: fs.readFileSync(path.join(__dirname, 'server-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'server-cert.pem')),\n// Enable session resumption\nsessionTimeout: 300, // Session timeout in seconds\nticketKeys: Buffer.from('0123456789abcdef0123456789abcdef'), // 32 bytes for key encryption\n};\n\n// Create TLS server\nconst server = tls.createServer(serverOptions, (socket) => {\nconsole.log('Client connected');\n\n// Check if this is a resumed session\nif (socket.isSessionReused()) {\nconsole.log('Session reused!');\n} else {\nconsole.log('New session');\n}\n\nsocket.on('data', (data) => {\nconsole.log('Received:', data.toString());\nsocket.write('Hello back!');\n});\n\nsocket.on('end', () => {\nconsole.log('Client disconnected');\n});\n});\n\nserver.listen(8443, () => {\nconsole.log('TLS server listening on port 8443');\n\n// First client connection\nconnectClient(() => {\n// Second client connection - should use session resumption\nconnectClient();\n});\n});\n\n// Function to create a client with session resumption\nlet savedSession = null;\n\nfunction connectClient(callback) {\nconst clientOptions = {\nrejectUnauthorized: false, // For self-signed certificates\nsession: savedSession // Use saved session if available\n};\n\nconst client = tls.connect(8443, 'localhost', clientOptions, () => {\nconsole.log('Client connected. Authorized:', client.authorized);\nconsole.log('Using session resumption:', client.isSessionReused());\n\n// Save the session for future connections\nsavedSession = client.getSession();\n\n// Send data\nclient.write('Hello server!');\n\n// Close after a short delay\nsetTimeout(() => {\nclient.end();\nif (callback) setTimeout(callback, 100);\n}, 100);\n});\n\nclient.on('data', (data) => {\nconsole.log('Client received:', data.toString());\n});\n\nclient.on('error', (err) => {\nconsole.error('Client error:', err);\n});\n}",
        "const tls = require('tls');\nconst fs = require('fs');\nconst path = require('path');\n\n// Load different certificates for different domains\nconst serverOptions = {\nSNICallback: (servername, cb) => {\nconsole.log(`SNI request for: ${servername}`);\n\n// Different certificate contexts based on hostname\nif (servername === 'example.com') {\nconst context = tls.createSecureContext({\nkey: fs.readFileSync(path.join(__dirname, 'example.com-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'example.com-cert.pem'))\n});\ncb(null, context);\n}\nelse if (servername === 'another.com') {\nconst context = tls.createSecureContext({\nkey: fs.readFileSync(path.join(__dirname, 'another.com-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'another.com-cert.pem'))\n});\ncb(null, context);\n}\nelse {\n// Default certificate\nconst context = tls.createSecureContext({\nkey: fs.readFileSync(path.join(__dirname, 'default-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'default-cert.pem'))\n});\ncb(null, context);\n}\n},\n// Default keys and certificates (used as a fallback)\nkey: fs.readFileSync(path.join(__dirname, 'default-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'default-cert.pem'))\n};\n\n// Create server\nconst server = tls.createServer(serverOptions, (socket) => {\nsocket.write(`Hello, you connected to ${socket.servername || 'unknown'}!\\n`);\nsocket.end();\n});\n\nserver.listen(8443, () => {\nconsole.log('TLS SNI server running on port 8443');\n});",
        "const tls = require('tls');\nconst fs = require('fs');\nconst path = require('path');\n\n// Load multiple CA certificates\nconst caCerts = [\nfs.readFileSync(path.join(__dirname, 'ca1-cert.pem')),\nfs.readFileSync(path.join(__dirname, 'ca2-cert.pem')),\nfs.readFileSync(path.join(__dirname, 'intermediate-cert.pem'))\n];\n\n// Server with multiple CA certificates\nconst serverOptions = {\nkey: fs.readFileSync(path.join(__dirname, 'server-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'server-cert.pem')),\nca: caCerts,  // Array of CA certificates\nrequestCert: true,\nrejectUnauthorized: true\n};\n\nconst server = tls.createServer(serverOptions, (socket) => {\nconsole.log('Client connected:', socket.authorized ? 'Authorized' : 'Unauthorized');\n\n// Get peer certificate\nconst cert = socket.getPeerCertificate();\nconsole.log('Client certificate subject:', cert.subject);\nconsole.log('Issuer:', cert.issuer.CN);\n\nsocket.write('Welcome to the secure server!\\n');\nsocket.end();\n});\n\nserver.listen(8000, () => {\nconsole.log('TLS server running on port 8000');\n});",
        "const tls = require('tls');\nconst fs = require('fs');\nconst crypto = require('crypto');\n\n// Load CRL (Certificate Revocation List)\nconst crl = fs.readFileSync('revoked-certs.pem');\n\n// Parse CRL to check against\nconst checkRevocation = (cert) => {\n// In a real application, you would parse the CRL and check\n// if the certificate's serial number is in the revocation list\n\n// For demonstration, we'll just check against a known revoked serial\nconst revokedSerials = [\n'0123456789ABCDEF', // Example revoked serial\n'FEDCBA9876543210'\n];\n\nconst certInfo = crypto.certificateVerify(\ncert.raw,\n'sha256',\nBuffer.from(''),\nBuffer.from('')\n);\n\nreturn !revokedSerials.includes(certInfo.serialNumber.toString('hex').toUpperCase());\n};\n\nconst server = tls.createServer({\nkey: fs.readFileSync('server-key.pem'),\ncert: fs.readFileSync('server-cert.pem'),\nrequestCert: true,\nrejectUnauthorized: true,\n\n// Custom certificate validation\ncheckServerIdentity: (host, cert) => {\nif (!checkRevocation(cert)) {\nreturn new Error('Certificate has been revoked');\n}\nreturn undefined; // No error means certificate is valid\n}\n}, (socket) => {\n// Handle connection\nconsole.log('Client connected:', socket.authorized ? 'Authorized' : 'Unauthorized');\nsocket.end('Hello secure world!\\n');\n});\n\nserver.listen(8000);",
        "const tls = require('tls');\nconst https = require('https');\nconst fs = require('fs');\nconst path = require('path');\nconst { execSync } = require('child_process');\n\nclass TLSCertManager {\nconstructor(domain, email) {\nthis.domain = domain;\nthis.email = email;\nthis.certDir = path.join(__dirname, 'certs', domain);\nthis.ensureCertDir();\n}\n\nensureCertDir() {\nif (!fs.existsSync(this.certDir)) {\nfs.mkdirSync(this.certDir, { recursive: true });\n}\n}\n\nasync getCertificates() {\nconst keyPath = path.join(this.certDir, 'privkey.pem');\nconst certPath = path.join(this.certDir, 'cert.pem');\nconst chainPath = path.join(this.certDir, 'chain.pem');\n\n// Check if certificates exist and are valid\nif (this.certsValid(keyPath, certPath, chainPath)) {\nreturn {\nkey: fs.readFileSync(keyPath),\ncert: fs.readFileSync(certPath),\nca: fs.readFileSync(chainPath)\n};\n}\n\n// Use certbot to obtain new certificates\nreturn await this.obtainCertificates();\n}\n\ncertsValid(keyPath, certPath, chainPath) {\ntry {\nif (!fs.existsSync(keyPath) || !fs.existsSync(certPath) || !fs.existsSync(chainPath)) {\nreturn false;\n}\n\n// Check if certificate is valid for at least 7 more days\nconst cert = fs.readFileSync(certPath);\nconst notAfter = cert.toString().match(/Not After : (.*?)\\n/)[1];\nconst expiryDate = new Date(notAfter);\nconst now = new Date();\n\nreturn (expiryDate - now) > 7 * 24 * 60 * 60 * 1000; // 7 days in ms\n} catch (err) {\nconsole.error('Error checking certificate validity:', err);\nreturn false;\n}\n}\n\nasync obtainCertificates() {\ntry {\n// This is a simplified example - in production, use a proper ACME client\nconsole.log('Obtaining new certificates from Let\\'s Encrypt...');\n\n// In a real application, you would use an ACME client like 'greenlock' or 'acme'\n// This is just a placeholder to illustrate the concept\nexecSync(`certbot certonly --standalone -d ${this.domain} --email ${this.email} --agree-tos --non-interactive`);\n\n// Copy certificates to our certs directory\nconst certs = {\nkey: fs.readFileSync(`/etc/letsencrypt/live/${this.domain}/privkey.pem`),\ncert: fs.readFileSync(`/etc/letsencrypt/live/${this.domain}/cert.pem`),\nca: fs.readFileSync(`/etc/letsencrypt/live/${this.domain}/chain.pem`)\n};\n\n// Save certificates for future use\nfs.writeFileSync(path.join(this.certDir, 'privkey.pem'), certs.key);\nfs.writeFileSync(path.join(this.certDir, 'cert.pem'), certs.cert);\nfs.writeFileSync(path.join(this.certDir, 'chain.pem'), certs.ca);\n\nreturn certs;\n} catch (err) {\nconsole.error('Failed to obtain certificates:', err);\nthrow err;\n}\n}\n}\n\n// Usage example\nasync function createSecureServer() {\nconst certManager = new TLSCertManager('example.com', 'admin@example.com');\n\ntry {\nconst certs = await certManager.getCertificates();\n\nconst server = https.createServer({\nkey: certs.key,\ncert: certs.cert,\nca: certs.ca,\nrequestCert: true,\nrejectUnauthorized: true\n}, (req, res) => {\nres.writeHead(200);\nres.end('Hello, secure world!\\n');\n});\n\nserver.listen(443, () => {\nconsole.log('HTTPS server running on port 443');\n});\n\n// Schedule certificate renewal check (e.g., daily)\nsetInterval(async () => {\ntry {\nawait certManager.getCertificates();\n} catch (err) {\nconsole.error('Certificate renewal check failed:', err);\n}\n}, 24 * 60 * 60 * 1000); // Check daily\n\n} catch (err) {\nconsole.error('Failed to start secure server:', err);\nprocess.exit(1);\n}\n}\n\ncreateSecureServer();",
        "const options = {\n// Disable older TLS versions\nminVersion: 'TLSv1.2',\n\n// Explicitly disallow TLS 1.0 and 1.1\nsecureOptions: crypto.constants.SSL_OP_NO_TLSv1 |\ncrypto.constants.SSL_OP_NO_TLSv1_1\n};",
        "const options = {\n// Prioritize modern, secure cipher suites\nciphers: [\n'TLS_AES_256_GCM_SHA384',\n'TLS_CHACHA20_POLY1305_SHA256',\n'TLS_AES_128_GCM_SHA256',\n'ECDHE-RSA-AES256-GCM-SHA384',\n'ECDHE-RSA-AES128-GCM-SHA256'\n].join(':')\n};",
        "// Cipher suites with ECDHE (Elliptic Curve Diffie-Hellman Ephemeral) support PFS\nconst options = {\nciphers: 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384'\n};",
        "const tls = require('tls');\nconst https = require('https');\nconst fs = require('fs');\nconst path = require('path');\n\n// Server with OCSP stapling\nconst serverOptions = {\nkey: fs.readFileSync(path.join(__dirname, 'server-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'server-cert.pem')),\nca: fs.readFileSync(path.join(__dirname, 'ca-cert.pem')),\n\n// Enable OCSP stapling\nrequestOCSP: true,\n\n// OCSP response cache timeout (in milliseconds)\nocspCache: new tls.OCSPCache({\nmax: 1000,  // Maximum number of cached responses\nmaxAge: 60 * 60 * 1000  // Cache for 1 hour\n})\n};\n\n// Create HTTPS server with OCSP stapling\nconst server = https.createServer(serverOptions, (req, res) => {\nres.writeHead(200);\nres.end('Hello with OCSP stapling!\\n');\n});\n\n// Handle OCSP request errors\nserver.on('OCSPRequest', (cert, issuer, callback) => {\nif (!cert || !issuer) {\nreturn callback(new Error('No certificate or issuer provided'));\n}\n\n// Get OCSP URL from certificate\nconst ocspUrl = tls.getOCSPURL(cert);\nif (!ocspUrl) {\nreturn callback(new Error('No OCSP URL in certificate'));\n}\n\nconsole.log('OCSP request for:', cert.subject.CN);\n\n// In a real application, you would make an OCSP request here\n// and return the response via the callback\n\n// For demonstration, we'll just return a dummy response\nconst ocspResponse = Buffer.from('OCSP response would go here');\ncallback(null, ocspResponse);\n});\n\nserver.listen(443, () => {\nconsole.log('HTTPS server with OCSP stapling running on port 443');\n});\n\n// Client that verifies OCSP stapling\nconst clientOptions = {\nhost: 'example.com',\nport: 443,\nrejectUnauthorized: true,\nrequestOCSP: true  // Request OCSP stapling from server\n};\n\nconst req = https.request(clientOptions, (res) => {\nconsole.log('Response status code:', res.statusCode);\n\n// Get the OCSP response from the server\nconst ocspResponse = res.socket.getOCSPResponse();\nif (ocspResponse) {\nconsole.log('Received OCSP response');\n// Verify the OCSP response here\n} else {\nconsole.log('No OCSP response received');\n}\n\nres.on('data', (chunk) => {\nconsole.log('Received data:', chunk.toString());\n});\n});\n\nreq.on('error', (err) => {\nconsole.error('Request error:', err);\n});\n\nreq.end();",
        "const tls = require('tls');\nconst http2 = require('http2');\nconst https = require('https');\nconst fs = require('fs');\nconst path = require('path');\n\n// Server with ALPN and SNI support\nconst serverOptions = {\n// ALPN protocols in order of preference\nALPNProtocols: ['h2', 'http/1.1'],\n\n// SNI callback for multiple domains\nSNICallback: (servername, cb) => {\nconsole.log('SNI request for:', servername);\n\ntry {\nlet context;\n\n// Create different contexts for different domains\nif (servername === 'example.com') {\ncontext = tls.createSecureContext({\nkey: fs.readFileSync(path.join(__dirname, 'example.com-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'example.com-cert.pem')),\n// Enable OCSP stapling for this domain\nrequestOCSP: true,\n// Custom cipher suites for this domain\nciphers: [\n'TLS_AES_256_GCM_SHA384',\n'TLS_CHACHA20_POLY1305_SHA256',\n'TLS_AES_128_GCM_SHA256'\n].join(':')\n});\n} else {\n// Default context for other domains\ncontext = tls.createSecureContext({\nkey: fs.readFileSync(path.join(__dirname, 'default-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'default-cert.pem')),\n// Less strict ciphers for legacy clients\nciphers: [\n'TLS_AES_256_GCM_SHA384',\n'TLS_CHACHA20_POLY1305_SHA256',\n'TLS_AES_128_GCM_SHA256',\n'ECDHE-RSA-AES256-GCM-SHA384',\n'ECDHE-RSA-AES128-GCM-SHA256'\n].join(':')\n});\n}\n\n// Set ALPN protocols for this context\ncontext.setALPNProtocols(['h2', 'http/1.1']);\n\n// Return the created context\nif (cb) {\ncb(null, context);\n} else {\nreturn context;\n}\n} catch (err) {\nconsole.error('SNI callback error:', err);\nif (cb) {\ncb(err);\n} else {\nthrow err;\n}\n}\n},\n\n// Default key and cert (used if SNI is not supported by client)\nkey: fs.readFileSync(path.join(__dirname, 'default-key.pem')),\ncert: fs.readFileSync(path.join(__dirname, 'default-cert.pem'))\n};\n\n// Create HTTP/2 server with ALPN and SNI\nconst http2Server = http2.createSecureServer(serverOptions, (req, res) => {\nconst protocol = req.socket.alpnProtocol;\nres.writeHead(200);\nres.end(`Hello from ${req.socket.servername} using ${protocol}\\n`);\n});\n\nhttp2Server.on('error', (err) => {\nconsole.error('HTTP/2 server error:', err);\n});\n\nhttp2Server.on('stream', (stream, headers) => {\nconst protocol = stream.session.alpnProtocol;\nconst hostname = stream.session.servername || 'unknown';\n\nstream.respond({\n'content-type': 'text/plain; charset=utf-8',\n':status': 200\n});\n\nstream.end(`HTTP/2 stream from ${hostname} using ${protocol}\\n`);\n});\n\n// Create HTTPS server with ALPN and SNI\nconst httpsServer = https.createServer(serverOptions, (req, res) => {\nconst protocol = req.socket.alpnProtocol;\nres.writeHead(200, { 'Content-Type': 'text/plain' });\nres.end(`Hello from ${req.socket.servername} using ${protocol || 'HTTP/1.1'}\\n`);\n});\n\n// Handle upgrade to HTTP/2\nhttpsServer.on('upgrade', (req, socket, head) => {\nconst protocol = req.socket.alpnProtocol;\nif (protocol === 'h2') {\nhttp2Server.emit('connection', socket);\n} else {\nsocket.destroy();\n}\n});\n\n// Start servers\nconst PORT = 443;\n\nhttpsServer.listen(PORT, () => {\nconsole.log(`HTTPS server running on port ${PORT}`);\n});\n\n// Client example\nfunction makeRequest(hostname, port = 443) {\nconst options = {\nhostname,\nport,\npath: '/',\nmethod: 'GET',\n// Enable ALPN\nALPNProtocols: ['h2', 'http/1.1'],\n// Set SNI\nservername: hostname,\n// Verify certificate\nrejectUnauthorized: false, // For testing with self-signed certs\n// Custom check for server identity\ncheckServerIdentity: (host, cert) => {\n// Implement custom certificate validation\nreturn undefined; // No error means success\n}\n};\n\nconst req = https.request(options, (res) => {\nconsole.log(`Status: ${res.statusCode}`);\nconsole.log('ALPN Protocol:', res.socket.alpnProtocol);\nconsole.log('Negotiated Protocol:', res.socket.getProtocol());\n\nlet data = '';\nres.on('data', (chunk) => {\ndata += chunk;\n});\n\nres.on('end', () => {\nconsole.log('Response:', data.trim());\n});\n});\n\nreq.on('error', (err) => {\nconsole.error('Request error:', err);\n});\n\nreq.end();\n}\n\n// Example usage\n// makeRequest('example.com');\n// makeRequest('another-domain.com');",
        "// In an Express application\napp.use((req, res, next) => {\nres.setHeader('Strict-Transport-Security', 'max-age=31536000; includeSubDomains; preload');\nnext();\n});",
        "server-key.pem",
        "server-cert.pem",
        "tls.createServer()",
        "tls.connect()",
        "key",
        "cert",
        "ca",
        "ciphers",
        "minVersion",
        "maxVersion",
        "requestCert",
        "rejectUnauthorized",
        "SNICallback",
        "servername",
        "checkServerIdentity",
        "session",
        "https"
      ]
    },
    {
      "title": "Node.js Net Module",
      "summary": "Introduction to the Net Module\nThe Net module is one of Node.js's core networking modules, allowing you to create TCP servers and clients. TCP (Transmission Control Protocol) is a reliable, ordered, and error-checked delivery of a stream of bytes between applications running on networked devices.\nUnlike the HTTP module, which is built on top of the Net module, the Net module provides lower-level networking capabilities, giving you more control over the communication protocol.\nNote: The Net module is best suited for scenarios where you need a custom TCP protocol or want to implement your own application-level protocol on top of TCP.\nImporting the Net Module\nTo use the Net module, you need to import it in your Node.js application:\nCreating a TCP Server\nThe Net module makes it easy to create a TCP server that listens for connections:\nIn this example:\nnet.createServer() creates a new TCP server\nThe callback function is called when a client connects\nThe socket object represents the connection to the client\nWe set up event handlers for data, end, and error events\nserver.listen(8080) starts the server on port 8080\nCreating a TCP Client\nYou can also create a TCP client to connect to a TCP server:\nIn this example:\nnet.createConnection() creates a client connection to a TCP server\nWe provide the port (and optionally host) to connect to\nThe callback function is called when the connection is established\nWe set up event handlers for data, end, and error events\nNote: To test the client and server together, run the server script in one terminal and the client script in another terminal.\nSocket Properties and Methods\nThe Socket object provided to the server connection callback and returned by createConnection() has many useful properties and methods:\nServer Properties and Methods\nThe Server object returned by createServer() has these useful properties and methods:\nCreating a Chat Server\nLet's create a simple chat server that broadcasts messages to all connected clients:\nTo connect to this chat server, you can use a TCP client or a terminal tool like telnet:\nYou can also create a dedicated chat client using the Net module:\nBuilding a Simple Protocol\nOne of the advantages of using the Net module is the ability to create your own application protocols. Let's create a simple JSON-based protocol:\nAnd here's a client that uses this protocol:\nNote: In this protocol, we use JSON for message serialization and newline characters (\\n) as message boundaries. This makes it easy to parse messages and allows for a variety of message types and payloads.\nSocket Timeouts\nTo handle inactive connections, you can set a timeout on the socket:\nWorking with IPC (Inter-Process Communication)\nThe Net module can also create IPC (Inter-Process Communication) servers and clients using Unix domain sockets or named pipes on Windows:\nAnd here's an IPC client:\nNote: IPC connections using Unix domain sockets or named pipes are generally faster and more secure than TCP connections because they don't use the network stack and are restricted to the local machine.\nBest Practices\nError Handling: Always handle socket errors to prevent your application from crashing.\nTimeouts: Implement timeouts to handle inactive connections and prevent resource leaks.\nKeep-Alive: Use keep-alive for long-lived connections to detect disconnections.\nBuffering: Implement proper message framing and buffering for your protocol to handle partial messages.\nConnection Limits: Set server.maxConnections to avoid overwhelming your server.\nGraceful Shutdown: Implement proper cleanup when shutting down servers to release resources.\nBinary Data: Use Buffer objects for binary data transmission rather than strings to avoid encoding issues.\nBackpressure: Check the return value of socket.write() to handle backpressure when the client can't keep up.\nNet Module vs. HTTP Module\nUse the Net module when:\nYou need to implement a custom protocol\nYou want maximum control over the communication\nYou need to optimize for performance\nYou're building a non-HTTP TCP server (chat, game, etc.)\nUse the HTTP module when:\nYou're building a web server or API\nYou need HTTP-specific features like request routing, headers, etc.\nYou want to use higher-level web frameworks like Express\nSummary\nThe Node.js Net module provides powerful tools for creating TCP servers and clients. It offers:\nLow-level socket access for custom protocols\nAsynchronous, event-driven API for handling connections\nSupport for both TCP/IP and IPC communication\nBuilding blocks for higher-level protocols\nWhile it requires more manual work than higher-level modules like HTTP, the Net module gives you the flexibility to implement exactly the protocol you need for your application.\nNote: Always monitor your TCP server's performance using tools like netstat, ss, or lsof to identify bottlenecks and connection issues.",
      "examples": [
        "const net = require('net');",
        "const net = require('net');\n\n// Create a TCP server\nconst server = net.createServer((socket) => {\nconsole.log('Client connected');\n\n// Set encoding to utf8 so we receive strings instead of Buffer objects\nsocket.setEncoding('utf8');\n\n// Handle data from client\nsocket.on('data', (data) => {\nconsole.log(`Received from client: ${data}`);\n\n// Echo the data back to the client\nsocket.write(`Echo: ${data}`);\n});\n\n// Handle client disconnection\nsocket.on('end', () => {\nconsole.log('Client disconnected');\n});\n\n// Handle errors\nsocket.on('error', (err) => {\nconsole.error('Socket error:', err);\n});\n\n// Send a welcome message to the client\nsocket.write('Welcome to the TCP server!\\r\\n');\n});\n\n// Start the server and listen on port 8080\nserver.listen(8080, () => {\nconsole.log('TCP Server running on port 8080');\n});",
        "const net = require('net');\n\n// Create a TCP client\nconst client = net.createConnection({ port: 8080 }, () => {\nconsole.log('Connected to server');\n\n// Send a message to the server\nclient.write('Hello from client!');\n});\n\n// Set encoding\nclient.setEncoding('utf8');\n\n// Handle data from server\nclient.on('data', (data) => {\nconsole.log(`Received from server: ${data}`);\n\n// Send another message\nclient.write('More data from client');\n});\n\n// Handle connection end\nclient.on('end', () => {\nconsole.log('Disconnected from server');\n});\n\n// Handle errors\nclient.on('error', (err) => {\nconsole.error('Connection error:', err);\n});",
        "const net = require('net');\n\n// Store all client connections\nconst clients = [];\n\n// Create a chat server\nconst server = net.createServer((socket) => {\n// Generate a client ID\nconst clientId = `${socket.remoteAddress}:${socket.remotePort}`;\nconsole.log(`Client connected: ${clientId}`);\n\n// Set encoding\nsocket.setEncoding('utf8');\n\n// Add client to the list\nclients.push(socket);\n\n// Send welcome message\nsocket.write(`Welcome to the chat server! There are ${clients.length} users online.\\r\\n`);\n\n// Broadcast message to all clients except the sender\nfunction broadcast(message, sender) {\nclients.forEach(client => {\nif (client !== sender) {\nclient.write(message);\n}\n});\n}\n\n// Notify all clients about the new connection\nbroadcast(`User ${clientId} joined the chat.\\r\\n`, socket);\n\n// Handle client messages\nsocket.on('data', (data) => {\nconsole.log(`${clientId}: ${data.trim()}`);\n\n// Broadcast the message to all other clients\nbroadcast(`${clientId}: ${data}`, socket);\n});\n\n// Handle client disconnection\nsocket.on('end', () => {\nconsole.log(`Client disconnected: ${clientId}`);\n\n// Remove client from the list\nconst index = clients.indexOf(socket);\nif (index !== -1) {\nclients.splice(index, 1);\n}\n\n// Notify all clients about the disconnection\nbroadcast(`User ${clientId} left the chat.\\r\\n`, null);\n});\n\n// Handle errors\nsocket.on('error', (err) => {\nconsole.error(`Socket error from ${clientId}:`, err);\n});\n});\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Chat server running on port ${PORT}`);\n});\n\n// Handle server errors\nserver.on('error', (err) => {\nconsole.error('Server error:', err);\n});",
        "telnet localhost 8080",
        "const net = require('net');\nconst readline = require('readline');\n\n// Create interface for reading from the terminal\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\n// Create a client connection\nconst client = net.createConnection({ port: 8080 }, () => {\nconsole.log('Connected to chat server');\nconsole.log('Type a message and press Enter to send');\n\n// Start reading user input\nrl.prompt();\n});\n\n// Set encoding\nclient.setEncoding('utf8');\n\n// Handle data from server\nclient.on('data', (data) => {\n// Move cursor to beginning of line and clear it\nprocess.stdout.write('\\r\\x1b[K');\n\n// Print the server message\nconsole.log(data.trim());\n\n// Re-display the prompt\nrl.prompt();\n});\n\n// Handle connection end\nclient.on('end', () => {\nconsole.log('Disconnected from server');\nrl.close();\nprocess.exit(0);\n});\n\n// Handle errors\nclient.on('error', (err) => {\nconsole.error('Connection error:', err);\nrl.close();\nprocess.exit(1);\n});\n\n// Handle user input\nrl.on('line', (input) => {\n// Send the user input to the server\nclient.write(input);\nrl.prompt();\n});\n\n// Close the connection when the user exits\nrl.on('close', () => {\nconsole.log('Exiting chat...');\nclient.end();\n});",
        "const net = require('net');\n\n// Create a server that supports a JSON-based protocol\nconst server = net.createServer((socket) => {\nconsole.log('Client connected');\n\n// Buffer for incoming data\nlet buffer = '';\n\n// Handle data\nsocket.on('data', (data) => {\n// Add the new data to our buffer\nbuffer += data.toString();\n\n// Process complete messages\nlet boundary = buffer.indexOf('\\n');\nwhile (boundary !== -1) {\n// Extract the complete message\nconst message = buffer.substring(0, boundary);\nbuffer = buffer.substring(boundary + 1);\n\n// Process the message\ntry {\nconst parsedMessage = JSON.parse(message);\nconsole.log('Received message:', parsedMessage);\n\n// Handle different message types\nswitch (parsedMessage.type) {\ncase 'greeting':\nsocket.write(JSON.stringify({\ntype: 'welcome',\nmessage: `Hello, ${parsedMessage.name}!`,\ntimestamp: Date.now()\n}) + '\\n');\nbreak;\n\ncase 'query':\nsocket.write(JSON.stringify({\ntype: 'response',\nqueryId: parsedMessage.queryId,\nresult: handleQuery(parsedMessage.query),\ntimestamp: Date.now()\n}) + '\\n');\nbreak;\n\ndefault:\nsocket.write(JSON.stringify({\ntype: 'error',\nmessage: 'Unknown message type',\ntimestamp: Date.now()\n}) + '\\n');\n}\n} catch (err) {\nconsole.error('Error processing message:', err);\nsocket.write(JSON.stringify({\ntype: 'error',\nmessage: 'Invalid JSON format',\ntimestamp: Date.now()\n}) + '\\n');\n}\n\n// Look for the next message\nboundary = buffer.indexOf('\\n');\n}\n});\n\n// Handle disconnection\nsocket.on('end', () => {\nconsole.log('Client disconnected');\n});\n\n// Handle errors\nsocket.on('error', (err) => {\nconsole.error('Socket error:', err);\n});\n});\n\n// Simple function to handle queries\nfunction handleQuery(query) {\nif (query === 'time') {\nreturn { time: new Date().toISOString() };\n} else if (query === 'stats') {\nreturn {\nuptime: process.uptime(),\nmemory: process.memoryUsage(),\nplatform: process.platform\n};\n} else {\nreturn { error: 'Unknown query' };\n}\n}\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`JSON protocol server running on port ${PORT}`);\n});",
        "const net = require('net');\n\n// Connect to the server\nconst client = net.createConnection({ port: 8080 }, () => {\nconsole.log('Connected to server');\n\n// Send a greeting\nsend({\ntype: 'greeting',\nname: 'Client'\n});\n\n// Send a query\nsend({\ntype: 'query',\nqueryId: 1,\nquery: 'time'\n});\n\n// Send another query\nsetTimeout(() => {\nsend({\ntype: 'query',\nqueryId: 2,\nquery: 'stats'\n});\n}, 1000);\n});\n\n// Buffer for incoming data\nlet buffer = '';\n\n// Handle data from server\nclient.on('data', (data) => {\n// Add the new data to our buffer\nbuffer += data.toString();\n\n// Process complete messages\nlet boundary = buffer.indexOf('\\n');\nwhile (boundary !== -1) {\n// Extract the complete message\nconst message = buffer.substring(0, boundary);\nbuffer = buffer.substring(boundary + 1);\n\n// Process the message\ntry {\nconst parsedMessage = JSON.parse(message);\nconsole.log('Received from server:', parsedMessage);\n} catch (err) {\nconsole.error('Error parsing message:', err);\n}\n\n// Look for the next message\nboundary = buffer.indexOf('\\n');\n}\n});\n\n// Helper function to send messages\nfunction send(message) {\nconst jsonString = JSON.stringify(message) + '\\n';\nconsole.log('Sending:', message);\nclient.write(jsonString);\n}\n\n// Handle connection end\nclient.on('end', () => {\nconsole.log('Disconnected from server');\n});\n\n// Handle errors\nclient.on('error', (err) => {\nconsole.error('Connection error:', err);\n});\n\n// Close the connection after some time\nsetTimeout(() => {\nconsole.log('Closing connection');\nclient.end();\n}, 5000);",
        "const net = require('net');\n\nconst server = net.createServer((socket) => {\nconsole.log('Client connected');\n\n// Set a timeout of 10 seconds\nsocket.setTimeout(10000);\n\n// Handle timeout\nsocket.on('timeout', () => {\nconsole.log('Socket timeout');\nsocket.write('You have been inactive for too long. Disconnecting...\\r\\n');\nsocket.end();\n});\n\n// Handle data\nsocket.on('data', (data) => {\nconsole.log(`Received: ${data.toString().trim()}`);\nsocket.write(`Echo: ${data}`);\n});\n\n// Handle disconnection\nsocket.on('end', () => {\nconsole.log('Client disconnected');\n});\n});\n\nserver.listen(8080, () => {\nconsole.log('Server with timeout running on port 8080');\n});",
        "const net = require('net');\nconst path = require('path');\n\n// Define the path for the IPC socket\nconst socketPath = path.join(__dirname, 'ipc-socket');\n\n// Create an IPC server\nconst server = net.createServer((socket) => {\nconsole.log('Client connected to IPC server');\n\nsocket.on('data', (data) => {\nconsole.log(`Received via IPC: ${data.toString().trim()}`);\nsocket.write(`Echo: ${data}`);\n});\n\nsocket.on('end', () => {\nconsole.log('Client disconnected from IPC server');\n});\n});\n\n// Start the IPC server\nserver.listen(socketPath, () => {\nconsole.log(`IPC server running at ${socketPath}`);\n});\n\n// Clean up the socket file when the server closes\nserver.on('close', () => {\nconsole.log('Cleaning up socket file');\nrequire('fs').unlinkSync(socketPath);\n});\n\n// Handle process termination\nprocess.on('SIGINT', () => {\nserver.close(() => {\nconsole.log('IPC server closed');\nprocess.exit(0);\n});\n});",
        "const net = require('net');\nconst path = require('path');\n\n// Define the path for the IPC socket\nconst socketPath = path.join(__dirname, 'ipc-socket');\n\n// Create an IPC client\nconst client = net.createConnection({ path: socketPath }, () => {\nconsole.log('Connected to IPC server');\nclient.write('Hello from IPC client!');\n});\n\nclient.on('data', (data) => {\nconsole.log(`Received from IPC server: ${data.toString().trim()}`);\nclient.end();\n});\n\nclient.on('end', () => {\nconsole.log('Disconnected from IPC server');\n});\n\nclient.on('error', (err) => {\nconsole.error('Connection error:', err);\n});",
        "net.createServer()",
        "socket",
        "data",
        "end",
        "error",
        "server.listen(8080)",
        "net.createConnection()",
        "createConnection()",
        "socket.write(data[, encoding][, callback])",
        "socket.end([data][, encoding][, callback])",
        "socket.setEncoding(encoding)",
        "socket.setTimeout(timeout[, callback])",
        "socket.setKeepAlive([enable][, initialDelay])",
        "socket.address()",
        "socket.remoteAddress",
        "socket.remotePort",
        "socket.localAddress",
        "socket.localPort",
        "socket.bytesRead",
        "socket.bytesWritten",
        "createServer()",
        "server.listen(port[, hostname][, backlog][, callback])",
        "server.close([callback])",
        "server.address()",
        "server.maxConnections",
        "server.connections",
        "server.listening",
        "socket.write()",
        "netstat",
        "ss",
        "lsof"
      ]
    },
    {
      "title": "Node.js Zlib Module",
      "summary": "Introduction to the Zlib Module\nThe Zlib module provides bindings to the zlib and brotli compression libraries, enabling you to:\nCompress and decompress files and data streams\nImplement HTTP compression\nWork with compressed file formats (.gz, .zip)\nOptimize bandwidth usage in web applications\nImporting the Zlib Module\nCompression Methods\nThe Zlib module supports several compression methods:\nBasic Compression and Decompression\nUsing Callbacks\nUsing Promises\nWorking with Streams\nThe Zlib module can be used with streams for processing large files or data:\nNote: Using streams is memory-efficient for processing large files since the entire file doesn't need to be loaded into memory at once.\nHTTP Compression\nThe Zlib module is commonly used for HTTP compression to reduce bandwidth usage:\nWorking with Brotli Compression\nBrotli is a modern compression algorithm that often achieves better compression ratios than Gzip:\nNote: Brotli compression is available in Node.js 10.16.0 and later versions. It typically achieves better compression ratios but may be slower than Gzip.\nCompression Options\nYou can customize compression behavior with options:\nCommon Zlib options include:\nlevel: Compression level (0-9, 0=none, 9=best)\nmemLevel: Memory usage (1-9, 1=lowest, 9=highest)\nstrategy: Compression strategy (e.g., Z_DEFAULT_STRATEGY)\ndictionary: Pre-defined dictionary for compression\nwindowBits: Window size logarithm\nError Handling\nProper error handling is crucial when working with compression:\nPractical Applications\n1. Compressing Log Files\n2. API Response Compression\nAdvanced Compression Techniques\n1. Compression Strategies\nZlib offers different compression strategies that can be more effective for certain types of data:\n2. Custom Dictionaries\nFor specific data patterns, custom dictionaries can improve compression ratio:\n3. Progressive Compression\nProcess data in chunks as it becomes available:\nPerformance Considerations\nCompression level trade-offs: Higher levels = better compression but slower processing\nMemory usage: Compression can be memory-intensive, especially with high levels\nWhen to compress: Only compress data that benefits from compression (text, JSON, etc.)\nAlready compressed data: Don't compress files that are already compressed (images, videos, etc.)\nStreaming: Use streams for large files to avoid memory issues\nThread pool usage: Zlib operations use libuv's thread pool; configure with UV_THREADPOOL_SIZE if needed\nSummary\nThe Node.js Zlib module provides essential compression and decompression functionality for:\nReducing file sizes and bandwidth usage\nWorking with compressed formats\nImplementing HTTP compression\nProcessing large data efficiently using streams\nKey features include:\nSupport for multiple compression algorithms (Gzip, Deflate, Brotli)\nBoth synchronous and asynchronous APIs\nStream-based processing for memory efficiency\nConfigurable compression levels and options\nUnderstanding the Zlib module is essential for optimizing data transfer and storage in Node.js applications.",
      "examples": [
        "const zlib = require('zlib');",
        "const zlib = require('zlib');\n\nconst input = 'This is some text that will be compressed using the zlib module in Node.js.';\n\n// Compress data using gzip\nzlib.gzip(input, (err, compressed) => {\nif (err) {\nconsole.error('Compression error:', err);\nreturn;\n}\n\nconsole.log('Original size:', input.length, 'bytes');\nconsole.log('Compressed size:', compressed.length, 'bytes');\nconsole.log('Compression ratio:', Math.round(100 - (compressed.length / input.length * 100)) + '%');\n\n// Decompress the data\nzlib.gunzip(compressed, (err, decompressed) => {\nif (err) {\nconsole.error('Decompression error:', err);\nreturn;\n}\n\nconsole.log('Decompressed data:', decompressed.toString());\nconsole.log('Successfully decompressed:', input === decompressed.toString());\n});\n});",
        "const zlib = require('zlib');\nconst { promisify } = require('util');\n\n// Convert callback-based functions to promise-based\nconst gzipPromise = promisify(zlib.gzip);\nconst gunzipPromise = promisify(zlib.gunzip);\n\nasync function compressAndDecompress(input) {\ntry {\n// Compress\nconst compressed = await gzipPromise(input);\nconsole.log('Original size:', input.length, 'bytes');\nconsole.log('Compressed size:', compressed.length, 'bytes');\n\n// Decompress\nconst decompressed = await gunzipPromise(compressed);\nconsole.log('Decompressed data:', decompressed.toString());\nconsole.log('Success:', input === decompressed.toString());\n\nreturn compressed;\n} catch (err) {\nconsole.error('Error:', err);\n}\n}\n\n// Example usage\nconst testData = 'This is some test data that will be compressed with the zlib module.';\ncompressAndDecompress(testData);",
        "const zlib = require('zlib');\nconst fs = require('fs');\nconst path = require('path');\n\n// Compress a file\nfunction compressFile(inputPath) {\nconst outputPath = inputPath + '.gz';\n\n// Create read and write streams\nconst input = fs.createReadStream(inputPath);\nconst output = fs.createWriteStream(outputPath);\n\n// Create gzip transform stream\nconst gzip = zlib.createGzip();\n\n// Pipe data through the compression stream\ninput.pipe(gzip).pipe(output);\n\n// Handle events\ninput.on('error', (err) => console.error('Input error:', err));\ngzip.on('error', (err) => console.error('Compression error:', err));\noutput.on('error', (err) => console.error('Output error:', err));\n\noutput.on('finish', () => {\nconsole.log(`File compressed successfully: ${outputPath}`);\n\n// Get file sizes for comparison\nconst inputStats = fs.statSync(inputPath);\nconst outputStats = fs.statSync(outputPath);\n\nconsole.log(`Original size: ${inputStats.size} bytes`);\nconsole.log(`Compressed size: ${outputStats.size} bytes`);\nconsole.log(`Compression ratio: ${Math.round(100 - (outputStats.size / inputStats.size * 100))}%`);\n});\n}\n\n// Decompress a file\nfunction decompressFile(inputPath) {\n// Remove .gz extension for output path\nconst outputPath = inputPath.endsWith('.gz')\n? inputPath.slice(0, -3)\n: inputPath + '.uncompressed';\n\n// Create streams\nconst input = fs.createReadStream(inputPath);\nconst output = fs.createWriteStream(outputPath);\nconst gunzip = zlib.createGunzip();\n\n// Pipe data through decompression stream\ninput.pipe(gunzip).pipe(output);\n\n// Handle events\ninput.on('error', (err) => console.error('Input error:', err));\ngunzip.on('error', (err) => console.error('Decompression error:', err));\noutput.on('error', (err) => console.error('Output error:', err));\n\noutput.on('finish', () => {\nconsole.log(`File decompressed successfully: ${outputPath}`);\n});\n}\n\n// Example usage (assuming you have a text file)\n// compressFile('example.txt');\n// decompressFile('example.txt.gz');\n\n// Note: Uncomment the above lines to actually run the compression/decompression\nconsole.log('This example shows how to compress and decompress files using streams.');\nconsole.log('Create a text file named \"example.txt\" and uncomment the function calls to test.');",
        "const http = require('http');\nconst zlib = require('zlib');\n\n// Create an HTTP server with compression\nconst server = http.createServer((req, res) => {\n// Sample response content\nconst responseBody = `\n<!DOCTYPE html>\n<html>\n<head>\n<title>Zlib Compression Example</title>\n</head>\n<body>\n<h1>HTTP Compression with Zlib</h1>\n<p>This content is being compressed with Gzip before sending to your browser.</p>\n<p>Compression reduces bandwidth usage and improves page load times.</p>\n${'<p>This paragraph is repeated to demonstrate compression efficiency.</p>'.repeat(50)}\n</body>\n</html>\n`;\n\n// Check if client accepts gzip encoding\nconst acceptEncoding = req.headers['accept-encoding'] || '';\n\n// Set content type\nres.setHeader('Content-Type', 'text/html');\n\n// Compress response if client supports it\nif (/\\bgzip\\b/.test(acceptEncoding)) {\n// Client supports gzip\nres.setHeader('Content-Encoding', 'gzip');\n\n// Compress and send\nzlib.gzip(responseBody, (err, compressed) => {\nif (err) {\nres.statusCode = 500;\nres.end('Internal Server Error');\nreturn;\n}\n\nres.end(compressed);\n});\n} else if (/\\bdeflate\\b/.test(acceptEncoding)) {\n// Client supports deflate\nres.setHeader('Content-Encoding', 'deflate');\n\n// Compress and send\nzlib.deflate(responseBody, (err, compressed) => {\nif (err) {\nres.statusCode = 500;\nres.end('Internal Server Error');\nreturn;\n}\n\nres.end(compressed);\n});\n} else {\n// No compression supported\nres.end(responseBody);\n}\n});\n\n// Start server on port 8080\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\nconsole.log('Open this URL in your browser to see compression in action');\nconsole.log('The browser will automatically decompress the content');\n});",
        "const zlib = require('zlib');\n\n// Sample data to compress\nconst input = 'This is some test data that will be compressed with different algorithms for comparison.'.repeat(20);\n\n// Compare compression methods\nfunction compareCompression() {\nconsole.log(`Original data size: ${input.length} bytes`);\n\n// Gzip compression\nzlib.gzip(input, (err, gzipped) => {\nif (err) {\nconsole.error('Gzip error:', err);\nreturn;\n}\n\nconsole.log(`Gzip size: ${gzipped.length} bytes (${Math.round(100 - (gzipped.length / input.length * 100))}% reduction)`);\n\n// Deflate compression\nzlib.deflate(input, (err, deflated) => {\nif (err) {\nconsole.error('Deflate error:', err);\nreturn;\n}\n\nconsole.log(`Deflate size: ${deflated.length} bytes (${Math.round(100 - (deflated.length / input.length * 100))}% reduction)`);\n\n// Brotli compression (if available)\nif (typeof zlib.brotliCompress === 'function') {\nzlib.brotliCompress(input, (err, brotli) => {\nif (err) {\nconsole.error('Brotli error:', err);\nreturn;\n}\n\nconsole.log(`Brotli size: ${brotli.length} bytes (${Math.round(100 - (brotli.length / input.length * 100))}% reduction)`);\n});\n} else {\nconsole.log('Brotli compression not available in this Node.js version');\n}\n});\n});\n}\n\n// Run the comparison\ncompareCompression();",
        "const zlib = require('zlib');\n\nconst input = 'This is example content for compression with custom options.'.repeat(50);\n\n// Test different compression levels\nfunction testCompressionLevels() {\nconsole.log(`Original size: ${input.length} bytes`);\n\n// Default compression (level 6)\nzlib.gzip(input, (err, compressed) => {\nif (err) throw err;\nconsole.log(`Default compression (level 6): ${compressed.length} bytes`);\n\n// Fastest compression (level 1)\nzlib.gzip(input, { level: 1 }, (err, fastCompressed) => {\nif (err) throw err;\nconsole.log(`Fast compression (level 1): ${fastCompressed.length} bytes`);\n\n// Best compression (level 9)\nzlib.gzip(input, { level: 9 }, (err, bestCompressed) => {\nif (err) throw err;\nconsole.log(`Best compression (level 9): ${bestCompressed.length} bytes`);\n});\n});\n});\n}\n\n// Test compression with custom memory usage\nfunction testMemoryLevels() {\n// Memory levels: 1 (lowest) to 9 (highest)\nzlib.gzip(input, { memLevel: 9 }, (err, compressed) => {\nif (err) throw err;\nconsole.log(`High memory usage (memLevel 9): ${compressed.length} bytes`);\n\nzlib.gzip(input, { memLevel: 4 }, (err, lowMemCompressed) => {\nif (err) throw err;\nconsole.log(`Low memory usage (memLevel 4): ${lowMemCompressed.length} bytes`);\n});\n});\n}\n\n// Run tests\ntestCompressionLevels();\nsetTimeout(testMemoryLevels, 1000); // Slight delay to separate console output",
        "const zlib = require('zlib');\nconst fs = require('fs');\n\n// Function to safely decompress data\nfunction safeDecompress(compressedData) {\nreturn new Promise((resolve, reject) => {\nzlib.gunzip(compressedData, { finishFlush: zlib.constants.Z_SYNC_FLUSH }, (err, result) => {\nif (err) {\n// Handle specific error types\nif (err.code === 'Z_DATA_ERROR') {\nreject(new Error('Invalid or corrupt compressed data'));\n} else if (err.code === 'Z_BUF_ERROR') {\nreject(new Error('Incomplete compressed data'));\n} else {\nreject(err);\n}\nreturn;\n}\n\nresolve(result);\n});\n});\n}\n\n// Example usage with error handling\nasync function demonstrateErrorHandling() {\ntry {\n// Valid compression\nconst validData = await zlib.gzipSync('This is valid data');\nconsole.log('Successfully compressed valid data');\n\n// Try to decompress valid data\nconst result = await safeDecompress(validData);\nconsole.log('Successfully decompressed:', result.toString());\n\n// Try to decompress invalid data\nconst invalidData = Buffer.from('This is not compressed data');\nawait safeDecompress(invalidData);\n\n} catch (err) {\nconsole.error('Error occurred:', err.message);\n}\n}\n\ndemonstrateErrorHandling();",
        "const zlib = require('zlib');\nconst fs = require('fs');\nconst path = require('path');\n\n// Compress log files and add timestamp\nfunction compressLogFile(logFilePath) {\n// Generate output path with timestamp\nconst timestamp = new Date().toISOString().replace(/:/g, '-');\nconst basename = path.basename(logFilePath);\nconst outputPath = path.join(\npath.dirname(logFilePath),\n`${basename}-${timestamp}.gz`\n);\n\n// Create streams\nconst input = fs.createReadStream(logFilePath);\nconst output = fs.createWriteStream(outputPath);\nconst gzip = zlib.createGzip();\n\n// Pipe the streams\ninput.pipe(gzip).pipe(output);\n\n// Handle events\noutput.on('finish', () => {\nconsole.log(`Log file compressed: ${outputPath}`);\n\n// Optionally, clear the original log file\nfs.writeFile(logFilePath, '', err => {\nif (err) {\nconsole.error(`Error clearing log file: ${err.message}`);\n} else {\nconsole.log(`Original log file cleared: ${logFilePath}`);\n}\n});\n});\n\ninput.on('error', err => console.error(`Read error: ${err.message}`));\ngzip.on('error', err => console.error(`Compression error: ${err.message}`));\noutput.on('error', err => console.error(`Write error: ${err.message}`));\n}\n\n// Example usage\n// compressLogFile('server.log');\n\n// Note: Uncomment the line above to compress an actual log file\nconsole.log('This example shows how to compress log files with timestamps.');",
        "const http = require('http');\nconst zlib = require('zlib');\n\n// Sample API data (imagine this is from a database)\nconst apiData = {\nusers: Array.from({ length: 100 }, (_, i) => ({\nid: i + 1,\nname: `User ${i + 1}`,\nemail: `user${i + 1}@example.com`,\nrole: i % 3 === 0 ? 'admin' : 'user',\ncreated: new Date().toISOString(),\nprofile: {\nbio: `This is a sample bio for user ${i + 1}. It contains some text to demonstrate compression.`,\ninterests: ['programming', 'reading', 'hiking', 'cooking', 'music'],\nsettings: {\nnotifications: true,\ntheme: 'dark',\nlanguage: 'en'\n}\n}\n}))\n};\n\n// Create a simple API server\nconst server = http.createServer((req, res) => {\n// Only handle GET requests to /api/users\nif (req.method === 'GET' && req.url === '/api/users') {\n// Convert data to JSON string\nconst jsonData = JSON.stringify(apiData);\n\n// Check if client accepts compression\nconst acceptEncoding = req.headers['accept-encoding'] || '';\n\n// Set JSON content type\nres.setHeader('Content-Type', 'application/json');\n\n// Compress based on accepted encoding\nif (/\\bgzip\\b/.test(acceptEncoding)) {\nres.setHeader('Content-Encoding', 'gzip');\n\n// Compress and send\nzlib.gzip(jsonData, (err, compressed) => {\nif (err) {\nres.statusCode = 500;\nres.end(JSON.stringify({ error: 'Compression failed' }));\nreturn;\n}\n\nconsole.log(`Original size: ${jsonData.length} bytes`);\nconsole.log(`Compressed size: ${compressed.length} bytes`);\nconsole.log(`Compression ratio: ${Math.round(100 - (compressed.length / jsonData.length * 100))}%`);\n\nres.end(compressed);\n});\n} else {\n// No compression\nconsole.log(`Sending uncompressed response: ${jsonData.length} bytes`);\nres.end(jsonData);\n}\n} else {\n// Not found\nres.statusCode = 404;\nres.end(JSON.stringify({ error: 'Not found' }));\n}\n});\n\n// Start server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`API server running at http://localhost:${PORT}/`);\nconsole.log('Test the API by visiting: http://localhost:8080/api/users');\n});",
        "const zlib = require('zlib');\n\n// Sample data with repeated patterns (good for RLE)\nconst repeatedData = 'ABC'.repeat(1000);\n\n// Test different compression strategies\nfunction testStrategies(data) {\nconst strategies = [\n{ name: 'DEFAULT_STRATEGY', value: zlib.constants.Z_DEFAULT_STRATEGY },\n{ name: 'FILTERED', value: zlib.constants.Z_FILTERED },\n{ name: 'HUFFMAN_ONLY', value: zlib.constants.Z_HUFFMAN_ONLY },\n{ name: 'RLE', value: zlib.constants.Z_RLE },\n{ name: 'FIXED', value: zlib.constants.Z_FIXED }\n];\n\nconsole.log(`Original size: ${data.length} bytes`);\n\nstrategies.forEach(({ name, value }) => {\nconst compressed = zlib.gzipSync(data, { strategy: value });\nconsole.log(`${name.padEnd(20)}: ${compressed.length.toString().padEnd(5)} bytes`);\n});\n}\n\ntestStrategies(repeatedData);",
        "const zlib = require('zlib');\n\n// Create a custom dictionary with common terms\nconst dictionary = Buffer.from('username,password,email,first_name,last_name,created_at,updated_at,status,active,inactive,pending,admin,user,role,permissions');\n\n// Sample data that benefits from the dictionary\nconst userData = JSON.stringify({\nusername: 'johndoe',\nemail: 'john@example.com',\nfirst_name: 'John',\nlast_name: 'Doe',\nrole: 'admin',\nstatus: 'active',\ncreated_at: new Date().toISOString(),\nupdated_at: new Date().toISOString()\n});\n\n// Compress with and without dictionary\nconst compressedWithout = zlib.deflateSync(userData);\nconst compressedWith = zlib.deflateSync(userData, { dictionary });\n\nconsole.log('Original size:', Buffer.byteLength(userData), 'bytes');\nconsole.log('Compressed without dictionary:', compressedWithout.length, 'bytes');\nconsole.log('Compressed with dictionary:', compressedWith.length, 'bytes');\nconsole.log('Improvement:', Math.round((1 - (compressedWith.length / compressedWithout.length)) * 100) + '%');\n\n// Decompress with dictionary\nconst decompressed = zlib.inflateSync(compressedWith, { dictionary });\nconsole.log('Decompressed matches original:', decompressed.toString() === userData);",
        "const zlib = require('zlib');\nconst { Transform } = require('stream');\n\nclass ProgressTracker extends Transform {\nconstructor(options = {}) {\nsuper(options);\nthis.processedBytes = 0;\nthis.startTime = Date.now();\n}\n\n_transform(chunk, encoding, callback) {\nthis.processedBytes += chunk.length;\nconst elapsed = (Date.now() - this.startTime) / 1000;\nconst rate = (this.processedBytes / 1024 / 1024 / elapsed).toFixed(2);\n\nprocess.stdout.write(`\\rProcessed: ${(this.processedBytes / 1024 / 1024).toFixed(2)} MB | ` +\n`Rate: ${rate} MB/s`);\n\nthis.push(chunk);\ncallback();\n}\n}\n\n// Simulate processing a large file\nfunction processLargeFile() {\nconst gzip = zlib.createGzip({ level: 6 });\nconst progress = new ProgressTracker();\n\n// Generate 100MB of random data\nconst data = Buffer.alloc(1024 * 1024 * 100);\n\n// Create a readable stream from buffer\nconst { Readable } = require('stream');\nconst readable = Readable.from(data);\n\nconsole.log('Starting compression...');\n\nreadable\n.pipe(progress)\n.pipe(gzip)\n.pipe(process.stdout);\n\ngzip.on('end', () => {\nconsole.log('\\nCompression complete!');\n});\n}\n\n// Uncomment to run (creates a large file)\n// processLargeFile();",
        "level",
        "memLevel",
        "strategy",
        "dictionary",
        "windowBits"
      ]
    },
    {
      "title": "Node.js Real-World Examples",
      "summary": "RESTful API with Express\nOne of the most common Node.js applications is building RESTful APIs. Here's an example of a simple but practical Todo API with Express:\nExample: Todo API with ExpressGet your own Node.js Server\nThis example demonstrates a complete CRUD (Create, Read, Update, Delete) API with proper error handling and status codes.\nREMOVE ADS\nAuthentication System\nMost applications need authentication. Here's an example of JWT-based authentication in Node.js:\nExample: JWT Authentication with Express\nFile Upload Service\nNode.js makes it easy to handle file uploads, which is common in many web applications:\nExample: File Upload with Express and Multer\nMicroservice Architecture\nNode.js is ideal for building microservices. Here's a simple example of a microservice with health checks and proper separation of concerns:\nExample: Product Catalog Microservice\nBest Practice: In a real microservice architecture, each service would have its own repository, deployment pipeline, and database.\nTask Scheduler\nNode.js can efficiently handle scheduled tasks and background jobs:\nExample: Cron-like Task Scheduler\nReal-time Analytics Dashboard\nTrack and visualize application metrics in real-time with WebSockets and Chart.js:\nExample: Real-time Analytics Server\nNote: For production use, consider persisting analytics data to a database and implementing proper authentication.\nBest Practices for Real-World Node.js Applications\nWhen building production Node.js applications, follow these best practices:\nApplication Structure\nUse a clear project structure (MVC or similar)\nSeparate business logic from routes\nKeep configuration in environment variables\nUse dependency injection where appropriate\nError Handling\nImplement global error handling middleware\nLog errors with proper context\nReturn appropriate HTTP status codes\nHandle uncaught exceptions and unhandled promises\nSecurity\nAlways validate and sanitize user input\nUse HTTPS and secure cookies\nImplement rate limiting for APIs\nKeep dependencies updated\nUse security headers (Helmet.js)\nPerformance & Scalability\nUse compression for HTTP responses\nImplement proper caching strategies\nConsider using a cluster or PM2 for multi-core utilization\nMonitor memory usage and implement garbage collection\nUse async/await for better readability\nPro Tip: For production applications, always include comprehensive monitoring, logging, and alerting to quickly identify and resolve issues.",
      "examples": [
        "const express = require('express');\nconst app = express();\n\n// In-memory data store (in a real app, you would use a database)\nlet todos = [\n{ id: 1, title: 'Learn Node.js', completed: false },\n{ id: 2, title: 'Build a REST API', completed: false }\n];\n\n// Middleware\napp.use(express.json());\n\n// Log all requests\napp.use((req, res, next) => {\nconsole.log(`${req.method} ${req.url}`);\nnext();\n});\n\n// GET all todos\napp.get('/todos', (req, res) => {\nres.json(todos);\n});\n\n// GET a single todo\napp.get('/todos/:id', (req, res) => {\nconst todo = todos.find(t => t.id === parseInt(req.params.id));\nif (!todo) return res.status(404).json({ error: 'Todo not found' });\nres.json(todo);\n});\n\n// POST a new todo\napp.post('/todos', (req, res) => {\nif (!req.body.title) {\nreturn res.status(400).json({ error: 'Title is required' });\n}\n\nconst newTodo = {\nid: todos.length > 0 ? Math.max(...todos.map(t => t.id)) + 1 : 1,\ntitle: req.body.title,\ncompleted: req.body.completed || false\n};\n\ntodos.push(newTodo);\nres.status(201).json(newTodo);\n});\n\n// PUT (update) a todo\napp.put('/todos/:id', (req, res) => {\nconst todo = todos.find(t => t.id === parseInt(req.params.id));\nif (!todo) return res.status(404).json({ error: 'Todo not found' });\n\nif (req.body.title) todo.title = req.body.title;\nif (req.body.completed !== undefined) todo.completed = req.body.completed;\n\nres.json(todo);\n});\n\n// DELETE a todo\napp.delete('/todos/:id', (req, res) => {\nconst index = todos.findIndex(t => t.id === parseInt(req.params.id));\nif (index === -1) return res.status(404).json({ error: 'Todo not found' });\n\nconst deletedTodo = todos[index];\ntodos.splice(index, 1);\n\nres.json(deletedTodo);\n});\n\n// Error handling middleware\napp.use((err, req, res, next) => {\nconsole.error(err.stack);\nres.status(500).json({ error: 'Something went wrong!' });\n});\n\n// Start the server\nconst PORT = process.env.PORT || 8080;\napp.listen(PORT, () => {\nconsole.log(`Server running on port ${PORT}`);\n});",
        "const express = require('express');\nconst jwt = require('jsonwebtoken');\nconst bcrypt = require('bcrypt');\n\nconst app = express();\napp.use(express.json());\n\n// In a real app, use a database\nconst users = [];\n\n// Secret key for JWT\nconst JWT_SECRET = process.env.JWT_SECRET || 'your-secret-key';\n\n// Register a new user\napp.post('/register', async (req, res) => {\ntry {\nconst { username, password } = req.body;\n\n// Check if user already exists\nif (users.find(u => u.username === username)) {\nreturn res.status(400).json({ error: 'Username already exists' });\n}\n\n// Hash the password\nconst hashedPassword = await bcrypt.hash(password, 10);\n\n// Create new user\nconst user = {\nid: users.length + 1,\nusername,\npassword: hashedPassword\n};\n\nusers.push(user);\n\nres.status(201).json({ message: 'User registered successfully' });\n} catch (error) {\nres.status(500).json({ error: 'Registration failed' });\n}\n});\n\n// Login\napp.post('/login', async (req, res) => {\ntry {\nconst { username, password } = req.body;\n\n// Find user\nconst user = users.find(u => u.username === username);\nif (!user) {\nreturn res.status(401).json({ error: 'Invalid credentials' });\n}\n\n// Check password\nconst passwordMatch = await bcrypt.compare(password, user.password);\nif (!passwordMatch) {\nreturn res.status(401).json({ error: 'Invalid credentials' });\n}\n\n// Generate JWT token\nconst token = jwt.sign(\n{ userId: user.id, username: user.username },\nJWT_SECRET,\n{ expiresIn: '1h' }\n);\n\nres.json({ token });\n} catch (error) {\nres.status(500).json({ error: 'Authentication failed' });\n}\n});\n\n// Middleware to verify JWT token\nfunction authenticateToken(req, res, next) {\nconst authHeader = req.headers['authorization'];\nconst token = authHeader && authHeader.split(' ')[1];\n\nif (!token) return res.status(401).json({ error: 'Authentication required' });\n\njwt.verify(token, JWT_SECRET, (err, user) => {\nif (err) return res.status(403).json({ error: 'Invalid or expired token' });\nreq.user = user;\nnext();\n});\n}\n\n// Protected route example\napp.get('/profile', authenticateToken, (req, res) => {\nres.json({ user: req.user });\n});\n\napp.listen(8080, () => {\nconsole.log('Authentication server running on port 8080');\n});",
        "const express = require('express');\nconst multer = require('multer');\nconst path = require('path');\nconst fs = require('fs');\n\nconst app = express();\napp.use(express.json());\napp.use(express.static('public'));\n\n// Configure multer storage\nconst storage = multer.diskStorage({\ndestination: (req, file, cb) => {\nconst uploadDir = './uploads';\n\n// Create directory if it doesn't exist\nif (!fs.existsSync(uploadDir)) {\nfs.mkdirSync(uploadDir);\n}\n\ncb(null, uploadDir);\n},\nfilename: (req, file, cb) => {\n// Generate unique filename with original extension\nconst uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);\nconst ext = path.extname(file.originalname);\ncb(null, file.fieldname + '-' + uniqueSuffix + ext);\n}\n});\n\n// File filter function\nconst fileFilter = (req, file, cb) => {\n// Accept images and PDFs only\nif (file.mimetype.startsWith('image/') || file.mimetype === 'application/pdf') {\ncb(null, true);\n} else {\ncb(new Error('Unsupported file type'), false);\n}\n};\n\nconst upload = multer({\nstorage: storage,\nfileFilter: fileFilter,\nlimits: { fileSize: 5 * 1024 * 1024 } // 5MB limit\n});\n\n// Serve upload form\napp.get('/', (req, res) => {\nres.sendFile(path.join(__dirname, 'public', 'index.html'));\n});\n\n// Single file upload endpoint\napp.post('/upload/single', upload.single('file'), (req, res) => {\nif (!req.file) {\nreturn res.status(400).json({ error: 'No file uploaded' });\n}\n\nres.json({\nmessage: 'File uploaded successfully',\nfile: {\nfilename: req.file.filename,\noriginalname: req.file.originalname,\nmimetype: req.file.mimetype,\nsize: req.file.size\n}\n});\n});\n\n// Multiple file upload endpoint (max 5)\napp.post('/upload/multiple', upload.array('files', 5), (req, res) => {\nif (!req.files || req.files.length === 0) {\nreturn res.status(400).json({ error: 'No files uploaded' });\n}\n\nres.json({\nmessage: `${req.files.length} files uploaded successfully`,\nfiles: req.files.map(file => ({\nfilename: file.filename,\noriginalname: file.originalname,\nmimetype: file.mimetype,\nsize: file.size\n}))\n});\n});\n\n// Error handling middleware\napp.use((err, req, res, next) => {\nif (err instanceof multer.MulterError) {\n// Multer-specific errors\nreturn res.status(400).json({ error: err.message });\n} else if (err) {\n// Other errors\nreturn res.status(500).json({ error: err.message });\n}\nnext();\n});\n\napp.listen(8080, () => {\nconsole.log('File upload server running on port 8080');\n});",
        "// src/index.js\nconst express = require('express');\nconst routes = require('./routes');\nconst errorHandler = require('./middleware/errorHandler');\nconst logger = require('./middleware/logger');\nconst config = require('./config');\n\nconst app = express();\n\n// Middleware\napp.use(express.json());\napp.use(logger);\n\n// Health check\napp.get('/health', (req, res) => {\nres.status(200).json({ status: 'ok', service: 'product-catalog', timestamp: new Date() });\n});\n\n// Routes\napp.use('/api/products', routes.productRoutes);\n\n// Error handling\napp.use(errorHandler);\n\n// Start server\napp.listen(config.PORT, () => {\nconsole.log(`Product catalog service running on port ${config.PORT}`);\n});\n\n// Handle graceful shutdown\nprocess.on('SIGTERM', () => {\nconsole.log('SIGTERM received, shutting down gracefully');\n// Close database connections, etc.\nprocess.exit(0);\n});",
        "// src/routes/productRoutes.js\nconst express = require('express');\nconst productController = require('../controllers/productController');\n\nconst router = express.Router();\n\nrouter.get('/', productController.getAllProducts);\nrouter.get('/:id', productController.getProductById);\nrouter.post('/', productController.createProduct);\nrouter.put('/:id', productController.updateProduct);\nrouter.delete('/:id', productController.deleteProduct);\n\nmodule.exports = router;",
        "const cron = require('node-cron');\nconst nodemailer = require('nodemailer');\nconst express = require('express');\n\nconst app = express();\n\n// Configure mail transporter (this is just an example)\nconst transporter = nodemailer.createTransport({\nhost: 'smtp.example.com',\nport: 587,\nsecure: false,\nauth: {\nuser: 'user@example.com',\npass: 'password'\n}\n});\n\n// Schedule a task to run every day at 9:00 AM\ncron.schedule('0 9 * * *', async () => {\nconsole.log('Running daily report task');\n\ntry {\n// Generate report data (in a real app, fetch from database)\nconst reportData = {\ndate: new Date().toISOString().split('T')[0],\nmetrics: {\nusers: 1250,\norders: 350,\nrevenue: 12500\n}\n};\n\n// Send email with report\nawait transporter.sendMail({\nfrom: 'system@example.com',\nto: 'admin@example.com',\nsubject: `Daily Report - ${reportData.date}`,\nhtml: `\n<h1>Daily Report</h1>\n<p><strong>Date:</strong> ${reportData.date}</p>\n<h2>Key Metrics</h2>\n<ul>\n<li>Users: ${reportData.metrics.users}</li>\n<li>Orders: ${reportData.metrics.orders}</li>\n<li>Revenue: $${reportData.metrics.revenue}</li>\n</ul>\n`\n});\n\nconsole.log('Daily report email sent successfully');\n} catch (error) {\nconsole.error('Error sending daily report:', error);\n}\n});\n\n// Schedule database backup every Sunday at midnight\ncron.schedule('0 0 * * 0', () => {\nconsole.log('Running weekly database backup');\n// In a real app, you would run a database backup command here\n});\n\n// Clean up temporary files every hour\ncron.schedule('0 * * * *', () => {\nconsole.log('Cleaning up temporary files');\n// In a real app, you would delete old temporary files here\n});\n\n// API to add a one-time job\nconst scheduledJobs = new Map();\napp.use(express.json());\n\napp.post('/schedule-job', (req, res) => {\nconst { id, scheduledTime, task } = req.body;\n\nif (!id || !scheduledTime || !task) {\nreturn res.status(400).json({ error: 'Missing required parameters' });\n}\n\nconst jobTime = new Date(scheduledTime).getTime();\nconst currentTime = Date.now();\n\nif (jobTime <= currentTime) {\nreturn res.status(400).json({ error: 'Scheduled time must be in the future' });\n}\n\n// Schedule the job\nconst timeout = setTimeout(() => {\nconsole.log(`Executing job: ${id}`);\n// In a real app, use a job queue like Bull to handle the tasks\nconsole.log(`Task: ${task}`);\n\nscheduledJobs.delete(id);\n}, jobTime - currentTime);\n\nscheduledJobs.set(id, { timeout, scheduledTime, task });\n\nres.status(201).json({\nmessage: 'Job scheduled successfully',\njob: { id, scheduledTime, task }\n});\n});\n\n// Start server\napp.listen(8080, () => {\nconsole.log('Task scheduler running on port 8080');\n});",
        "const express = require('express');\nconst http = require('http');\nconst socketIo = require('socket.io');\nconst { v4: uuidv4 } = require('uuid');\n\nconst app = express();\nconst server = http.createServer(app);\nconst io = socketIo(server, {\ncors: {\norigin: '*', // In production, replace with your frontend domain\nmethods: ['GET', 'POST']\n}\n});\n\n// In-memory store for analytics data (use a database in production)\nconst analyticsData = {\npageViews: {},\nactiveUsers: new Set(),\nevents: []\n};\n\n// Track page views\napp.use((req, res, next) => {\nconst page = req.path;\nanalyticsData.pageViews[page] = (analyticsData.pageViews[page] || 0) + 1;\n\n// Emit update to all connected clients\nio.emit('analytics:update', {\ntype: 'pageView',\ndata: { page, count: analyticsData.pageViews[page] }\n});\n\nnext();\n});\n\n// Track custom events\napp.post('/track', express.json(), (req, res) => {\nconst { event, data } = req.body;\nconst eventId = uuidv4();\nconst timestamp = new Date().toISOString();\n\nconst eventData = { id: eventId, event, data, timestamp };\nanalyticsData.events.push(eventData);\n\n// Keep only the last 1000 events\nif (analyticsData.events.length > 1000) {\nanalyticsData.events.shift();\n}\n\n// Emit event to all connected clients\nio.emit('analytics:event', eventData);\n\nres.status(201).json({ success: true, eventId });\n});\n\n// WebSocket connection handling\nio.on('connection', (socket) => {\nconst userId = socket.handshake.query.userId || 'anonymous';\nanalyticsData.activeUsers.add(userId);\n\n// Send initial data to the newly connected client\nsocket.emit('analytics:init', {\npageViews: analyticsData.pageViews,\nactiveUsers: analyticsData.activeUsers.size,\nrecentEvents: analyticsData.events.slice(-50)\n});\n\n// Update all clients about the new active user count\nio.emit('analytics:update', {\ntype: 'activeUsers',\ndata: analyticsData.activeUsers.size\n});\n\n// Handle disconnection\nsocket.on('disconnect', () => {\nanalyticsData.activeUsers.delete(userId);\nio.emit('analytics:update', {\ntype: 'activeUsers',\ndata: analyticsData.activeUsers.size\n});\n});\n\n// Handle custom events from the client\nsocket.on('analytics:event', (data) => {\nconst eventId = uuidv4();\nconst timestamp = new Date().toISOString();\nconst eventData = { id: eventId, ...data, timestamp, userId };\n\nanalyticsData.events.push(eventData);\nif (analyticsData.events.length > 1000) {\nanalyticsData.events.shift();\n}\n\nio.emit('analytics:event', eventData);\n});\n});\n\n// API to get analytics data\napp.get('/api/analytics', (req, res) => {\nres.json({\npageViews: analyticsData.pageViews,\nactiveUsers: analyticsData.activeUsers.size,\ntotalEvents: analyticsData.events.length,\nrecentEvents: analyticsData.events.slice(-50)\n});\n});\n\n// Serve the dashboard\napp.use(express.static('public'));\n\nconst PORT = process.env.PORT || 3000;\nserver.listen(PORT, () => {\nconsole.log(`Analytics server running on port ${PORT}`);\nconsole.log(`Dashboard available at http://localhost:${PORT}/dashboard.html`);\n});"
      ]
    },
    {
      "title": "Node.js and Raspberry Pi",
      "summary": "Raspberry Pi is a small, multi-use computer.\nWith Node.js you can do amazing things with your Raspberry Pi.\nWhat is the Raspberry Pi?\nThe Raspberry Pi is a small, affordable, and amazingly capable, credit card size computer.\nIt is developed by the Raspberry Pi Foundation, and it might be the most versatile tech ever created.\nCreator Eben Upton's goal was to create a low-cost device that would improve programming skills and hardware understanding.\nDue to the small size and price of the device, it has become the center of a wide range of projects by tinkerers, makers, and electronics enthusiasts.\nRaspberry Pi and Node.js\nThe Raspberry Pi has a row of GPIO (General Purpose input/output) pins, and these can be used to interact in amazing ways with the real world. This tutorial will focus on how to use these with Node.js.\nWhat Do I Need?\nFor this tutorial you need a Raspberry Pi. In our examples we use a Raspberry Pi 3, but this tutorial should work for most versions.\nHardware needed:\nRaspberry Pi computer\nMicroSD memory card (We recommend a class 10 with 16 GB or higher)\nMicroSD to SD memory card adapter (usually included with the MicroSD card)\nMicro USB power supply to power the Raspberry Pi (2.5A or greater recommended)\nWiFi/Ethernet Cable connection for the Raspberry Pi (Not needed for Raspberry Pi 3 as it has built in WiFi)\nA working computer with internet and SD memory card reader (used to get the OS (Operating System) for the Raspberry Pi onto the memory card). In our tutorial we use a Windows computer for this, but you can use a Mac or Linux computer if you prefer\nHDMI monitor, USB keyboard (we need these only temporarily for the first boot of the Raspberry Pi)\nFor later chapters in this tutorial we will use special sensors or devices that we connect to the Raspberry Pi. We will specify these as special requirements in the relevant chapters.\nIf you already have a Raspberry Pi set up with Raspbian, internet and enabled SSH, you can skip to the step \"Install Node.js on Raspberry Pi\".\nWrite Raspbian OS Image to MicroSD Card\nBefore we can start using our Raspberry Pi for anything, we need to get a OS installed.\nRaspbian is a free operating system based on Debian Linux, and it is optimized Raspberry Pi.\nDownload the latest Raspbian image from https://www.raspberrypi.org/downloads/raspbian/ to your computer.\nWe use the \"LITE\" version in our tutorial, since we are setting the Raspberry Pi up as a headless server (we will connect to it through SSH, without having a keyboard/display connected to it). You can use whichever version you want, but this tutorial is written with the \"LITE\" version as its focus.\nInsert the MicroSD memory card in your computer (via the SD adapter if needed). Open File Explorer to verify that it is operational.\nEtcher is a program for flashing images to memory cards. Download and install Etcher from: https://etcher.io/\nLaunch Etcher:\nClick \"Select image\" button and find the Raspbian zip file that you downloaded.\nClick the \"Select drive\" button and specify the memory card as the target location.\nClick the \"Flash!\" button to write the image to the memory card.\nAfter Etcher is finished writing the image to the memory card, remove it from your computer.\nSet up Your Raspberry Pi\nTo get the Raspberry Pi ready to boot we need to:\nInsert the MicroSD memory card into the Raspberry Pi\nConnect the USB keyboard\nConnect the HDMI cable\nConnect the USB Wi-Fi adapter (or Ethernet cable). Skip this step if you are using a Raspberry Pi 3\nConnect the micro USB power supply\nThe Raspberry Pi should now be booting up\nWhen the Raspberry Pi is finished booting up, log in using username: pi and password: raspberry\nSet Up Network on the Raspberry Pi\nIf you will use a Ethernet cable to connect your Raspberry Pi to the internet, you can skip this step.\nFor this section we will assume you have a Raspberry Pi 3, with built in WiFi.\nStart by scanning for wireless networks:\nThis will list all of the available WiFi networks. (It also confirms that your WiFi is working)\nNow we need to open the wpa-supplicant file, to add the network you want to connect to:\nThis will open the file in the Nano editor. Add the following to the bottom of the file (change wifiName and wifiPassword with the actual network name and password):\nPress \"Ctrl+x\" to save the code. Confirm with \"y\", and confirm the name with \"Enter\".\nAnd reboot the Raspberry Pi:\nAfter reboot, log in again, and confirm that the WiFi is connected and working:\nIf the WiFi is working propery, the information displayed should include an IP address, similar to this:\nWrite down that IP address, as we will use it to connect to the Raspberry Pi via SSH.\nREMOVE ADS\nEnable SSH, Change Hostname and Password\nNow your Raspberry Pi is connected to the internet, it is time to enable SSH.\nSSH allows you up use the Raspberry Pi without having a monitor and keyboard connected to it.\n(You will need a SSH client for this on your non-Raspberry Pi computer. We use\nPuTTY\nfor windows)\nOpen the Raspberry Pi Software Configuration Tool:\nYou should see a menu like this:\nSelect option 5 Interfacing Options:\nSelect option P2 SSH, to activate SSH:\nConfirm with YES, to activate SSH:\nSSH is now enabled, and you should be in the main menu again.\nSelect 1 Change User Password, and follow the instructions to change the password. Choose a secure password, but something you will remember:\nAfter you have finished changing the password, you should be back in the main menu.\nSelect 2 Hostname, and follow the instructions to change the hostname:\nAfter you have finished changing the hostname, you should be back in the main menu.\nNow we will close the menu and save the changes:\nWhen selecting Finish, you will get the option to reboot. Select Yes to reboot the Raspberry Pi.\nYou can now unplug the monitor and keyboard from the Raspberry Pi, and we can log in using out SSH client.\nOpen PuTTY, type in the IP address for your Raspberry Pi, and click Open:\nLog in using the username pi and the new password you specified.\nYou should now see a command line like this: (we used w3demopi as our hostname)\nYou are now able to run your Raspberry Pi in \"Headless-mode\", meaning you do not need a monitor or keyboard. And if you have a WiFi connection, you do not need a ethernet cable either, just the power cable!\nInstall Node.js on Raspberry Pi\nWith the Raspberry Pi properly set up, login in via SSH, and update your Raspberry Pi system packages to their latest versions.\nUpdate your system package list:\nUpgrade all your installed packages to their latest version:\nDoing this regularly will keep your Raspberry Pi installation up to date.\nTo download and install newest version of Node.js, use the following command:\nNow install it by running:\nCheck that the installation was successful, and the version number of Node.js with:\nGet Started with Raspberry Pi and Node.js\nNow you have a Raspberry Pi with Node.js installed!\nIf you want to learn more about Node.js, follow our tutorial: https://www.w3schools.com/nodejs/\nIn the next chapter we will get to know the GPIO and how to use it with Node.js.",
      "examples": [
        "pi@raspberrypi:~ $ sudo iwlist wlan0 scan",
        "pi@raspberrypi:~ $ sudo nano /etc/wpa_supplicant/wpa_supplicant.conf",
        "network={\nssid=\"wifiName\"\npsk=\"wifiPassword\"\n}",
        "pi@raspberrypi:~ $ sudo reboot",
        "pi@raspberrypi:~ $ ifconfig wlan0",
        "inet addr:192.168.1.50",
        "pi@raspberrypi:~ $ sudo raspi-config",
        "pi@w3demopi:~ $",
        "pi@w3demopi:~ $ sudo apt-get update",
        "pi@w3demopi:~ $ sudo apt-get dist-upgrade",
        "pi@w3demopi:~ $ curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -",
        "pi@w3demopi:~ $ sudo apt-get install -y nodejs",
        "pi@w3demopi:~ $ node -v",
        "pi",
        "raspberry",
        "wifiName",
        "wifiPassword",
        "Ctrl+x",
        "y",
        "Enter",
        "5 Interfacing Options",
        "P2 SSH",
        "YES",
        "1 Change User Password",
        "2 Hostname",
        "Finish",
        "Yes",
        "Open"
      ]
    },
    {
      "title": "Node.js Raspberry Pi - GPIO Introduction",
      "summary": "What is GPIO?\nGPIO stands for General Purpose Input Output.\nThe Raspberry Pi has two rows of GPIO pins, which are connections between the Raspberry Pi, and the real world.\nOutput pins are like switches that the Raspberry Pi can turn on or off (like turning on/off a LED light). But it can also send a signal to another device.\nInput pins are like switches that you can turn on or off from the outside world (like a on/off light switch). But it can also be a data from a sensor, or a signal from another device.\nThat means that you can interact with the real world, and control devices and electronics using the Raspberry PI and its GPIO pins!\nTaking a Closer Look at the GPIO Pins\nThis is an illustration of the Raspberry Pi 3.\nThe GPIO pins are the small red squares in two rows on the right side of the Raspberry Pi, on the actual Raspberry Pi they are small metal pins.\nThe Raspberry Pi 3 has 26 GPIO pins, the rest of the pins are power, ground or \"other\".\nThe pin placements correspond with the table below.\nRaspberry Pi B+, 2, 3 & Zero\nLegend\nREMOVE ADS\nTaking a Closer Look at the Breadboard\nA breadboard is used for prototyping electronics, it allows you to create circuits without soldering. It is basically a plastic board, with a grid of tie-points (holes). Inside the board there are metal strips connecting the different tie-points in specific ways.\nIn the illustration below we have highlighted some of the sections with different colors. This is to show you how the grid is connected.\nThe different sections of the breadboard:\nOn the left, and right, side there are 2 columns of tie-points. All the tie points in each of these columns are connected.\nThe Power Bus - The columns highlighted with red. There are usually used to connect power to the Breadboard. Since the entire column is connected, you can connect power to any of the tie-points in the column.\nThe Ground Bus - The columns highlighted with blue. There are usually used to connect Ground to the Breadboard. Since the entire column is connected, you can connect ground to any of the tie-points in the column.\nRows of connected Tie-Points - The rows highlighted with green. The tie-points of each of these rows are connected, but not the entire row! The left side tie-points are connected (A-B-C-D-E), and the right side tie-points are connected (F-G-H-I-J).\nIn the center of the Breadboard there is a Trench, this separates the left and right rows. The width of the trench is designed so that many Integrated Circuits fit across it.\nInstall the onoff Module\nTo interface with the GPIO on the Raspberry Pi using Node.js, we will use a Module called \"onoff\".\nInstall the onoff module using npm:\nNow onoff should be installed and we can interact with the GPIO of the Raspberry Pi.",
      "examples": [
        "pi@w3demopi:~ $ npm install onoff"
      ]
    },
    {
      "title": "Node.js Raspberry Pi GPIO - Blinking LED",
      "summary": "Using the GPIO for Output\nIn this chapter we will use a Raspberry Pi and its GPIO to make a LED blink.\nWe use Node.js with the onoff module to control the GPIO.\nTo get a LED light to turn on, we use a GPIO pin as \"Output\", and create a script to turn it on and off (blinking).\nWhat do we need?\nIn this chapter we will create a simple example where we control a LED light.\nFor this you need:\nA Raspberry Pi with Raspian, internet, SSH, with Node.js installed\nThe onoff module for Node.js\n1 x Breadboard\n1 x 68 Ohm resistor\n1 x Through Hole LED\n2 x Female to male jumper wires\nClick the links in the list above for descriptions of the different components.\nNote: The resistor you need can be different from what we use depending on the type of LED you use. Most small LEDs only need a small resistor, around 200-500 ohms. It is generally not critical what exact value you use, but the smaller the value of the resistor, the brighter the LED will shine.\nBuilding the Circuit\nNow it is time to build the circuit on our Breadboard.\nIf you are new to electronics, we recommend you turn off the power for the Raspberry Pi. And use an anti-static mat or a grounding strap to avoid damaging it.\nShut down the Raspberry Pi properly with the command:\nAfter the LEDs stop blinking on the Raspberry Pi, then pull out the power plug from the Raspberry Pi (or turn off the power strip it is connected to).\nJust pulling the plug without shutting down properly may cause corruption of the memory card.\nLook at the above illustration of the circuit.\nOn the Raspberry Pi, connect the female leg of the first jumper wire to Ground. You can use any GND pin. In this example we used Physical Pin 9 (GND, row 5, left column)\nOn the Breadboard, connect the male leg of the first jumper wire to the Ground Bus column on the right. That entire column of your breadboard is connected, so it doesn't matter which row. In this example we have attached it to row 1\nOn the Raspberry Pi, connect the female leg of the second jumper cable to a GPIO pin. In this example we used Physical Pin 7 (GPIO 4, row 4, left column)\nOn the Breadboard, connect the male leg of the second jumper wire to the Tie-Point row of your choice. In this example we connected it to row 5, column A\nOn the Breadboard, connect one leg of the resistor to the Ground Bus column on the right side. That entire column of your breadboard is connected, so it doesn't matter which row. In this example we have attached it to row 5\nOn the Breadboard, connect the other leg of the resistor to the right side Tie-Point row of your choice. In this example we have used row 5, column J\nOn the Breadboard, connect the cathode leg (the shortest leg) of the LED to the same Tie-Point row that you connected the resistor from GND to. In this example we used row 5, column F\nOn the Breadboard, connect the anode leg (the longest leg) of the LED to the same Tie-Point row that you connected the jumper from the GPIO pin to. In this example we used row 5, column E\nYour circuit should now be complete, and your connections should look pretty similar to the illustration above.\nNow it is time to boot up the Raspberry Pi, and write the Node.js script to interact with it.\nREMOVE ADS\nRaspberry Pi and Node.js Blinking LED Script\nNow that we have everything set up, we can write a script to turn the LED on and off.\nStart by making a directory where we can keep our Node.js scripts:\nGo to our new directory:\nNow we will create a new file called \"blink.js\" using the Nano Editor:\nThe file is now open and can be edited with the built in Nano Editor.\nWrite, or paste the following code:\nblink.jsGet your own Node.js Server\nPress \"Ctrl+x\" to save the code. Confirm with \"y\", and confirm the name with \"Enter\".\nRun the code:\nNow the LED should blink for 5 seconds (10 times) before turning off again!",
      "examples": [
        "pi@w3demopi:~ $ sudo shutdown -h now",
        "pi@w3demopi:~ $ mkdir nodetest",
        "pi@w3demopi:~ $ cd nodetest",
        "pi@w3demopi:~ $ nano blink.js",
        "let Gpio = require('onoff').Gpio; //include onoff to interact with the GPIO\nlet LED = new Gpio(4, 'out'); //use GPIO pin 4, and specify that it is output\nlet blinkInterval = setInterval(blinkLED, 250); //run the blinkLED function every 250ms\n\nfunction blinkLED() { //function to start blinking\nif (LED.readSync() === 0) { //check the pin state, if the state is 0 (or off)\nLED.writeSync(1); //set pin state to 1 (turn LED on)\n} else {\nLED.writeSync(0); //set pin state to 0 (turn LED off)\n}\n}\n\nfunction endBlink() { //function to stop blinking\nclearInterval(blinkInterval); // Stop blink intervals\nLED.writeSync(0); // Turn LED off\nLED.unexport(); // Unexport GPIO to free resources\n}\n\nsetTimeout(endBlink, 5000); //stop blinking after 5 seconds",
        "pi@w3demopi:~ $ node blink.js",
        "blink.js",
        "Ctrl+x",
        "y",
        "Enter"
      ]
    },
    {
      "title": "Node.js Raspberry Pi GPIO - LED and Pushbutton",
      "summary": "Using both Input and Output\nIn the previous chapter we learned how to use a Raspberry Pi and its GPIO to make a LED blink.\nFor that we used a GPIO pin as \"Output\".\nIn this chapter we will use another GPIO pin as \"Input\".\nInstead of blinking for 5 seconds, we want the LED to light up when you push a button connected to the breadboard.\nWhat do we need?\nIn this chapter we will create a simple example where we control a LED light with a Push Button.\nFor this you need:\nA Raspberry Pi with Raspian, internet, SSH, with Node.js installed\nThe onoff module for Node.js\n1 x Breadboard\n1 x 68 Ohm resistor\n1 x 1k Ohm resistor\n1 x Through Hole LED\n1 x Push Button\n4 x Female to male jumper wires\n1 x Male to Male jumper wires\nClick the links in the list above for descriptions of the different components.\nNote: The resistor you need can be different from what we use depending on the type of LED you use. Most small LEDs only need a small resistor, around 200-500 ohms. It is generally not critical what exact value you use, but the smaller the value of the resistor, the brighter the LED will shine.\nIn this chapter we will build on the circuit we built in last chapter, so you will recognize some of the parts in the list above.\nBuilding the Circuit\nNow it is time to build the circuit on our Breadboard. We will use the circuit we created in the last chapter as a starting point.\nIf you are new to electronics, we recommend you turn off the power for the Raspberry Pi. And use an anti-static mat or a grounding strap to avoid damaging it.\nShut down the Raspberry Pi properly with the command:\nAfter the LEDs stop blinking on the Raspberry Pi, then pull out the power plug from the Raspberry Pi (or turn of the power strip it is connected to).\nJust pulling the plug without shutting down properly may cause corruption of the memory card.\nLook at the above illustration of the circuit.\nStarting with the circuit we created in the last chapter:\nOn the Raspberry Pi, connect the female leg of a jumper wire to a 5V power pin. In our example we used Physical Pin 2 (5V, row 1, right column)\nOn the Breadboard, connect the male leg of the jumper wire connected to the 5V power, to the Power Bus on the right side. That entire column of your breadboard is connected, so it doesn't matter which row. In our example we attached it to row 1\nOn the Breadboard, connect the push button so that it fits across the Trench. In our example it connects to rows 13 and 15, columns E and F\nOn the Breadboard, connect one leg of the 1k ohm resistor to the Ground Bus column on the right side, and the other leg to the right side Tie-Point row where it connects to one of the right side legs of the push button. In our example we attached one side to Tie-Point row 13, column J, and the other side to the closest Ground Bus hole\nOn the Breadboard, connect a male-to-male jumper wire from the right Power Bus, to the right Tie-Point row that connects to the other leg of the push button. In our example we attached one side to Tie-Point row 15, column J, and the other side to the closest Power Bus hole\nOn the Raspberry Pi, connect the female leg of a jumper wire to a GPIO pin. In our example we used Physical Pin 11 (GPIO 17, row 6, left column)\nOn the Breadboard, connect the male leg of the jumper wire to left Tie-Point row the Push Button leg that is directly across the Ground connection leg.  In our example we attached it to row 13, column A\nYour circuit should now be complete, and your connections should look pretty similar to the illustration above.\nNow it is time to boot up the Raspberry Pi, and write the Node.js script to interact with it.\nREMOVE ADS\nRaspberry Pi and Node.js LED and Button Script\nGo to the \"nodetest\" directory, and create a new file called \"buttonled.js\":\nThe file is now open and can be edited with the built in Nano Editor.\nWrite, or paste the following:\nbuttonled.jsGet your own Node.js Server\nPress \"Ctrl+x\" to save the code. Confirm with \"y\", and confirm the name with \"Enter\".\nRun the code:\nNow the LED should turn on when you press the button, and turn off when you release it.\nEnd the program with Ctrl+c.",
      "examples": [
        "pi@w3demopi:~ $ sudo shutdown -h now",
        "pi@w3demopi:~ $ nano buttonled.js",
        "var Gpio = require('onoff').Gpio; //include onoff to interact with the GPIO\nlet LED = new Gpio(4, 'out'); //use GPIO pin 4 as output\nlet pushButton = new Gpio(17, 'in', 'both'); //use GPIO pin 17 as input, and 'both' button presses, and releases should be handled\n\npushButton.watch(function (err, value) { //Watch for hardware interrupts on pushButton GPIO, specify callback function\nif (err) { //if an error\nconsole.error('There was an error', err); //output error message to console\nreturn;\n}\nLED.writeSync(value); //turn LED on or off depending on the button state (0 or 1)\n});\n\nfunction unexportOnClose() { //function to run when exiting program\nLED.writeSync(0); // Turn LED off\nLED.unexport(); // Unexport LED GPIO to free resources\npushButton.unexport(); // Unexport Button GPIO to free resources\n};\n\nprocess.on('SIGINT', unexportOnClose); //function to run when user closes using ctrl+c",
        "pi@w3demopi:~ $ node buttonled.js",
        "buttonled.js",
        "Ctrl+x",
        "y",
        "Enter",
        "Ctrl+c"
      ]
    },
    {
      "title": "Node.js Raspberry Pi GPIO - Flowing LEDs",
      "summary": "Using Array With Output to Create Flowing LEDs\nIn this chapter we will use several GPIO pins to create a \"flowing\" effect by turning them on and off in sequence.\nWhat do we need?\nFor this you need:\nA Raspberry Pi with Raspian, internet, SSH, with Node.js installed\nThe onoff module for Node.js\n1 x Breadboard\n8 x 220 Ohm resistor\n8 x Through Hole LED\n9 x Female to male jumper wires\nNote: The resistor you need can be different from what we use depending on the type of LEDs you use. Most small LEDs only need a small resistor, around 200-500 ohms. It is generally not critical what exact value you use, but the smaller the value of the resistor, the brighter the LED will shine.\nClick the links in the list above for descriptions of the different components.\nBuilding the Circuit\nNow it is time to build the circuit on our Breadboard.\nIf you are new to electronics, we recommend you turn off the power for the Raspberry Pi. And use an anti-static mat or a grounding strap to avoid damaging it.\nShut down the Raspberry Pi properly with the command:\nAfter the LEDs stop blinking on the Raspberry Pi, then pull out the power plug from the Raspberry Pi (or turn of the power strip it is connected to).\nJust pulling the plug without shutting down properly may cause corruption of the memory card.\nLook at the above illustration of the circuit.\nOn the Raspberry Pi, connect the female leg of a jumper wire to a GND pin. In our example we used Physical Pin 6 (GND, row 3, right column)\nOn the Breadboard, connect the male leg of the jumper wire connected to the GND power, to the Ground Bus on the right side. That entire column of your breadboard is connected, so it doesn't matter which row. In our example we attached it to row 1\nFor each LED: Connect the LED so that it connects to 2 Tie-Point rows. In our example we connected:\nLED1 to rows 5 (cathode) & 6 (anode) column J\nLED2 to rows 8 (cathode) & 9 (anode) column J\nLED3 to rows 11 (cathode) & 12 (anode) column J\nLED4 to rows 14 (cathode) & 15 (anode) column J\nLED5 to rows 17 (cathode) & 18 (anode) column J\nLED6 to rows 20 (cathode) & 21 (anode) column J\nLED7 to rows 23 (cathode) & 24 (anode) column J\nLED8 to rows 26 (cathode) & 27 (anode) column J\nLED1 to rows 5 (cathode) & 6 (anode) column J\nLED2 to rows 8 (cathode) & 9 (anode) column J\nLED3 to rows 11 (cathode) & 12 (anode) column J\nLED4 to rows 14 (cathode) & 15 (anode) column J\nLED5 to rows 17 (cathode) & 18 (anode) column J\nLED6 to rows 20 (cathode) & 21 (anode) column J\nLED7 to rows 23 (cathode) & 24 (anode) column J\nLED8 to rows 26 (cathode) & 27 (anode) column J\nFor each LED: Connect one of the legs of a 220 ohm resistor from the the Ground Bus column on the right side, and the other leg to the right side Tie-Point row where it connects to the cathode leg of the LED. In our example we connected:\nLED1 to row 5 column I\nLED2 to row 8 column I\nLED3 to row 11 column I\nLED4 to row 14 column I\nLED5 to row 17 column I\nLED6 to row 20 column I\nLED7 to row 23 column I\nLED8 to row 26 column I\nLED1 to row 5 column I\nLED2 to row 8 column I\nLED3 to row 11 column I\nLED4 to row 14 column I\nLED5 to row 17 column I\nLED6 to row 20 column I\nLED7 to row 23 column I\nLED8 to row 26 column I\nFor each LED: Connect the female leg of a jumper wire to a GPIO pin on the Raspberry Pi, and the male leg of the jumper wire to the right side Tie-Point row where it connects to the anode leg of the LED. In our example we connected:\nLED1 from Physical Pin 7 (GPIO 4, row 4, left column) to Tie-point row 6 column F\nLED2 from Physical Pin 11 (GPIO 17, row 6, left column) to Tie-point row 9 column F\nLED3 from Physical Pin 13 (GPIO 27, row 7, left column) to Tie-point row 12 column F\nLED4 from Physical Pin 15 (GPIO 22, row 8, left column) to Tie-point row 15 column F\nLED5 from Physical Pin 12 (GPIO 18, row 6, right column) to Tie-point row 18 column F\nLED6 from Physical Pin 16 (GPIO 23, row 8, right column) to Tie-point row 21 column F\nLED7 from Physical Pin 18 (GPIO 24, row 9, right column) to Tie-point row 24 column F\nLED8 from Physical Pin 22 (GPIO 25, row 11, right column) to Tie-point row 27 column F\nLED1 from Physical Pin 7 (GPIO 4, row 4, left column) to Tie-point row 6 column F\nLED2 from Physical Pin 11 (GPIO 17, row 6, left column) to Tie-point row 9 column F\nLED3 from Physical Pin 13 (GPIO 27, row 7, left column) to Tie-point row 12 column F\nLED4 from Physical Pin 15 (GPIO 22, row 8, left column) to Tie-point row 15 column F\nLED5 from Physical Pin 12 (GPIO 18, row 6, right column) to Tie-point row 18 column F\nLED6 from Physical Pin 16 (GPIO 23, row 8, right column) to Tie-point row 21 column F\nLED7 from Physical Pin 18 (GPIO 24, row 9, right column) to Tie-point row 24 column F\nLED8 from Physical Pin 22 (GPIO 25, row 11, right column) to Tie-point row 27 column F\nYour circuit should now be complete, and your connections should look pretty similar to the illustration above.\nNow it is time to boot up the Raspberry Pi, and write the Node.js script to interact with it.\nREMOVE ADS\nRaspberry Pi and Node.js Flowing LEDs Script\nGo to the \"nodetest\" directory, and create a new file called \"flowingleds.js\":\nThe file is now open and can be edited with the built in Nano Editor.\nWrite, or paste the following:\nflowingleds.jsGet your own Node.js Server\nPress \"Ctrl+x\" to save the code. Confirm with \"y\", and confirm the name with \"Enter\".\nRun the code:\nNow the LEDs should turn on and off in sequence, creating a flowing effect.\nEnd the program with Ctrl+c.",
      "examples": [
        "pi@w3demopi:~ $ sudo shutdown -h now",
        "pi@w3demopi:~ $ nano flowingleds.js",
        "let Gpio = require('onoff').Gpio; //include onoff to interact with the GPIO\nlet LED04 = new Gpio(4, 'out'), //use declare variables for all the GPIO output pins\nLED17 = new Gpio(17, 'out'),\nLED27 = new Gpio(27, 'out'),\nLED22 = new Gpio(22, 'out'),\nLED18 = new Gpio(18, 'out'),\nLED23 = new Gpio(23, 'out'),\nLED24 = new Gpio(24, 'out'),\nLED25 = new Gpio(25, 'out');\n\n//Put all the LED variables in an array\nlet leds = [LED04, LED17, LED27, LED22, LED18, LED23, LED24, LED25];\nlet indexCount = 0; //a counter\ndir = \"up\"; //variable for flowing direction\n\nlet flowInterval = setInterval(flowingLeds, 100); //run the flowingLeds function every 100ms\n\nfunction flowingLeds() { //function for flowing Leds\nleds.forEach(function(currentValue) { //for each item in array\ncurrentValue.writeSync(0); //turn off LED\n});\nif (indexCount == 0) dir = \"up\"; //set flow direction to \"up\" if the count reaches zero\nif (indexCount >= leds.length) dir = \"down\"; //set flow direction to \"down\" if the count reaches 7\nif (dir == \"down\") indexCount--; //count downwards if direction is down\nleds[indexCount].writeSync(1); //turn on LED that where array index matches count\nif (dir == \"up\") indexCount++ //count upwards if direction is up\n};\n\nfunction unexportOnClose() { //function to run when exiting program\nclearInterval(flowInterval); //stop flow interwal\nleds.forEach(function(currentValue) { //for each LED\ncurrentValue.writeSync(0); //turn off LED\ncurrentValue.unexport(); //unexport GPIO\n});\n};\n\nprocess.on('SIGINT', unexportOnClose); //function to run when user closes using ctrl+cc",
        "pi@w3demopi:~ $ node flowingleds.js",
        "flowingleds.js",
        "Ctrl+x",
        "y",
        "Enter",
        "Ctrl+c"
      ]
    },
    {
      "title": "Node.js and Raspberry Pi - Webserver with WebSocket",
      "summary": "What is WebSocket?\nWebSocket enables bidirectional communication in real time over the web.\nWebSocket can be run together with a normal HTTP server. You can click a button in a web browser, and enable a GPIO on your Raspberry Pi which turns on a light in your house. All in real time, and with communication going both ways!\nIn this chapter, we will set up a web server with WebSocket. Then create a browser UI to interact with our earlier example of turning a LED on and off with a button.\nWhat Do I Need?\nFor this tutorial you need a Raspberry Pi. In our examples we use a a Raspberry Pi 3, but this tutorial should work for most versions.\nFor this you need:\nA Raspberry Pi with Raspian, internet, SSH, with Node.js installed\nThe onoff module for Node.js\nThe socket.io module for Node.js\n1 x Breadboard\n1 x 68 Ohm resistor\n1 x 1k Ohm resistor\n1 x Through Hole LED\n1 x Push Button\n4 x Female to male jumper wires\n1 x Male to Male jumper wires\nClick the links in the list above for descriptions of the different components.\nNote: The resistor you need can be different from what we use depending on the type of LED you use. Most small LEDs only need a small resistor, around 200-500 ohms. It is generally not critical what exact value you use, but the smaller the value of the resistor, the brighter the LED will shine.\nCompared to our earlier example, the only new thing we need is to set up a web server, and install the socket.io module.\nWebserver for Raspberry Pi and Node.js\nFollowing the earlier chapters in this Node.js tutorial, lets set up a web server that can serve HTML files.\nIn our \"nodetest\" directory create a new directory we can use for static html files:\nNow lets set up a webserver. Create a Node.js file that opens the requested file and returns the content to the client. If anything goes wrong, throw a 404 error.\nwebserver.js:\nGo to the folder \"public\":\nAnd create a HTML file, index.html:\nindex.html:\nThis file will not have any functionality yet. For now it is just a placeholder. Lets see if the webserver is working:\nOpen the website in a browser using http://[RaspberryPi_IP]:8080/:\nThe webserver should now be up and running, and we can move on to the WebSocket part.\nInstall socket.io for Node.js\nWith the webserver set up, update your Raspberry Pi system packages to their latest versions.\nUpdate your system package list:\nUpgrade all your installed packages to their latest version:\nDoing this regularly will keep your Raspberry Pi installation up to date.\nTo download and install newest version of socket.io, use the following command:\nREMOVE ADS\nAdding WebSocket to our Webserver\nNow we can use WebSocket in our application. Lets update our index.html file:\nindex.html:\nAnd our webserver.js file:\nwebserver.js:\nLets test the server:\nOpen the website in a browser using http://[RaspberryPi_IP]:8080/:\nNow the server should output all the changes to the checkbox to the console on the Raspberry Pi.\nThe client is sending the changes to the server, and the server is responding.\nLets add the push button controlled LED from a previous chapter.\nAdding Hardware, and sending a response to the Client\nLets update our webserver.js file again. We will use a lot of the code from the Pushbutton controlled LED chapter.\nwebserver.js:\nLets test the server:\nOpen the website in a browser using http://[RaspberryPi_IP]:8080/:\nNow the server should output all the changes to the checkbox to the console on the Raspberry Pi.\nThe client is sending the changes to the server, and the server is responding.\nEnd the program with Ctrl+c.",
      "examples": [
        "pi@w3demopi:~/nodetest $ mkdir public",
        "pi@w3demopi:~/nodetest $ nano webserver.js",
        "let http = require('http').createServer(handler); //require http server, and create server with function handler()\nlet fs = require('fs'); //require filesystem module\n\nhttp.listen(8080); //listen to port 8080\n\nfunction handler (req, res) { //create server\nfs.readFile(__dirname + '/public/index.html', function(err, data) { //read file index.html in public folder\nif (err) {\nres.writeHead(404, {'Content-Type': 'text/html'}); //display 404 on error\nreturn res.end(\"404 Not Found\");\n}\nres.writeHead(200, {'Content-Type': 'text/html'}); //write HTML\nres.write(data); //write data from index.html\nreturn res.end();\n});\n}",
        "pi@w3demopi:~/nodetest $ cd public",
        "pi@w3demopi:~/nodetest/public $ nano index.html",
        "<!DOCTYPE html>\n<html>\n<body>\n\n<h1>Control LED light</h1>\n<input id=\"light\" type=\"checkbox\">LED\n\n</body>\n</html>",
        "pi@w3demopi:~/nodetest/public $ cd ..",
        "pi@w3demopi:~/nodetest $ node webserver.js",
        "pi@w3demopi:~ $ sudo apt-get update",
        "pi@w3demopi:~ $ sudo apt-get dist-upgrade",
        "pi@w3demopi:~ $ npm install socket.io --save",
        "<!DOCTYPE html>\n<html>\n<body>\n\n<h1>Control LED light</h1>\n<p><input type=\"checkbox\" id=\"light\"></p>\n\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.0.3/socket.io.js\"></script> <!-- include socket.io client side script -->\n<script>\nlet socket = io(); //load socket.io-client and connect to the host that serves the page\nwindow.addEventListener(\"load\", function(){ //when page loads\nlet lightbox = document.getElementById(\"light\");\nlightbox.addEventListener(\"change\", function() { //add event listener for when checkbox changes\nsocket.emit(\"light\", Number(this.checked)); //send button status to server (as 1 or 0)\n});\n});\nsocket.on('light', function (data) { //get button status from client\ndocument.getElementById(\"light\").checked = data; //change checkbox according to push button on Raspberry Pi\nsocket.emit(\"light\", data); //send push button status to back to server\n});\n</script>\n\n</body>\n</html>",
        "let http = require('http').createServer(handler); //require http server, and create server with function handler()\nlet fs = require('fs'); //require filesystem module\nlet io = require('socket.io')(http) //require socket.io module and pass the http object (server)\n\nhttp.listen(8080); //listen to port 8080\n\nfunction handler (req, res) { //create server\nfs.readFile(__dirname + '/public/index.html', function(err, data) { //read file index.html in public folder\nif (err) {\nres.writeHead(404, {'Content-Type': 'text/html'}); //display 404 on error\nreturn res.end(\"404 Not Found\");\n}\nres.writeHead(200, {'Content-Type': 'text/html'}); //write HTML\nres.write(data); //write data from index.html\nreturn res.end();\n});\n}\n\nio.sockets.on('connection', function (socket) {// WebSocket Connection\nlet lightvalue = 0; //static variable for current status\nsocket.on('light', function(data) { //get light switch status from client\nlightvalue = data;\nif (lightvalue) {\nconsole.log(lightvalue); //turn LED on or off, for now we will just show it in console.log\n}\n});\n});",
        "pi@w3demopi:~ $ node webserver.js",
        "let http = require('http').createServer(handler); //require http server, and create server with function handler()\nlet fs = require('fs'); //require filesystem module\nlet io = require('socket.io')(http) //require socket.io module and pass the http object (server)\nlet Gpio = require('onoff').Gpio; //include onoff to interact with the GPIO\nlet LED = new Gpio(4, 'out'); //use GPIO pin 4 as output\nlet pushButton = new Gpio(17, 'in', 'both'); //use GPIO pin 17 as input, and 'both' button presses, and releases should be handled\n\nhttp.listen(8080); //listen to port 8080\n\nfunction handler (req, res) { //create server\nfs.readFile(__dirname + '/public/index.html', function(err, data) { //read file index.html in public folder\nif (err) {\nres.writeHead(404, {'Content-Type': 'text/html'}); //display 404 on error\nreturn res.end(\"404 Not Found\");\n}\nres.writeHead(200, {'Content-Type': 'text/html'}); //write HTML\nres.write(data); //write data from index.html\nreturn res.end();\n});\n}\n\nio.sockets.on('connection', function (socket) {// WebSocket Connection\nlet lightvalue = 0; //static variable for current status\npushButton.watch(function (err, value) { //Watch for hardware interrupts on pushButton\nif (err) { //if an error\nconsole.error('There was an error', err); //output error message to console\nreturn;\n}\nlightvalue = value;\nsocket.emit('light', lightvalue); //send button status to client\n});\nsocket.on('light', function(data) { //get light switch status from client\nlightvalue = data;\nif (lightvalue != LED.readSync()) { //only change LED if status has changed\nLED.writeSync(lightvalue); //turn LED on or off\n}\n});\n});\n\nprocess.on('SIGINT', function () { //on ctrl+c\nLED.writeSync(0); // Turn LED off\nLED.unexport(); // Unexport LED GPIO to free resources\npushButton.unexport(); // Unexport Button GPIO to free resources\nprocess.exit(); //exit completely\n});",
        "Ctrl+c"
      ]
    },
    {
      "title": "Node.js Raspberry Pi RGB LED with WebSocket",
      "summary": "Using Pulse-Width Modulation\nIn the previous chapters we have learned how to use WebSocket, and how to use GPIO to turn LEDs on and off.\nIn this we will use chapter we use a RGB LED, with PWM (Pulse-width modulation) to display different colors based on user input via WebSocket.\nAn RGB LED is a LED with 3 different colors. It has a RED, GREEN and BLUE LED (RGB LED).\nAnd using PWM, we can set the individual strength of the 3 LEDs. This will allow us to mix them, to set a color.\nWhat do we need?\nIn this chapter we will create an example where we control an RGB LED with a web page via WebSocket.\nFor this you need:\nA Raspberry Pi with Raspian, internet, SSH, with Node.js installed\nThe pigpio module for Node.js\nThe socket.io module for Node.js\n1 x Breadboard\n3 x 220 Ohm resistor\n1 x RGB LED (common anode or common cathode)\n4 x Female to male jumper wires\nClick the links in the list above for descriptions of the different components.\nNote: The resistor you need can be different from what we use depending on the type of LED you use. Most small LEDs only need a small resistor, around 200-500 ohms. It is generally not critical what exact value you use, but the smaller the value of the resistor, the brighter the LED will shine.\nInstall the pigpio Module\nEarlier, we have used the \"onoff\" module, which works great for just turning on and off. Now we want to set the set the strength of the LEDs, so we need a GPIO Module with a bit more functionality.\nWe will use the \"pigpio\" Node.js module, as this allows for PWM.\nWith PWM we can set the strength of a LED from 0 to 255.\nThe \"pigpio\" Node.js module is based on the pigpio C library.\nIf you are using the \"Lite\" version of Raspbian, this is most likely not included and must be manually installed.\nUpdate your system package list:\nInstall the pigpio C library:\nNow we can install the \"pigpio\" Node.js module using npm:\nNow the \"pigpio\" module should be installed and we can use it to interact with the GPIO of the Raspberry Pi.\nNote: Since the \"pigpio\" module uses the pigpio C library, it requires root/sudo privileges to access hardware peripherals (like the GPIO).\nBuilding the Circuit\nNow it is time to build the circuit on our Breadboard.\nIf you are new to electronics, we recommend you turn off the power for the Raspberry Pi. And use an anti-static mat or a grounding strap to avoid damaging it.\nShut down the Raspberry Pi properly with the command:\nAfter the LEDs stop blinking on the Raspberry Pi, then pull out the power plug from the Raspberry Pi (or turn of the power strip it is connected to).\nJust pulling the plug without shutting down properly may cause corruption of the memory card.\nIn building this Circuit it is important to know if you have a common anode, or common cathode, RGB LED:\nYou can check with your provider, or test it yourself:\nConnect cables to GND and 3.3V pin. Connect GND to the longest leg of the RGB LED and the 3.3 V to any other leg. If the it lights up, your RGB LED has a common cathode. If not, it has a common anode.\nLook at the above illustration of the circuit.\nOn the Breadboard, connect the RGB LED to the right ground bus column, and make sure that each leg connects to a different row. The longest leg is the common cathode leg. In this example we have connected the LED to rows 1-4, with the common cathode leg connected to row 2 column I. The RED leg is connected to row 1 column J, the GREEN leg is connected to row 3 column J, and the BLUE leg is connected to row 4 column J\nOn the Raspberry Pi, connect the female leg of the first jumper wire to Ground. You can use any GND pin. In this example we used Physical Pin 9 (GND, row 5, left column)\nOn the Breadboard, connect the male leg of the first jumper wire to the same row of the right ground bus column that you connected the common cathode to. In this example we connected it to row 2 column F\nOn the Raspberry Pi, connect the female leg of the second jumper cable to a GPIO pin. We will use this for the RED leg, In this example we used Physical Pin 7 (GPIO 4, row 4, left column)\nOn the Breadboard, connect the male leg of the second jumper wire to the left ground bus, same row as the RED leg of the LED is connected. In this example we connected it to row 1, column A\nOn the Breadboard, connect a resistor between the left and right ground bus columns for the row with the RED leg of the LED. In this example we have attached it to row 1, column E and F\nOn the Raspberry Pi, connect the female leg of the third jumper cable to a GPIO pin. We will use this for the GREEN leg, In this example we used Physical Pin 11 (GPIO 17, row 6, left column)\nOn the Breadboard, connect the male leg of the third jumper wire to the left ground bus, same row as the GREEN leg of the LED is connected. In this example we connected it to row 3, column A\nOn the Breadboard, connect a resistor between the left and right ground bus columns for the row with the GREEN leg of the LED. In this example we have attached it to row 3, column E and F\nOn the Raspberry Pi, connect the female leg of the forth jumper cable to a GPIO pin. We will use this for the BLUE leg, In this example we used Physical Pin 13 (GPIO 27, row 7, left column)\nOn the Breadboard, connect the male leg of the forth jumper wire to the left ground bus, same row as the BLUE leg of the LED is connected. In this example we connected it to row 4, column A\nOn the Breadboard, connect a resistor between the left and right ground bus columns for the row with the BLUE leg of the LED. In this example we have attached it to row 4, column E and F\nYour circuit should now be complete, and your connections should look pretty similar to the illustration above.\nNow it is time to boot up the Raspberry Pi, and write the Node.js script to interact with it.\nLook at the above illustration of the circuit.\nOn the Breadboard, connect the RGB LED to the right ground bus column, and make sure that each leg connects to a different row. The longest leg is the common anode leg. In this example we have connected the LED to rows 1-4, with the common cathode leg connected to row 2 column I. The RED leg is connected to row 1 column J, the GREEN leg is connected to row 3 column J, and the BLUE leg is connected to row 4 column J\nOn the Raspberry Pi, connect the female leg of the first jumper cable to a GPIO pin. We will use this for the RED leg, In this example we used Physical Pin 7 (GPIO 4, row 4, left column)\nOn the Breadboard, connect the male leg of the first jumper wire to the left ground bus, same row as the RED leg of the LED is connected. In this example we connected it to row 1, column A\nOn the Breadboard, connect a resistor between the left and right ground bus columns for the row with the RED leg of the LED. In this example we have attached it to row 1, column E and F\nOn the Raspberry Pi, connect the female leg of the second jumper cable to a GPIO pin. We will use this for the GREEN leg, In this example we used Physical Pin 11 (GPIO 17, row 6, left column)\nOn the Breadboard, connect the male leg of the second jumper wire to the left ground bus, same row as the GREEN leg of the LED is connected. In this example we connected it to row 3, column A\nOn the Breadboard, connect a resistor between the left and right ground bus columns for the row with the GREEN leg of the LED. In this example we have attached it to row 3, column E and F\nOn the Raspberry Pi, connect the female leg of the third jumper cable to a GPIO pin. We will use this for the BLUE leg, In this example we used Physical Pin 13 (GPIO 27, row 7, left column)\nOn the Breadboard, connect the male leg of the third jumper wire to the left ground bus, same row as the BLUE leg of the LED is connected. In this example we connected it to row 4, column A\nOn the Breadboard, connect a resistor between the left and right ground bus columns for the row with the BLUE leg of the LED. In this example we have attached it to row 4, column E and F\nOn the Raspberry Pi, connect the female leg of the forth jumper wire to 3.3V. In this example we used Physical Pin 1 (3.3V, row 1, left column)\nOn the Breadboard, connect the male leg of the forth jumper wire to the same row of the right ground bus column that you connected the common anode to. In this example we connected it to row 2 column F\nYour circuit should now be complete, and your connections should look pretty similar to the illustration above.\nNow it is time to boot up the Raspberry Pi, and write the Node.js script to interact with it.\nREMOVE ADS\nRaspberry Pi and Node.js RGB LED and WebSocket Script\nGo to the \"nodetest\" directory, and create a new file called \"rgbws.js\":\nThe file is now open and can be edited with the built in Nano Editor.\nWrite, or paste the following:\nrgbws.jsGet your own Node.js Server\nPress \"Ctrl+x\" to save the code. Confirm with \"y\", and confirm the name with \"Enter\".\nWrite, or paste the following:\nrgbws.js\nPress \"Ctrl+x\" to save the code. Confirm with \"y\", and confirm the name with \"Enter\".\nRaspberry Pi and Node.js WebSocket UI\nNow it is time add the HTML that allows for user input via WebSocket.\nFor this we want:\n3 color sliders, one for each color (RGB)\nA color picker\nA div showing the current color\nGo to the folder \"public\":\nAnd create a HTML file, rgb.html:\nrgb.html:\nReturn to the \"nodetest\" folder:\nRun the code:\nNote: Since the \"pigpio\" module uses the pigpio C library, it requires root/sudo privileges to access hardware peripherals (like the GPIO).\nOpen the website in a browser using http://[RaspberryPi_IP]:8080/\nNow the RGB LED should change color depending on the user input.\nEnd the program with Ctrl+c.",
      "examples": [
        "pi@w3demopi:~ $ sudo apt-get update",
        "pi@w3demopi:~ $ sudo apt-get install pigpio",
        "pi@w3demopi:~ $ npm install pigpio",
        "pi@w3demopi:~ $ sudo shutdown -h now",
        "pi@w3demopi:~ $ nano rgbws.js",
        "let http = require('http').createServer(handler); //require http server, and create server with function handler()\nlet fs = require('fs'); //require filesystem module\nlet io = require('socket.io')(http) //require socket.io module and pass the http object (server)\nlet Gpio = require('pigpio').Gpio, //include pigpio to interact with the GPIO\nledRed = new Gpio(4, {mode: Gpio.OUTPUT}), //use GPIO pin 4 as output for RED\nledGreen = new Gpio(17, {mode: Gpio.OUTPUT}), //use GPIO pin 17 as output for GREEN\nledBlue = new Gpio(27, {mode: Gpio.OUTPUT}), //use GPIO pin 27 as output for BLUE\nredRGB = 0, //set starting value of RED variable to off (0 for common cathode)\ngreenRGB = 0, //set starting value of GREEN variable to off (0 for common cathode)\nblueRGB = 0; //set starting value of BLUE variable to off (0 for common cathode)\n\n//RESET RGB LED\nledRed.digitalWrite(0); // Turn RED LED off\nledGreen.digitalWrite(0); // Turn GREEN LED off\nledBlue.digitalWrite(0); // Turn BLUE LED off\n\nhttp.listen(8080); //listen to port 8080\n\nfunction handler (req, res) { //what to do on requests to port 8080\nfs.readFile(__dirname + '/public/rgb.html', function(err, data) { //read file rgb.html in public folder\nif (err) {\nres.writeHead(404, {'Content-Type': 'text/html'}); //display 404 on error\nreturn res.end(\"404 Not Found\");\n}\nres.writeHead(200, {'Content-Type': 'text/html'}); //write HTML\nres.write(data); //write data from rgb.html\nreturn res.end();\n});\n}\n\nio.sockets.on('connection', function (socket) {// Web Socket Connection\nsocket.on('rgbLed', function(data) { //get light switch status from client\nconsole.log(data); //output data from WebSocket connection to console\n\n//for common cathode RGB LED 0 is fully off, and 255 is fully on\nredRGB=parseInt(data.red);\ngreenRGB=parseInt(data.green);\nblueRGB=parseInt(data.blue);\n\nledRed.pwmWrite(redRGB); //set RED LED to specified value\nledGreen.pwmWrite(greenRGB); //set GREEN LED to specified value\nledBlue.pwmWrite(blueRGB); //set BLUE LED to specified value\n});\n});\n\nprocess.on('SIGINT', function () { //on ctrl+c\nledRed.digitalWrite(0); // Turn RED LED off\nledGreen.digitalWrite(0); // Turn GREEN LED off\nledBlue.digitalWrite(0); // Turn BLUE LED off\nprocess.exit(); //exit completely\n});",
        "let http = require('http').createServer(handler); //require http server, and create server with function handler()\nlet fs = require('fs'); //require filesystem module\nlet io = require('socket.io')(http) //require socket.io module and pass the http object (server)\nlet Gpio = require('pigpio').Gpio, //include pigpio to interact with the GPIO\nledRed = new Gpio(4, {mode: Gpio.OUTPUT}), //use GPIO pin 4 as output for RED\nledGreen = new Gpio(17, {mode: Gpio.OUTPUT}), //use GPIO pin 17 as output for GREEN\nledBlue = new Gpio(27, {mode: Gpio.OUTPUT}), //use GPIO pin 27 as output for BLUE\nredRGB = 255, //set starting value of RED variable to off (255 for common anode)\ngreenRGB = 255, //set starting value of GREEN variable to off (255 for common anode)\nblueRGB = 255; //set starting value of BLUE variable to off (255 for common anode)\n\n//RESET RGB LED\nledRed.digitalWrite(1); // Turn RED LED off\nledGreen.digitalWrite(1); // Turn GREEN LED off\nledBlue.digitalWrite(1); // Turn BLUE LED off\n\nhttp.listen(8080); //listen to port 8080\n\nfunction handler (req, res) { //what to do on requests to port 8080\nfs.readFile(__dirname + '/public/rgb.html', function(err, data) { //read file rgb.html in public folder\nif (err) {\nres.writeHead(404, {'Content-Type': 'text/html'}); //display 404 on error\nreturn res.end(\"404 Not Found\");\n}\nres.writeHead(200, {'Content-Type': 'text/html'}); //write HTML\nres.write(data); //write data from rgb.html\nreturn res.end();\n});\n}\n\nio.sockets.on('connection', function (socket) {// Web Socket Connection\nsocket.on('rgbLed', function(data) { //get light switch status from client\nconsole.log(data); //output data from WebSocket connection to console\n\n//for common anode RGB LED  255 is fully off, and 0 is fully on, so we have to change the value from the client\nredRGB=255-parseInt(data.red);\ngreenRGB=255-parseInt(data.green);\nblueRGB=255-parseInt(data.blue);\n\nconsole.log(\"rbg: \" + redRGB + \", \" + greenRGB + \", \" + blueRGB); //output converted to console\n\nledRed.pwmWrite(redRGB); //set RED LED to specified value\nledGreen.pwmWrite(greenRGB); //set GREEN LED to specified value\nledBlue.pwmWrite(blueRGB); //set BLUE LED to specified value\n});\n});\n\nprocess.on('SIGINT', function () { //on ctrl+c\nledRed.digitalWrite(1); // Turn RED LED off\nledGreen.digitalWrite(1); // Turn GREEN LED off\nledBlue.digitalWrite(1); // Turn BLUE LED off\nprocess.exit(); //exit completely\n});",
        "pi@w3demopi:~/nodetest $ cd public",
        "pi@w3demopi:~/nodetest/public $ nano rgb.html",
        "<!DOCTYPE html>\n<html>\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://www.w3schools.com/w3css/4/w3.css\">\n<style>\n.slider {\n-webkit-appearance: none;\nwidth: 100%;\nheight: 15px;\nborder-radius: 5px;\nbackground: #d3d3d3;\noutline: none;\nopacity: 0.7;\n-webkit-transition: .2s;\ntransition: opacity .2s;\n}\n\n.slider:hover {opacity: 1;}\n\n.slider::-webkit-slider-thumb {\n-webkit-appearance: none;\nappearance: none;\nwidth: 25px;\nheight: 25px;\nborder-radius: 50%;\ncursor: pointer;\n}\n\n.slider::-moz-range-thumb {\nwidth: 25px;\nheight: 25px;\nborder-radius: 50%;\nbackground: #4CAF50;\ncursor: pointer;\n}\n#redSlider::-webkit-slider-thumb {background: red;}\n#redSlider::-moz-range-thumb {background: red;}\n#greenSlider::-webkit-slider-thumb {background: green;}\n#greenSlider::-moz-range-thumb {background: green;}\n#blueSlider::-webkit-slider-thumb {background: blue;}\n#blueSlider::-moz-range-thumb {background: blue;}\n</style>\n<body>\n\n<div class=\"w3-container\">\n<h1>RGB Color</h1>\n<div class=\"w3-cell-row\">\n<div class=\"w3-container w3-cell w3-mobile\">\n<p><input type=\"range\" min=\"0\" max=\"255\" value=\"0\" class=\"slider\" id=\"redSlider\"></p>\n<p><input type=\"range\" min=\"0\" max=\"255\" value=\"0\" class=\"slider\" id=\"greenSlider\"></p>\n<p><input type=\"range\" min=\"0\" max=\"255\" value=\"0\" class=\"slider\" id=\"blueSlider\"></p>\n</div>\n<div class=\"w3-container w3-cell w3-mobile\" style=\"background-color:black\" id=\"colorShow\">\n<div></div>\n</div>\n</div>\n<p>Or pick a color: <input type=\"color\" id=\"pickColor\"></p>\n</div>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.0.3/socket.io.js\"></script>\n<script src=\"https://www.w3schools.com/lib/w3color.js\"></script>\n<script>\nlet socket = io(); //load socket.io-client and connect to the host that serves the page\nlet rgb = w3color(\"rgb(0,0,0)\"); //we use the w3color.js library to keep the color as an object\nwindow.addEventListener(\"load\", function(){ //when page loads\nlet rSlider = document.getElementById(\"redSlider\");\nlet gSlider = document.getElementById(\"greenSlider\");\nlet bSlider = document.getElementById(\"blueSlider\");\nlet picker = document.getElementById(\"pickColor\");\n\nrSlider.addEventListener(\"change\", function() { //add event listener for when red slider changes\nrgb.red = this.value; //update the RED color according to the slider\ncolorShow.style.backgroundColor = rgb.toRgbString(); //update the \"Current color\"\nsocket.emit(\"rgbLed\", rgb); //send the updated color to RGB LED via WebSocket\n});\ngSlider.addEventListener(\"change\", function() { //add event listener for when green slider changes\nrgb.green = this.value; //update the GREEN color according to the slider\ncolorShow.style.backgroundColor = rgb.toRgbString(); //update the \"Current color\"\nsocket.emit(\"rgbLed\", rgb); //send the updated color to RGB LED via WebSocket\n});\nbSlider.addEventListener(\"change\", function() { //add event listener for when blue slider changes\nrgb.blue = this.value;  //update the BLUE color according to the slider\ncolorShow.style.backgroundColor = rgb.toRgbString(); //update the \"Current color\"\nsocket.emit(\"rgbLed\", rgb); //send the updated color to RGB LED via WebSocket\n});\npicker.addEventListener(\"input\", function() { //add event listener for when colorpicker changes\nrgb.red = w3color(this.value).red; //Update the RED color according to the picker\nrgb.green = w3color(this.value).green; //Update the GREEN color according to the picker\nrgb.blue = w3color(this.value).blue; //Update the BLUE color according to the picker\ncolorShow.style.backgroundColor = rgb.toRgbString();  //update the \"Current color\"\nrSlider.value = rgb.red;  //Update the RED slider position according to the picker\ngSlider.value = rgb.green;  //Update the GREEN slider position according to the picker\nbSlider.value = rgb.blue;  //Update the BLUE slider position according to the picker\nsocket.emit(\"rgbLed\", rgb);  //send the updated color to RGB LED via WebSocket\n});\n});\n</script>\n\n</body>\n</html>",
        "pi@w3demopi:~/nodetest $ cd ..",
        "pi@w3demopi:~ $ sudo node rgbws.js",
        "rgbws.js",
        "Ctrl+x",
        "y",
        "Enter",
        "Ctrl+c"
      ]
    },
    {
      "title": "Node.js Raspberry Pi - Components",
      "summary": "What are Components?\nComponents are parts of a larger whole. In this chapter, we explain the different components we use in our tutorial.\nThe Raspberry Pi and GPIO Pins\nThis is an illustration of the Raspberry Pi 3.\nThe GPIO pins are the small red squares in two rows on the right side of the Raspberry Pi, on the actual Raspberry Pi they are small metal pins.\nInput pins are like switches that you can turn on or off from the outside world (like a on/off light switch).\nOutput pins are like switches that the Raspberry Pi can turn on or off (like turning on/off a LED light).\nThe Raspberry Pi 3 has 26 GPIO pins, the rest of the pins are power, ground or \"other\".\nThe pin placements correspond with the table below.\nRaspberry Pi B+, 2, 3 & Zero\nLegend\nREMOVE ADS\nThe Breadboard\nA breadboard is used for prototyping electronics, it allows you to create circuits without soldering. It is basically a plastic board, with a grid of tie-points (holes). Inside the board there are metal strips connecting the different tie-points in specific ways.\nIn the illustration below we have highlighted some of the sections with different colors. This is to show you how the grid is connected.\nThe different sections of the breadboard:\nOn the left, and right, side there are 2 columns of tie-points. All the tie points in each of these columns are connected.\nThe Power Bus - The columns highlighted with red. There are usually used to connect power to the Breadboard. Since the entire column is connected, you can connect power to any of the tie-points in the column.\nThe Ground Bus - The columns highlighted with blue. There are usually used to connect Ground to the Breadboard. Since the entire column is connected, you can connect ground to any of the tie-points in the column.\nRows of connected Tie-Points - The rows highlighted with green. The tie-points of each of these rows are connected, but not the entire row! The left side tie-points are connected (A-B-C-D-E), and the right side tie-points are connected (F-G-H-I-J).\nIn the center of the Breadboard there is a Trench, this separates the left and right rows. The width of the trench is designed so that many Integrated Circuits fit across it.\nOther Electrical Components\nThrough Hole LED\nLight emitting diode (LED). An LED is a diode that emits light when a voltage is applied to it. In our example we use a Through Hole LED. They have a positive (called Anode), and a negative (called Cathode) pin. The longer leg on the LED should indicate the positive pin.\nRGB LED\nLight emitting diode (LED). An LED is a diode that emits light when a voltage is applied to it. An RGB LED has 4 pins. One for each color (R = Red, G = Green, and, B = Blue), and a common cathode/anode. This one LED can display the pure colors, or with PWD to modulate and mix colors.\nPush Button\nA push button is a type of switch. A switch makes or breaks a connection an an electric circuit.\nJumper Wire - Female to Male\nShort pieces of wire called jumper wires are used to make connections. Female to Male jumper wires can be used to connect from the GPIO on the Raspberry Pi to the Breadboard.\nJumper Wire - Male to Male\nShort pieces of wire called jumper wires are used to make connections. Male to Male jumper wires can be used to make connections between different parts of the Breadboard.\nResistor - 68 Ohm\nResistors are used to reduce current, adjust signal levels, etc. This is a 68 Ohm resistor.\nResistor - 220 Ohm\nResistors are used to reduce current, adjust signal levels, etc. This is a 220 Ohm resistor.\nResistor - 1k Ohm\nResistors are used to reduce current, adjust signal levels, etc. This is a 1k Ohm resistor.\nNode.js Modules\nonoff - GPIO access and interrupt detection with Node.js\ndocumentation\nSocket.IO - real-time bidirectional event-based communication\ndocumentation\npigpio - wrapper for pigpio C library. Enables GPIO, PWM, servo control, state change notification and interrupt handling with Node.js\ndocumentation",
      "examples": []
    },
    {
      "title": "Node.js Built-in Modules",
      "summary": "Node.js has a set of built-in modules which you can use without any further installation.\nHere is a list of the built-in modules of Node.js version 6.10.3:",
      "examples": []
    },
    {
      "title": "Node.js EventEmitter Reference",
      "summary": "EventEmitter Object\nThe EventEmitter is a module that facilitates communication between objects in Node.js. It's at the core of Node's asynchronous event-driven architecture.\nMany of Node's built-in modules inherit from EventEmitter, including HTTP servers, streams, and more.\nImport EventEmitter\nCreating an EventEmitter\nEventEmitter Methods\nEventEmitter Properties\nBasic EventEmitter Usage\nPassing Arguments to Listeners\nOne-time Event Listeners\nError Events\nGetting Event Names and Listeners\nRemoving Listeners\nSetting Maximum Listeners\nOrder of Listeners\nExtending EventEmitter\nA common pattern in Node.js is to create a class that extends EventEmitter, adding custom functionality:\nAsynchronous vs. Synchronous\nEventEmitter calls all listeners synchronously in the order they were registered. Important for maintaining the expected execution order:\nTo run listeners asynchronously, you can use setImmediate() or process.nextTick():\nPromise Integration\nEventEmitter in modern Node.js versions can handle Promises and capture rejections:\nReal-World Example: HTTP Server\nEventEmitter powers many Node.js core modules. Here's how an HTTP server uses events:\nCommon Patterns and Best Practices\n1. Always Listen for 'error' Events\nIf an EventEmitter emits an 'error' event and there are no listeners, Node.js will throw the error and crash the process. Always add error handlers:\n2. Cleanup Listeners to Prevent Memory Leaks\n3. Use Named Functions for Removable Listeners",
      "examples": [
        "// Method 1: Using require\nconst EventEmitter = require('events');\n\n// Method 2: ES6 destructuring\nconst { EventEmitter } = require('events');",
        "const EventEmitter = require('events');\n\n// Create a new EventEmitter instance\nconst myEmitter = new EventEmitter();\n\n// Create a class that extends EventEmitter\nclass MyEmitter extends EventEmitter {\nconstructor() {\nsuper();\n}\n}\n\n// Instantiate the extended class\nconst myExtendedEmitter = new MyEmitter();",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Register an event listener\nmyEmitter.on('event', () => {\nconsole.log('An event occurred!');\n});\n\n// Emit the event\nmyEmitter.emit('event');",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Event with multiple arguments\nmyEmitter.on('status', (code, message) => {\nconsole.log(`Got status: ${code} ${message}`);\n});\n\n// Emit with arguments\nmyEmitter.emit('status', 200, 'OK');",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Add one-time listener\nmyEmitter.once('onetime', () => {\nconsole.log('This will be called only once');\n});\n\n// First emit - will trigger the listener\nmyEmitter.emit('onetime');\n\n// Second emit - won't trigger the listener\nmyEmitter.emit('onetime');",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Error event handler\nmyEmitter.on('error', (err) => {\nconsole.error('Error occurred:', err.message);\n});\n\n// Emit an error event\nmyEmitter.emit('error', new Error('Something went wrong'));\n\n// If no 'error' listener is added, Node will throw and crash\n// Always add an error handler!",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Add some listeners\nmyEmitter.on('event1', () => console.log('Event 1'));\nmyEmitter.on('event2', () => console.log('Event 2'));\nmyEmitter.on('event2', () => console.log('Event 2 again'));\n\n// Get all event names\nconsole.log('Event names:', myEmitter.eventNames());\n\n// Get listeners for a specific event\nconsole.log('Listeners for event2:', myEmitter.listeners('event2'));\n\n// Count listeners\nconsole.log('Listener count for event2:', myEmitter.listenerCount('event2'));",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Define listener function (needed for removal)\nfunction listener1() {\nconsole.log('Listener 1 executed');\n}\n\nfunction listener2() {\nconsole.log('Listener 2 executed');\n}\n\n\n// Add listeners\nmyEmitter.on('event', listener1);\nmyEmitter.on('event', listener2);\n\nconsole.log('Listeners before removal:', myEmitter.listenerCount('event'));\n\n// Remove a specific listener\nmyEmitter.removeListener('event', listener1);\n// or using the alias: myEmitter.off('event', listener1);\n\nconsole.log('Listeners after removal:', myEmitter.listenerCount('event'));\n\n// Remove all listeners for an event\nmyEmitter.removeAllListeners('event');\n\nconsole.log('Listeners after removeAll:', myEmitter.listenerCount('event'));",
        "const EventEmitter = require('events');\n\n// Set the default max listeners for all EventEmitter instances\nEventEmitter.defaultMaxListeners = 15;\n\nconst myEmitter = new EventEmitter();\n\n// Set max listeners for a specific instance\nmyEmitter.setMaxListeners(20);\n\nconsole.log('Default max listeners:', EventEmitter.defaultMaxListeners);\nconsole.log('myEmitter max listeners:', myEmitter.getMaxListeners());\n\n// Adding more than maxListeners will trigger a warning\n// The warning helps identify potential memory leaks",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Default behavior: listeners execute in order they were added\nmyEmitter.on('event', () => console.log('First listener'));\nmyEmitter.on('event', () => console.log('Second listener'));\n\n// Prepend a listener (it will execute first)\nmyEmitter.prependListener('event', () => console.log('Prepended listener'));\n\n// One-time prepended listener\nmyEmitter.prependOnceListener('event', () => console.log('Prepended once listener'));\n\n\n// Emit the event\nmyEmitter.emit('event');\n\n// Output will be:\n// Prepended once listener\n// Prepended listener\n// First listener\n// Second listener",
        "const EventEmitter = require('events');\n\n// Custom class that extends EventEmitter\nclass MyApp extends EventEmitter {\nconstructor() {\nsuper();\nthis.name = 'MyApp';\n}\n\nprocess(data) {\n// Do some processing\nconsole.log(`Processing data: ${data}`);\n\n// Emit events based on processing results\nif (data.length > 10) {\nthis.emit('large-data', data);\n} else {\nthis.emit('small-data', data);\n}\n\n// Emit completion event\nthis.emit('processed', data);\n}\n}\n\n// Create an instance\nconst app = new MyApp();\n\n// Register event listeners\napp.on('large-data', (data) => {\nconsole.log(`Large data detected: ${data.length} bytes`);\n});\n\napp.on('small-data', (data) => {\nconsole.log(`Small data detected: ${data.length} bytes`);\n});\n\napp.on('processed', (data) => {\nconsole.log('Processing completed');\n});\n\n// Use the app\napp.process('Hello');\napp.process('Hello, this is a longer string of data');",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Register listener\nmyEmitter.on('event', () => {\nconsole.log('Listener executed');\n});\n\n// Emit event\nconsole.log('Before emit');\nmyEmitter.emit('event');\nconsole.log('After emit');\n\n// Output:\n// Before emit\n// Listener executed\n// After emit",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Register async listener using setImmediate\nmyEmitter.on('async-event', () => {\nsetImmediate(() => {\nconsole.log('Async listener executed');\n});\n});\n\nconsole.log('Before emit');\nmyEmitter.emit('async-event');\nconsole.log('After emit');\n\n// Output:\n// Before emit\n// After emit\n// Async listener executed",
        "const EventEmitter = require('events');\n\n// Enable capture rejections (Node.js 12.16.0+)\nconst myEmitter = new EventEmitter({ captureRejections: true });\n\n// OR set it globally\n// EventEmitter.captureRejections = true;\n\n// Event handler that returns a Promise\nmyEmitter.on('async-operation', async () => {\n// This rejected promise will be captured and converted to an 'error' event\nthrow new Error('Async operation failed');\n});\n\n// Error handler\nmyEmitter.on('error', (err) => {\nconsole.error('Caught error:', err.message);\n});\n\n// Trigger the event\nmyEmitter.emit('async-operation');",
        "const http = require('http');\n\n// HTTP Server is an EventEmitter\nconst server = http.createServer();\n\n// Listen for 'request' events\nserver.on('request', (request, response) => {\nconsole.log(`Received ${request.method} request for ${request.url}`);\nresponse.writeHead(200, { 'Content-Type': 'text/plain' });\nresponse.end('Hello World\\n');\n});\n\n// Listen for 'connection' events\nserver.on('connection', (socket) => {\nconsole.log('New client connection from', socket.remoteAddress);\n});\n\n// Listen for 'close' event\nserver.on('close', () => {\nconsole.log('Server closed');\n});\n\n// Listen on port 8080\nserver.listen(8080, () => {\nconsole.log('Server listening on port 8080');\n});\n\n// Later, we can close the server\n// server.close();",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Always add error handlers\nmyEmitter.on('error', (err) => {\nconsole.error('Error occurred:', err);\n// Handle the error appropriately\n});",
        "const EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\nfunction setupHandler() {\nconst handler = () => console.log('Event handled');\n\n// Add the handler\nmyEmitter.on('some-event', handler);\n\n// Return a cleanup function\nreturn function cleanup() {\nmyEmitter.removeListener('some-event', handler);\n};\n}\n\n// Set up a handler\nconst cleanup = setupHandler();\n\n// Later, when no longer needed\ncleanup();",
        "// BAD - Cannot remove this listener later\nemitter.on('event', () => console.log('Anonymous function'));\n\n// GOOD - Can be removed by reference\nfunction namedHandler() {\nconsole.log('Named function');\n}\n\nemitter.on('event', namedHandler);\n\n// Later\nemitter.removeListener('event', namedHandler);",
        "on()",
        "emitter.setMaxListeners(n)",
        "EventEmitter.defaultMaxListeners",
        "removeListener()",
        "once()"
      ]
    },
    {
      "title": "Node.js Worker Reference",
      "summary": "Worker Object\nThe Worker class is part of the Node.js cluster module, which enables the creation of child processes (workers) that run simultaneously and share server ports. This is particularly useful for taking advantage of multi-core systems to handle load.\nImport Worker\nWorker objects are created automatically when using the cluster module:\nWorker Properties\nWorker Methods\nWorker Events\nBasic Cluster Example\nHere's a basic example of using cluster with Worker objects to create a multi-process HTTP server:\nWorker Communication\nYou can send messages between the primary process and worker processes:\nGraceful Shutdown\nHandling graceful shutdown of workers is important for production applications:\nWorker Zero-Downtime Restart\nImplementing a zero-downtime restart pattern for rolling worker updates:\nWorker Status Monitoring\nMonitoring worker status and collecting metrics:\nWorker Best Practices\n1. Ensure State Isolation\nKeep worker processes stateless or ensure proper state management:\n2. Handle Unexpected Worker Termination\n3. Use Worker Sticky Sessions",
      "examples": [
        "// Workers are created via the cluster module\nconst cluster = require('cluster');\n\n// To access a Worker object\nif (cluster.isPrimary) {\n// Fork workers\nconst worker = cluster.fork();\n\n// Now 'worker' is a Worker object\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;\n\nif (cluster.isPrimary) {\nconsole.log(`Primary ${process.pid} is running`);\n\n// Fork workers\nfor (let i = 0; i < numCPUs; i++) {\ncluster.fork();\n}\n\n// Listen for dying workers\ncluster.on('exit', (worker, code, signal) => {\nconsole.log(`Worker ${worker.process.pid} died with code: ${code} and signal: ${signal}`);\nconsole.log('Starting a new worker');\ncluster.fork();\n});\n\n// Event handlers for Worker objects\ncluster.on('fork', (worker) => {\nconsole.log(`Worker ${worker.id} (PID: ${worker.process.pid}) has been forked`);\n});\n\ncluster.on('online', (worker) => {\nconsole.log(`Worker ${worker.id} is online`);\n});\n\ncluster.on('listening', (worker, address) => {\nconsole.log(`Worker ${worker.id} is listening on ${address.address}:${address.port}`);\n});\n\ncluster.on('disconnect', (worker) => {\nconsole.log(`Worker ${worker.id} has disconnected`);\n});\n\n} else {\n// Workers can share any TCP connection\n// In this case it is an HTTP server\nhttp.createServer((req, res) => {\nres.writeHead(200);\nres.end(`Hello from Worker ${process.pid}\\n`);\n}).listen(8000);\n\nconsole.log(`Worker ${process.pid} started`);\n}",
        "const cluster = require('cluster');\nconst http = require('http');\n\nif (cluster.isPrimary) {\n// Keep track of http requests\nlet numRequests = 0;\n\n// Create two workers\nconst worker1 = cluster.fork();\nconst worker2 = cluster.fork();\n\n// Count requests\nfunction messageHandler(msg) {\nif (msg.cmd && msg.cmd === 'notifyRequest') {\nnumRequests += 1;\nconsole.log(`Total requests: ${numRequests}`);\n}\n}\n\n// Listen for messages from workers\nworker1.on('message', messageHandler);\nworker2.on('message', messageHandler);\n\n// Send periodic messages to workers\nsetInterval(() => {\n// Send a message to both workers\nworker1.send({ cmd: 'updateTime', time: Date.now() });\nworker2.send({ cmd: 'updateTime', time: Date.now() });\n}, 5000);\n\n} else {\n// Worker process\n\n// Track the last update time\nlet lastUpdate = Date.now();\n\n// Receive messages from the primary\nprocess.on('message', (msg) => {\nif (msg.cmd && msg.cmd === 'updateTime') {\nlastUpdate = msg.time;\nconsole.log(`Worker ${process.pid} received time update: ${new Date(lastUpdate)}`);\n}\n});\n\n// Create an HTTP server\nhttp.createServer((req, res) => {\n// Notify the primary about the request\nprocess.send({ cmd: 'notifyRequest' });\n\n// Respond to the request\nres.writeHead(200);\nres.end(`Hello from Worker ${process.pid}. Last update: ${new Date(lastUpdate)}\\n`);\n}).listen(8000);\n\nconsole.log(`Worker ${process.pid} started`);\n}",
        "const cluster = require('cluster');\nconst http = require('http');\n\nif (cluster.isPrimary) {\nconsole.log(`Primary ${process.pid} is running`);\n\n// Fork workers\nconst numCPUs = require('os').cpus().length;\nconst workers = [];\n\nfor (let i = 0; i < numCPUs; i++) {\nworkers.push(cluster.fork());\n}\n\n// Graceful shutdown function\nconst shutdown = () => {\nconsole.log('Primary: starting graceful shutdown...');\n\n// Disconnect all workers\nfor (const worker of workers) {\nconsole.log(`Disconnecting worker ${worker.id}`);\nworker.disconnect();\n}\n\n// Exit after a timeout if workers haven't exited\nsetTimeout(() => {\nconsole.log('Primary: some workers did not exit, forcing shutdown');\nprocess.exit(1);\n}, 5000);\n};\n\n// Listen for worker events\ncluster.on('exit', (worker, code, signal) => {\nconsole.log(`Worker ${worker.process.pid} died (${signal || code}). ` +\n`exitedAfterDisconnect: ${worker.exitedAfterDisconnect}`);\n\n// If it's a planned disconnect, don't restart\nif (!worker.exitedAfterDisconnect) {\nconsole.log('Worker died unexpectedly, replacing it...');\nworkers.push(cluster.fork());\n}\n\n// Check if all workers are gone\nlet activeWorkers = 0;\nfor (const id in cluster.workers) {\nactiveWorkers++;\n}\n\nconsole.log(`Active workers: ${activeWorkers}`);\n\nif (activeWorkers === 0) {\nconsole.log('All workers have exited, shutting down primary');\nprocess.exit(0);\n}\n});\n\n// Handle signals for graceful shutdown\nprocess.on('SIGTERM', shutdown);\nprocess.on('SIGINT', shutdown);\n\n} else {\n// Worker process\n\n// Create a server\nconst server = http.createServer((req, res) => {\nres.writeHead(200);\nres.end(`Hello from worker ${process.pid}\\n`);\n});\n\nserver.listen(8000);\n\nconsole.log(`Worker ${process.pid} started`);\n\n// Handle disconnect signal from primary\nprocess.on('disconnect', () => {\nconsole.log(`Worker ${process.pid} disconnected, closing server...`);\n\n// Close the server\nserver.close(() => {\nconsole.log(`Worker ${process.pid} closed server, exiting`);\nprocess.exit(0);\n});\n\n// Forcefully exit after timeout\nsetTimeout(() => {\nconsole.log(`Worker ${process.pid} timed out closing server, forcing exit`);\nprocess.exit(1);\n}, 2000);\n});\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;\n\nif (cluster.isPrimary) {\nconsole.log(`Primary ${process.pid} is running`);\n\n// Fork initial workers\nfor (let i = 0; i < numCPUs; i++) {\ncluster.fork();\n}\n\n// Store worker refs\nlet workers = Object.values(cluster.workers);\n\n// Restart one worker at a time\nfunction restartWorker(workerIndex) {\nconst worker = workers[workerIndex];\nconsole.log(`Restarting worker #${worker.id}`);\n\n// Create a new worker\nconst newWorker = cluster.fork();\n\n// Add the new worker to our array\nworkers.push(newWorker);\n\n// When the new worker is online, disconnect the old worker\nnewWorker.on('online', () => {\nif (worker) {\nconsole.log(`New worker #${newWorker.id} is online, disconnecting old worker #${worker.id}`);\nworker.disconnect();\n}\n});\n\n// When the old worker is disconnected, remove it from the array\nworker.on('disconnect', () => {\nconsole.log(`Worker #${worker.id} disconnected`);\nworkers = workers.filter(w => w.id !== worker.id);\n});\n\n// Continue the process if there are more workers to restart\nif (workerIndex + 1 < workers.length) {\nsetTimeout(() => {\nrestartWorker(workerIndex + 1);\n}, 5000);\n}\n}\n\n// Example: trigger a rolling restart after 15 seconds\nsetTimeout(() => {\nconsole.log('Starting rolling restart of workers...');\nrestartWorker(0);\n}, 15000);\n\n// Additional event handlers\ncluster.on('exit', (worker, code, signal) => {\nconsole.log(`Worker ${worker.process.pid} exited with code ${code}`);\n});\n\n} else {\n// Worker process\nhttp.createServer((req, res) => {\nres.writeHead(200);\nres.end(`Hello from worker ${process.pid}, started at ${new Date().toISOString()}\\n`);\n}).listen(8000);\n\nconsole.log(`Worker ${process.pid} started`);\n}",
        "const cluster = require('cluster');\nconst http = require('http');\nconst os = require('os');\n\nif (cluster.isPrimary) {\nconsole.log(`Primary ${process.pid} is running`);\n\n// Fork workers\nconst workers = [];\nfor (let i = 0; i < os.cpus().length; i++) {\nworkers.push(cluster.fork());\n}\n\n// Store metrics for each worker\nconst workerMetrics = {};\n\n// Set up metrics collection\nfor (const worker of workers) {\nworkerMetrics[worker.id] = {\nid: worker.id,\npid: worker.process.pid,\nrequests: 0,\nerrors: 0,\nlastActive: Date.now(),\nmemoryUsage: {}\n};\n\n// Handle messages from workers\nworker.on('message', (msg) => {\nif (msg.type === 'metrics') {\n// Update metrics\nworkerMetrics[worker.id] = {\n...workerMetrics[worker.id],\n...msg.data,\nlastActive: Date.now()\n};\n}\n});\n}\n\n// Create an HTTP server for monitoring\nhttp.createServer((req, res) => {\nif (req.url === '/metrics') {\nres.writeHead(200, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify({\nworkers: Object.values(workerMetrics),\nsystem: {\nloadAvg: os.loadavg(),\ntotalMem: os.totalmem(),\nfreeMem: os.freemem(),\nuptime: os.uptime()\n}\n}, null, 2));\n} else {\nres.writeHead(404);\nres.end('Not found');\n}\n}).listen(8001);\n\nconsole.log('Primary: Monitoring server running on port 8001');\n\n// Check for unresponsive workers\nsetInterval(() => {\nconst now = Date.now();\n\nfor (const worker of workers) {\nconst metrics = workerMetrics[worker.id];\n\n// If worker hasn't reported in 30 seconds\nif (now - metrics.lastActive > 80800) {\nconsole.warn(`Worker ${worker.id} appears unresponsive, restarting...`);\n\n// Kill the unresponsive worker\nworker.kill();\n\n// Fork a replacement\nconst newWorker = cluster.fork();\n\n// Set up metrics for new worker\nworkerMetrics[newWorker.id] = {\nid: newWorker.id,\npid: newWorker.process.pid,\nrequests: 0,\nerrors: 0,\nlastActive: Date.now(),\nmemoryUsage: {}\n};\n\n// Replace in workers array\nconst index = workers.indexOf(worker);\nif (index !== -1) {\nworkers[index] = newWorker;\n}\n\n// Clean up old metrics\ndelete workerMetrics[worker.id];\n}\n}\n}, 10000);\n\n} else {\n// Worker process\nconsole.log(`Worker ${process.pid} started`);\n\n// Track metrics\nlet requestCount = 0;\nlet errorCount = 0;\n\n// Report metrics to primary every 5 seconds\nsetInterval(() => {\nprocess.send({\ntype: 'metrics',\ndata: {\nrequests: requestCount,\nerrors: errorCount,\nmemoryUsage: process.memoryUsage()\n}\n});\n}, 5000);\n\n// Create HTTP server\nhttp.createServer((req, res) => {\nrequestCount++;\n\ntry {\nres.writeHead(200);\nres.end(`Hello from worker ${process.pid}\\n`);\n} catch (error) {\nerrorCount++;\nconsole.error(`Worker ${process.pid} error:`, error);\n}\n}).listen(8000);\n}",
        "// BAD - State shared across forked processes won't work as expected\nlet requestCount = 0;\n\n// GOOD - Each worker has its own isolated state\nif (cluster.isPrimary) {\n// Primary logic\n} else {\n// Worker-specific state\nlet workerRequestCount = 0;\n}",
        "if (cluster.isPrimary) {\ncluster.on('exit', (worker, code, signal) => {\nif (code !== 0 && !worker.exitedAfterDisconnect) {\nconsole.log(`Worker ${worker.id} crashed. Restarting...`);\ncluster.fork();\n}\n});\n}",
        "const cluster = require('cluster');\nconst http = require('http');\n\nif (cluster.isPrimary) {\n// Setup sticky session logic\ncluster.schedulingPolicy = cluster.SCHED_NONE;\n\n// Start workers\nconst numCPUs = require('os').cpus().length;\nfor (let i = 0; i < numCPUs; i++) {\ncluster.fork();\n}\n\n// Create routes based on connection's remote IP\ncluster.on('connection', (connection, address) => {\n// Calculate which worker gets connection based on IP\nconst worker = Object.values(cluster.workers)[\nNumber(address.toString().split(':')[3]) % Object.keys(cluster.workers).length\n];\nworker.send('sticky-session:connection', connection);\n});\n} else {\n// Worker code\nhttp.createServer((req, res) => {\nres.end(`Handled by worker ${process.pid}`);\n}).listen(8000, () => {\nconsole.log(`Worker ${process.pid} listening`);\n});\n\n// Receive sticky connections\nprocess.on('message', (message, connection) => {\nif (message !== 'sticky-session:connection') return;\n\n// Emulate a connection event on the server\nserver.emit('connection', connection);\nconnection.resume();\n});\n}",
        "cluster",
        "child_process.fork()",
        "true",
        ".kill()",
        ".disconnect()",
        "undefined",
        "false",
        "worker.process.kill()",
        "signal",
        "child_process.send()",
        "worker.disconnect()",
        "(code, signal)",
        "code",
        "(address)",
        "(message, handle)",
        "message",
        "handle"
      ]
    },
    {
      "title": "Node.js Cipher Reference",
      "summary": "Cipher Object\nThe Cipher class is part of Node.js's crypto module. It provides a way to encrypt data using various algorithms. Cipher instances are created using the crypto.createCipheriv() method.\nNote: The crypto.createCipher() method is deprecated since Node.js v10.0.0 due to security concerns. Always use crypto.createCipheriv() instead, which requires an explicit initialization vector (IV).\nImport Crypto Module\nCipher Methods\nBasic Encryption Example\nThe following example demonstrates how to encrypt data using the AES-256-CBC algorithm:\nEncrypting with Different Algorithms\nNode.js supports numerous encryption algorithms. Here's how to use different ones:\nEncrypting Binary Data\nYou can encrypt binary data as well as text:\nUsing AEAD Encryption\nAuthenticated Encryption with Associated Data (AEAD) provides both confidentiality and data integrity:\nManual Padding Control\nYou can control the padding behavior manually:\nComplete Encryption/Decryption Example\nHere's a complete example showing both encryption and decryption:\nEncryption with a Password\nFor many applications, you might want to derive an encryption key from a password:\nSupported Encryption Algorithms\nNode.js supports many encryption algorithms. You can get a list of all supported algorithms with:\nCommon algorithms include:\nSecurity Best Practices\nUse createCipheriv() instead of the deprecated createCipher(): This ensures you're explicitly providing the IV.\nGenerate secure random keys and IVs: Always use crypto.randomBytes() to generate these values.\nNever reuse IVs with the same key: This can severely weaken the encryption.\nPrefer authenticated encryption (AEAD): Algorithms like AES-GCM or ChaCha20-Poly1305 provide both confidentiality and integrity.\nSecurely store keys: Never hardcode keys in your application code.\nUse key derivation functions: When deriving keys from passwords, use PBKDF2, Scrypt, or Argon2 with appropriate parameters.\nKeep your Node.js version updated: Cryptographic vulnerabilities are fixed in security updates.",
      "examples": [
        "// Import the crypto module\nconst crypto = require('crypto');\n\n// Create a cipher with createCipheriv\nconst algorithm = 'aes-256-cbc';\nconst key = crypto.randomBytes(32); // 32 bytes for AES-256\nconst iv = crypto.randomBytes(16); // 16 bytes for AES\nconst cipher = crypto.createCipheriv(algorithm, key, iv);",
        "const crypto = require('crypto');\n\n// Generate encryption key and initialization vector\n// In a real application, you would securely store and retrieve these values\nconst key = crypto.randomBytes(32); // Key for AES-256 (32 bytes)\nconst iv = crypto.randomBytes(16); // IV for AES (16 bytes)\n\n// Create a cipher\nconst algorithm = 'aes-256-cbc';\nconst cipher = crypto.createCipheriv(algorithm, key, iv);\n\n// Data to encrypt\nconst plainText = 'This is a secret message';\n\n// Encrypt the data\nlet encrypted = cipher.update(plainText, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\nconsole.log('Original Text:', plainText);\nconsole.log('Encrypted Text:', encrypted);\nconsole.log('Key (hex):', key.toString('hex'));\nconsole.log('IV (hex):', iv.toString('hex'));\n\n// The encrypted message, key, and IV would be needed for decryption",
        "const crypto = require('crypto');\n\n// The data to encrypt\nconst plainText = 'Hello, this is a test message';\n\n// Function to encrypt data with different algorithms\nfunction encryptWithAlgorithm(algorithm, keySize, ivSize, plainText) {\n// Generate key and IV\nconst key = crypto.randomBytes(keySize);\nconst iv = crypto.randomBytes(ivSize);\n\n// Create cipher\nconst cipher = crypto.createCipheriv(algorithm, key, iv);\n\n// Encrypt data\nlet encrypted = cipher.update(plainText, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\nreturn {\nalgorithm,\nencrypted,\nkey: key.toString('hex'),\niv: iv.toString('hex')\n};\n}\n\n// Test different algorithms\nconst algorithms = [\n{ name: 'aes-128-cbc', keySize: 16, ivSize: 16 },\n{ name: 'aes-192-cbc', keySize: 24, ivSize: 16 },\n{ name: 'aes-256-cbc', keySize: 32, ivSize: 16 },\n{ name: 'aes-256-gcm', keySize: 32, ivSize: 16 }\n];\n\nalgorithms.forEach(algo => {\ntry {\nconst result = encryptWithAlgorithm(algo.name, algo.keySize, algo.ivSize, plainText);\nconsole.log(`Encrypted with ${result.algorithm}: ${result.encrypted}`);\n} catch (error) {\nconsole.error(`Error with ${algo.name}: ${error.message}`);\n}\n});",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Generate key and IV\nconst key = crypto.randomBytes(32);\nconst iv = crypto.randomBytes(16);\n\n// Create read and write streams\nconst readStream = fs.createReadStream('input.jpg');\nconst writeStream = fs.createWriteStream('encrypted.jpg.enc');\n\n// Create cipher stream\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\n\n// Encrypt the file\nreadStream\n.pipe(cipher)\n.pipe(writeStream);\n\n// Save the key and IV for decryption\nfs.writeFileSync('encryption_key.txt', key.toString('hex'));\nfs.writeFileSync('encryption_iv.txt', iv.toString('hex'));\n\nwriteStream.on('finish', () => {\nconsole.log('File encryption completed');\n});",
        "const crypto = require('crypto');\n\n// Data to encrypt\nconst plainText = 'Secret message';\nconst associatedData = 'Additional data to authenticate';\n\n// Generate key and IV (nonce)\nconst key = crypto.randomBytes(32);\nconst iv = crypto.randomBytes(12); // 12 bytes (96 bits) is recommended for GCM\n\n// Create cipher using AES-GCM (an AEAD algorithm)\nconst cipher = crypto.createCipheriv('aes-256-gcm', key, iv);\n\n// Set the Additional Authenticated Data (AAD)\ncipher.setAAD(Buffer.from(associatedData));\n\n// Encrypt the data\nlet encrypted = cipher.update(plainText, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\n// Get the authentication tag\nconst authTag = cipher.getAuthTag();\n\nconsole.log('Encrypted Text:', encrypted);\nconsole.log('Auth Tag (hex):', authTag.toString('hex'));\nconsole.log('Key (hex):', key.toString('hex'));\nconsole.log('IV (hex):', iv.toString('hex'));\nconsole.log('Associated Data:', associatedData);\n\n// All this information is needed for decryption and verification",
        "const crypto = require('crypto');\n\n// Generate key and IV\nconst key = crypto.randomBytes(32);\nconst iv = crypto.randomBytes(16);\n\n// Data to encrypt\nconst plainText = 'This is a test message';\n\n// Function to encrypt with different padding options\nfunction encryptWithPadding(usePadding) {\n// Create cipher\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\n\n// Set padding option\ncipher.setAutoPadding(usePadding);\n\ntry {\n// Encrypt data\nlet encrypted = cipher.update(plainText, 'utf8', 'hex');\nencrypted += cipher.final('hex');\nreturn encrypted;\n} catch (error) {\nreturn `Error: ${error.message}`;\n}\n}\n\n// With default padding (true)\nconsole.log('With padding:', encryptWithPadding(true));\n\n// Without padding\n// This will likely fail unless data length is a multiple of the block size\nconsole.log('Without padding:', encryptWithPadding(false));\n\n// Example with manual padding to block size (16 bytes for AES)\nfunction manualPadding(text) {\nconst blockSize = 16;\nconst padLength = blockSize - (text.length % blockSize);\nreturn text + '\\0'.repeat(padLength);\n}\n\n// Create cipher without auto padding\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\ncipher.setAutoPadding(false);\n\n// Manually pad the data\nconst paddedText = manualPadding(plainText);\nconsole.log('Original length:', plainText.length);\nconsole.log('Padded length:', paddedText.length);\n\n// Encrypt manually padded data\nlet encrypted = cipher.update(paddedText, 'utf8', 'hex');\nencrypted += cipher.final('hex');\nconsole.log('With manual padding:', encrypted);",
        "const crypto = require('crypto');\n\n// The message to encrypt\nconst message = 'This is a secret message that needs to be encrypted';\n\n// Generate encryption key and IV\nconst key = crypto.randomBytes(32);\nconst iv = crypto.randomBytes(16);\n\n// Encryption function\nfunction encrypt(text) {\n// Create cipher\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\n\n// Encrypt data\nlet encrypted = cipher.update(text, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\nreturn encrypted;\n}\n\n// Decryption function (using the Decipher class)\nfunction decrypt(encryptedText) {\n// Create decipher with the same key and IV\nconst decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);\n\n// Decrypt data\nlet decrypted = decipher.update(encryptedText, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nreturn decrypted;\n}\n\n// Encrypt the message\nconst encryptedMessage = encrypt(message);\nconsole.log('Original Message:', message);\nconsole.log('Encrypted Message:', encryptedMessage);\n\n// Decrypt the message\nconst decryptedMessage = decrypt(encryptedMessage);\nconsole.log('Decrypted Message:', decryptedMessage);\n\n// Verify the result\nconsole.log('Decryption successful:', message === decryptedMessage);",
        "const crypto = require('crypto');\n\n// Password and salt\nconst password = 'mysecretpassword';\nconst salt = crypto.randomBytes(16);\n\n// Generate a key from the password\nfunction getKeyFromPassword(password, salt) {\n// Use PBKDF2 to derive a key from the password\nreturn crypto.pbkdf2Sync(password, salt, 100000, 32, 'sha256');\n}\n\n// Password-based encryption\nfunction encryptWithPassword(text, password) {\n// Generate key from password\nconst key = getKeyFromPassword(password, salt);\n\n// Generate IV\nconst iv = crypto.randomBytes(16);\n\n// Create cipher\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\n\n// Encrypt data\nlet encrypted = cipher.update(text, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\n// Return encrypted data and IV (we'll need both for decryption)\nreturn {\niv: iv.toString('hex'),\nsalt: salt.toString('hex'),\nencryptedData: encrypted\n};\n}\n\n// Password-based decryption\nfunction decryptWithPassword(encryptedInfo, password) {\n// Get the key from the password\nconst key = getKeyFromPassword(\npassword,\nBuffer.from(encryptedInfo.salt, 'hex')\n);\n\n// Get the IV from encryptedInfo\nconst iv = Buffer.from(encryptedInfo.iv, 'hex');\n\n// Create decipher\nconst decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);\n\n// Decrypt data\nlet decrypted = decipher.update(encryptedInfo.encryptedData, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nreturn decrypted;\n}\n\n// Test encryption with password\nconst message = 'Secret message protected by a password';\nconst encryptedInfo = encryptWithPassword(message, password);\n\nconsole.log('Encrypted:', encryptedInfo);\n\n// Test decryption with password\nconst decryptedMessage = decryptWithPassword(encryptedInfo, password);\nconsole.log('Decrypted:', decryptedMessage);\n\n// Try with wrong password\ntry {\nconst wrongPassword = 'wrongpassword';\nconst failedDecryption = decryptWithPassword(encryptedInfo, wrongPassword);\nconsole.log('Decrypted with wrong password:', failedDecryption);\n} catch (error) {\nconsole.log('Decryption failed with wrong password:', error.message);\n}",
        "const crypto = require('crypto');\n\n// Get all supported cipher algorithms\nconsole.log(crypto.getCiphers());",
        "crypto",
        "crypto.createCipheriv()",
        "crypto.createCipher()",
        "data",
        "inputEncoding",
        "outputEncoding",
        "autoPadding",
        "createCipheriv()",
        "createCipher()",
        "crypto.randomBytes()"
      ]
    },
    {
      "title": "Node.js Decipher Reference",
      "summary": "Decipher Object\nThe Decipher class is part of Node.js's crypto module. It provides a way to decrypt data that was encrypted using the Cipher class. Decipher instances are created using the crypto.createDecipheriv() method.\nNote: The crypto.createDecipher() method is deprecated since Node.js v10.0.0 due to security concerns. Always use crypto.createDecipheriv() instead, which requires an explicit initialization vector (IV).\nImport Crypto Module\nDecipher Methods\nBasic Decryption Example\nThe following example demonstrates how to decrypt data that was encrypted with AES-256-CBC:\nComplete Encryption/Decryption Example\nHere's a complete example showing both encryption and decryption:\nDecrypting Binary Data\nYou can decrypt binary data such as encrypted files:\nUsing AEAD Decryption\nAuthenticated Encryption with Associated Data (AEAD) provides both confidentiality and data integrity. Here's how to decrypt data that was encrypted with an AEAD algorithm:\nAEAD Complete Example\nHere's a complete example of AEAD encryption and decryption:\nManual Padding Control\nYou can control the padding behavior for decryption manually:\nPassword-Based Decryption\nDecrypt data that was encrypted using a password-derived key:\nComplete Password-Based Example\nHere's a complete example of password-based encryption and decryption:\nHandling Errors\nDecryption can fail for various reasons. It's important to handle these errors properly:\nSecurity Best Practices\nUse createDecipheriv() instead of the deprecated createDecipher(): This ensures you're explicitly providing the IV.\nSecure key and IV storage: Store encryption keys securely, consider using a key management service.\nVerify decryption: When possible, include a way to verify that decryption was successful (e.g., using authenticated encryption).\nProtect against chosen-ciphertext attacks: Use authenticated encryption (AEAD) to prevent tampering with encrypted data.\nHandle errors securely: Avoid leaking information about the decryption process in error messages.\nUse constant-time comparison: When verifying authentication tags or other sensitive values, use constant-time comparisons to prevent timing attacks.",
      "examples": [
        "// Import the crypto module\nconst crypto = require('crypto');\n\n// Create a decipher with createDecipheriv\nconst algorithm = 'aes-256-cbc';\nconst key = Buffer.from('your-encryption-key-in-hex', 'hex'); // 32 bytes for AES-256\nconst iv = Buffer.from('your-iv-in-hex', 'hex'); // 16 bytes for AES\nconst decipher = crypto.createDecipheriv(algorithm, key, iv);",
        "const crypto = require('crypto');\n\n// Encryption key and initialization vector\n// In a real application, these would be securely stored and retrieved\nconst key = Buffer.from('1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef', 'hex');\nconst iv = Buffer.from('1234567890abcdef1234567890abcdef', 'hex');\n\n// Encrypted text (from a previous encryption)\nconst encryptedText = '7a9c2c7157819144ede3cb9532263cb97c94a7b45d95163bb79aa1af55d4101d';\n\n// Create a decipher\nconst algorithm = 'aes-256-cbc';\nconst decipher = crypto.createDecipheriv(algorithm, key, iv);\n\n// Decrypt the data\nlet decrypted = decipher.update(encryptedText, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nconsole.log('Encrypted Text:', encryptedText);\nconsole.log('Decrypted Text:', decrypted);",
        "const crypto = require('crypto');\n\n// The message to encrypt\nconst message = 'This is a secret message that needs to be encrypted';\n\n// Generate encryption key and IV\nconst key = crypto.randomBytes(32);\nconst iv = crypto.randomBytes(16);\n\n// Encryption function using Cipher\nfunction encrypt(text) {\n// Create cipher\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\n\n// Encrypt data\nlet encrypted = cipher.update(text, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\nreturn encrypted;\n}\n\n// Decryption function using Decipher\nfunction decrypt(encryptedText) {\n// Create decipher with the same key and IV\nconst decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);\n\n// Decrypt data\nlet decrypted = decipher.update(encryptedText, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nreturn decrypted;\n}\n\n// Encrypt the message\nconst encryptedMessage = encrypt(message);\nconsole.log('Original Message:', message);\nconsole.log('Encrypted Message:', encryptedMessage);\n\n// Decrypt the message\nconst decryptedMessage = decrypt(encryptedMessage);\nconsole.log('Decrypted Message:', decryptedMessage);\n\n// Verify the result\nconsole.log('Decryption successful:', message === decryptedMessage);",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Read the encryption key and IV (saved during encryption)\nconst key = Buffer.from(fs.readFileSync('encryption_key.txt', 'utf8'), 'hex');\nconst iv = Buffer.from(fs.readFileSync('encryption_iv.txt', 'utf8'), 'hex');\n\n// Create read and write streams\nconst readStream = fs.createReadStream('encrypted.jpg.enc');\nconst writeStream = fs.createWriteStream('decrypted.jpg');\n\n// Create decipher stream\nconst decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);\n\n// Decrypt the file\nreadStream\n.pipe(decipher)\n.pipe(writeStream);\n\nwriteStream.on('finish', () => {\nconsole.log('File decryption completed');\n});",
        "const crypto = require('crypto');\n\n// Encryption values (would be stored and retrieved securely in a real application)\nconst key = Buffer.from('1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef', 'hex');\nconst iv = Buffer.from('123456789012123456789012', 'hex'); // 12 bytes for GCM\nconst encryptedData = 'af56c283ae95963c1e1877adb558d860';\nconst authTag = Buffer.from('1234567890abcdef1234567890abcdef', 'hex');\nconst associatedData = 'Additional data that was authenticated';\n\n// Create decipher using AES-GCM\nconst decipher = crypto.createDecipheriv('aes-256-gcm', key, iv);\n\n// Set the Additional Authenticated Data (AAD)\ndecipher.setAAD(Buffer.from(associatedData));\n\n// Set the authentication tag\ndecipher.setAuthTag(authTag);\n\ntry {\n// Decrypt the data\nlet decrypted = decipher.update(encryptedData, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nconsole.log('Decrypted Text:', decrypted);\nconsole.log('Authentication verified successfully');\n} catch (error) {\nconsole.error('Authentication failed:', error.message);\n// If authentication fails, the decryption will throw an error\n}",
        "const crypto = require('crypto');\n\n// Data to encrypt\nconst plainText = 'Secret message';\nconst associatedData = 'Additional data to authenticate';\n\n// Generate key and IV (nonce)\nconst key = crypto.randomBytes(32);\nconst iv = crypto.randomBytes(12); // 12 bytes (96 bits) is recommended for GCM\n\n// === ENCRYPTION ===\n// Create cipher using AES-GCM\nconst cipher = crypto.createCipheriv('aes-256-gcm', key, iv);\n\n// Set the Additional Authenticated Data (AAD)\ncipher.setAAD(Buffer.from(associatedData));\n\n// Encrypt the data\nlet encrypted = cipher.update(plainText, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\n// Get the authentication tag\nconst authTag = cipher.getAuthTag();\n\nconsole.log('Encrypted Text:', encrypted);\nconsole.log('Auth Tag (hex):', authTag.toString('hex'));\nconsole.log('Associated Data:', associatedData);\n\n// === DECRYPTION ===\n// Create decipher\nconst decipher = crypto.createDecipheriv('aes-256-gcm', key, iv);\n\n// Set the same AAD\ndecipher.setAAD(Buffer.from(associatedData));\n\n// Set the authentication tag\ndecipher.setAuthTag(authTag);\n\ntry {\n// Decrypt\nlet decrypted = decipher.update(encrypted, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nconsole.log('Decrypted Text:', decrypted);\nconsole.log('Decryption successful:', plainText === decrypted);\n} catch (error) {\nconsole.error('Decryption failed:', error.message);\n}\n\n// === DECRYPTION WITH WRONG AUTH TAG (will fail) ===\ntry {\nconst wrongDecipher = crypto.createDecipheriv('aes-256-gcm', key, iv);\nwrongDecipher.setAAD(Buffer.from(associatedData));\n\n// Set a wrong authentication tag\nconst wrongAuthTag = crypto.randomBytes(16);\nwrongDecipher.setAuthTag(wrongAuthTag);\n\n// Try to decrypt\nlet wrongDecrypted = wrongDecipher.update(encrypted, 'hex', 'utf8');\nwrongDecrypted += wrongDecipher.final('utf8'); // This will throw\n\nconsole.log('Should not reach here');\n} catch (error) {\nconsole.error('Decryption with wrong auth tag failed (expected):', error.message);\n}",
        "const crypto = require('crypto');\n\n// Generate key and IV\nconst key = crypto.randomBytes(32);\nconst iv = crypto.randomBytes(16);\n\n// Data to encrypt\nconst plainText = 'This is a test message';\n\n// First encrypt with disabled auto padding\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\ncipher.setAutoPadding(false);\n\n// Manually pad to block size (16 bytes for AES)\nfunction padToBlockSize(text, blockSize = 16) {\nconst padLength = blockSize - (text.length % blockSize);\nreturn text + '\\0'.repeat(padLength);\n}\n\n// Encrypt manually padded data\nconst paddedText = padToBlockSize(plainText);\nlet encrypted = cipher.update(paddedText, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\n// Now decrypt with auto padding disabled\nfunction decryptWithPadding(encryptedText, usePadding) {\nconst decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);\ndecipher.setAutoPadding(usePadding);\n\ntry {\nlet decrypted = decipher.update(encryptedText, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\nreturn decrypted;\n} catch (error) {\nreturn `Error: ${error.message}`;\n}\n}\n\n// With auto padding (default)\nconsole.log('With auto padding:', decryptWithPadding(encrypted, true));\n\n// Without auto padding (will include padding bytes)\nconst manualDecrypted = decryptWithPadding(encrypted, false);\nconsole.log('Without auto padding:', manualDecrypted);\n\n// Manually remove padding (trim null bytes)\nfunction removeNullPadding(paddedText) {\nreturn paddedText.replace(/\\0+$/, '');\n}\n\nconsole.log('With manual padding removal:', removeNullPadding(manualDecrypted));",
        "const crypto = require('crypto');\n\n// Password and salt (from the encryption process)\nconst password = 'mysecretpassword';\nconst salt = Buffer.from('0123456789abcdef0123456789abcdef', 'hex');\n\n// Encrypted data and IV from the encryption process\nconst encryptedData = '7a9c2c7157819144ede3cb9532263cb97c94a7b45d95163bb79aa1af55d4101d';\nconst iv = Buffer.from('0123456789abcdef0123456789abcdef', 'hex');\n\n// Generate a key from the password\nfunction getKeyFromPassword(password, salt) {\n// Use PBKDF2 to derive a key from the password\nreturn crypto.pbkdf2Sync(password, salt, 100000, 32, 'sha256');\n}\n\n// Decrypt data\nfunction decryptWithPassword(encryptedText, password, salt, iv) {\n// Generate key from password\nconst key = getKeyFromPassword(password, salt);\n\n// Create decipher\nconst decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);\n\n// Decrypt data\nlet decrypted = decipher.update(encryptedText, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nreturn decrypted;\n}\n\ntry {\n// Decrypt the data\nconst decryptedText = decryptWithPassword(encryptedData, password, salt, iv);\nconsole.log('Decrypted:', decryptedText);\n} catch (error) {\nconsole.error('Decryption failed:', error.message);\n}\n\n// Try with wrong password\ntry {\nconst wrongPassword = 'wrongpassword';\nconst decryptedWithWrongPass = decryptWithPassword(encryptedData, wrongPassword, salt, iv);\nconsole.log('Decrypted with wrong password:', decryptedWithWrongPass);\n} catch (error) {\nconsole.log('Decryption with wrong password failed (expected):', error.message);\n}",
        "const crypto = require('crypto');\n\n// Password and message\nconst password = 'mysecretpassword';\nconst message = 'This is a secret message protected by a password';\n\n// Password-based encryption\nfunction encryptWithPassword(text, password) {\n// Generate a random salt\nconst salt = crypto.randomBytes(16);\n\n// Derive a key from the password\nconst key = crypto.pbkdf2Sync(password, salt, 100000, 32, 'sha256');\n\n// Generate random IV\nconst iv = crypto.randomBytes(16);\n\n// Create cipher\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\n\n// Encrypt data\nlet encrypted = cipher.update(text, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\n// Return all values needed for decryption\nreturn {\nsalt: salt.toString('hex'),\niv: iv.toString('hex'),\nencrypted: encrypted\n};\n}\n\n// Password-based decryption\nfunction decryptWithPassword(encryptedInfo, password) {\n// Parse the values\nconst salt = Buffer.from(encryptedInfo.salt, 'hex');\nconst iv = Buffer.from(encryptedInfo.iv, 'hex');\nconst encrypted = encryptedInfo.encrypted;\n\n// Derive the same key\nconst key = crypto.pbkdf2Sync(password, salt, 100000, 32, 'sha256');\n\n// Create decipher\nconst decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);\n\n// Decrypt data\nlet decrypted = decipher.update(encrypted, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nreturn decrypted;\n}\n\n// Encrypt the message\nconst encryptedInfo = encryptWithPassword(message, password);\nconsole.log('Encrypted information:', encryptedInfo);\n\n// Decrypt the message\nconst decryptedMessage = decryptWithPassword(encryptedInfo, password);\nconsole.log('Decrypted message:', decryptedMessage);\nconsole.log('Decryption successful:', message === decryptedMessage);\n\n// Try with wrong password\ntry {\nconst wrongPassword = 'wrongpassword';\nconst decryptedWithWrong = decryptWithPassword(encryptedInfo, wrongPassword);\nconsole.log('Decrypted with wrong password:', decryptedWithWrong);\n} catch (error) {\nconsole.log('Decryption with wrong password failed (expected):', error.message);\n}",
        "const crypto = require('crypto');\n\n// Generate key and IV\nconst key = crypto.randomBytes(32);\nconst iv = crypto.randomBytes(16);\n\n// Create sample encrypted data\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\nconst validEncrypted = cipher.update('valid data', 'utf8', 'hex') + cipher.final('hex');\n\n// Function to attempt decryption and handle errors\nfunction tryDecrypt(encryptedText, decryptKey, decryptIv) {\ntry {\nconst decipher = crypto.createDecipheriv('aes-256-cbc', decryptKey, decryptIv);\nconst decrypted = decipher.update(encryptedText, 'hex', 'utf8') + decipher.final('utf8');\nreturn { success: true, data: decrypted };\n} catch (error) {\nreturn { success: false, error: error.message };\n}\n}\n\n// Case 1: Correct key and IV\nconst result1 = tryDecrypt(validEncrypted, key, iv);\nconsole.log('Case 1 (correct key and IV):', result1);\n\n// Case 2: Wrong key\nconst wrongKey = crypto.randomBytes(32);\nconst result2 = tryDecrypt(validEncrypted, wrongKey, iv);\nconsole.log('Case 2 (wrong key):', result2);\n\n// Case 3: Wrong IV\nconst wrongIv = crypto.randomBytes(16);\nconst result3 = tryDecrypt(validEncrypted, key, wrongIv);\nconsole.log('Case 3 (wrong IV):', result3);\n\n// Case 4: Invalid encrypted data\nconst result4 = tryDecrypt('invalidhexdata', key, iv);\nconsole.log('Case 4 (invalid data):', result4);\n\n// Case 5: Corrupted encrypted data\nconst corruptedData = validEncrypted.substring(0, validEncrypted.length - 2);\nconst result5 = tryDecrypt(corruptedData, key, iv);\nconsole.log('Case 5 (corrupted data):', result5);",
        "crypto",
        "crypto.createDecipheriv()",
        "crypto.createDecipher()",
        "data",
        "inputEncoding",
        "outputEncoding",
        "autoPadding",
        "createDecipheriv()",
        "createDecipher()"
      ]
    },
    {
      "title": "Node.js DiffieHellman Reference",
      "summary": "DiffieHellman Object\nThe DiffieHellman class is part of Node.js's crypto module. It implements the Diffie-Hellman key exchange protocol, which allows two parties to securely establish a shared secret over an insecure channel.\nImport Crypto Module\nDiffieHellman Methods\nCreating DiffieHellman Instances\nThere are multiple ways to create a DiffieHellman instance:\nThe getDiffieHellman() method supports the following predefined groups:\nBasic Key Exchange Example\nThe following example demonstrates the basic Diffie-Hellman key exchange between two parties (Alice and Bob):\nUsing Predefined Groups\nFor standardized applications, using predefined groups can ensure compatibility:\nDiffie-Hellman with Encryption\nThis example shows a complete scenario of using Diffie-Hellman to establish a shared key for AES encryption:\nWorking with Custom Parameters\nWhen you need specific parameters for Diffie-Hellman:\nKey Generation with Specific Encoding\nYou can specify encodings when working with DiffieHellman keys:\nError Handling\nError handling is important when working with cryptographic operations:\nSecurity Considerations\nWhen using Diffie-Hellman key exchange, consider these security best practices:\nUse appropriate key sizes: For modern applications, use at least 2048-bit primes.\nUse validated groups: Whenever possible, use standardized groups like those defined in RFCs.\nProtect private keys: Never expose private keys in logs, debugging output, or client-side code.\nAdd authentication: Pure Diffie-Hellman is vulnerable to man-in-the-middle attacks. Consider using authenticated key exchange protocols like ECDHE with digital signatures.\nCheck parameter validation: Always check dh.verifyError to ensure the parameters are valid.\nUse ephemeral keys: Generate new keys for each session to provide forward secrecy.\nDerive encryption keys properly: Don't use the shared secret directly as an encryption key. Use a key derivation function (KDF) like HKDF or PBKDF2.\nComparing with ECDH\nDiffie-Hellman (DH) and Elliptic Curve Diffie-Hellman (ECDH) are both key exchange protocols, but ECDH offers advantages:\nFor most modern applications, ECDH is preferred due to its better performance and smaller key sizes.",
      "examples": [
        "// Import the crypto module\nconst crypto = require('crypto');\n\n// Create a DiffieHellman instance\nconst dh = crypto.createDiffieHellman(2048); // 2048-bit prime length",
        "const crypto = require('crypto');\n\n// Method 1: Generate a new DH group with specified prime length\nconst dh1 = crypto.createDiffieHellman(2048);\nconsole.log('Generated prime length:', dh1.getPrime().length * 8, 'bits');\n\n// Method 2: Create a DH group using a predefined prime\nconst prime = Buffer.from('prime-number-in-hex', 'hex');\nconst dh2 = crypto.createDiffieHellman(prime);\n\n// Method 3: Create a DH group using a predefined prime and generator\nconst generator = Buffer.from('02', 'hex'); // Often 2, 5, or other small values\nconst dh3 = crypto.createDiffieHellman(prime, generator);\n\n// Method 4: Using predefined groups with getDiffieHellman()\nconst predefinedGroupName = 'modp14'; // RFC 3526 2048-bit MODP Group\nconst dh4 = crypto.getDiffieHellman(predefinedGroupName);",
        "const crypto = require('crypto');\n\n// Alice generates parameters and keys\nconsole.log('Alice: Creating DiffieHellman instance...');\nconst alice = crypto.createDiffieHellman(2048);\nconst aliceKeys = alice.generateKeys();\n\n// Bob also needs parameters from Alice\nconsole.log('Alice: Sending parameters to Bob...');\nconst p = alice.getPrime();\nconst g = alice.getGenerator();\n\n// Bob creates a DiffieHellman instance with the same parameters\nconsole.log('Bob: Creating DiffieHellman instance with Alice\\'s parameters...');\nconst bob = crypto.createDiffieHellman(p, g);\nconst bobKeys = bob.generateKeys();\n\n// Exchange public keys (over an insecure channel)\nconsole.log('Exchanging public keys...');\nconst alicePublicKey = alice.getPublicKey();\nconst bobPublicKey = bob.getPublicKey();\n\n// Alice computes the shared secret using Bob's public key\nconsole.log('Alice: Computing shared secret...');\nconst aliceSecret = alice.computeSecret(bobPublicKey);\n\n// Bob computes the shared secret using Alice's public key\nconsole.log('Bob: Computing shared secret...');\nconst bobSecret = bob.computeSecret(alicePublicKey);\n\n// Both secrets should be the same\nconsole.log('Alice\\'s secret:', aliceSecret.toString('hex'));\nconsole.log('Bob\\'s secret:', bobSecret.toString('hex'));\nconsole.log('Do they match?', aliceSecret.equals(bobSecret));\n\n// This shared secret can now be used as a key for symmetric encryption",
        "const crypto = require('crypto');\n\n// Using the RFC 3526 MODP Group 14 (2048 bits)\nconsole.log('Alice: Creating DiffieHellman using predefined group...');\nconst alice = crypto.getDiffieHellman('modp14');\nalice.generateKeys();\n\n// Bob also uses the same predefined group\nconsole.log('Bob: Creating DiffieHellman using predefined group...');\nconst bob = crypto.getDiffieHellman('modp14');\nbob.generateKeys();\n\n// Exchange public keys (over an insecure channel)\nconsole.log('Exchanging public keys...');\nconst alicePublicKey = alice.getPublicKey();\nconst bobPublicKey = bob.getPublicKey();\n\n// Compute shared secrets\nconst aliceSecret = alice.computeSecret(bobPublicKey);\nconst bobSecret = bob.computeSecret(alicePublicKey);\n\n// Verify that the shared secrets match\nconsole.log('Do the shared secrets match?', aliceSecret.equals(bobSecret));\n\n// Output information about the group\nconsole.log('Group prime size:', alice.getPrime().length * 8, 'bits');\nconsole.log('Generator value:', alice.getGenerator().toString('hex'));",
        "const crypto = require('crypto');\n\n// Create DiffieHellman instances for Alice and Bob\nconst alice = crypto.createDiffieHellman(2048);\nalice.generateKeys();\n\n// Bob uses Alice's parameters\nconst bob = crypto.createDiffieHellman(alice.getPrime(), alice.getGenerator());\nbob.generateKeys();\n\n// Exchange public keys\nconst alicePublicKey = alice.getPublicKey();\nconst bobPublicKey = bob.getPublicKey();\n\n// Compute shared secrets\nconst aliceSecret = alice.computeSecret(bobPublicKey);\nconst bobSecret = bob.computeSecret(alicePublicKey);\n\n// Use the shared secret as a key for encryption\n// First, derive a suitable key using a hash function\nfunction deriveKey(secret, salt, keyLength) {\nreturn crypto.pbkdf2Sync(secret, salt, 1000, keyLength, 'sha256');\n}\n\n// Alice sends an encrypted message to Bob\nfunction encrypt(text, secret) {\n// Create a salt and derive a key\nconst salt = crypto.randomBytes(16);\nconst key = deriveKey(secret, salt, 32); // 32 bytes for AES-256\nconst iv = crypto.randomBytes(16);\n\n// Encrypt the message\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\nlet encrypted = cipher.update(text, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\n// Return everything Bob needs to decrypt\nreturn {\nsalt: salt.toString('hex'),\niv: iv.toString('hex'),\nencrypted\n};\n}\n\n// Bob decrypts the message from Alice\nfunction decrypt(encryptedInfo, secret) {\n// Parse values\nconst salt = Buffer.from(encryptedInfo.salt, 'hex');\nconst iv = Buffer.from(encryptedInfo.iv, 'hex');\nconst encrypted = encryptedInfo.encrypted;\n\n// Derive the same key\nconst key = deriveKey(secret, salt, 32);\n\n// Decrypt the message\nconst decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);\nlet decrypted = decipher.update(encrypted, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nreturn decrypted;\n}\n\n// Alice encrypts a message using the shared secret\nconst message = 'Hello Bob, this is a secret message from Alice!';\nconsole.log('Original message:', message);\n\nconst encryptedMessage = encrypt(message, aliceSecret);\nconsole.log('Encrypted message:', encryptedMessage);\n\n// Bob decrypts the message using his shared secret\nconst decryptedMessage = decrypt(encryptedMessage, bobSecret);\nconsole.log('Decrypted message:', decryptedMessage);",
        "const crypto = require('crypto');\n\n// Custom prime and generator values\n// These would normally be carefully chosen for security\nconst primeHex = `\nffffffffffffffffc90fdaa22168c234c4c6628b80dc1cd129024e088a67cc74\n020bbea63b139b22514a08798e3404ddef9519b3cd3a431b302b0a6df25f1437\n4fe1356d6d51c245e485b576625e7ec6f44c42e9a637ed6b0bff5cb6f406b7ed\nee386bfb5a899fa5ae9f24117c4b1fe649286651ece45b3dc2007cb8a163bf05\n98da48361c55d39a69163fa8fd24cf5f83655d23dca3ad961c62f356208552bb\n9ed529077096966d670c354e4abc9804f1746c08ca18217c32905e462e36ce3b\ne39e772c180e86039b2783a2ec07a28fb5c55df06f4c52c9de2bcbf695581718\n3995497cea956ae515d2261898fa051015728e5a8aacaa68ffffffffffffffff\n`.replace(/\\s+/g, '');\n\nconst prime = Buffer.from(primeHex, 'hex');\nconst generator = Buffer.from('02', 'hex');\n\n// Create DiffieHellman with custom parameters\nconst dh = crypto.createDiffieHellman(prime, generator);\n\n// Generate keys\ndh.generateKeys();\n\n// Verify the parameters\nconsole.log('Using custom prime of length:', prime.length * 8, 'bits');\nconsole.log('Generator:', generator.toString('hex'));\n\n// Validation\nconsole.log('Verify error code:', dh.verifyError);\nif (dh.verifyError) {\nconsole.error('The parameters did not pass validation!');\n} else {\nconsole.log('The parameters passed validation.');\n}\n\n// Output public and private keys\nconsole.log('Public key length:', dh.getPublicKey().length * 8, 'bits');\nconsole.log('Private key length:', dh.getPrivateKey().length * 8, 'bits');",
        "const crypto = require('crypto');\n\n// Create DiffieHellman instance\nconst dh = crypto.createDiffieHellman(1024);\n\n// Generate keys\ndh.generateKeys();\n\n// Get keys and parameters with different encodings\nconsole.log('With Buffer (default):');\nconsole.log('  - Prime:', dh.getPrime());\nconsole.log('  - Generator:', dh.getGenerator());\nconsole.log('  - Public Key:', dh.getPublicKey());\nconsole.log('  - Private Key:', dh.getPrivateKey());\n\nconsole.log('\\nWith hex encoding:');\nconsole.log('  - Prime:', dh.getPrime('hex'));\nconsole.log('  - Generator:', dh.getGenerator('hex'));\nconsole.log('  - Public Key:', dh.getPublicKey('hex'));\nconsole.log('  - Private Key:', dh.getPrivateKey('hex'));\n\nconsole.log('\\nWith base64 encoding:');\nconsole.log('  - Prime:', dh.getPrime('base64'));\nconsole.log('  - Generator:', dh.getGenerator('base64'));\nconsole.log('  - Public Key:', dh.getPublicKey('base64'));\nconsole.log('  - Private Key:', dh.getPrivateKey('base64'));\n\n// Set keys using specific encoding\nconst newPublicKey = crypto.randomBytes(dh.getPrime().length - 10);\ndh.setPublicKey(newPublicKey);\nconsole.log('\\nAfter setting new public key:');\nconsole.log('  - Public Key (hex):', dh.getPublicKey('hex'));",
        "const crypto = require('crypto');\n\n// Function to safely create DiffieHellman\nfunction createDHSafely(options) {\ntry {\nlet dh;\n\nif (typeof options === 'number') {\n// Create with prime length\ndh = crypto.createDiffieHellman(options);\n} else if (options.group) {\n// Create with predefined group\ndh = crypto.getDiffieHellman(options.group);\n} else if (options.prime) {\n// Create with custom prime and optional generator\nconst prime = Buffer.from(options.prime, options.encoding || 'hex');\nconst generator = options.generator ?\nBuffer.from(options.generator, options.encoding || 'hex') :\nundefined;\n\ndh = generator ?\ncrypto.createDiffieHellman(prime, generator) :\ncrypto.createDiffieHellman(prime);\n} else {\nthrow new Error('Invalid options for DiffieHellman creation');\n}\n\n// Check for errors\nif (dh.verifyError) {\nconst errors = [];\n// Check specific error flags\nif (dh.verifyError & crypto.constants.DH_CHECK_P_NOT_SAFE_PRIME)\nerrors.push('DH_CHECK_P_NOT_SAFE_PRIME');\nif (dh.verifyError & crypto.constants.DH_CHECK_P_NOT_PRIME)\nerrors.push('DH_CHECK_P_NOT_PRIME');\nif (dh.verifyError & crypto.constants.DH_UNABLE_TO_CHECK_GENERATOR)\nerrors.push('DH_UNABLE_TO_CHECK_GENERATOR');\nif (dh.verifyError & crypto.constants.DH_NOT_SUITABLE_GENERATOR)\nerrors.push('DH_NOT_SUITABLE_GENERATOR');\n\nthrow new Error(`DiffieHellman parameter validation failed: ${errors.join(', ')}`);\n}\n\nreturn dh;\n} catch (error) {\nconsole.error('Error creating DiffieHellman instance:', error.message);\nthrow error;\n}\n}\n\n// Test with valid options\ntry {\nconst dh1 = createDHSafely(2048);\nconsole.log('Successfully created DH with 2048-bit prime');\n\nconst dh2 = createDHSafely({ group: 'modp14' });\nconsole.log('Successfully created DH with predefined group modp14');\n} catch (error) {\nconsole.error('Error in valid tests:', error.message);\n}\n\n// Test with invalid options\ntry {\n// Invalid prime value\nconst invalidPrime = '12345'; // Too short, not a prime\nconst dh3 = createDHSafely({\nprime: invalidPrime,\nencoding: 'hex'\n});\n} catch (error) {\nconsole.error('Expected error with invalid prime:', error.message);\n}\n\ntry {\n// Invalid group name\nconst dh4 = createDHSafely({ group: 'nonexistent-group' });\n} catch (error) {\nconsole.error('Expected error with invalid group:', error.message);\n}",
        "crypto",
        "encoding",
        "inputEncoding",
        "otherPublicKey",
        "outputEncoding",
        "publicKey",
        "privateKey",
        "getDiffieHellman()",
        "dh.verifyError"
      ]
    },
    {
      "title": "Node.js ECDH Reference",
      "summary": "ECDH Object\nThe ECDH (Elliptic Curve Diffie-Hellman) class is part of Node.js's crypto module. It implements the Elliptic Curve Diffie-Hellman key exchange protocol, which allows two parties to securely establish a shared secret over an insecure channel using elliptic curve cryptography.\nECDH offers advantages over traditional Diffie-Hellman key exchange, including smaller key sizes, faster computation, and equivalent security strength.\nImport Crypto Module\nECDH Methods\nSupported Curves\nNode.js supports various elliptic curves for ECDH. You can get a list of all supported curves with:\nCommon curves for ECDH include:\nBasic Key Exchange Example\nThe following example demonstrates the basic ECDH key exchange between two parties (Alice and Bob):\nECDH with Different Encoding Formats\nECDH supports different public key encoding formats:\nECDH with Encryption\nThis example shows a complete scenario of using ECDH to establish a shared key for AES encryption:\nSetting Private Key Manually\nYou can manually set a private key instead of generating one:\nECDH with Different Curves\nThis example shows how to use different elliptic curves with ECDH:\nPerformance Comparison\nThis example compares the performance of ECDH with traditional Diffie-Hellman:\nECDH Key Pair Generation for TLS\nThis example shows how to generate ECDH key pairs for use with TLS:\nSecurity Considerations\nWhen using ECDH key exchange, consider these security best practices:\nChoose appropriate curves: For most applications, P-256 (prime256v1) provides a good balance of security and performance. For higher security requirements, consider P-384 or P-521.\nAvoid weak or deprecated curves: Some curves are known to have weaknesses. Always use standard curves recommended by security authorities.\nUse ephemeral keys: Generate new ECDH key pairs for each session to provide forward secrecy.\nAdd authentication: Pure ECDH (like DH) is vulnerable to man-in-the-middle attacks. Consider using authenticated key exchange protocols like ECDHE with digital signatures.\nProtect private keys: Never expose private keys in logs, debugging output, or client-side code.\nDerive encryption keys properly: Don't use the shared secret directly as an encryption key. Use a key derivation function (KDF) like HKDF or PBKDF2.\nValidate public keys: Validate that received public keys are valid points on the elliptic curve to prevent invalid-curve attacks.\nComparing DH and ECDH\nThis table compares traditional Diffie-Hellman with Elliptic Curve Diffie-Hellman:\nFor most modern applications, ECDH is preferred due to its better performance and smaller key sizes while providing equivalent or better security.",
      "examples": [
        "// Import the crypto module\nconst crypto = require('crypto');\n\n// Create an ECDH instance with a specific curve\nconst ecdh = crypto.createECDH('prime256v1'); // Also known as P-256 or secp256r1",
        "const crypto = require('crypto');\n\n// Get all supported elliptic curves\nconsole.log(crypto.getCurves());",
        "const crypto = require('crypto');\n\n// Alice creates an ECDH instance and generates keys\nconsole.log('Alice: Creating ECDH instance...');\nconst alice = crypto.createECDH('prime256v1');\nalice.generateKeys();\n\n// Bob creates an ECDH instance and generates keys\nconsole.log('Bob: Creating ECDH instance...');\nconst bob = crypto.createECDH('prime256v1');\nbob.generateKeys();\n\n// Exchange public keys (over an insecure channel)\nconsole.log('Exchanging public keys...');\nconst alicePublicKey = alice.getPublicKey();\nconst bobPublicKey = bob.getPublicKey();\n\n// Alice computes the shared secret using Bob's public key\nconsole.log('Alice: Computing shared secret...');\nconst aliceSecret = alice.computeSecret(bobPublicKey);\n\n// Bob computes the shared secret using Alice's public key\nconsole.log('Bob: Computing shared secret...');\nconst bobSecret = bob.computeSecret(alicePublicKey);\n\n// Both secrets should be the same\nconsole.log('Alice\\'s secret:', aliceSecret.toString('hex'));\nconsole.log('Bob\\'s secret:', bobSecret.toString('hex'));\nconsole.log('Do they match?', aliceSecret.equals(bobSecret));\n\n// This shared secret can now be used as a key for symmetric encryption",
        "const crypto = require('crypto');\n\n// Create an ECDH instance\nconst ecdh = crypto.createECDH('prime256v1');\necdh.generateKeys();\n\n// Get public key in different formats\nconst uncompressedKey = ecdh.getPublicKey('hex', 'uncompressed');\nconst compressedKey = ecdh.getPublicKey('hex', 'compressed');\nconst hybridKey = ecdh.getPublicKey('hex', 'hybrid');\n\nconsole.log('Uncompressed public key:', uncompressedKey);\nconsole.log('Compressed public key:', compressedKey);\nconsole.log('Hybrid public key:', hybridKey);\n\n// Get key length in each format\nconsole.log('\\nKey lengths:');\nconsole.log('Uncompressed:', Buffer.from(uncompressedKey, 'hex').length, 'bytes');\nconsole.log('Compressed:', Buffer.from(compressedKey, 'hex').length, 'bytes');\nconsole.log('Hybrid:', Buffer.from(hybridKey, 'hex').length, 'bytes');\n\n// Use a public key in different formats\nconst otherEcdh = crypto.createECDH('prime256v1');\notherEcdh.generateKeys();\n\n// Another party can use any format to compute the same secret\nconst secret1 = otherEcdh.computeSecret(\nBuffer.from(uncompressedKey, 'hex')\n);\n\nconst secret2 = otherEcdh.computeSecret(\nBuffer.from(compressedKey, 'hex')\n);\n\nconsole.log('\\nSame secret computed from different formats?',\nsecret1.equals(secret2));",
        "const crypto = require('crypto');\n\n// Create ECDH instances for Alice and Bob\nconst alice = crypto.createECDH('prime256v1');\nalice.generateKeys();\n\nconst bob = crypto.createECDH('prime256v1');\nbob.generateKeys();\n\n// Exchange public keys\nconst alicePublicKey = alice.getPublicKey();\nconst bobPublicKey = bob.getPublicKey();\n\n// Compute shared secrets\nconst aliceSecret = alice.computeSecret(bobPublicKey);\nconst bobSecret = bob.computeSecret(alicePublicKey);\n\n// Use the shared secret as a key for encryption\n// First, derive a suitable key using a hash function\nfunction deriveKey(secret, salt, keyLength) {\nreturn crypto.pbkdf2Sync(secret, salt, 1000, keyLength, 'sha256');\n}\n\n// Alice sends an encrypted message to Bob\nfunction encrypt(text, secret) {\n// Create a salt and derive a key\nconst salt = crypto.randomBytes(16);\nconst key = deriveKey(secret, salt, 32); // 32 bytes for AES-256\nconst iv = crypto.randomBytes(16);\n\n// Encrypt the message\nconst cipher = crypto.createCipheriv('aes-256-cbc', key, iv);\nlet encrypted = cipher.update(text, 'utf8', 'hex');\nencrypted += cipher.final('hex');\n\n// Return everything Bob needs to decrypt\nreturn {\nsalt: salt.toString('hex'),\niv: iv.toString('hex'),\nencrypted\n};\n}\n\n// Bob decrypts the message from Alice\nfunction decrypt(encryptedInfo, secret) {\n// Parse values\nconst salt = Buffer.from(encryptedInfo.salt, 'hex');\nconst iv = Buffer.from(encryptedInfo.iv, 'hex');\nconst encrypted = encryptedInfo.encrypted;\n\n// Derive the same key\nconst key = deriveKey(secret, salt, 32);\n\n// Decrypt the message\nconst decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);\nlet decrypted = decipher.update(encrypted, 'hex', 'utf8');\ndecrypted += decipher.final('utf8');\n\nreturn decrypted;\n}\n\n// Alice encrypts a message using the shared secret\nconst message = 'Hello Bob, this is a secret message from Alice using ECDH!';\nconsole.log('Original message:', message);\n\nconst encryptedMessage = encrypt(message, aliceSecret);\nconsole.log('Encrypted message:', encryptedMessage);\n\n// Bob decrypts the message using his shared secret\nconst decryptedMessage = decrypt(encryptedMessage, bobSecret);\nconsole.log('Decrypted message:', decryptedMessage);\n\n// Verify the result\nconsole.log('Decryption successful:', message === decryptedMessage);",
        "const crypto = require('crypto');\n\n// Create an ECDH instance\nconst ecdh = crypto.createECDH('prime256v1');\n\n// Generate a random private key (32 bytes for prime256v1)\nconst privateKey = crypto.randomBytes(32);\nconsole.log('Private key (hex):', privateKey.toString('hex'));\n\n// Set the private key\necdh.setPrivateKey(privateKey);\n\n// Derive the public key from the private key\nconst publicKey = ecdh.getPublicKey('hex', 'uncompressed');\nconsole.log('Public key (hex):', publicKey);\n\n// You can also set the private key from a hex string\nconst ecdh2 = crypto.createECDH('prime256v1');\necdh2.setPrivateKey(privateKey.toString('hex'), 'hex');\n\n// Check if both instances generate the same public key\nconst publicKey2 = ecdh2.getPublicKey('hex', 'uncompressed');\nconsole.log('Same public keys:', publicKey === publicKey2);\n\n// This is useful for deterministic key generation or when loading keys from storage",
        "const crypto = require('crypto');\n\n// Function to perform ECDH key exchange with a specific curve\nfunction testCurve(curveName) {\nconsole.log(`\\nTesting curve: ${curveName}`);\n\ntry {\n// Create ECDH instances\nconst alice = crypto.createECDH(curveName);\nalice.generateKeys();\n\nconst bob = crypto.createECDH(curveName);\nbob.generateKeys();\n\n// Exchange public keys\nconst alicePublicKey = alice.getPublicKey();\nconst bobPublicKey = bob.getPublicKey();\n\n// Compute shared secrets\nconst aliceSecret = alice.computeSecret(bobPublicKey);\nconst bobSecret = bob.computeSecret(alicePublicKey);\n\n// Check if secrets match\nconst match = aliceSecret.equals(bobSecret);\n\n// Output results\nconsole.log(`Public key size: ${alicePublicKey.length} bytes`);\nconsole.log(`Shared secret size: ${aliceSecret.length} bytes`);\nconsole.log(`Secrets match: ${match}`);\n\nreturn match;\n} catch (error) {\nconsole.error(`Error with curve ${curveName}: ${error.message}`);\nreturn false;\n}\n}\n\n// Test different curves\nconst curves = [\n'prime256v1',  // P-256 / secp256r1\n'secp384r1',   // P-384\n'secp521r1',   // P-521\n'secp256k1',   // Bitcoin curve\n'curve25519'   // Ed25519 curve (if supported)\n];\n\ncurves.forEach(curve => {\ntestCurve(curve);\n});\n\n// Note: Not all curves may be supported in your Node.js version",
        "const crypto = require('crypto');\nconst { performance } = require('perf_hooks');\n\n// Function to measure DH key generation time\nfunction measureDH(bits) {\nconst startTime = performance.now();\n\nconst dh = crypto.createDiffieHellman(bits);\ndh.generateKeys();\n\nconst endTime = performance.now();\nreturn endTime - startTime;\n}\n\n// Function to measure ECDH key generation time\nfunction measureECDH(curve) {\nconst startTime = performance.now();\n\nconst ecdh = crypto.createECDH(curve);\necdh.generateKeys();\n\nconst endTime = performance.now();\nreturn endTime - startTime;\n}\n\n// Function to measure secret computation time\nfunction measureSecretComputation(type, params) {\nlet alice, bob;\n\n// Create instances and generate keys\nif (type === 'DH') {\nalice = crypto.createDiffieHellman(params);\nalice.generateKeys();\n\nbob = crypto.createDiffieHellman(alice.getPrime(), alice.getGenerator());\nbob.generateKeys();\n} else {\nalice = crypto.createECDH(params);\nalice.generateKeys();\n\nbob = crypto.createECDH(params);\nbob.generateKeys();\n}\n\n// Exchange public keys\nconst alicePublicKey = alice.getPublicKey();\nconst bobPublicKey = bob.getPublicKey();\n\n// Measure time for computing secrets\nconst startTime = performance.now();\n\nalice.computeSecret(bobPublicKey);\nbob.computeSecret(alicePublicKey);\n\nconst endTime = performance.now();\nreturn endTime - startTime;\n}\n\n// Run performance tests\nconsole.log('Key Generation Performance:');\nconsole.log(`DH (1024 bits): ${measureDH(1024).toFixed(2)} ms`);\nconsole.log(`DH (2048 bits): ${measureDH(2048).toFixed(2)} ms`);\nconsole.log(`ECDH (P-256): ${measureECDH('prime256v1').toFixed(2)} ms`);\nconsole.log(`ECDH (P-384): ${measureECDH('secp384r1').toFixed(2)} ms`);\nconsole.log(`ECDH (P-521): ${measureECDH('secp521r1').toFixed(2)} ms`);\n\nconsole.log('\\nSecret Computation Performance:');\nconsole.log(`DH (1024 bits): ${measureSecretComputation('DH', 1024).toFixed(2)} ms`);\nconsole.log(`DH (2048 bits): ${measureSecretComputation('DH', 2048).toFixed(2)} ms`);\nconsole.log(`ECDH (P-256): ${measureSecretComputation('ECDH', 'prime256v1').toFixed(2)} ms`);\nconsole.log(`ECDH (P-384): ${measureSecretComputation('ECDH', 'secp384r1').toFixed(2)} ms`);\nconsole.log(`ECDH (P-521): ${measureSecretComputation('ECDH', 'secp521r1').toFixed(2)} ms`);",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Function to generate and save ECDH keys for TLS\nfunction generateEcdhKeysForTLS(curveName, keyFilePrefix) {\n// Create ECDH instance\nconst ecdh = crypto.createECDH(curveName);\n\n// Generate keys\necdh.generateKeys();\n\n// Get keys in PEM format\nconst privateKey = ecdh.getPrivateKey('hex');\nconst publicKey = ecdh.getPublicKey('hex', 'uncompressed');\n\n// Save keys to files\nfs.writeFileSync(`${keyFilePrefix}_private.hex`, privateKey);\nfs.writeFileSync(`${keyFilePrefix}_public.hex`, publicKey);\n\nconsole.log(`Generated ECDH key pair using ${curveName}`);\nconsole.log(`Private key saved to ${keyFilePrefix}_private.hex`);\nconsole.log(`Public key saved to ${keyFilePrefix}_public.hex`);\n\nreturn {\ncurve: curveName,\nprivateKey,\npublicKey\n};\n}\n\n// Generate keys for different curves\ngenerateEcdhKeysForTLS('prime256v1', 'ecdh_p256');\ngenerateEcdhKeysForTLS('secp384r1', 'ecdh_p384');\n\nconsole.log(\"\\nThese keys can be used for ECDHE (Ephemeral ECDH) in TLS connections.\");\nconsole.log(\"In a real application, you would use these with the TLS module or a library like Node.js's tls module.\");",
        "crypto",
        "encoding",
        "format",
        "inputEncoding",
        "otherPublicKey",
        "outputEncoding",
        "privateKey"
      ]
    },
    {
      "title": "Node.js Hash Reference",
      "summary": "Hash Object\nThe Hash class is part of Node.js's crypto module. It provides a way to create cryptographic hash digests of data. Hash instances are created using the crypto.createHash() method.\nHash functions are one-way functions that map data of arbitrary size to a fixed-size value called a digest. They are designed to be fast to compute but practically impossible to reverse.\nImport Crypto Module\nHash Methods\nSupported Hash Algorithms\nNode.js supports many hash algorithms. You can get a list of all supported algorithms with:\nCommon hash algorithms include:\nBasic Hash Example\nThe following example demonstrates how to create a hash digest of a string:\nComparing Different Hash Algorithms\nThis example compares different hash algorithms:\nHashing with Multiple Updates\nYou can update a hash with multiple pieces of data before calculating the digest:\nHash with Different Encodings\nYou can get a hash digest in different encodings:\nFile Hashing\nYou can hash the contents of a file:\nUsing hash.copy()\nThe hash.copy() method allows you to create a copy of a hash object:\nHash Performance Comparison\nThis example compares the performance of different hash algorithms:\nPassword Hashing\nWarning: The following example demonstrates password hashing with general-purpose hash functions. For secure password storage, use specialized algorithms like bcrypt, scrypt, or Argon2, which are specifically designed for password hashing and include salt and work factors.\nThis example shows how to hash passwords with a salt:\nBetter Password Hashing with crypto.pbkdf2\nA more secure approach to password hashing using PBKDF2:\nHash Collisions\nHash collisions occur when two different inputs produce the same hash value. This example demonstrates how to check for hash collisions:\nIncremental Hash Processing\nWhen working with large amounts of data, you can process it incrementally:\nSecurity Best Practices\nWhen using hash functions, consider these security best practices:\nChoose secure algorithms: For security-critical applications, use SHA-256, SHA-512, SHA-3, or newer hash functions. Avoid MD5 and SHA-1 for security purposes.\nUse purpose-specific functions: For password hashing, use specialized functions like bcrypt, scrypt, or Argon2 instead of general-purpose hash functions.\nAlways use salts with passwords: When storing password hashes, always use a unique random salt for each password.\nConsider HMAC for message authentication: When verifying data integrity with a secret key, use HMAC instead of plain hashes.\nBe aware of length extension attacks: Some hash functions (SHA-256, SHA-512, but not SHA-3) are vulnerable to length extension attacks when used naively for message authentication.\nKeep dependencies updated: Security vulnerabilities in cryptographic implementations are regularly discovered and patched.",
      "examples": [
        "// Import the crypto module\nconst crypto = require('crypto');\n\n// Create a hash object\nconst hash = crypto.createHash('sha256');",
        "const crypto = require('crypto');\n\n// Get all supported hash algorithms\nconsole.log(crypto.getHashes());",
        "const crypto = require('crypto');\n\n// Data to hash\nconst data = 'Hello, World!';\n\n// Create a hash object\nconst hash = crypto.createHash('sha256');\n\n// Update the hash with data\nhash.update(data);\n\n// Get the digest in hex format\nconst digest = hash.digest('hex');\n\nconsole.log('Data:', data);\nconsole.log('SHA-256 Hash:', digest);",
        "const crypto = require('crypto');\n\n// Data to hash\nconst data = 'Node.js Crypto Hash Example';\n\n// Function to hash data with different algorithms\nfunction hashWithAlgorithm(algorithm, data) {\nconst hash = crypto.createHash(algorithm);\nhash.update(data);\nreturn hash.digest('hex');\n}\n\n// Test various hash algorithms\nconst algorithms = ['md5', 'sha1', 'sha256', 'sha512', 'sha3-256', 'sha3-512'];\n\nconsole.log(`Data: \"${data}\"`);\nconsole.log('------------------------------------');\n\nalgorithms.forEach(algorithm => {\ntry {\nconst digest = hashWithAlgorithm(algorithm, data);\nconsole.log(`${algorithm}: ${digest}`);\nconsole.log(`Length: ${digest.length / 2} bytes (${digest.length * 4} bits)`);\nconsole.log('------------------------------------');\n} catch (error) {\nconsole.log(`${algorithm}: Not supported - ${error.message}`);\nconsole.log('------------------------------------');\n}\n});",
        "const crypto = require('crypto');\n\n// Create a hash object\nconst hash = crypto.createHash('sha256');\n\n// Update the hash with multiple pieces of data\nhash.update('First part of the data.');\nhash.update(' Second part of the data.');\nhash.update(' Third part of the data.');\n\n// Calculate the final digest\nconst digest = hash.digest('hex');\n\nconsole.log('Combined data: First part of the data. Second part of the data. Third part of the data.');\nconsole.log('SHA-256 Hash:', digest);\n\n// You can achieve the same result with a single update\nconst singleHash = crypto.createHash('sha256');\nsingleHash.update('First part of the data. Second part of the data. Third part of the data.');\nconst singleDigest = singleHash.digest('hex');\n\nconsole.log('Single update hash matches multiple updates?', singleDigest === digest);",
        "const crypto = require('crypto');\n\n// Data to hash\nconst data = 'Hello, Node.js!';\n\n// Function to hash data and get digest in different encodings\nfunction hashWithEncoding(algorithm, data, encoding) {\nconst hash = crypto.createHash(algorithm);\nhash.update(data);\nreturn hash.digest(encoding);\n}\n\n// Hash the data with SHA-256 and display in different encodings\nconsole.log(`Data: \"${data}\"`);\nconsole.log(`SHA-256 (hex): ${hashWithEncoding('sha256', data, 'hex')}`);\nconsole.log(`SHA-256 (base64): ${hashWithEncoding('sha256', data, 'base64')}`);\nconsole.log(`SHA-256 (base64url): ${hashWithEncoding('sha256', data, 'base64url')}`);\nconsole.log(`SHA-256 (binary): ${hashWithEncoding('sha256', data, 'binary')}`);\n\n// Get the digest as a Buffer (no encoding)\nconst hash = crypto.createHash('sha256');\nhash.update(data);\nconst buffer = hash.digest();\nconsole.log('SHA-256 (Buffer):', buffer);\nconsole.log('Buffer length:', buffer.length, 'bytes');",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Function to hash a file using streams\nfunction hashFile(filePath, algorithm) {\nreturn new Promise((resolve, reject) => {\n// Create hash object\nconst hash = crypto.createHash(algorithm);\n\n// Create read stream\nconst stream = fs.createReadStream(filePath);\n\n// Handle stream events\nstream.on('data', (data) => {\nhash.update(data);\n});\n\nstream.on('end', () => {\nconst digest = hash.digest('hex');\nresolve(digest);\n});\n\nstream.on('error', (error) => {\nreject(error);\n});\n});\n}\n\n// Example usage (adjust file path as needed)\nconst filePath = 'example.txt';\n\n// Create a test file if it doesn't exist\nif (!fs.existsSync(filePath)) {\nfs.writeFileSync(filePath, 'This is a test file for hashing.\\n'.repeat(100));\nconsole.log(`Created test file: ${filePath}`);\n}\n\n// Hash the file with different algorithms\nPromise.all([\nhashFile(filePath, 'md5'),\nhashFile(filePath, 'sha1'),\nhashFile(filePath, 'sha256')\n])\n.then(([md5Digest, sha1Digest, sha256Digest]) => {\nconsole.log(`File: ${filePath}`);\nconsole.log(`MD5: ${md5Digest}`);\nconsole.log(`SHA-1: ${sha1Digest}`);\nconsole.log(`SHA-256: ${sha256Digest}`);\n})\n.catch(error => {\nconsole.error('Error hashing file:', error.message);\n});",
        "const crypto = require('crypto');\n\n// Create a hash object\nconst hash = crypto.createHash('sha256');\n\n// Update with common data\nhash.update('Common prefix data');\n\n// Create a copy\nconst hashCopy = hash.copy();\n\n// Update the original hash with more data\nhash.update(' with additional data for original');\nconst originalDigest = hash.digest('hex');\n\n// Update the copy with different data\nhashCopy.update(' with different data for copy');\nconst copyDigest = hashCopy.digest('hex');\n\nconsole.log('Original hash:', originalDigest);\nconsole.log('Copy hash:', copyDigest);\nconsole.log('Are they different?', originalDigest !== copyDigest);\n\n// This is useful when you want to create multiple hash variations\n// from a common starting point, without recalculating the common portion",
        "const crypto = require('crypto');\nconst { performance } = require('perf_hooks');\n\n// Data to hash (1MB of random data)\nconst data = crypto.randomBytes(1024 * 1024);\n\n// Function to measure hash algorithm performance\nfunction measureHashPerformance(algorithm, iterations = 100) {\n// Ensure the algorithm is supported\ntry {\ncrypto.createHash(algorithm);\n} catch (error) {\nreturn { algorithm, error: error.message };\n}\n\nconst startTime = performance.now();\n\nfor (let i = 0; i < iterations; i++) {\nconst hash = crypto.createHash(algorithm);\nhash.update(data);\nhash.digest();\n}\n\nconst endTime = performance.now();\nconst totalTime = endTime - startTime;\n\nreturn {\nalgorithm,\niterations,\ntotalTimeMs: totalTime.toFixed(2),\ntimePerHashMs: (totalTime / iterations).toFixed(4),\nhashesPerSecond: Math.floor(iterations / (totalTime / 1000))\n};\n}\n\n// Test various hash algorithms\nconst algorithms = ['md5', 'sha1', 'sha256', 'sha512', 'sha3-256', 'sha3-512'];\nconst results = [];\n\nconsole.log('Measuring hash performance for 1MB of data...');\n\nalgorithms.forEach(algorithm => {\nresults.push(measureHashPerformance(algorithm));\n});\n\n// Display results in a table format\nconsole.table(results);\n\n// Display relative performance (normalized to the fastest algorithm)\nconsole.log('\\nRelative Performance:');\n\n// Find the fastest algorithm\nconst fastest = results.reduce((prev, current) => {\nif (current.error) return prev;\nreturn (prev && prev.hashesPerSecond > current.hashesPerSecond) ? prev : current;\n}, null);\n\nif (fastest) {\nresults.forEach(result => {\nif (!result.error) {\nconst relativeSpeed = (result.hashesPerSecond / fastest.hashesPerSecond).toFixed(2);\nconsole.log(`${result.algorithm}: ${relativeSpeed}x (${result.hashesPerSecond} hashes/sec)`);\n} else {\nconsole.log(`${result.algorithm}: Error - ${result.error}`);\n}\n});\n}",
        "const crypto = require('crypto');\n\n// Function to hash a password with a salt\nfunction hashPassword(password, salt) {\n// Create hash object\nconst hash = crypto.createHash('sha256');\n\n// Update with salt and password\nhash.update(salt);\nhash.update(password);\n\n// Return digest\nreturn hash.digest('hex');\n}\n\n// Generate a random salt\nfunction generateSalt() {\nreturn crypto.randomBytes(16).toString('hex');\n}\n\n// Example usage\nconst password = 'mySecurePassword123';\n\n// For a new user, generate a salt and hash the password\nconst salt = generateSalt();\nconst hashedPassword = hashPassword(password, salt);\n\nconsole.log('Password:', password);\nconsole.log('Salt:', salt);\nconsole.log('Hashed Password:', hashedPassword);\n\n// To verify a password, hash it with the same salt and compare\nfunction verifyPassword(password, salt, storedHash) {\nconst hash = hashPassword(password, salt);\nreturn hash === storedHash;\n}\n\n// Check correct password\nconsole.log('Verification with correct password:',\nverifyPassword(password, salt, hashedPassword));\n\n// Check incorrect password\nconsole.log('Verification with incorrect password:',\nverifyPassword('wrongPassword', salt, hashedPassword));\n\n// Note: For production, use crypto.pbkdf2, bcrypt, scrypt, or Argon2 instead",
        "const crypto = require('crypto');\n\n// Secure password hashing with PBKDF2\nfunction hashPasswordSecure(password, salt, iterations = 100000) {\nreturn new Promise((resolve, reject) => {\ncrypto.pbkdf2(\npassword,\nsalt,\niterations,\n64,      // Key length in bytes\n'sha512', // Hash function\n(err, derivedKey) => {\nif (err) reject(err);\nresolve(derivedKey.toString('hex'));\n}\n);\n});\n}\n\n// Generate a random salt\nfunction generateSalt() {\nreturn crypto.randomBytes(16).toString('hex');\n}\n\n// Example usage\nasync function example() {\ntry {\nconst password = 'mySecurePassword123';\n\n// For a new user, generate a salt and hash the password\nconst salt = generateSalt();\nconst iterations = 100000; // Higher is more secure but slower\n\nconsole.log('Password:', password);\nconsole.log('Salt:', salt);\nconsole.log('Iterations:', iterations);\n\nconst hashedPassword = await hashPasswordSecure(password, salt, iterations);\nconsole.log('Hashed Password:', hashedPassword);\n\n// To verify a password\nconst verifyCorrect = await hashPasswordSecure(password, salt, iterations) === hashedPassword;\nconsole.log('Verification with correct password:', verifyCorrect);\n\nconst verifyWrong = await hashPasswordSecure('wrongPassword', salt, iterations) === hashedPassword;\nconsole.log('Verification with incorrect password:', verifyWrong);\n\n// For storage, you would save: salt, iterations, and hashedPassword\n} catch (error) {\nconsole.error('Error:', error.message);\n}\n}\n\nexample();",
        "const crypto = require('crypto');\n\n// Function to generate random string\nfunction generateRandomString(length) {\nreturn crypto.randomBytes(length).toString('hex').substring(0, length);\n}\n\n// Function to find a partial hash collision (first few characters match)\nfunction findPartialCollision(targetLength) {\nconst hashMap = new Map();\nlet attempts = 0;\n\nconsole.log(`Searching for partial SHA-256 collisions (first ${targetLength} characters)...`);\n\nwhile (true) {\nattempts++;\n\n// Generate a random input\nconst input = generateRandomString(8);\n\n// Hash the input\nconst hash = crypto.createHash('sha256').update(input).digest('hex');\n\n// Get the target portion of the hash\nconst targetPortion = hash.substring(0, targetLength);\n\n// Check if we've seen this target portion before\nif (hashMap.has(targetPortion)) {\nconst previousInput = hashMap.get(targetPortion);\n\nconsole.log(`Found a collision after ${attempts} attempts!`);\nconsole.log(`Input 1: \"${previousInput}\"`);\nconsole.log(`Input 2: \"${input}\"`);\nconsole.log(`SHA-256 (Input 1): ${crypto.createHash('sha256').update(previousInput).digest('hex')}`);\nconsole.log(`SHA-256 (Input 2): ${hash}`);\nconsole.log(`Both hashes start with: ${targetPortion}`);\n\nreturn {\nattempts,\ninput1: previousInput,\ninput2: input,\ncollidingPrefix: targetPortion\n};\n}\n\n// Store this hash\nhashMap.set(targetPortion, input);\n\n// Show progress\nif (attempts % 100000 === 0) {\nconsole.log(`Checked ${attempts} values, ${hashMap.size} unique prefixes found...`);\n}\n\n// Safety limit\nif (attempts >= 1000000) {\nconsole.log('Reached attempt limit without finding a collision.');\nbreak;\n}\n}\n\nreturn { attempts, collisionFound: false };\n}\n\n// Find a collision for the first few characters (increase for more challenge)\nfindPartialCollision(4);\n\n// Note: Finding a full collision for SHA-256 is computationally infeasible\n// This example only demonstrates partial collisions",
        "const crypto = require('crypto');\n\n// Simulate processing a large file in chunks\nfunction processLargeDataIncrementally() {\n// Create a hash object\nconst hash = crypto.createHash('sha256');\n\n// Simulate reading data in chunks\nconst totalChunks = 10;\n\nconsole.log(`Processing data in ${totalChunks} chunks...`);\n\nfor (let i = 0; i < totalChunks; i++) {\n// In a real scenario, this would be data read from a file or stream\nconst chunk = `Chunk ${i + 1} of data with some random content: ${crypto.randomBytes(10).toString('hex')}`;\n\nconsole.log(`Processing chunk ${i + 1}/${totalChunks}, size: ${chunk.length} bytes`);\n\n// Update the hash with this chunk\nhash.update(chunk);\n}\n\n// Calculate final hash after all chunks are processed\nconst finalHash = hash.digest('hex');\nconsole.log('Final SHA-256 hash:', finalHash);\n}\n\n// Run the example\nprocessLargeDataIncrementally();",
        "crypto",
        "crypto.createHash()",
        "data",
        "inputEncoding",
        "hash.update()",
        "encoding",
        "hash.copy()"
      ]
    },
    {
      "title": "Node.js Hmac Reference",
      "summary": "Hmac Object\nThe Hmac class is part of Node.js's crypto module. It provides a way to create cryptographic HMAC (Hash-based Message Authentication Code) digests. HMAC instances are created using the crypto.createHmac() method.\nHMAC combines a cryptographic hash function with a secret key to produce a message authentication code, providing both data integrity and authentication.\nImport Crypto Module\nHmac Methods\nBasic Hmac Example\nThe following example demonstrates how to create an HMAC digest of a string:\nComparing Different HMAC Algorithms\nThis example compares different hash algorithms with HMAC:\nHMAC with Multiple Updates\nYou can update an HMAC with multiple pieces of data before calculating the digest:\nHMAC with Different Encodings\nYou can get an HMAC digest in different encodings:\nFile Authentication with HMAC\nYou can create an HMAC digest of a file's contents:\nVerifying File Integrity with HMAC\nThis example demonstrates how to verify a file's integrity using a previously generated HMAC:\nUsing Different Types of Keys\nHMAC can work with different types of keys:\nHMAC for API Authentication\nHMAC is commonly used for API authentication, where the server and client share a secret key:\nHMAC vs Plain Hash\nThis example demonstrates the difference between a plain hash and an HMAC:\nSecurity Best Practices\nWhen using HMAC, consider these security best practices:\nUse strong hash algorithms: Prefer SHA-256, SHA-384, SHA-512, or SHA-3 over MD5 and SHA-1.\nUse a strong, random key: The key should be at least as long as the hash output (e.g., 32 bytes for SHA-256).\nKeep the key secret: The security of HMAC depends on the secrecy of the key.\nUse constant-time comparison: When verifying HMAC values, use crypto.timingSafeEqual() to avoid timing attacks.\nUse modern key management: Consider using the KeyObject API or a key management service for sensitive keys.\nConsider HMAC's purpose: HMAC provides data integrity and authentication, not confidentiality. For encryption, combine HMAC with encryption algorithms.\nCommon Use Cases for HMAC\nAPI Authentication: Signing API requests to verify the sender's identity and data integrity.\nMessage Authentication: Ensuring messages haven't been tampered with during transmission.\nCookie/Token Verification: Creating and verifying signed cookies or tokens in web applications.\nFile Integrity Verification: Checking that files haven't been modified or corrupted.\nPassword Storage: Though specialized algorithms like bcrypt are preferred, HMAC can be used as part of a password hashing scheme.\nKey Derivation: As a component in key derivation functions like HKDF.",
      "examples": [
        "// Import the crypto module\nconst crypto = require('crypto');\n\n// Create an Hmac object\nconst hmac = crypto.createHmac('sha256', 'your-secret-key');",
        "const crypto = require('crypto');\n\n// Data to authenticate\nconst data = 'Hello, World!';\n\n// Secret key\nconst secretKey = 'my-secret-key';\n\n// Create an Hmac object\nconst hmac = crypto.createHmac('sha256', secretKey);\n\n// Update the hmac with data\nhmac.update(data);\n\n// Get the digest in hex format\nconst digest = hmac.digest('hex');\n\nconsole.log('Data:', data);\nconsole.log('Secret Key:', secretKey);\nconsole.log('HMAC-SHA256:', digest);",
        "const crypto = require('crypto');\n\n// Data to authenticate\nconst data = 'Node.js Crypto HMAC Example';\n\n// Secret key\nconst secretKey = 'my-secret-key';\n\n// Function to create HMAC with different algorithms\nfunction createHmacWithAlgorithm(algorithm, data, key) {\nconst hmac = crypto.createHmac(algorithm, key);\nhmac.update(data);\nreturn hmac.digest('hex');\n}\n\n// Test various HMAC algorithms\nconst algorithms = ['md5', 'sha1', 'sha256', 'sha512', 'sha3-256', 'sha3-512'];\n\nconsole.log(`Data: \"${data}\"`);\nconsole.log(`Secret Key: \"${secretKey}\"`);\nconsole.log('------------------------------------');\n\nalgorithms.forEach(algorithm => {\ntry {\nconst digest = createHmacWithAlgorithm(algorithm, data, secretKey);\nconsole.log(`HMAC-${algorithm}: ${digest}`);\nconsole.log(`Length: ${digest.length / 2} bytes (${digest.length * 4} bits)`);\nconsole.log('------------------------------------');\n} catch (error) {\nconsole.log(`HMAC-${algorithm}: Not supported - ${error.message}`);\nconsole.log('------------------------------------');\n}\n});",
        "const crypto = require('crypto');\n\n// Secret key\nconst secretKey = 'my-secret-key';\n\n// Create an Hmac object\nconst hmac = crypto.createHmac('sha256', secretKey);\n\n// Update the hmac with multiple pieces of data\nhmac.update('First part of the data.');\nhmac.update(' Second part of the data.');\nhmac.update(' Third part of the data.');\n\n// Calculate the final digest\nconst digest = hmac.digest('hex');\n\nconsole.log('Combined data: First part of the data. Second part of the data. Third part of the data.');\nconsole.log('Secret Key:', secretKey);\nconsole.log('HMAC-SHA256:', digest);\n\n// You can achieve the same result with a single update\nconst singleHmac = crypto.createHmac('sha256', secretKey);\nsingleHmac.update('First part of the data. Second part of the data. Third part of the data.');\nconst singleDigest = singleHmac.digest('hex');\n\nconsole.log('Single update HMAC matches multiple updates?', singleDigest === digest);",
        "const crypto = require('crypto');\n\n// Data to authenticate\nconst data = 'Hello, Node.js!';\n\n// Secret key\nconst secretKey = 'my-secret-key';\n\n// Function to create HMAC and get digest in different encodings\nfunction createHmacWithEncoding(algorithm, data, key, encoding) {\nconst hmac = crypto.createHmac(algorithm, key);\nhmac.update(data);\nreturn hmac.digest(encoding);\n}\n\n// Create HMAC with SHA-256 and display in different encodings\nconsole.log(`Data: \"${data}\"`);\nconsole.log(`Secret Key: \"${secretKey}\"`);\nconsole.log(`HMAC-SHA256 (hex): ${createHmacWithEncoding('sha256', data, secretKey, 'hex')}`);\nconsole.log(`HMAC-SHA256 (base64): ${createHmacWithEncoding('sha256', data, secretKey, 'base64')}`);\nconsole.log(`HMAC-SHA256 (base64url): ${createHmacWithEncoding('sha256', data, secretKey, 'base64url')}`);\nconsole.log(`HMAC-SHA256 (binary): ${createHmacWithEncoding('sha256', data, secretKey, 'binary')}`);\n\n// Get the digest as a Buffer (no encoding)\nconst hmac = crypto.createHmac('sha256', secretKey);\nhmac.update(data);\nconst buffer = hmac.digest();\nconsole.log('HMAC-SHA256 (Buffer):', buffer);\nconsole.log('Buffer length:', buffer.length, 'bytes');",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Function to create HMAC for a file using streams\nfunction createHmacForFile(filePath, algorithm, key) {\nreturn new Promise((resolve, reject) => {\n// Create Hmac object\nconst hmac = crypto.createHmac(algorithm, key);\n\n// Create read stream\nconst stream = fs.createReadStream(filePath);\n\n// Handle stream events\nstream.on('data', (data) => {\nhmac.update(data);\n});\n\nstream.on('end', () => {\nconst digest = hmac.digest('hex');\nresolve(digest);\n});\n\nstream.on('error', (error) => {\nreject(error);\n});\n});\n}\n\n// Secret key\nconst secretKey = 'file-authentication-key';\n\n// Example usage (adjust file path as needed)\nconst filePath = 'example.txt';\n\n// Create a test file if it doesn't exist\nif (!fs.existsSync(filePath)) {\nfs.writeFileSync(filePath, 'This is a test file for HMAC authentication.\\n'.repeat(100));\nconsole.log(`Created test file: ${filePath}`);\n}\n\n// Create HMAC for the file with different algorithms\nPromise.all([\ncreateHmacForFile(filePath, 'md5', secretKey),\ncreateHmacForFile(filePath, 'sha1', secretKey),\ncreateHmacForFile(filePath, 'sha256', secretKey)\n])\n.then(([md5Digest, sha1Digest, sha256Digest]) => {\nconsole.log(`File: ${filePath}`);\nconsole.log(`Secret Key: ${secretKey}`);\nconsole.log(`HMAC-MD5: ${md5Digest}`);\nconsole.log(`HMAC-SHA1: ${sha1Digest}`);\nconsole.log(`HMAC-SHA256: ${sha256Digest}`);\n\n// Store the HMAC for later verification\nfs.writeFileSync(`${filePath}.hmac`, sha256Digest);\nconsole.log(`HMAC stored in: ${filePath}.hmac`);\n})\n.catch(error => {\nconsole.error('Error creating HMAC for file:', error.message);\n});",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Function to create HMAC for a file\nfunction createHmacForFile(filePath, algorithm, key) {\nreturn new Promise((resolve, reject) => {\nconst hmac = crypto.createHmac(algorithm, key);\nconst stream = fs.createReadStream(filePath);\n\nstream.on('data', (data) => {\nhmac.update(data);\n});\n\nstream.on('end', () => {\nconst digest = hmac.digest('hex');\nresolve(digest);\n});\n\nstream.on('error', (error) => {\nreject(error);\n});\n});\n}\n\n// Function to verify file integrity\nasync function verifyFileIntegrity(filePath, storedHmacPath, algorithm, key) {\ntry {\n// Read the stored HMAC\nconst storedHmac = fs.readFileSync(storedHmacPath, 'utf8').trim();\n\n// Calculate the current HMAC\nconst currentHmac = await createHmacForFile(filePath, algorithm, key);\n\n// Compare the HMACs\nconst isValid = currentHmac === storedHmac;\n\nreturn {\nisValid,\nstoredHmac,\ncurrentHmac\n};\n} catch (error) {\nthrow new Error(`Verification failed: ${error.message}`);\n}\n}\n\n// Secret key (must be the same as used to create the original HMAC)\nconst secretKey = 'file-authentication-key';\n\n// Example usage\nconst filePath = 'example.txt';\nconst hmacPath = `${filePath}.hmac`;\n\n// Verify the file integrity\nverifyFileIntegrity(filePath, hmacPath, 'sha256', secretKey)\n.then(result => {\nconsole.log(`File: ${filePath}`);\nconsole.log(`HMAC file: ${hmacPath}`);\nconsole.log(`Integrity verified: ${result.isValid}`);\n\nif (!result.isValid) {\nconsole.log('Stored HMAC:', result.storedHmac);\nconsole.log('Current HMAC:', result.currentHmac);\nconsole.log('The file has been modified!');\n} else {\nconsole.log('The file is intact and has not been tampered with.');\n}\n})\n.catch(error => {\nconsole.error('Error:', error.message);\n});",
        "const crypto = require('crypto');\n\n// Data to authenticate\nconst data = 'Data to authenticate with HMAC';\n\n// Function to create HMAC with different key types\nfunction createHmacWithKey(algorithm, data, key, keyType) {\nconst hmac = crypto.createHmac(algorithm, key);\nhmac.update(data);\nreturn {\nkeyType,\nhmac: hmac.digest('hex')\n};\n}\n\nconsole.log(`Data: \"${data}\"`);\nconsole.log('------------------------------------');\n\n// 1. String key\nconst stringKey = 'my-secret-key';\nconsole.log(createHmacWithKey('sha256', data, stringKey, 'String key'));\n\n// 2. Buffer key\nconst bufferKey = Buffer.from('buffer-secret-key');\nconsole.log(createHmacWithKey('sha256', data, bufferKey, 'Buffer key'));\n\n// 3. TypedArray key\nconst uint8ArrayKey = new Uint8Array([72, 101, 108, 108, 111]); // \"Hello\" in ASCII\nconsole.log(createHmacWithKey('sha256', data, uint8ArrayKey, 'Uint8Array key'));\n\n// 4. DataView key\nconst arrayBuffer = new ArrayBuffer(5);\nconst dataView = new DataView(arrayBuffer);\ndataView.setUint8(0, 72);  // H\ndataView.setUint8(1, 101); // e\ndataView.setUint8(2, 108); // l\ndataView.setUint8(3, 108); // l\ndataView.setUint8(4, 111); // o\nconsole.log(createHmacWithKey('sha256', data, dataView, 'DataView key'));\n\n// 5. KeyObject (recommended for sensitive keys)\nconst keyObject = crypto.createSecretKey(Buffer.from('key-object-secret'));\nconsole.log(createHmacWithKey('sha256', data, keyObject, 'KeyObject'));",
        "const crypto = require('crypto');\n\n// Simulated API request\nfunction createApiRequest(apiKey, secretKey, method, path, queryParams, body, timestamp) {\n// Create the string to sign\nconst stringToSign = [\nmethod.toUpperCase(),\npath,\nnew URLSearchParams(queryParams).toString(),\ntypeof body === 'string' ? body : JSON.stringify(body || {}),\ntimestamp\n].join('\\n');\n\n// Create HMAC signature\nconst hmac = crypto.createHmac('sha256', secretKey);\nhmac.update(stringToSign);\nconst signature = hmac.digest('hex');\n\n// Return the request with authentication headers\nreturn {\nurl: `https://api.example.com${path}?${new URLSearchParams(queryParams)}`,\nmethod,\nheaders: {\n'Content-Type': 'application/json',\n'X-Api-Key': apiKey,\n'X-Timestamp': timestamp,\n'X-Signature': signature\n},\nbody: body || {},\n// For debugging/verification\nstringToSign\n};\n}\n\n// Simulate API server verification\nfunction verifyApiRequest(apiKey, secretKey, method, path, queryParams, body, timestamp, signature) {\n// Recreate the string that was signed\nconst stringToSign = [\nmethod.toUpperCase(),\npath,\nnew URLSearchParams(queryParams).toString(),\ntypeof body === 'string' ? body : JSON.stringify(body || {}),\ntimestamp\n].join('\\n');\n\n// Verify HMAC signature\nconst hmac = crypto.createHmac('sha256', secretKey);\nhmac.update(stringToSign);\nconst expectedSignature = hmac.digest('hex');\n\nreturn {\nisValid: crypto.timingSafeEqual(\nBuffer.from(signature, 'hex'),\nBuffer.from(expectedSignature, 'hex')\n),\nexpectedSignature\n};\n}\n\n// API credentials\nconst apiKey = 'user123';\nconst secretKey = 'very-secret-api-key';\n\n// Create a request\nconst timestamp = new Date().toISOString();\nconst request = createApiRequest(\napiKey,\nsecretKey,\n'POST',\n'/api/v1/users',\n{ filter: 'active' },\n{ name: 'John Doe', email: 'john@example.com' },\ntimestamp\n);\n\nconsole.log('API Request:');\nconsole.log(`URL: ${request.url}`);\nconsole.log(`Method: ${request.method}`);\nconsole.log('Headers:', request.headers);\nconsole.log('Body:', request.body);\nconsole.log('\\nString that was signed:');\nconsole.log(request.stringToSign);\n\n// Server verifies the request\nconst verification = verifyApiRequest(\napiKey,\nsecretKey,\n'POST',\n'/api/v1/users',\n{ filter: 'active' },\n{ name: 'John Doe', email: 'john@example.com' },\ntimestamp,\nrequest.headers['X-Signature']\n);\n\nconsole.log('\\nVerification result:');\nconsole.log(`Is signature valid? ${verification.isValid}`);\n\n// Try with tampered data\nconst tamperedVerification = verifyApiRequest(\napiKey,\nsecretKey,\n'POST',\n'/api/v1/users',\n{ filter: 'active' },\n{ name: 'Jane Doe', email: 'jane@example.com' }, // Changed body\ntimestamp,\nrequest.headers['X-Signature']\n);\n\nconsole.log('\\nTampered verification result:');\nconsole.log(`Is signature valid? ${tamperedVerification.isValid}`);",
        "const crypto = require('crypto');\n\n// Data and keys\nconst data = 'Message to authenticate';\nconst key1 = 'secret-key-1';\nconst key2 = 'secret-key-2';\n\n// Plain SHA-256 hash (no key)\nfunction createHash(data) {\nconst hash = crypto.createHash('sha256');\nhash.update(data);\nreturn hash.digest('hex');\n}\n\n// HMAC-SHA-256 (with key)\nfunction createHmac(data, key) {\nconst hmac = crypto.createHmac('sha256', key);\nhmac.update(data);\nreturn hmac.digest('hex');\n}\n\n// Compare results\nconsole.log(`Data: \"${data}\"`);\nconsole.log('\\nPlain SHA-256 (no key):');\nconsole.log(createHash(data));\n\nconsole.log('\\nHMAC-SHA-256 with key1:');\nconsole.log(createHmac(data, key1));\n\nconsole.log('\\nHMAC-SHA-256 with key2:');\nconsole.log(createHmac(data, key2));\n\n// Demonstrate hash extension attack vulnerability\n// This is a simplified illustration - actual extension attacks are more complex\nconsole.log('\\nHash Extension Attack Vulnerability:');\n\nconst originalData = 'original-message';\nconst originalHash = createHash(originalData);\nconsole.log(`Original data: \"${originalData}\"`);\nconsole.log(`Original SHA-256: ${originalHash}`);\n\n// Attacker doesn't know the original data, but knows its hash\n// and wants to append malicious data\nconst appendedData = 'malicious-appendage';\nconst combinedData = `${originalData}${appendedData}`;\nconst combinedHash = createHash(combinedData);\nconsole.log(`Appended data: \"${appendedData}\"`);\nconsole.log(`Combined data: \"${combinedData}\"`);\nconsole.log(`Combined SHA-256: ${combinedHash}`);\nconsole.log('With plain hash, an attacker who knows the hash of original data can compute valid hash for combined data without knowing the original data');\n\n// HMAC is not vulnerable to extension attacks\nconsole.log('\\nHMAC Protection:');\nconst originalHmac = createHmac(originalData, key1);\nconst combinedHmac = createHmac(combinedData, key1);\nconsole.log(`Original HMAC: ${originalHmac}`);\nconsole.log(`Combined HMAC: ${combinedHmac}`);\nconsole.log('With HMAC, an attacker cannot compute a valid HMAC for combined data without knowing the secret key');",
        "crypto",
        "crypto.createHmac()",
        "data",
        "inputEncoding",
        "hmac.update()",
        "encoding",
        "crypto.timingSafeEqual()"
      ]
    },
    {
      "title": "Node.js Sign Reference",
      "summary": "Sign Object\nThe Sign class is part of Node.js's crypto module. It provides a way to generate cryptographic digital signatures. Sign instances are created using the crypto.createSign() method.\nDigital signatures allow you to verify the authenticity and integrity of a message, ensuring that it was created by a known sender and was not altered in transit.\nImport Crypto Module\nSign Methods\nBasic Sign Example\nThe following example demonstrates how to create a digital signature of a message:\nSigning with Different Algorithms\nThe Sign class supports various signature algorithms, depending on the crypto provider:\nThe available signature algorithms depend on your Node.js version and the installed OpenSSL version. Common signature algorithms include:\nSigning with Multiple Updates\nYou can update a Sign object with multiple pieces of data before calculating the signature:\nSigning Files\nYou can create a digital signature for a file's contents:\nUsing Different Types of Keys\nThe Sign class can work with different formats of private keys:\nComplete Sign and Verify Example\nThis example demonstrates the full process of creating and verifying a digital signature:\nDSA and ECDSA Signatures\nThis example demonstrates using DSA and ECDSA for digital signatures:\nSigning with OpenSSL Options\nAdvanced signing with specific OpenSSL options:\nSecurity Best Practices\nWhen using digital signatures, consider these security best practices:\nUse strong keys: For RSA, use at least 2048 bits. For ECDSA, use curves like prime256v1 (P-256) or stronger.\nUse modern signature algorithms: Prefer RSA-PSS over PKCS#1 v1.5, and consider ECDSA or EdDSA for better performance.\nProtect private keys: Store private keys securely, possibly using a hardware security module (HSM) or key management service.\nUse strong hash algorithms: Always use SHA-256 or stronger for the underlying hash function.\nValidate data before signing: Ensure you're signing the intended data to avoid signing malicious content.\nConsider key rotation: Regularly update your signing keys, especially for long-term applications.\nUse KeyObject: When possible, use the KeyObject API for better security and to prevent sensitive key material from being directly accessible.\nCommon Use Cases for Digital Signatures\nCode Signing: Signing software packages, executables, or scripts to verify their authenticity and integrity.\nDocument Signing: Creating legally binding electronic signatures for PDFs and other documents.\nJWT Signing: Signing JSON Web Tokens (JWTs) for secure authentication and authorization.\nAPI Authentication: Verifying the identity of API clients and ensuring request integrity.\nCertificate Signing: Creating and validating certificate chains in a PKI system.\nSecure Communication: Authenticating messages in secure communication protocols.",
      "examples": [
        "// Import the crypto module\nconst crypto = require('crypto');\n\n// Create a Sign object\nconst sign = crypto.createSign('RSA-SHA256');",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Generate a keypair for this example\nfunction generateKeyPair() {\nreturn crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n}\n\n// For this example, generate keys in memory\n// In a real application, you would load existing keys from storage\nconst { privateKey, publicKey } = generateKeyPair();\n\n// Message to sign\nconst message = 'This is a message to be signed';\n\n// Create a Sign object\nconst sign = crypto.createSign('SHA256');\n\n// Update with the message\nsign.update(message);\n\n// Sign the message with the private key\nconst signature = sign.sign(privateKey, 'hex');\n\nconsole.log('Message:', message);\nconsole.log('Signature:', signature);\n\n// We'll save these for the verification example\nfs.writeFileSync('message.txt', message);\nfs.writeFileSync('signature.hex', signature);\nfs.writeFileSync('public_key.pem', publicKey);",
        "const crypto = require('crypto');\n\n// Generate key pairs for different algorithms\nfunction generateRSAKeyPair() {\nreturn crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n}\n\nfunction generateECKeyPair() {\nreturn crypto.generateKeyPairSync('ec', {\nnamedCurve: 'prime256v1',\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'sec1',\nformat: 'pem'\n}\n});\n}\n\n// Generate different key pairs\nconst rsaKeys = generateRSAKeyPair();\nconst ecKeys = generateECKeyPair();\n\n// Message to sign\nconst message = 'Message to sign with different algorithms';\n\n// Function to sign with a specific algorithm\nfunction signWithAlgorithm(algorithm, privateKey, message) {\ntry {\nconst sign = crypto.createSign(algorithm);\nsign.update(message);\nreturn sign.sign(privateKey, 'hex');\n} catch (error) {\nreturn `Error: ${error.message}`;\n}\n}\n\n// Test various signature algorithms\nconsole.log(`Message: \"${message}\"`);\nconsole.log('-----------------------------------------------');\n\n// RSA signatures with different hash algorithms\nconsole.log('RSA-SHA256:', signWithAlgorithm('SHA256', rsaKeys.privateKey, message));\nconsole.log('RSA-SHA384:', signWithAlgorithm('SHA384', rsaKeys.privateKey, message));\nconsole.log('RSA-SHA512:', signWithAlgorithm('SHA512', rsaKeys.privateKey, message));\n\nconsole.log('-----------------------------------------------');\n\n// ECDSA signatures\nconsole.log('ECDSA-SHA256:', signWithAlgorithm('SHA256', ecKeys.privateKey, message));\nconsole.log('ECDSA-SHA384:', signWithAlgorithm('SHA384', ecKeys.privateKey, message));",
        "const crypto = require('crypto');\n\n// Generate a keypair for this example\nconst { privateKey, publicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Create a Sign object\nconst sign = crypto.createSign('SHA256');\n\n// Update with multiple pieces of data\nsign.update('First part of the message. ');\nsign.update('Second part of the message. ');\nsign.update('Third part of the message.');\n\n// Create the signature\nconst signature = sign.sign(privateKey, 'hex');\n\nconsole.log('Combined message: First part of the message. Second part of the message. Third part of the message.');\nconsole.log('Signature:', signature);\n\n// You can achieve the same result with a single update\nconst singleSign = crypto.createSign('SHA256');\nsingleSign.update('First part of the message. Second part of the message. Third part of the message.');\nconst singleSignature = singleSign.sign(privateKey, 'hex');\n\nconsole.log('Single update signature matches multiple updates?', singleSignature === signature);",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Function to sign a file\nfunction signFile(filePath, privateKey, algorithm = 'SHA256') {\nreturn new Promise((resolve, reject) => {\n// Create Sign object\nconst sign = crypto.createSign(algorithm);\n\n// Create read stream\nconst readStream = fs.createReadStream(filePath);\n\n// Handle stream events\nreadStream.on('data', (data) => {\nsign.update(data);\n});\n\nreadStream.on('end', () => {\n// Create signature\nconst signature = sign.sign(privateKey, 'hex');\nresolve(signature);\n});\n\nreadStream.on('error', (error) => {\nreject(error);\n});\n});\n}\n\n// Generate a keypair for this example\nconst { privateKey, publicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Save the public key for verification\nfs.writeFileSync('public_key_file.pem', publicKey);\n\n// Example usage (adjust file path as needed)\nconst filePath = 'example_to_sign.txt';\n\n// Create a test file if it doesn't exist\nif (!fs.existsSync(filePath)) {\nfs.writeFileSync(filePath, 'This is a test file for digital signature.\\n'.repeat(100));\nconsole.log(`Created test file: ${filePath}`);\n}\n\n// Sign the file\nsignFile(filePath, privateKey)\n.then(signature => {\nconsole.log(`File: ${filePath}`);\nconsole.log(`Signature: ${signature}`);\n\n// Save the signature for later verification\nfs.writeFileSync(`${filePath}.sig`, signature);\nconsole.log(`Signature saved to: ${filePath}.sig`);\n})\n.catch(error => {\nconsole.error('Error signing file:', error.message);\n});",
        "const crypto = require('crypto');\n\n// Message to sign\nconst message = 'Message to sign with different key formats';\n\n// Function to sign with different key formats\nfunction signWithKey(privateKey, keyFormat) {\ntry {\nconst sign = crypto.createSign('SHA256');\nsign.update(message);\nreturn {\nformat: keyFormat,\nsignature: sign.sign(privateKey, 'hex')\n};\n} catch (error) {\nreturn {\nformat: keyFormat,\nerror: error.message\n};\n}\n}\n\n// Generate a new RSA key pair\nconst { privateKey: pemPrivateKey, publicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\nconsole.log(`Message: \"${message}\"`);\n\n// 1. Sign with PEM-encoded private key (string)\nconsole.log('\\n1. PEM-encoded private key (string):');\nconsole.log(signWithKey(pemPrivateKey, 'PEM string'));\n\n// 2. Sign with PEM-encoded private key (buffer)\nconsole.log('\\n2. PEM-encoded private key (buffer):');\nconsole.log(signWithKey(Buffer.from(pemPrivateKey), 'PEM buffer'));\n\n// 3. Sign with KeyObject\nconsole.log('\\n3. KeyObject:');\nconst keyObject = crypto.createPrivateKey(pemPrivateKey);\nconsole.log(signWithKey(keyObject, 'KeyObject'));\n\n// 4. Sign with PassThrough crypto engine (if available)\ntry {\n// Note: This might not be available in all Node.js versions/configurations\nconsole.log('\\n4. Private key with engine:');\nconst engineKey = {\nkey: pemPrivateKey,\npadding: crypto.constants.RSA_PKCS1_PADDING\n};\nconsole.log(signWithKey(engineKey, 'Key with options'));\n} catch (error) {\nconsole.log('\\n4. Private key with engine:');\nconsole.log({ format: 'Key with options', error: error.message });\n}\n\n// 5. Sign with JSON Web Key (JWK)\n// Note: This requires conversion, as Node.js doesn't directly support JWK for sign\nconsole.log('\\n5. JWK (requires conversion):');\ntry {\n// This is a simplified example - actual JWK handling would be more complex\nconst pemToJwk = require('pem-jwk').pem2jwk; // You would need to install this package\nconst jwk = pemToJwk(pemPrivateKey);\nconsole.log({ format: 'JWK', note: 'JWK needs to be converted to PEM or KeyObject first' });\n} catch (error) {\nconsole.log({ format: 'JWK', note: 'Example requires pem-jwk package' });\n}",
        "const crypto = require('crypto');\n\n// Generate a keypair\nconst { privateKey, publicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Original message\nconst message = 'This is the original message to sign and verify';\nconsole.log(`Original message: \"${message}\"`);\n\n// Sign the message\nfunction signMessage(message, privateKey) {\nconst sign = crypto.createSign('SHA256');\nsign.update(message);\nreturn sign.sign(privateKey, 'hex');\n}\n\nconst signature = signMessage(message, privateKey);\nconsole.log(`Signature: ${signature}`);\n\n// Verify the message (using the Verify class)\nfunction verifySignature(message, signature, publicKey) {\nconst verify = crypto.createVerify('SHA256');\nverify.update(message);\nreturn verify.verify(publicKey, signature, 'hex');\n}\n\n// Verify the original message\nconst isValidOriginal = verifySignature(message, signature, publicKey);\nconsole.log(`Original message verification: ${isValidOriginal}`);\n\n// Try to verify a tampered message\nconst tamperedMessage = message + ' with some tampering';\nconst isValidTampered = verifySignature(tamperedMessage, signature, publicKey);\nconsole.log(`Tampered message verification: ${isValidTampered}`);\n\n// Try to use a different public key\nconst { publicKey: differentPublicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\nconst isValidDifferentKey = verifySignature(message, signature, differentPublicKey);\nconsole.log(`Verification with different public key: ${isValidDifferentKey}`);",
        "const crypto = require('crypto');\n\n// Message to sign\nconst message = 'Message for DSA and ECDSA signatures';\n\n// Generate ECDSA key pair\nfunction generateECKeyPair(curveName = 'prime256v1') {\nreturn crypto.generateKeyPairSync('ec', {\nnamedCurve: curveName,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'sec1', // or 'pkcs8'\nformat: 'pem'\n}\n});\n}\n\n// Function to sign and verify with a specific algorithm and key pair\nfunction testSignatureAlgorithm(algorithm, keyType, keyPair, message) {\ntry {\n// Sign the message\nconst sign = crypto.createSign(algorithm);\nsign.update(message);\nconst signature = sign.sign(keyPair.privateKey, 'hex');\n\n// Verify the signature\nconst verify = crypto.createVerify(algorithm);\nverify.update(message);\nconst isValid = verify.verify(keyPair.publicKey, signature, 'hex');\n\nreturn {\nalgorithm: `${keyType}-${algorithm}`,\nsignatureLength: signature.length / 2, // Convert hex to bytes\nisValid\n};\n} catch (error) {\nreturn {\nalgorithm: `${keyType}-${algorithm}`,\nerror: error.message\n};\n}\n}\n\n// Test ECDSA with different curves\nconst curves = ['prime256v1', 'secp384r1', 'secp521r1'];\n\nconsole.log(`Message: \"${message}\"`);\nconsole.log('\\nECDSA Signatures:');\n\ncurves.forEach(curve => {\nconst ecKeyPair = generateECKeyPair(curve);\n\n// Test with different hash algorithms\nconst hashAlgos = ['SHA256', 'SHA384', 'SHA512'];\n\nhashAlgos.forEach(hashAlgo => {\nconst result = testSignatureAlgorithm(hashAlgo, `ECDSA-${curve}`, ecKeyPair, message);\nconsole.log(result);\n});\n});\n\n// Test EdDSA if available\ntry {\nconsole.log('\\nEdDSA Signatures:');\n\n// Ed25519\nconst ed25519KeyPair = crypto.generateKeyPairSync('ed25519', {\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Sign with Ed25519\nconst sign = crypto.createSign('SHA512'); // Hash algorithm is ignored for Ed25519\nsign.update(message);\nconst signature = sign.sign(ed25519KeyPair.privateKey, 'hex');\n\n// Verify with Ed25519\nconst verify = crypto.createVerify('SHA512');\nverify.update(message);\nconst isValid = verify.verify(ed25519KeyPair.publicKey, signature, 'hex');\n\nconsole.log({\nalgorithm: 'Ed25519',\nsignatureLength: signature.length / 2,\nisValid\n});\n} catch (error) {\nconsole.log({\nalgorithm: 'Ed25519',\nerror: error.message\n});\n}",
        "const crypto = require('crypto');\n\n// Generate RSA key pair\nconst { privateKey, publicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Message to sign\nconst message = 'Message to sign with different options';\n\n// Function to sign with specific options\nfunction signWithOptions(algorithm, message, privateKey, options = {}) {\ntry {\n// Create private key with options\nconst keyWithOptions = {\nkey: privateKey,\n...options\n};\n\n// Sign the message\nconst sign = crypto.createSign(algorithm);\nsign.update(message);\nreturn sign.sign(keyWithOptions, 'hex');\n} catch (error) {\nreturn `Error: ${error.message}`;\n}\n}\n\nconsole.log(`Message: \"${message}\"`);\nconsole.log('\\nRSA Signatures with Different Options:');\n\n// 1. Standard PKCS#1 v1.5 padding (default)\nconsole.log('\\n1. Standard PKCS#1 v1.5 padding:');\nconst sig1 = signWithOptions('SHA256', message, privateKey);\nconsole.log(sig1);\n\n// 2. PSS padding\nconsole.log('\\n2. PSS padding:');\nconst sig2 = signWithOptions('SHA256', message, privateKey, {\npadding: crypto.constants.RSA_PKCS1_PSS_PADDING,\nsaltLength: 32\n});\nconsole.log(sig2);\n\n// 3. Different salt lengths with PSS padding\nconsole.log('\\n3. PSS padding with different salt lengths:');\n[20, 32, 48].forEach(saltLength => {\ntry {\nconst sigSalt = signWithOptions('SHA256', message, privateKey, {\npadding: crypto.constants.RSA_PKCS1_PSS_PADDING,\nsaltLength\n});\nconsole.log(`Salt length ${saltLength}: ${sigSalt.substring(0, 64)}...`);\n} catch (error) {\nconsole.log(`Salt length ${saltLength}: Error - ${error.message}`);\n}\n});\n\n// 4. Try to use no padding (will likely fail for signatures)\nconsole.log('\\n4. No padding (expect error):');\nconst sig4 = signWithOptions('SHA256', message, privateKey, {\npadding: crypto.constants.RSA_NO_PADDING\n});\nconsole.log(sig4);",
        "crypto",
        "crypto.createSign()",
        "data",
        "inputEncoding",
        "sign.update()",
        "privateKey",
        "outputEncoding"
      ]
    },
    {
      "title": "Node.js Verify Reference",
      "summary": "Verify Object\nThe Verify class is part of Node.js's crypto module.\nIt provides a way to verify cryptographic digital signatures.\nVerify instances are created using the crypto.createVerify() method.\nVerify is used in conjunction with the Sign class to validate that a message was signed by a known sender and was not altered in transit.\nImport Crypto Module\nVerify Methods\nBasic Verify Example\nThe following example demonstrates how to verify a digital signature of a message:\nVerifying with Different Algorithms\nThe Verify class supports various signature algorithms:\nVerifying with Multiple Updates\nYou can update a Verify object with multiple pieces of data:\nVerifying File Signatures\nThis example demonstrates verifying a digital signature for a file:\nVerifying with Different Key Types\nThe Verify class can work with different formats of public keys:\nVerifying with Advanced Options\nVerifying signatures with specific OpenSSL options:\nCertificate-Based Verification\nVerifying signatures using X.509 certificates:\nSecurity Best Practices\nWhen verifying digital signatures, consider these security best practices:\nTrust management: Validate the source of the public key used for verification. Don't trust a public key unless it comes from a trusted source.\nCertificate validation: When using certificates, verify the entire certificate chain and check certificate revocation status.\nMatching signing algorithm: Ensure the verification algorithm matches the signing algorithm, including any options like padding or salt length.\nInput validation: Validate and sanitize any data before verification to prevent injection attacks.\nFail securely: Always default to rejecting signatures that fail verification for any reason.\nKeep verification code simple: Complexity increases the risk of verification bypass vulnerabilities.\nConsider timing attacks: Signature verification may be vulnerable to timing attacks in some implementations.\nCommon Use Cases for Signature Verification\nSoftware Updates: Verifying the authenticity of updates before installation.\nDocument Verification: Ensuring digitally signed documents haven't been modified.\nAPI Authentication: Verifying the identity of API requests.\nJWT Validation: Verifying JSON Web Token signatures.\nCertificate Chain Validation: Verifying signatures in a certificate chain.\nSecure Communication: Authenticating messages in secure protocols.",
      "examples": [
        "// Import the crypto module\nconst crypto = require('crypto');\n\n// Create a Verify object\nconst verify = crypto.createVerify('RSA-SHA256');",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Load the message, signature, and public key\n// In a real application, these would typically come from files or network\n// For this example, we'll try to load from the files created in the Sign example\nlet message, signature, publicKey;\n\ntry {\nmessage = fs.readFileSync('message.txt', 'utf8');\nsignature = fs.readFileSync('signature.hex', 'utf8');\npublicKey = fs.readFileSync('public_key.pem', 'utf8');\n} catch (error) {\n// If files don't exist, create example data\nconst { privateKey, publicKey: newPublicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\nmessage = 'This is a message to be verified';\npublicKey = newPublicKey;\n\n// Create a signature for the example\nconst sign = crypto.createSign('SHA256');\nsign.update(message);\nsignature = sign.sign(privateKey, 'hex');\n}\n\n// Create a Verify object\nconst verify = crypto.createVerify('SHA256');\n\n// Update with the message\nverify.update(message);\n\n// Verify the signature with the public key\nconst isValid = verify.verify(publicKey, signature, 'hex');\n\nconsole.log('Message:', message);\nconsole.log('Signature:', signature);\nconsole.log('Is signature valid?', isValid);",
        "const crypto = require('crypto');\n\n// Generate key pairs for different algorithms\nfunction generateRSAKeyPair() {\nreturn crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n}\n\nfunction generateECKeyPair() {\nreturn crypto.generateKeyPairSync('ec', {\nnamedCurve: 'prime256v1',\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'sec1',\nformat: 'pem'\n}\n});\n}\n\n// Generate different key pairs\nconst rsaKeys = generateRSAKeyPair();\nconst ecKeys = generateECKeyPair();\n\n// Message to sign and verify\nconst message = 'Message to verify with different algorithms';\n\n// Function to sign and verify with a specific algorithm\nfunction testSignatureVerification(algorithm, privateKey, publicKey, message) {\ntry {\n// Sign the message\nconst sign = crypto.createSign(algorithm);\nsign.update(message);\nconst signature = sign.sign(privateKey, 'hex');\n\n// Verify the signature\nconst verify = crypto.createVerify(algorithm);\nverify.update(message);\nconst isValid = verify.verify(publicKey, signature, 'hex');\n\n// Try to verify with a tampered message\nconst tamperedVerify = crypto.createVerify(algorithm);\ntamperedVerify.update(message + ' (tampered)');\nconst isTamperedValid = tamperedVerify.verify(publicKey, signature, 'hex');\n\nreturn {\nalgorithm,\nisValid,\nisTamperedValid\n};\n} catch (error) {\nreturn {\nalgorithm,\nerror: error.message\n};\n}\n}\n\n// Test various signature algorithms\nconsole.log(`Message: \"${message}\"`);\nconsole.log('-----------------------------------------------');\n\n// RSA signatures with different hash algorithms\nconsole.log('RSA Signatures:');\n['SHA256', 'SHA384', 'SHA512'].forEach(hash => {\nconsole.log(testSignatureVerification(hash, rsaKeys.privateKey, rsaKeys.publicKey, message));\n});\n\nconsole.log('-----------------------------------------------');\n\n// ECDSA signatures\nconsole.log('ECDSA Signatures:');\n['SHA256', 'SHA384'].forEach(hash => {\nconsole.log(testSignatureVerification(hash, ecKeys.privateKey, ecKeys.publicKey, message));\n});",
        "const crypto = require('crypto');\n\n// Generate a keypair\nconst { privateKey, publicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Create a signature with multiple updates\nconst sign = crypto.createSign('SHA256');\nsign.update('First part of the message. ');\nsign.update('Second part of the message. ');\nsign.update('Third part of the message.');\nconst signature = sign.sign(privateKey, 'hex');\n\nconsole.log('Signature created with multiple updates');\n\n// Create a Verify object\nconst verify = crypto.createVerify('SHA256');\n\n// Verify with multiple updates matching the original\nverify.update('First part of the message. ');\nverify.update('Second part of the message. ');\nverify.update('Third part of the message.');\nconst isValidMultiple = verify.verify(publicKey, signature, 'hex');\n\nconsole.log('Verification with matching multiple updates:', isValidMultiple);\n\n// Verify with a single update containing the same data\nconst verifySingle = crypto.createVerify('SHA256');\nverifySingle.update('First part of the message. Second part of the message. Third part of the message.');\nconst isValidSingle = verifySingle.verify(publicKey, signature, 'hex');\n\nconsole.log('Verification with single update of same data:', isValidSingle);\n\n// Try to verify with different updates\nconst verifyDifferent = crypto.createVerify('SHA256');\nverifyDifferent.update('First part of the message. ');\nverifyDifferent.update('Modified second part. ');\nverifyDifferent.update('Third part of the message.');\nconst isValidDifferent = verifyDifferent.verify(publicKey, signature, 'hex');\n\nconsole.log('Verification with different updates:', isValidDifferent);",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Function to verify a file's signature\nfunction verifyFile(filePath, signaturePath, publicKey, algorithm = 'SHA256') {\nreturn new Promise((resolve, reject) => {\ntry {\n// Read the signature\nconst signature = fs.readFileSync(signaturePath, 'utf8');\n\n// Create Verify object\nconst verify = crypto.createVerify(algorithm);\n\n// Create read stream for the file\nconst readStream = fs.createReadStream(filePath);\n\n// Handle stream events\nreadStream.on('data', (data) => {\nverify.update(data);\n});\n\nreadStream.on('end', () => {\n// Verify the signature\nconst isValid = verify.verify(publicKey, signature, 'hex');\nresolve(isValid);\n});\n\nreadStream.on('error', (error) => {\nreject(error);\n});\n} catch (error) {\nreject(error);\n}\n});\n}\n\n// For this example, create a file, sign it, and verify it\nconst filePath = 'example_to_verify.txt';\nconst signaturePath = `${filePath}.sig`;\nconst publicKeyPath = 'verify_public_key.pem';\n\n// Create a test environment if files don't exist\nif (!fs.existsSync(filePath) || !fs.existsSync(signaturePath) || !fs.existsSync(publicKeyPath)) {\nconsole.log('Creating test environment...');\n\n// Generate a keypair\nconst { privateKey, publicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Save the public key\nfs.writeFileSync(publicKeyPath, publicKey);\n\n// Create a test file\nfs.writeFileSync(filePath, 'This is a test file for signature verification.\\n'.repeat(100));\n\n// Sign the file\nconst sign = crypto.createSign('SHA256');\nconst fileContent = fs.readFileSync(filePath);\nsign.update(fileContent);\nconst signature = sign.sign(privateKey, 'hex');\n\n// Save the signature\nfs.writeFileSync(signaturePath, signature);\n\nconsole.log('Test environment created');\n}\n\n// Load the public key\nconst publicKey = fs.readFileSync(publicKeyPath, 'utf8');\n\n// Verify the file signature\nverifyFile(filePath, signaturePath, publicKey)\n.then(isValid => {\nconsole.log(`File: ${filePath}`);\nconsole.log(`Signature: ${signaturePath}`);\nconsole.log(`Verification result: ${isValid ? 'Valid signature' : 'Invalid signature'}`);\n\n// Demonstrate a tampered file\nif (isValid) {\nconst tamperedFilePath = `${filePath}.tampered`;\nfs.copyFileSync(filePath, tamperedFilePath);\n\n// Make a small change to the file\nconst content = fs.readFileSync(tamperedFilePath, 'utf8');\nfs.writeFileSync(tamperedFilePath, content.replace('verification', 'TAMPERED'));\n\n// Verify the tampered file with the original signature\nreturn verifyFile(tamperedFilePath, signaturePath, publicKey)\n.then(isTamperedValid => {\nconsole.log(`\\nTampered file: ${tamperedFilePath}`);\nconsole.log(`Verification result: ${isTamperedValid ? 'Valid signature (unexpected!)' : 'Invalid signature (expected)'}`);\n});\n}\n})\n.catch(error => {\nconsole.error('Error verifying file:', error.message);\n});",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Message to sign and verify\nconst message = 'Message to verify with different key formats';\n\n// Function to sign and verify with different key formats\nfunction verifyWithKeyFormat(publicKey, keyFormat, algorithm = 'SHA256') {\ntry {\n// Generate keypair for test\nconst { privateKey, publicKey: generatedPublicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Sign the message with private key\nconst sign = crypto.createSign(algorithm);\nsign.update(message);\nconst signature = sign.sign(privateKey, 'hex');\n\n// Verify with the provided public key format\nconst verify = crypto.createVerify(algorithm);\nverify.update(message);\nreturn {\nformat: keyFormat,\nisValid: verify.verify(publicKey, signature, 'hex')\n};\n} catch (error) {\nreturn {\nformat: keyFormat,\nerror: error.message\n};\n}\n}\n\n// Generate an RSA key pair\nconst { privateKey, publicKey: pemPublicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Sign the message for verification tests\nconst sign = crypto.createSign('SHA256');\nsign.update(message);\nconst signature = sign.sign(privateKey, 'hex');\n\n// Function to verify with different key formats\nfunction testVerifyWithKey(publicKey, keyFormat) {\ntry {\nconst verify = crypto.createVerify('SHA256');\nverify.update(message);\nreturn {\nformat: keyFormat,\nisValid: verify.verify(publicKey, signature, 'hex')\n};\n} catch (error) {\nreturn {\nformat: keyFormat,\nerror: error.message\n};\n}\n}\n\nconsole.log(`Message: \"${message}\"`);\nconsole.log('Signature:', signature.substring(0, 32) + '...');\n\n// 1. Verify with PEM-encoded public key (string)\nconsole.log('\\n1. PEM-encoded public key (string):');\nconsole.log(testVerifyWithKey(pemPublicKey, 'PEM string'));\n\n// 2. Verify with PEM-encoded public key (buffer)\nconsole.log('\\n2. PEM-encoded public key (buffer):');\nconsole.log(testVerifyWithKey(Buffer.from(pemPublicKey), 'PEM buffer'));\n\n// 3. Verify with KeyObject\nconsole.log('\\n3. KeyObject:');\nconst keyObject = crypto.createPublicKey(pemPublicKey);\nconsole.log(testVerifyWithKey(keyObject, 'KeyObject'));\n\n// 4. Try to verify with X.509 certificate\nconsole.log('\\n4. X.509 Certificate (simulated):');\nconsole.log({\nformat: 'X.509 Certificate',\nnote: 'In a real scenario, you would load an X.509 certificate containing the public key'\n});\n\n// 5. Try to verify with JWK (requires conversion)\nconsole.log('\\n5. JWK (requires conversion):');\nconsole.log({\nformat: 'JWK',\nnote: 'JWK needs to be converted to PEM or KeyObject first'\n});",
        "const crypto = require('crypto');\n\n// Generate RSA key pair\nconst { privateKey, publicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// Message to sign\nconst message = 'Message to verify with different options';\n\n// Function to sign with specific options\nfunction signWithOptions(algorithm, message, privateKey, options = {}) {\n// Create private key with options\nconst keyWithOptions = {\nkey: privateKey,\n...options\n};\n\n// Sign the message\nconst sign = crypto.createSign(algorithm);\nsign.update(message);\nreturn sign.sign(keyWithOptions, 'hex');\n}\n\n// Function to verify with specific options\nfunction verifyWithOptions(algorithm, message, publicKey, signature, options = {}) {\ntry {\n// Create public key with options\nconst keyWithOptions = {\nkey: publicKey,\n...options\n};\n\n// Verify the signature\nconst verify = crypto.createVerify(algorithm);\nverify.update(message);\nreturn verify.verify(keyWithOptions, signature, 'hex');\n} catch (error) {\nreturn `Error: ${error.message}`;\n}\n}\n\nconsole.log(`Message: \"${message}\"`);\n\n// 1. Sign and verify with standard PKCS#1 v1.5 padding (default)\nconst sig1 = signWithOptions('SHA256', message, privateKey);\nconsole.log('\\n1. Standard PKCS#1 v1.5 padding:');\nconsole.log('Signature:', sig1.substring(0, 32) + '...');\nconsole.log('Verification result:', verifyWithOptions('SHA256', message, publicKey, sig1));\n\n// 2. Sign and verify with PSS padding\nconst pssOptions = {\npadding: crypto.constants.RSA_PKCS1_PSS_PADDING,\nsaltLength: 32\n};\nconst sig2 = signWithOptions('SHA256', message, privateKey, pssOptions);\nconsole.log('\\n2. PSS padding:');\nconsole.log('Signature:', sig2.substring(0, 32) + '...');\nconsole.log('Verification result (matching options):',\nverifyWithOptions('SHA256', message, publicKey, sig2, pssOptions));\nconsole.log('Verification result (default options):',\nverifyWithOptions('SHA256', message, publicKey, sig2));\n\n// 3. Verify with PSS padding and different salt lengths\nconsole.log('\\n3. PSS padding with different salt lengths:');\n[20, 32, 48].forEach(saltLength => {\nconst sigSalt = signWithOptions('SHA256', message, privateKey, {\npadding: crypto.constants.RSA_PKCS1_PSS_PADDING,\nsaltLength\n});\n\nconsole.log(`Salt length ${saltLength}:`);\n\n// Try to verify with correct salt length\nconsole.log(`  - Verify with correct salt length (${saltLength}):`,\nverifyWithOptions('SHA256', message, publicKey, sigSalt, {\npadding: crypto.constants.RSA_PKCS1_PSS_PADDING,\nsaltLength\n}));\n\n// Try to verify with wrong salt length\nconst wrongSaltLength = saltLength + 10;\nconsole.log(`  - Verify with wrong salt length (${wrongSaltLength}):`,\nverifyWithOptions('SHA256', message, publicKey, sigSalt, {\npadding: crypto.constants.RSA_PKCS1_PSS_PADDING,\nsaltLength: wrongSaltLength\n}));\n});",
        "const crypto = require('crypto');\nconst fs = require('fs');\n\n// Function to simulate a certificate-based verification\nfunction demonstrateCertificateVerification() {\nconsole.log('Certificate-Based Verification Demonstration');\nconsole.log('-------------------------------------------');\n\nconsole.log('In a real application, you would:');\nconsole.log('1. Obtain an X.509 certificate containing the signer\\'s public key');\nconsole.log('2. Verify the certificate\\'s trust chain');\nconsole.log('3. Extract the public key from the certificate');\nconsole.log('4. Use that public key to verify the signature');\n\nconsole.log('\\nSimplified example:');\n\n// Generate a key pair\nconst { privateKey, publicKey } = crypto.generateKeyPairSync('rsa', {\nmodulusLength: 2048,\npublicKeyEncoding: {\ntype: 'spki',\nformat: 'pem'\n},\nprivateKeyEncoding: {\ntype: 'pkcs8',\nformat: 'pem'\n}\n});\n\n// In a real app, you'd have a certificate with the public key\nconst mockCertificate = `-----BEGIN CERTIFICATE-----\n(This would be a real X.509 certificate containing the public key)\n-----END CERTIFICATE-----`;\n\n// Message to sign\nconst message = 'Message signed with a certificate-backed key';\n\n// Sign the message\nconst sign = crypto.createSign('SHA256');\nsign.update(message);\nconst signature = sign.sign(privateKey, 'hex');\n\nconsole.log(`Message: \"${message}\"`);\nconsole.log(`Signature: ${signature.substring(0, 32)}...`);\n\nconsole.log('\\nVerification steps:');\nconsole.log('1. Extract public key from certificate (simulated)');\n\n// In a real scenario, you'd extract the public key from the certificate\n// For this example, we'll use our generated public key directly\nconsole.log('2. Verify the signature using the extracted public key');\n\nconst verify = crypto.createVerify('SHA256');\nverify.update(message);\nconst isValid = verify.verify(publicKey, signature, 'hex');\n\nconsole.log(`Verification result: ${isValid ? 'Valid signature' : 'Invalid signature'}`);\n}\n\n// Run the demonstration\ndemonstrateCertificateVerification();",
        "crypto",
        "crypto.createVerify()",
        "data",
        "inputEncoding",
        "object",
        "signature",
        "signatureEncoding",
        "true",
        "false"
      ]
    },
    {
      "title": "Node.js Socket Reference",
      "summary": "Socket Object\nThe Socket class is a duplex stream that allows for reading and writing data across network connections. It is used for both client and server connections in Node.js's net module.\nA Socket represents a TCP or IPC connection to a remote endpoint, providing methods and events for managing the connection lifecycle and transferring data.\nImport Net Module\nSocket Properties\nSocket Methods\nSocket Events\nCreating a TCP Client\nThis example shows how to create a TCP client that connects to a server:\nCreating a TCP Server\nThis example demonstrates creating a TCP server that handles socket connections:\nSocket Timeout\nThis example demonstrates how to set and handle socket timeouts:\nSocket Options\nThis example shows how to configure various socket options:\nWorking with Socket Buffers\nThis example demonstrates socket buffering and the 'drain' event:\nIPC Socket Communication\nThis example demonstrates Inter-Process Communication (IPC) using Unix domain sockets:\nHalf-Closed Sockets\nThis example demonstrates half-closed connections where one side has ended their write stream but can still receive data:\nBest Practices for Socket Programming\nWhen working with sockets in Node.js, consider these best practices:\nError handling: Always handle the 'error' event to prevent unhandled exceptions.\nClean up resources: Ensure sockets are properly closed to avoid memory leaks.\nBuffer management: Monitor socket.bufferSize and use the 'drain' event to avoid memory issues when sending large amounts of data.\nTimeouts: Set appropriate timeouts with socket.setTimeout() to handle stale connections.\nKeep-alive: Configure keep-alive settings for long-running connections.\nData encoding: Set appropriate encoding with socket.setEncoding() or handle binary data appropriately.\nSecurity: For secure communication, use the TLS/SSL module (tls) instead of raw TCP sockets.\nBackpressure: Pay attention to the return value of socket.write() to handle backpressure.",
      "examples": [
        "// Import the net module\nconst net = require('net');\n\n// Create a Socket\nconst socket = new net.Socket();",
        "const net = require('net');\n\n// Create a new socket\nconst client = new net.Socket();\n\n// Connect to a server\nclient.connect(8080, '127.0.0.1', () => {\nconsole.log('Connected to server');\n\n// Send data to the server\nclient.write('Hello, server! From client.');\n});\n\n// Handle data received from the server\nclient.on('data', (data) => {\nconsole.log(`Received from server: ${data.toString()}`);\n\n// Close the connection after receiving a response\nclient.end();\n});\n\n// Handle connection closure\nclient.on('close', () => {\nconsole.log('Connection closed');\n});\n\n// Handle errors\nclient.on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});",
        "const net = require('net');\n\n// Create a TCP server\nconst server = net.createServer((socket) => {\n// 'socket' is the client connection - an instance of net.Socket\n\nconsole.log(`Client connected: ${socket.remoteAddress}:${socket.remotePort}`);\n\n// Set encoding\nsocket.setEncoding('utf8');\n\n// Handle data from client\nsocket.on('data', (data) => {\nconsole.log(`Received from client: ${data}`);\n\n// Echo the data back to the client\nsocket.write(`You said: ${data}`);\n});\n\n// Handle client disconnection\nsocket.on('end', () => {\nconsole.log('Client disconnected');\n});\n\n// Handle socket errors\nsocket.on('error', (err) => {\nconsole.error(`Socket error: ${err.message}`);\n});\n\n// Send a welcome message to the client\nsocket.write('Welcome to the TCP server!\\n');\n});\n\n// Start the server on port 8080\nserver.listen(8080, '127.0.0.1', () => {\nconsole.log('Server listening on port 8080');\n});\n\n// Handle server errors\nserver.on('error', (err) => {\nconsole.error(`Server error: ${err.message}`);\n});",
        "const net = require('net');\n\n// Create a server with timeouts\nconst server = net.createServer((socket) => {\nconsole.log('Client connected');\n\n// Set socket timeout to 10 seconds\nsocket.setTimeout(10000);\n\n// Handle socket timeout\nsocket.on('timeout', () => {\nconsole.log('Socket timeout - no activity for 10 seconds');\nsocket.write('You have been inactive for too long. The connection will be closed.');\nsocket.end();\n});\n\n// Handle data\nsocket.on('data', (data) => {\nconsole.log(`Received: ${data.toString()}`);\nsocket.write('Data received');\n\n// Each time we receive data, the timeout is reset\nconsole.log('Timeout timer reset');\n});\n\n// Handle socket closure\nsocket.on('close', () => {\nconsole.log('Socket closed');\n});\n\n// Send welcome message\nsocket.write('Welcome! This connection will timeout after 10 seconds of inactivity.\\n');\n});\n\n// Start the server\nconst PORT = 8081;\nserver.listen(PORT, () => {\nconsole.log(`Timeout example server running on port ${PORT}`);\n\n// For testing: create a client that connects but doesn't send data\nconst client = new net.Socket();\nclient.connect(PORT, '127.0.0.1', () => {\nconsole.log('Test client connected');\n\n// We'll send a message after 5 seconds (before timeout)\nsetTimeout(() => {\nclient.write('Hello after 5 seconds');\n}, 5000);\n\n// We won't send anything else, so the connection should timeout\n// after another 10 seconds\n});\n\nclient.on('data', (data) => {\nconsole.log(`Client received: ${data.toString()}`);\n});\n\nclient.on('close', () => {\nconsole.log('Client disconnected');\n});\n});",
        "const net = require('net');\n\n// Create a socket with options\nconst socket = new net.Socket();\n\n// Configure socket options\nsocket.setKeepAlive(true, 1000); // Enable keep-alive with 1 second initial delay\nsocket.setNoDelay(true); // Disable Nagle's algorithm (no buffering)\n\n// Connect to a server\nsocket.connect({\nport: 80,\nhost: 'example.com',\nfamily: 4, // IPv4\nlocalAddress: '0.0.0.0', // Local interface to bind to\nlocalPort: 8000 // Local port to bind to\n}, () => {\nconsole.log('Connected with options');\n\n// Display socket information\nconsole.log(`Local address: ${socket.localAddress}:${socket.localPort}`);\nconsole.log(`Remote address: ${socket.remoteAddress}:${socket.remotePort}`);\nconsole.log(`Remote family: ${socket.remoteFamily}`);\n\n// Send a simple HTTP request\nsocket.write('GET / HTTP/1.1\\r\\n');\nsocket.write('Host: example.com\\r\\n');\nsocket.write('Connection: close\\r\\n');\nsocket.write('\\r\\n');\n});\n\n// Handle data\nlet responseData = '';\nsocket.on('data', (data) => {\nconst chunk = data.toString();\nresponseData += chunk;\n\n// Show first line of the response\nif (responseData.includes('\\r\\n') && !socket.firstLineShown) {\nconst firstLine = responseData.split('\\r\\n')[0];\nconsole.log(`First line of response: ${firstLine}`);\nsocket.firstLineShown = true;\n}\n});\n\n// Handle end of data\nsocket.on('end', () => {\nconsole.log('Response complete');\nconsole.log(`Total bytes received: ${socket.bytesRead}`);\nconsole.log(`Total bytes sent: ${socket.bytesWritten}`);\n});\n\n// Handle errors\nsocket.on('error', (err) => {\nconsole.error(`Socket error: ${err.message}`);\n});",
        "const net = require('net');\n\n// Create server to demonstrate buffer handling\nconst server = net.createServer((socket) => {\nconsole.log('Client connected');\n\n// Make buffer small to demonstrate filling it faster\nsocket.bufferSize = 1024; // Note: This doesn't actually limit the buffer size\n\n// Send a slow response to the client to demonstrate buffering\nsocket.on('data', (data) => {\nconsole.log(`Received data: ${data.toString().trim()}`);\nconsole.log('Sending large response...');\n\n// Function to write data until buffer is full\nconst writeUntilBufferFull = () => {\n// Generate some data to send\nconst chunk = 'x'.repeat(1024);\n\n// Keep writing until the buffer is full (write returns false)\nlet i = 0;\nwhile (i < 100) {\nconst canContinue = socket.write(`Chunk ${i}: ${chunk}\\n`);\nconsole.log(`Wrote chunk ${i}, buffer full? ${!canContinue}`);\n\n// If the buffer is full, wait for it to drain\nif (!canContinue) {\nconsole.log(`Buffer is full after ${i} writes. Current buffer size: ${socket.bufferSize} bytes`);\n// Stop writing and wait for the 'drain' event\nsocket.once('drain', () => {\nconsole.log('Buffer drained, resuming writes');\nwriteUntilBufferFull();\n});\nreturn;\n}\ni++;\n}\n\n// All chunks written\nconsole.log('All data sent');\nsocket.end('\\nTransmission complete');\n};\n\n// Start the writing process\nwriteUntilBufferFull();\n});\n\nsocket.on('end', () => {\nconsole.log('Client disconnected');\n});\n\nsocket.on('error', (err) => {\nconsole.error(`Socket error: ${err.message}`);\n});\n\nsocket.write('Send any message to receive a large response\\n');\n});\n\n// Start the server\nconst PORT = 8082;\nserver.listen(PORT, () => {\nconsole.log(`Buffer demonstration server running on port ${PORT}`);\n\n// For demonstration, create a client that connects and sends a message\nconst client = new net.Socket();\n\nclient.connect(PORT, '127.0.0.1', () => {\nconsole.log('Test client connected');\n\n// Send a message after 1 second\nsetTimeout(() => {\nclient.write('Please send me a large response');\n}, 1000);\n});\n\nlet receivedData = 0;\nclient.on('data', (data) => {\nreceivedData += data.length;\nconsole.log(`Client received ${data.length} bytes, total: ${receivedData}`);\n});\n\nclient.on('end', () => {\nconsole.log(`Client disconnected after receiving ${receivedData} bytes`);\nprocess.exit(0);\n});\n\nclient.on('error', (err) => {\nconsole.error(`Client error: ${err.message}`);\n});\n});",
        "const net = require('net');\nconst path = require('path');\nconst fs = require('fs');\n\n// IPC path - depending on OS\nconst socketPath = process.platform === 'win32'\n? path.join('\\\\\\\\?\\\\pipe', process.cwd(), 'ipc-demo.sock')\n: path.join(process.cwd(), 'ipc-demo.sock');\n\n// Remove existing socket file if it exists (Unix only)\nif (process.platform !== 'win32' && fs.existsSync(socketPath)) {\nfs.unlinkSync(socketPath);\n}\n\n// Create IPC server\nconst server = net.createServer((socket) => {\nconsole.log('Client connected to IPC socket');\n\nsocket.on('data', (data) => {\nconst message = data.toString().trim();\nconsole.log(`Server received: ${message}`);\n\n// Echo back\nsocket.write(`Echo: ${message}`);\n});\n\nsocket.on('end', () => {\nconsole.log('Client disconnected from IPC socket');\n});\n\nsocket.write('Connected to IPC server\\n');\n});\n\n// Handle server errors\nserver.on('error', (err) => {\nconsole.error(`IPC server error: ${err.message}`);\n});\n\n// Start IPC server\nserver.listen(socketPath, () => {\nconsole.log(`IPC server listening on ${socketPath}`);\n\n// Create client that connects to the IPC socket\nconst client = new net.Socket();\n\nclient.on('data', (data) => {\nconsole.log(`Client received: ${data.toString().trim()}`);\n});\n\nclient.on('end', () => {\nconsole.log('Disconnected from IPC server');\n});\n\nclient.on('error', (err) => {\nconsole.error(`IPC client error: ${err.message}`);\n});\n\n// Connect to the IPC server\nclient.connect(socketPath, () => {\nconsole.log('Connected to IPC server');\nclient.write('Hello via IPC socket');\n\n// Send multiple messages\nsetTimeout(() => {\nclient.write('Message 1');\n}, 1000);\n\nsetTimeout(() => {\nclient.write('Message 2');\nclient.end(); // Close after sending the last message\n}, 2000);\n});\n});\n\n// Cleanup on exit\nprocess.on('exit', () => {\nif (process.platform !== 'win32' && fs.existsSync(socketPath)) {\nfs.unlinkSync(socketPath);\n}\n});\n\n// Handle Ctrl+C\nprocess.on('SIGINT', () => {\nconsole.log('Shutting down...');\nprocess.exit(0);\n});",
        "const net = require('net');\n\n// Create server\nconst server = net.createServer((socket) => {\nconsole.log('Client connected');\n\n// Send initial message\nsocket.write('Welcome to the half-close demonstration server\\n');\n\n// Handle data from client\nsocket.on('data', (data) => {\nconsole.log(`Server received: ${data.toString().trim()}`);\n});\n\n// Handle socket end (client ended their write stream)\nsocket.on('end', () => {\nconsole.log('Client ended their write stream (half-closed)');\n\n// We can still write to the client after they've ended their write stream\nsocket.write('You have ended your side of the connection, but I can still talk to you.');\n\n// Close our side after a delay\nsetTimeout(() => {\nconsole.log('Server now closing its write stream');\nsocket.end('Goodbye! Closing my side of the connection now.');\n}, 8080);\n});\n\n// Handle complete socket closure\nsocket.on('close', (hadError) => {\nconsole.log(`Socket fully closed. Had error: ${hadError}`);\n});\n\nsocket.on('error', (err) => {\nconsole.error(`Socket error: ${err.message}`);\n});\n});\n\n// Start server\nconst PORT = 8083;\nserver.listen(PORT, () => {\nconsole.log(`Half-close demonstration server running on port ${PORT}`);\n\n// Create a client for demonstration\nconst client = new net.Socket();\n\nclient.connect(PORT, '127.0.0.1', () => {\nconsole.log('Client connected');\n\n// Send some data\nclient.write('Hello from client');\n\n// After a delay, end the client write stream (half-close)\nsetTimeout(() => {\nconsole.log('Client ending its write stream (half-closing)');\nclient.end();\n\n// We can't write anymore, but we can still receive data\nconsole.log('Client waiting to receive more data...');\n}, 2000);\n});\n\n// Handle data from server\nclient.on('data', (data) => {\nconsole.log(`Client received: ${data.toString().trim()}`);\n});\n\n// Handle server closing its write stream\nclient.on('end', () => {\nconsole.log('Server ended its write stream, connection fully closed');\n});\n\n// Handle complete connection closure\nclient.on('close', (hadError) => {\nconsole.log(`Client connection fully closed. Had error: ${hadError}`);\n});\n\nclient.on('error', (err) => {\nconsole.error(`Client error: ${err.message}`);\n});\n});",
        "net",
        "options",
        "port",
        "host",
        "localAddress",
        "localPort",
        "error",
        "data",
        "socket.pause()",
        "null",
        "initialDelay",
        "true",
        "false",
        "hadError",
        "socket.bufferSize",
        "socket.setTimeout()",
        "socket.setEncoding()",
        "tls",
        "socket.write()"
      ]
    },
    {
      "title": "Node.js ReadStream Reference",
      "summary": "ReadStream Object\nA ReadStream is a stream that allows you to read data from a resource. Node.js provides ReadStream implementations for different use cases, such as reading from files (fs.ReadStream) or standard input (process.stdin).\nReadStreams implement the stream.Readable interface, which means they provide methods and events for reading data asynchronously, handling backpressure, and working with different stream modes (flowing/paused).\nCommon ReadStream Types\nfs.ReadStream - For reading from files\nprocess.stdin - For reading from standard input\nnet.Socket (when reading) - For reading from network connections\nhttp.IncomingMessage - For reading HTTP request bodies\nReadStream Properties\nHere are the properties commonly available on Node.js ReadStream objects, primarily based on the fs.ReadStream implementation:\nReadStream Methods\nHere are the most important methods available on ReadStream objects:\nReadStream Events\nReadStream objects emit the following events:\nReading from a File\nThis example shows how to create a file ReadStream and read data from it:\nControlling Stream Flow\nThis example demonstrates how to control the flow of data with pause() and resume():\nUsing the read() Method\nThis example demonstrates using the read() method in the 'readable' event:\nPiping between Streams\nThis example demonstrates how to use pipe() to send data from a ReadStream to a WriteStream:\nReading from Standard Input\nThis example shows how to use the process.stdin ReadStream:\nHTTP ReadStream Example\nThis example shows how to use a ReadStream to handle HTTP request data:\nError Handling with ReadStreams\nThis example demonstrates proper error handling with ReadStreams:\nBest Practices for ReadStreams\nWhen working with ReadStreams in Node.js, consider these best practices:\nAlways handle errors: Always listen for and handle 'error' events from ReadStreams to prevent unhandled exceptions.\nClean up resources: Ensure streams are properly closed or destroyed when no longer needed.\nUse pipe() for most cases: The pipe() method automatically handles backpressure and is typically the best way to connect streams.\nSet appropriate buffer sizes: Use the highWaterMark option to control memory usage, especially for large files.\nChoose the right mode: Understand the difference between flowing and paused modes, and use the appropriate one for your use case.\nConsider encoding: Set the appropriate encoding with setEncoding() if you're working with text.\nUse stream.finished(): For cleanup, consider using stream.finished() from the stream module to detect when a stream is no longer readable, writable or has experienced an error or premature close.\nAvoid reading entire files into memory: Use streams instead of methods like fs.readFile() for large files to avoid memory issues.",
      "examples": [
        "const fs = require('fs');\nconst path = require('path');\n\n// Create a sample file for the example\nconst sampleFile = path.join(__dirname, 'readstream-example.txt');\nfs.writeFileSync(sampleFile, 'This is a test file.\\nIt has multiple lines.\\nEach line has its own content.\\nStreaming makes file reading efficient.');\n\n// Create a ReadStream to read from the file\nconst readStream = fs.createReadStream(sampleFile, {\n// Options\nencoding: 'utf8',  // Set the encoding (utf8, ascii, binary, etc.)\nhighWaterMark: 64, // Buffer size in bytes\nautoClose: true    // Automatically close the file descriptor when the stream ends\n});\n\nconsole.log('File ReadStream properties:');\nconsole.log(`- Path: ${readStream.path}`);\nconsole.log(`- Pending: ${readStream.pending}`);\nconsole.log(`- High Water Mark: ${readStream.readableHighWaterMark} bytes`);\n\n// Handle stream events\nreadStream.on('open', (fd) => {\nconsole.log(`File opened with descriptor: ${fd}`);\n});\n\nreadStream.on('ready', () => {\nconsole.log('ReadStream is ready');\n});\n\n// Handle data events\nreadStream.on('data', (chunk) => {\nconsole.log('\\nReceived chunk:');\nconsole.log('-'.repeat(20));\nconsole.log(chunk);\nconsole.log('-'.repeat(20));\nconsole.log(`Bytes read so far: ${readStream.bytesRead}`);\n});\n\nreadStream.on('end', () => {\nconsole.log('\\nReached end of file');\nconsole.log(`Total bytes read: ${readStream.bytesRead}`);\n\n// Clean up the sample file\nfs.unlinkSync(sampleFile);\nconsole.log('Sample file removed');\n});\n\nreadStream.on('close', () => {\nconsole.log('Stream closed');\n});\n\nreadStream.on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});",
        "const fs = require('fs');\nconst path = require('path');\n\n// Create a large sample file for the flow control example\nconst flowFile = path.join(__dirname, 'flow-control-example.txt');\nlet sampleContent = '';\nfor (let i = 1; i <= 1000; i++) {\nsampleContent += `This is line ${i} of the test file.\\n`;\n}\nfs.writeFileSync(flowFile, sampleContent);\n\n// Create a ReadStream\nconst readStream = fs.createReadStream(flowFile, {\nencoding: 'utf8',\nhighWaterMark: 1024 // 1KB buffer\n});\n\nlet chunkCount = 0;\nlet totalBytes = 0;\nlet isPaused = false;\n\n// Handle data chunks with flow control\nreadStream.on('data', (chunk) => {\nchunkCount++;\ntotalBytes += chunk.length;\n\nconsole.log(`Chunk #${chunkCount} received, size: ${chunk.length} bytes`);\n\n// Pause the stream every 5 chunks to demonstrate flow control\nif (chunkCount % 5 === 0 && !isPaused) {\nconsole.log('\\nPausing the stream for 1 second...');\nisPaused = true;\n\n// Pause the stream\nreadStream.pause();\n\n// Resume after 1 second\nsetTimeout(() => {\nconsole.log('Resuming the stream...\\n');\nisPaused = false;\nreadStream.resume();\n}, 1000);\n}\n});\n\nreadStream.on('end', () => {\nconsole.log(`\\nFinished reading file. Received ${chunkCount} chunks, ${totalBytes} bytes total.`);\n\n// Clean up the sample file\nfs.unlinkSync(flowFile);\nconsole.log('Sample file removed');\n});\n\nreadStream.on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});",
        "const fs = require('fs');\nconst path = require('path');\n\n// Create a sample file\nconst readableFile = path.join(__dirname, 'readable-example.txt');\nfs.writeFileSync(readableFile, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.repeat(100));\n\n// Create a ReadStream without auto-flowing\nconst readStream = fs.createReadStream(readableFile, {\nhighWaterMark: 32 // Small buffer to demonstrate multiple reads\n});\n\nconsole.log('Using the readable event and read() method:');\n\n// Using the 'readable' event for manual reading\nreadStream.on('readable', () => {\nlet chunk;\n// read() returns null when there is no more data to read\nwhile (null !== (chunk = readStream.read(16))) {\nconsole.log(`Read ${chunk.length} bytes: ${chunk.toString('utf8').substring(0, 10)}...`);\n}\n});\n\nreadStream.on('end', () => {\nconsole.log('End of stream reached');\n\n// Clean up the sample file\nfs.unlinkSync(readableFile);\nconsole.log('Sample file removed');\n});\n\nreadStream.on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});",
        "const fs = require('fs');\nconst path = require('path');\nconst zlib = require('zlib');\n\n// Source and destination file paths\nconst sourceFile = path.join(__dirname, 'pipe-source-example.txt');\nconst destFile = path.join(__dirname, 'pipe-destination.txt');\nconst compressedFile = path.join(__dirname, 'pipe-compressed.gz');\n\n// Create sample content\nfs.writeFileSync(sourceFile, 'This is the source content for the pipe example.\\n'.repeat(100));\n\n// Create ReadStream and various WriteStreams\nconst readStream = fs.createReadStream(sourceFile);\nconst writeStream = fs.createWriteStream(destFile);\nconst compressStream = zlib.createGzip(); // Compression transform stream\nconst compressedWriteStream = fs.createWriteStream(compressedFile);\n\n// Pipe the ReadStream directly to the WriteStream\nreadStream.pipe(writeStream);\n\n// Listen for completion events\nwriteStream.on('finish', () => {\nconsole.log(`File copied from ${sourceFile} to ${destFile}`);\n\n// Create a new ReadStream to demonstrate chained pipes\nconst readStream2 = fs.createReadStream(sourceFile);\n\n// Chain multiple pipes: read -> compress -> write\nreadStream2.pipe(compressStream).pipe(compressedWriteStream);\n\ncompressedWriteStream.on('finish', () => {\nconsole.log(`File compressed from ${sourceFile} to ${compressedFile}`);\n\n// Compare file sizes\nconst originalSize = fs.statSync(sourceFile).size;\nconst compressedSize = fs.statSync(compressedFile).size;\nconsole.log(`Original size: ${originalSize} bytes`);\nconsole.log(`Compressed size: ${compressedSize} bytes`);\nconsole.log(`Compression ratio: ${(compressedSize / originalSize * 100).toFixed(2)}%`);\n\n// Clean up files after demonstration\n[sourceFile, destFile, compressedFile].forEach(file => {\nfs.unlinkSync(file);\n});\nconsole.log('All sample files removed');\n});\n});\n\n// Handle errors\nreadStream.on('error', (err) => console.error(`Read error: ${err.message}`));\nwriteStream.on('error', (err) => console.error(`Write error: ${err.message}`));\ncompressStream.on('error', (err) => console.error(`Compression error: ${err.message}`));\ncompressedWriteStream.on('error', (err) => console.error(`Compressed write error: ${err.message}`));",
        "// process.stdin is a ReadStream\n\nconsole.log('Enter some text (press Ctrl+D or Ctrl+C to end input):');\n\n// Set the encoding to utf8 to get strings instead of Buffer objects\nprocess.stdin.setEncoding('utf8');\n\nlet inputData = '';\n\n// Handle data from stdin\nprocess.stdin.on('data', (chunk) => {\nconsole.log(`Received chunk: \"${chunk.trim()}\"`);\ninputData += chunk;\n});\n\n// Handle the end of input\nprocess.stdin.on('end', () => {\nconsole.log('\\nEnd of input.');\nconsole.log(`Total input received: ${inputData.length} characters`);\nconsole.log('You entered:');\nconsole.log('-'.repeat(20));\nconsole.log(inputData);\nconsole.log('-'.repeat(20));\n});\n\n// Handle Ctrl+C (SIGINT)\nprocess.on('SIGINT', () => {\nconsole.log('\\nInput interrupted with Ctrl+C');\nprocess.exit();\n});\n\n// Note: This example requires user input in a terminal\n// Can't be effectively demonstrated in the W3Schools TryIt editor",
        "const http = require('http');\n\n// Create an HTTP server\nconst server = http.createServer((req, res) => {\n// req is an http.IncomingMessage, which is a ReadStream\nconsole.log(`Received ${req.method} request to ${req.url}`);\n\n// Set response headers\nres.setHeader('Content-Type', 'text/plain');\n\n// Handle different types of requests\nif (req.method === 'GET') {\nres.end('Send a POST request with a body to see the ReadStream in action');\n}\nelse if (req.method === 'POST') {\n// Set encoding for the request stream\nreq.setEncoding('utf8');\n\nlet body = '';\n\n// Handle data events from the request stream\nreq.on('data', (chunk) => {\nconsole.log(`Received chunk of ${chunk.length} bytes`);\nbody += chunk;\n\n// Implement a simple flood protection\nif (body.length > 1e6) {\n// If body is too large, destroy the stream\nbody = '';\nres.writeHead(413, {'Content-Type': 'text/plain'});\nres.end('Request entity too large');\nreq.destroy();\n}\n});\n\n// Handle the end of the request stream\nreq.on('end', () => {\nconsole.log('End of request data');\n\ntry {\n// Try to parse as JSON\nconst data = JSON.parse(body);\nconsole.log('Parsed JSON data:', data);\n\n// Send a response\nres.writeHead(200, {'Content-Type': 'application/json'});\nres.end(JSON.stringify({\nmessage: 'Data received',\nsize: body.length,\ndata: data\n}));\n} catch (e) {\n// If not valid JSON, just echo back the raw data\nconsole.log('Could not parse as JSON, treating as plain text');\n\nres.writeHead(200, {'Content-Type': 'text/plain'});\nres.end(`Received ${body.length} bytes of data:\\n${body}`);\n}\n});\n}\nelse {\n// For other HTTP methods\nres.writeHead(405, {'Content-Type': 'text/plain'});\nres.end('Method not allowed');\n}\n});\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`HTTP ReadStream example server running at http://localhost:${PORT}`);\nconsole.log('To test:');\nconsole.log(`1. Open http://localhost:${PORT} in a browser for GET request`);\nconsole.log(`2. Use curl or Postman to send POST requests with a body to http://localhost:${PORT}`);\n});\n\n// Note: To test with curl:\n// curl -X POST -H \"Content-Type: application/json\" -d '{\"name\":\"John\",\"age\":30}' http://localhost:8080",
        "const fs = require('fs');\nconst path = require('path');\n\n// Function to create and handle a ReadStream with proper error handling\nfunction readWithErrorHandling(filePath) {\nconsole.log(`Attempting to read: ${filePath}`);\n\n// Create the ReadStream\nconst readStream = fs.createReadStream(filePath);\n\n// Set up promise to capture result or error\nreturn new Promise((resolve, reject) => {\nlet data = '';\n\n// Handle data events\nreadStream.on('data', (chunk) => {\ndata += chunk;\n});\n\n// Handle successful completion\nreadStream.on('end', () => {\nconsole.log(`Successfully read ${readStream.bytesRead} bytes from ${filePath}`);\nresolve(data);\n});\n\n// Handle errors\nreadStream.on('error', (err) => {\nconsole.error(`Error reading ${filePath}: ${err.message}`);\nreject(err);\n});\n\n// Handle stream closure (always happens, even if there's an error)\nreadStream.on('close', () => {\nconsole.log(`Stream for ${filePath} closed`);\n});\n});\n}\n\n// Test with both existing and non-existing files\nconst existingFile = path.join(__dirname, 'test-existing.txt');\nconst nonExistingFile = path.join(__dirname, 'non-existing-file.txt');\n\n// Create the test file\nfs.writeFileSync(existingFile, 'This is test content for error handling example');\n\n// Example 1: Reading an existing file\nconsole.log('Example 1: Reading an existing file');\nreadWithErrorHandling(existingFile)\n.then(data => {\nconsole.log('File content:', data);\n\n// Example 2: Reading a non-existing file\nconsole.log('\\nExample 2: Reading a non-existing file');\nreturn readWithErrorHandling(nonExistingFile);\n})\n.catch(err => {\nconsole.log('Error caught in Promise catch:', err.message);\n})\n.finally(() => {\n// Clean up the test file\nif (fs.existsSync(existingFile)) {\nfs.unlinkSync(existingFile);\nconsole.log('Test file removed');\n}\n});\n\n// Example 3: Demonstrating destroyed streams\nconsole.log('\\nExample 3: Demonstrating destroyed streams');\nconst destroyTestFile = path.join(__dirname, 'destroy-test.txt');\nfs.writeFileSync(destroyTestFile, 'A'.repeat(10000));\n\nconst destroyStream = fs.createReadStream(destroyTestFile);\n\ndestroyStream.on('data', (chunk) => {\nconsole.log(`Received ${chunk.length} bytes before destroying the stream`);\n\n// Destroy the stream after receiving the first chunk\nconsole.log('Deliberately destroying the stream');\ndestroyStream.destroy(new Error('Stream manually destroyed'));\n});\n\ndestroyStream.on('error', (err) => {\nconsole.error(`Destruction error: ${err.message}`);\n});\n\ndestroyStream.on('close', () => {\nconsole.log('Destroyed stream closed');\n\n// Clean up\nfs.unlinkSync(destroyTestFile);\nconsole.log('Destroy test file removed');\n});",
        "fs.ReadStream",
        "process.stdin",
        "stream.Readable",
        "net.Socket",
        "http.IncomingMessage",
        "true",
        "null",
        "size",
        "pause()",
        "pipe()",
        "read()",
        "Buffer",
        "setEncoding()",
        "resume()",
        "highWaterMark",
        "stream.finished()",
        "stream",
        "fs.readFile()"
      ]
    },
    {
      "title": "Node.js WriteStream Reference",
      "summary": "WriteStream Object\nA WriteStream is a stream that allows you to write data to a destination. Node.js provides WriteStream implementations for different use cases, such as writing to files (fs.WriteStream) or standard output (process.stdout).\nWriteStreams implement the stream.Writable interface, which means they provide methods and events for writing data asynchronously and handling backpressure.\nCommon WriteStream Types\nfs.WriteStream - For writing to files\nprocess.stdout and process.stderr - For writing to standard output and error\nnet.Socket (when writing) - For writing to network connections\nhttp.ServerResponse - For writing HTTP responses\nWriteStream Properties\nHere are the properties commonly available on Node.js WriteStream objects, primarily based on the fs.WriteStream implementation:\nWriteStream Methods\nHere are the most important methods available on WriteStream objects:\nWriteStream Events\nWriteStream objects emit the following events:\nWriting to a File\nThis example shows how to create a file WriteStream and write data to it:\nHandling Backpressure\nThis example demonstrates how to handle backpressure when writing large amounts of data:\nUsing cork() and uncork()\nThis example demonstrates using cork() and uncork() to batch writes together:\nWriting to Standard Output\nThis example shows how to use the process.stdout WriteStream:\nHTTP WriteStream Example\nThis example shows how to use a WriteStream to handle HTTP response data:\nError Handling with WriteStreams\nThis example demonstrates proper error handling with WriteStreams:\nBest Practices for WriteStreams\nWhen working with WriteStreams in Node.js, consider these best practices:\nAlways handle errors: Always listen for and handle 'error' events from WriteStreams to prevent unhandled exceptions.\nHandle backpressure: Pay attention to the return value of write() and use the 'drain' event to control flow and prevent memory issues.\nUse cork() for batching: Use cork() and uncork() to batch write operations, improving performance for many small writes.\nClean up resources: Ensure streams are properly closed with end() or destroyed with destroy() when no longer needed.\nSet appropriate buffer sizes: Use the highWaterMark option to control memory usage, especially when dealing with high-throughput applications.\nUse pipe() when possible: The pipe() method automatically handles backpressure and is typically the best way to connect streams.\nConsider encoding: Set the appropriate encoding with setDefaultEncoding() when working with text.\nUse stream.finished(): For cleanup, consider using stream.finished() from the stream module to detect when a stream is no longer writable or has experienced an error or premature close.",
      "examples": [
        "const fs = require('fs');\nconst path = require('path');\n\n// Define the output file path\nconst outputFile = path.join(__dirname, 'writestream-example.txt');\n\n// Create a WriteStream to write to the file\nconst writeStream = fs.createWriteStream(outputFile, {\n// Options\nflags: 'w',          // 'w' for write (overwrites existing file)\nencoding: 'utf8',    // Set the encoding for strings\nmode: 0o666,         // File mode (permissions)\nautoClose: true      // Automatically close the file descriptor when the stream ends\n});\n\nconsole.log('File WriteStream properties:');\nconsole.log(`- Path: ${writeStream.path}`);\nconsole.log(`- Pending: ${writeStream.pending}`);\nconsole.log(`- High Water Mark: ${writeStream.writableHighWaterMark} bytes`);\n\n// Handle stream events\nwriteStream.on('open', (fd) => {\nconsole.log(`File opened with descriptor: ${fd}`);\n});\n\nwriteStream.on('ready', () => {\nconsole.log('WriteStream is ready');\n\n// Write data to the stream\nwriteStream.write('Hello, this is the first line.\\n');\nwriteStream.write('This is the second line.\\n');\nwriteStream.write('And this is the third line.\\n');\n\n// End the stream after writing all data\nwriteStream.end('This is the final line.\\n', () => {\nconsole.log('Finished writing to the file');\nconsole.log(`Total bytes written: ${writeStream.bytesWritten}`);\n});\n});\n\n// Handle drain event (when buffer is empty)\nwriteStream.on('drain', () => {\nconsole.log('Write buffer drained');\n});\n\n// Handle finish event (after end() and all data is flushed)\nwriteStream.on('finish', () => {\nconsole.log('All writes have been completed');\n\n// Read back the file contents to verify\nfs.readFile(outputFile, 'utf8', (err, data) => {\nif (err) {\nconsole.error(`Error reading file: ${err.message}`);\nreturn;\n}\n\nconsole.log('\\nFile content:');\nconsole.log('-'.repeat(20));\nconsole.log(data);\nconsole.log('-'.repeat(20));\n\n// Clean up the sample file\nfs.unlink(outputFile, (err) => {\nif (err) {\nconsole.error(`Error removing file: ${err.message}`);\nreturn;\n}\nconsole.log('Sample file removed');\n});\n});\n});\n\nwriteStream.on('close', () => {\nconsole.log('Stream closed');\n});\n\nwriteStream.on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});",
        "const fs = require('fs');\nconst path = require('path');\n\n// Define the output file path\nconst backpressureFile = path.join(__dirname, 'backpressure-example.txt');\n\n// Create a WriteStream with a small highWaterMark to demonstrate backpressure\nconst writeStream = fs.createWriteStream(backpressureFile, {\nhighWaterMark: 1024 // 1KB buffer (small to demonstrate backpressure)\n});\n\n// Counter for how many chunks we've written\nlet chunksWritten = 0;\nlet drainEvents = 0;\n\n// Function to write data until backpressure occurs\nfunction writeChunks() {\nconsole.log('Writing chunks...');\n\n// Create a large chunk of data\nconst chunk = 'a'.repeat(256); // 256 bytes per chunk\n\n// Try to write many chunks\nlet canContinue = true;\n\nwhile (canContinue && chunksWritten < 100) {\n// Attempt to write the chunk\ncanContinue = writeStream.write(`Chunk ${chunksWritten}: ${chunk}\\n`);\nchunksWritten++;\n\nif (chunksWritten % 10 === 0) {\nconsole.log(`Wrote ${chunksWritten} chunks so far`);\n}\n\n// If canContinue is false, we hit backpressure\nif (!canContinue) {\nconsole.log(`Backpressure hit after ${chunksWritten} chunks. Waiting for drain...`);\n\n// Wait for the drain event before continuing\nwriteStream.once('drain', () => {\ndrainEvents++;\nconsole.log(`Drain event #${drainEvents} occurred. Resuming writes...`);\nwriteChunks(); // Continue writing\n});\n}\n}\n\n// If we've written all chunks, end the stream\nif (chunksWritten >= 100) {\nwriteStream.end('\\nAll chunks have been written.\\n', () => {\nconsole.log('Ended the WriteStream after writing all chunks');\n});\n}\n}\n\n// Start writing chunks when the stream is ready\nwriteStream.on('ready', () => {\nconsole.log('WriteStream is ready with highWaterMark =',\nwriteStream.writableHighWaterMark, 'bytes');\n\n// Start writing chunks\nwriteChunks();\n});\n\n// Handle finish event\nwriteStream.on('finish', () => {\nconsole.log('\\nWrite operation completed');\nconsole.log(`Total chunks written: ${chunksWritten}`);\nconsole.log(`Total drain events: ${drainEvents}`);\nconsole.log(`Total bytes written: ${writeStream.bytesWritten}`);\n\n// Clean up the sample file\nfs.unlink(backpressureFile, (err) => {\nif (err) {\nconsole.error(`Error removing file: ${err.message}`);\nreturn;\n}\nconsole.log('Sample file removed');\n});\n});\n\n// Handle errors\nwriteStream.on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});",
        "const fs = require('fs');\nconst path = require('path');\n\n// Define the output file paths\nconst uncorkedFile = path.join(__dirname, 'uncorked-example.txt');\nconst corkedFile = path.join(__dirname, 'corked-example.txt');\n\n// Function to run the demonstration\nfunction demonstrateCorkUncork() {\nconsole.log('Demonstrating cork() and uncork() methods');\n\n// 1. Write without corking\nconst uncorkedStream = fs.createWriteStream(uncorkedFile);\n\nuncorkedStream.on('finish', () => {\nconsole.log(`Uncorked stream finished. Bytes written: ${uncorkedStream.bytesWritten}`);\n\n// 2. Now write with corking\nconst corkedStream = fs.createWriteStream(corkedFile);\n\ncorkedStream.on('finish', () => {\nconsole.log(`Corked stream finished. Bytes written: ${corkedStream.bytesWritten}`);\n\n// Compare files\nfs.readFile(uncorkedFile, 'utf8', (err, uncorkedData) => {\nif (err) {\nconsole.error(`Error reading uncorked file: ${err.message}`);\nreturn;\n}\n\nfs.readFile(corkedFile, 'utf8', (err, corkedData) => {\nif (err) {\nconsole.error(`Error reading corked file: ${err.message}`);\nreturn;\n}\n\nconsole.log('\\nFile comparison:');\nconsole.log(`- Uncorked file size: ${uncorkedData.length} bytes`);\nconsole.log(`- Corked file size: ${corkedData.length} bytes`);\nconsole.log(`- Content identical: ${uncorkedData === corkedData}`);\n\n// Clean up sample files\nfs.unlinkSync(uncorkedFile);\nfs.unlinkSync(corkedFile);\nconsole.log('Sample files removed');\n});\n});\n});\n\n// Start cork operation\nconsole.log('Writing with cork()...');\ncorkedStream.cork();\n\n// Write multiple chunks of data\nfor (let i = 0; i < 1000; i++) {\ncorkedStream.write(`Line ${i}: This data is being corked.\\n`);\n}\n\n// Uncork to flush the buffer - in real applications, you might cork/uncork\n// multiple times to batch writes together\ncorkedStream.uncork();\n\n// End the stream\ncorkedStream.end();\n});\n\n// Write without corking\nconsole.log('Writing without cork()...');\nfor (let i = 0; i < 1000; i++) {\nuncorkedStream.write(`Line ${i}: This data is not being corked.\\n`);\n}\n\n// End the stream\nuncorkedStream.end();\n}\n\n// Run the demonstration\ndemonstrateCorkUncork();",
        "// process.stdout is a WriteStream\n\n// Basic writing to stdout\nprocess.stdout.write('Hello, ');\nprocess.stdout.write('world!\\n');\n\n// Check if stdout supports color (most terminals do)\nconst supportsColor = process.stdout.hasColors && process.stdout.hasColors();\n\n// Simple formatting if color is supported\nif (supportsColor) {\n// ANSI escape codes for colors\nconst colors = {\nred: '\\x1b[31m',\ngreen: '\\x1b[32m',\nyellow: '\\x1b[33m',\nblue: '\\x1b[34m',\nreset: '\\x1b[0m'\n};\n\nprocess.stdout.write(`${colors.red}This text is red.\\n${colors.reset}`);\nprocess.stdout.write(`${colors.green}This text is green.\\n${colors.reset}`);\nprocess.stdout.write(`${colors.blue}This text is blue.\\n${colors.reset}`);\n} else {\nprocess.stdout.write('Your terminal does not support colors.\\n');\n}\n\n// Writing tabular data\nconst table = [\n['Name', 'Age', 'Country'],\n['John', '28', 'USA'],\n['Maria', '32', 'Spain'],\n['Yuki', '24', 'Japan']\n];\n\nprocess.stdout.write('\\nTable Example:\\n');\ntable.forEach(row => {\nprocess.stdout.write(`${row[0].padEnd(10)}${row[1].padEnd(5)}${row[2]}\\n`);\n});\n\n// Progress bar example\nprocess.stdout.write('\\nProgress Bar Example:\\n');\n\nfunction showProgress(percent) {\nconst width = 40;\nconst completed = Math.floor(width * (percent / 100));\nconst remaining = width - completed;\n\n// Create the progress bar\nconst bar = '[' + '#'.repeat(completed) + ' '.repeat(remaining) + ']';\n\n// Use \\r to return to the beginning of the line\nprocess.stdout.write(`\\r${bar} ${percent}%`);\n\n// When complete, add a newline\nif (percent === 100) {\nprocess.stdout.write('\\nComplete!\\n');\n}\n}\n\n// Simulate progress\nlet progress = 0;\nconst progressInterval = setInterval(() => {\nprogress += 10;\nshowProgress(progress);\n\nif (progress >= 100) {\nclearInterval(progressInterval);\n}\n}, 300);\n\n// Note: The progress bar example is more effective in a terminal\n// than in the W3Schools TryIt editor",
        "const http = require('http');\n\n// Create an HTTP server\nconst server = http.createServer((req, res) => {\n// res is an http.ServerResponse, which is a WriteStream\nconsole.log(`Received ${req.method} request to ${req.url}`);\n\n// Set response headers\nres.setHeader('Content-Type', 'text/html');\n\n// Check if the client requested a streaming response\nif (req.url === '/stream') {\n// Demonstrate streaming a large response\nstreamLargeResponse(res);\n} else {\n// Default handler - show links to examples\nres.writeHead(200, {'Content-Type': 'text/html'});\nres.end(`\n<!DOCTYPE html>\n<html>\n<head><title>HTTP WriteStream Example</title></head>\n<body>\n<h1>HTTP WriteStream Examples</h1>\n<ul>\n<li><a href=\"/stream\">Stream a large response</a></li>\n</ul>\n</body>\n</html>\n`);\n}\n});\n\n// Function to stream a large response piece by piece\nfunction streamLargeResponse(res) {\n// Set appropriate headers\nres.writeHead(200, {\n'Content-Type': 'text/html',\n'Transfer-Encoding': 'chunked'  // Enable chunked transfer encoding\n});\n\n// Write the HTML header\nres.write(`\n<!DOCTYPE html>\n<html>\n<head>\n<title>Streaming Response Example</title>\n<style>\nbody { font-family: Arial, sans-serif; margin: 20px; }\n.chunk { padding: 10px; margin: 5px; background-color: #f0f0f0; }\n</style>\n</head>\n<body>\n<h1>Streaming Response Example</h1>\n<p>This response is being streamed in chunks with delays between them.</p>\n<div id=\"chunks\">\n`);\n\n// Number of chunks to send\nconst totalChunks = 10;\nlet sentChunks = 0;\n\n// Function to send a chunk\nfunction sendChunk() {\nsentChunks++;\n\nconst now = new Date().toISOString();\nconst chunk = `\n<div class=\"chunk\">\n<h3>Chunk ${sentChunks} of ${totalChunks}</h3>\n<p>Sent at: ${now}</p>\n<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam vehicula magna eros,\neget gravida dolor fermentum non.</p>\n</div>\n`;\n\n// Write the chunk to the response\nres.write(chunk);\n\n// If we've sent all chunks, end the response\nif (sentChunks >= totalChunks) {\n// Write HTML footer\nres.end(`\n</div>\n<p>All chunks have been sent.</p>\n</body>\n</html>\n`);\nconsole.log('Finished streaming response');\n} else {\n// Otherwise, schedule the next chunk\nsetTimeout(sendChunk, 500); // Send a chunk every 500ms\n}\n}\n\n// Start sending chunks\nconsole.log('Starting to stream response');\nsendChunk();\n}\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`HTTP WriteStream example server running at http://localhost:${PORT}`);\n});\n\n// Note: To see this in action, you need to run the server and open the browser at\n// http://localhost:8080",
        "const fs = require('fs');\nconst path = require('path');\n\n// Function to write to a file with proper error handling\nfunction writeWithErrorHandling(filePath, data) {\nconsole.log(`Attempting to write to: ${filePath}`);\n\n// Create the WriteStream\nconst writeStream = fs.createWriteStream(filePath);\n\n// Set up promise to capture result or error\nreturn new Promise((resolve, reject) => {\n// Handle errors\nwriteStream.on('error', (err) => {\nconsole.error(`Error writing to ${filePath}: ${err.message}`);\n\n// Make sure the stream is destroyed properly\nwriteStream.destroy();\nreject(err);\n});\n\n// Handle successful completion\nwriteStream.on('finish', () => {\nconsole.log(`Successfully wrote ${writeStream.bytesWritten} bytes to ${filePath}`);\nresolve(writeStream.bytesWritten);\n});\n\n// Write the data\nwriteStream.write(data, (err) => {\nif (err) {\nconsole.error(`Error during write operation: ${err.message}`);\n// The 'error' event will also be emitted in this case\n} else {\nconsole.log('Data written successfully, ending stream');\nwriteStream.end();\n}\n});\n});\n}\n\n// Test with valid and invalid file paths\nconst validPath = path.join(__dirname, 'valid-path.txt');\nconst invalidPath = path.join('/', 'invalid', 'path', 'file.txt'); // Likely to be invalid on most systems\n\n// Example 1: Writing to a valid path\nconsole.log('Example 1: Writing to a valid path');\nwriteWithErrorHandling(validPath, 'This is test content for error handling example')\n.then(bytesWritten => {\nconsole.log(`Verified: ${bytesWritten} bytes written`);\n\n// Clean up the test file\nfs.unlinkSync(validPath);\nconsole.log('Test file removed');\n\n// Example 2: Writing to an invalid path\nconsole.log('\\nExample 2: Writing to an invalid path');\nreturn writeWithErrorHandling(invalidPath, 'This should fail');\n})\n.catch(err => {\nconsole.log('Error caught in Promise catch:', err.message);\n});\n\n// Example 3: Demonstrating destroyed streams\nconsole.log('\\nExample 3: Demonstrating destroyed streams');\n\nfunction demonstrateDestroyedStream() {\nconst destroyTestFile = path.join(__dirname, 'destroy-test.txt');\nconst writeStream = fs.createWriteStream(destroyTestFile);\n\nwriteStream.on('error', (err) => {\nconsole.error(`Destruction error: ${err.message}`);\n});\n\nwriteStream.on('close', () => {\nconsole.log('Destroyed stream closed');\n\n// Clean up if the file was created\nif (fs.existsSync(destroyTestFile)) {\nfs.unlinkSync(destroyTestFile);\nconsole.log('Destroy test file removed');\n}\n});\n\n// Write some data\nwriteStream.write('Initial data before destruction\\n');\n\n// Destroy the stream with an error\nconsole.log('Deliberately destroying the stream');\nwriteStream.destroy(new Error('Stream manually destroyed'));\n\n// Attempt to write after destruction (should fail silently)\nconst writeResult = writeStream.write('This should not be written');\nconsole.log(`Attempt to write after destruction returned: ${writeResult}`);\n}\n\ndemonstrateDestroyedStream();",
        "fs.WriteStream",
        "process.stdout",
        "stream.Writable",
        "process.stderr",
        "net.Socket",
        "http.ServerResponse",
        "true",
        "end()",
        "chunk",
        "false",
        "callback",
        "writeStream.write(chunk, encoding)",
        "writeStream.end(callback)",
        "uncork()",
        "cork()",
        "write()",
        "pipe()",
        "unpipe()",
        "destroy()",
        "highWaterMark",
        "setDefaultEncoding()",
        "stream.finished()",
        "stream"
      ]
    },
    {
      "title": "Node.js Server Reference",
      "summary": "Server Object\nServer objects in Node.js are used to create network servers. Different modules provide their own Server implementations:\nhttp.Server - For creating HTTP servers\nhttps.Server - For creating HTTPS servers\nnet.Server - For creating TCP servers\ntls.Server - For creating TLS/SSL servers\nThese server objects handle client connections, process requests, and deliver responses as appropriate for their respective protocols.\nCommon Server Methods\nCommon Server Events\nHTTP Server\nThe HTTP server in Node.js is created using the http.createServer() method:\nHTTPS Server\nThe HTTPS server requires SSL certificates and is created using the https.createServer() method:\nTCP Server (net.Server)\nA TCP server is created using the net.createServer() method:\nTLS/SSL Server\nA secure TLS/SSL server is created using the tls.createServer() method:\nHTTP Server with Routing\nA more complete HTTP server with basic routing:\nServer Timeouts and Limits\nConfiguring server timeouts and connection limits:\nHTTP/2 Server\nCreating an HTTP/2 server (introduced in Node.js v8.4.0):\nBest Practices\nError handling: Always handle server errors by listening for the 'error' event.\nGraceful shutdown: Implement proper shutdown procedures using server.close().\nTimeouts: Configure appropriate timeouts to prevent resource exhaustion.\nClustering: Use the cluster module to utilize multiple CPU cores.\nHTTPS/TLS: Use secure servers for production applications.\nConnection limits: Set appropriate limits based on your server's capabilities.\nMonitoring: Implement monitoring for connections, requests, and response times.",
      "examples": [
        "const http = require('http');\n\n// Create an HTTP server\nconst server = http.createServer((req, res) => {\n// Handle requests\nres.writeHead(200, {'Content-Type': 'text/plain'});\nres.end('Hello World\\n');\n});\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n});\n\n// Handle server events\nserver.on('error', (err) => {\nconsole.error(`Server error: ${err.message}`);\n});\n\nserver.on('close', () => {\nconsole.log('Server closed');\n});",
        "const https = require('https');\nconst fs = require('fs');\n\n// SSL options - in a production environment, use properly signed certificates\nconst options = {\nkey: fs.readFileSync('server-key.pem'),  // Path to your key file\ncert: fs.readFileSync('server-cert.pem') // Path to your certificate file\n};\n\n// Create an HTTPS server\nconst server = https.createServer(options, (req, res) => {\nres.writeHead(200, {'Content-Type': 'text/plain'});\nres.end('Hello Secure World\\n');\n});\n\n// Start the server\nconst PORT = 3443;\nserver.listen(PORT, () => {\nconsole.log(`Server running at https://localhost:${PORT}/`);\n});",
        "const net = require('net');\n\n// Create a TCP server\nconst server = net.createServer((socket) => {\nconsole.log('Client connected');\n\n// Handle data from client\nsocket.on('data', (data) => {\nconsole.log(`Received: ${data}`);\nsocket.write(`Echo: ${data}`);\n});\n\n// Handle client disconnection\nsocket.on('end', () => {\nconsole.log('Client disconnected');\n});\n\n// Handle socket errors\nsocket.on('error', (err) => {\nconsole.error(`Socket error: ${err.message}`);\n});\n});\n\n// Start the server\nconst PORT = 8888;\nserver.listen(PORT, () => {\nconsole.log(`TCP server listening on port ${PORT}`);\n});\n\n// Get server information after it's listening\nserver.on('listening', () => {\nconst address = server.address();\nconsole.log(`Server info: ${JSON.stringify(address)}`);\n});",
        "const tls = require('tls');\nconst fs = require('fs');\n\n// SSL options\nconst options = {\nkey: fs.readFileSync('server-key.pem'),\ncert: fs.readFileSync('server-cert.pem'),\n\n// Request client certificate (optional)\nrequestCert: true,\n\n// Reject connections without certificates (optional)\nrejectUnauthorized: false\n};\n\n// Create a TLS server\nconst server = tls.createServer(options, (socket) => {\nconsole.log('Client connected securely');\n\n// Check if client provided a certificate\nif (socket.authorized) {\nconsole.log('Client authorized');\n} else {\nconsole.log('Client unauthorized');\n}\n\n// Handle data from client\nsocket.on('data', (data) => {\nconsole.log(`Received: ${data}`);\nsocket.write(`Secure echo: ${data}`);\n});\n\n// Handle client disconnection\nsocket.on('end', () => {\nconsole.log('Client disconnected');\n});\n});\n\n// Start the server\nconst PORT = 8443;\nserver.listen(PORT, () => {\nconsole.log(`TLS server listening on port ${PORT}`);\n});",
        "const http = require('http');\nconst url = require('url');\n\n// Create an HTTP server with routing\nconst server = http.createServer((req, res) => {\n// Parse the URL\nconst parsedUrl = url.parse(req.url, true);\nconst path = parsedUrl.pathname;\nconst trimmedPath = path.replace(/^\\/+|\\/+$/g, '');\n\n// Get the HTTP method\nconst method = req.method.toLowerCase();\n\n// Get query parameters\nconst queryParams = parsedUrl.query;\n\n// Log the request\nconsole.log(`Request received: ${method} ${trimmedPath}`);\n\n// Route handler\nlet response = {\nstatus: 404,\ncontentType: 'application/json',\npayload: { message: 'Not Found' }\n};\n\n// Basic routing\nif (method === 'get') {\nif (trimmedPath === '') {\n// Home route\nresponse = {\nstatus: 200,\ncontentType: 'text/html',\npayload: '<h1>Home Page</h1><p>Welcome to the server</p>'\n};\n} else if (trimmedPath === 'api/users') {\n// API route - list users\nresponse = {\nstatus: 200,\ncontentType: 'application/json',\npayload: {\nusers: [\n{ id: 1, name: 'John' },\n{ id: 2, name: 'Jane' }\n]\n}\n};\n} else if (trimmedPath.startsWith('api/users/')) {\n// API route - get user by ID\nconst userId = trimmedPath.split('/')[2];\nresponse = {\nstatus: 200,\ncontentType: 'application/json',\npayload: { id: userId, name: `User ${userId}` }\n};\n}\n}\n\n// Return the response\nres.setHeader('Content-Type', response.contentType);\nres.writeHead(response.status);\n\n// Convert payload to string if it's an object\nconst payloadString = typeof response.payload === 'object'\n? JSON.stringify(response.payload)\n: response.payload;\n\nres.end(payloadString);\n});\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n});",
        "const http = require('http');\n\n// Create an HTTP server\nconst server = http.createServer((req, res) => {\n// Simulating a delayed response\nsetTimeout(() => {\nres.writeHead(200, {'Content-Type': 'text/plain'});\nres.end('Response after delay\\n');\n}, 2000);\n});\n\n// Configure server timeouts\nserver.timeout = 10000; // 10 seconds (default is 120000 or 2 minutes)\nserver.keepAliveTimeout = 5000; // 5 seconds (default is 5000)\nserver.maxHeadersCount = 1000; // Maximum headers count (default is 2000)\nserver.maxRequestsPerSocket = 100; // Max requests per socket (Node.js 14+)\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server with timeouts configured at http://localhost:${PORT}/`);\n\n// Display the server configuration\nconsole.log(`Server timeout: ${server.timeout}ms`);\nconsole.log(`Keep-alive timeout: ${server.keepAliveTimeout}ms`);\nconsole.log(`Max headers count: ${server.maxHeadersCount}`);\nconsole.log(`Max requests per socket: ${server.maxRequestsPerSocket || 'N/A'}`);\n});",
        "const http2 = require('http2');\nconst fs = require('fs');\n\n// SSL options for HTTP/2\nconst options = {\nkey: fs.readFileSync('server-key.pem'),\ncert: fs.readFileSync('server-cert.pem')\n};\n\n// Create an HTTP/2 server\nconst server = http2.createSecureServer(options);\n\n// Handle incoming streams\nserver.on('stream', (stream, headers) => {\nconst path = headers[':path'];\nconst method = headers[':method'];\n\nconsole.log(`${method} ${path}`);\n\n// Respond to the request\nstream.respond({\n'content-type': 'text/html',\n':status': 200\n});\n\nstream.end('<h1>HTTP/2 Server</h1><p>This page was served via HTTP/2</p>');\n});\n\n// Start the server\nconst PORT = 8443;\nserver.listen(PORT, () => {\nconsole.log(`HTTP/2 server running at https://localhost:${PORT}/`);\n});",
        "http.Server",
        "https.Server",
        "net.Server",
        "tls.Server",
        "http.createServer()",
        "https.createServer()",
        "net.createServer()",
        "tls.createServer()",
        "server.close()",
        "cluster"
      ]
    },
    {
      "title": "Node.js Agent Reference",
      "summary": "Agent Object\nThe Agent class in Node.js is responsible for managing connection persistence and reuse for HTTP/HTTPS client requests. It maintains a queue of pending requests for a given host and port, reusing a single socket connection for each in-flight request to that host and port.\nThere are two primary Agent implementations:\nhttp.Agent - For managing HTTP connections\nhttps.Agent - For managing HTTPS connections\nImporting Agent\nAgent Properties\nAgent Methods\nUsing the Default Agent\nBy default, HTTP/HTTPS client requests use the global agent (http.globalAgent or https.globalAgent):\nCreating a Custom Agent\nYou can create a custom agent with specific settings:\nHTTPS Agent\nFor HTTPS requests, you can create an HTTPS-specific agent with additional SSL/TLS options:\nDisabling Connection Pooling\nYou can disable connection pooling by setting the agent to false:\nConnection Pooling Example\nThis example demonstrates the performance benefits of connection pooling with multiple requests:\nCreating a Proxy Agent\nYou can extend the Agent class to create a proxy agent:\nBest Practices\nUse keepAlive: Enable keepAlive for persistent connections to improve performance when making multiple requests to the same server.\nSet maxSockets: Limit maxSockets to prevent overwhelming the target server or your own system's resources.\nClean up: Call agent.destroy() when the agent is no longer needed to free up resources.\nUse custom agents: Create different agent instances for different connection requirements or target servers.\nMonitor agent health: Track the number of active and free sockets to detect connection issues.\nSecurity: For HTTPS agents, always set appropriate SSL/TLS options and keep security settings up to date.\nError handling: Always handle potential errors in HTTP requests.",
      "examples": [
        "// Import HTTP module\nconst http = require('http');\n\n// The default agent\nconst defaultAgent = http.globalAgent;\n\n// Create a custom agent\nconst customAgent = new http.Agent({\nkeepAlive: true,\nmaxSockets: 25\n});",
        "const http = require('http');\n\n// Make a request using the default agent\nhttp.get('http://example.com', (res) => {\nconsole.log(`Status Code: ${res.statusCode}`);\n\n// Display global agent information\nconst agent = http.globalAgent;\nconsole.log(`Current sockets: ${Object.keys(agent.sockets).length}`);\nconsole.log(`Free sockets: ${Object.keys(agent.freeSockets).length}`);\nconsole.log(`Queued requests: ${Object.keys(agent.requests).length}`);\n\n// Consume response data\nres.resume();\n}).on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});",
        "const http = require('http');\n\n// Create a custom agent with keep-alive enabled\nconst keepAliveAgent = new http.Agent({\nkeepAlive: true,           // Keep connections open for reuse\nkeepAliveMsecs: 1000,      // Milliseconds to wait before sending TCP KeepAlive packet\nmaxSockets: 10,            // Maximum number of sockets per host\nmaxFreeSockets: 5,         // Maximum number of idle sockets when keepAlive is true\ntimeout: 60000,            // Socket timeout in milliseconds\nscheduling: 'fifo'         // FIFO request scheduling (instead of LIFO)\n});\n\n// Make a request using the custom agent\nconst options = {\nhostname: 'example.com',\npath: '/',\nmethod: 'GET',\nagent: keepAliveAgent     // Use our custom agent\n};\n\nconst req = http.request(options, (res) => {\nconsole.log(`Status Code: ${res.statusCode}`);\n\n// Display custom agent information\nconsole.log(`Current sockets: ${Object.keys(keepAliveAgent.sockets).length}`);\nconsole.log(`Free sockets: ${Object.keys(keepAliveAgent.freeSockets).length}`);\n\n// Consume response data\nres.resume();\n\n// Make a second request to demonstrate socket reuse\nsetTimeout(() => {\nconsole.log('Making second request to demonstrate socket reuse...');\n\nhttp.request(options, (res2) => {\nconsole.log(`Second request status: ${res2.statusCode}`);\nconsole.log(`Current sockets: ${Object.keys(keepAliveAgent.sockets).length}`);\nconsole.log(`Free sockets: ${Object.keys(keepAliveAgent.freeSockets).length}`);\n\n// Cleanup\nsetTimeout(() => {\nkeepAliveAgent.destroy();\nconsole.log('Agent destroyed');\n}, 1000);\n\nres2.resume();\n}).end();\n}, 2000);\n});\n\nreq.on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});\n\nreq.end();",
        "const https = require('https');\nconst fs = require('fs');\n\n// Create a custom HTTPS agent with SSL options\nconst httpsAgent = new https.Agent({\nkeepAlive: true,\nmaxSockets: 10,\n// SSL/TLS options\nca: fs.readFileSync('ca-cert.pem'),      // Certificate authority\ncert: fs.readFileSync('client-cert.pem'), // Client certificate\nkey: fs.readFileSync('client-key.pem'),   // Client private key\n// Additional TLS options\nrejectUnauthorized: true,                // Verify server certificate\nsecureProtocol: 'TLSv1_2_method',        // Use TLS v1.2\nciphers: 'HIGH:!aNULL:!MD5',             // Set allowed ciphers\nhonorCipherOrder: true                    // Honor cipher order\n});\n\n// Make a secure request using the HTTPS agent\nconst options = {\nhostname: 'secure-example.com',\npath: '/',\nmethod: 'GET',\nagent: httpsAgent\n};\n\nconst req = https.request(options, (res) => {\nconsole.log(`Status Code: ${res.statusCode}`);\n\n// Display the TLS/SSL-specific information\nconsole.log(`TLS Protocol: ${res.socket.getProtocol()}`);\nconsole.log(`Cipher: ${res.socket.getCipher().name}`);\nconsole.log(`Server Certificate Valid: ${res.socket.authorized}`);\n\n// Consume response data\nres.resume();\n\n// Cleanup\nsetTimeout(() => {\nhttpsAgent.destroy();\nconsole.log('HTTPS Agent destroyed');\n}, 1000);\n});\n\nreq.on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});\n\nreq.end();",
        "const http = require('http');\n\n// Make a request with agent: false to disable connection pooling\nconst options = {\nhostname: 'example.com',\npath: '/',\nmethod: 'GET',\nagent: false  // Disable connection pooling\n};\n\nconst req = http.request(options, (res) => {\nconsole.log(`Status Code: ${res.statusCode}`);\nconsole.log('Using a new connection (no agent)');\n\n// Consume response data\nres.resume();\n});\n\nreq.on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});\n\nreq.end();",
        "const http = require('http');\nconst { performance } = require('perf_hooks');\n\n// Function to make multiple requests with a given agent\nasync function makeMultipleRequests(useAgent, numRequests = 10) {\n// Define the target\nconst hostname = 'example.com';\nconst path = '/';\n\n// Choose agent\nconst agent = useAgent ? new http.Agent({ keepAlive: true }) : false;\n\nconsole.log(`Making ${numRequests} requests with ${useAgent ? 'custom agent' : 'no agent'}`);\nconst startTime = performance.now();\n\n// Make multiple requests\nfor (let i = 0; i < numRequests; i++) {\nawait new Promise((resolve, reject) => {\nconst req = http.request({\nhostname,\npath,\nmethod: 'GET',\nagent\n}, (res) => {\n// Consume response data\nres.resume();\nres.on('end', () => {\nresolve();\n});\n});\n\nreq.on('error', (err) => {\nconsole.error(`Request ${i + 1} error: ${err.message}`);\nreject(err);\n});\n\nreq.end();\n}).catch(() => {}); // Catch to continue the loop even if a request fails\n}\n\nconst endTime = performance.now();\nconsole.log(`Time taken: ${(endTime - startTime).toFixed(2)}ms`);\n\n// Cleanup\nif (useAgent && agent) {\nagent.destroy();\n}\n\nreturn endTime - startTime;\n}\n\n// Run the comparison\nasync function runComparison() {\nconsole.log('Testing HTTP request performance with and without Agent');\nconsole.log('----------------------------------------------------');\n\n// With no agent (no connection pooling)\nconst timeWithoutAgent = await makeMultipleRequests(false);\n\nconsole.log(''); // Separator\n\n// With agent (connection pooling)\nconst timeWithAgent = await makeMultipleRequests(true);\n\nconsole.log(''); // Separator\nconsole.log('Results:');\nconsole.log(`Without agent: ${timeWithoutAgent.toFixed(2)}ms`);\nconsole.log(`With agent: ${timeWithAgent.toFixed(2)}ms`);\nconsole.log(`Difference: ${(timeWithoutAgent - timeWithAgent).toFixed(2)}ms`);\nconsole.log(`Performance improvement: ${(100 * (timeWithoutAgent - timeWithAgent) / timeWithoutAgent).toFixed(2)}%`);\n}\n\n// Run the comparison\nrunComparison().catch(console.error);",
        "const http = require('http');\nconst net = require('net');\nconst { URL } = require('url');\n\n// A simple HTTP proxy agent implementation\nclass HttpProxyAgent extends http.Agent {\nconstructor(proxyUri, options = {}) {\nsuper(options);\nthis.proxyUri = new URL(proxyUri);\n}\n\n// Override createConnection to connect through the proxy\ncreateConnection(options, callback) {\n// Connect to the proxy server\nconst proxySocket = net.connect({\nhost: this.proxyUri.hostname,\nport: this.proxyUri.port || 80,\n}, () => {\n// Create the HTTP CONNECT request to the target through the proxy\nproxySocket.write(\n`CONNECT ${options.host}:${options.port} HTTP/1.1\\r\\n` +\n`Host: ${options.host}:${options.port}\\r\\n` +\n`Proxy-Connection: keep-alive\\r\\n` +\n// Add proxy authentication if provided\n(this.proxyUri.username && this.proxyUri.password\n? `Proxy-Authorization: Basic ${Buffer.from(\n`${this.proxyUri.username}:${this.proxyUri.password}`\n).toString('base64')}\\r\\n`\n: '') +\n'\\r\\n'\n);\n\n// Data handler for proxy response\nlet proxyResponse = '';\nconst onData = (chunk) => {\nproxyResponse += chunk.toString();\n\n// Check if we've received the full proxy response\nif (proxyResponse.includes('\\r\\n\\r\\n')) {\n// Parse status line\nconst statusLine = proxyResponse.split('\\r\\n')[0];\nconst statusCode = parseInt(statusLine.split(' ')[1], 10);\n\n// If the proxy connection was successful\nif (statusCode === 200) {\n// Remove data listener, we don't need it anymore\nproxySocket.removeListener('data', onData);\n\n// Callback with the socket\ncallback(null, proxySocket);\n} else {\n// Proxy connection failed\nproxySocket.destroy();\ncallback(new Error(`Proxy connection failed: ${statusLine}`));\n}\n}\n};\n\nproxySocket.on('data', onData);\n});\n\n// Handle socket errors\nproxySocket.on('error', (err) => {\ncallback(err);\n});\n\nreturn proxySocket;\n}\n}\n\n// Example usage of the proxy agent\nconst proxyAgent = new HttpProxyAgent('http://proxy.example.com:8080', {\nkeepAlive: true\n});\n\n// Make a request through the proxy\nconst options = {\nhostname: 'target-site.com',\npath: '/',\nmethod: 'GET',\nagent: proxyAgent\n};\n\nconst req = http.request(options, (res) => {\nconsole.log(`Status Code: ${res.statusCode}`);\n\n// Consume response data\nres.resume();\n\n// Cleanup\nsetTimeout(() => {\nproxyAgent.destroy();\nconsole.log('Proxy Agent destroyed');\n}, 1000);\n});\n\nreq.on('error', (err) => {\nconsole.error(`Error: ${err.message}`);\n});\n\nreq.end();",
        "http.Agent",
        "https.Agent",
        "keepAlive",
        "true",
        "net.createConnection()",
        "socket",
        "freeSockets",
        "request",
        "http.globalAgent",
        "https.globalAgent",
        "false",
        "maxSockets",
        "agent.destroy()"
      ]
    },
    {
      "title": "Node.js Request Reference",
      "summary": "HTTP Request Object\nThe HTTP Request object is created internally by Node.js and passed as the first parameter to the request event callback when making HTTP requests. It represents an incoming message from the client when used with HTTP servers, or an outgoing message when used with HTTP clients.\nThere are two main types of Request objects in Node.js:\nhttp.ClientRequest - Created when making outgoing HTTP requests\nhttp.IncomingMessage - Received by the server when handling client requests\nClientRequest Object\nThe http.ClientRequest object is an instance of Writable Stream created when calling http.request() or http.get(). It represents an outgoing HTTP request that you send to a server.\nCreating a ClientRequest\nClientRequest Properties\nClientRequest Methods\nClientRequest Events\nIncomingMessage Object\nThe http.IncomingMessage object is created by an HTTP server and passed as the first argument to the 'request' event. It represents an incoming message, typically a request from a client or a response from a server.\nAccessing IncomingMessage on a Server\nIncomingMessage Properties\nIncomingMessage Methods\nBasic GET Request Example\nA basic example using http.get() to make a GET request:\nPOST Request Example\nMaking a POST request with data:\nHandling Request Headers\nWorking with request headers:\nFile Upload Example\nUsing a request to upload a file:\nHandling Request Timeouts\nSetting and handling request timeouts:\nBest Practices\nError handling: Always attach an error event handler to HTTP requests.\nConsume response data: Always consume response data, even if you don't need it, to prevent memory leaks.\nSet timeouts: Set appropriate timeouts to prevent hanging requests.\nContent-Length: Always specify Content-Length for POST/PUT requests to ensure data is sent correctly.\nEnd the request: Always call request.end() to finish sending the request.\nHandle redirects: Be aware that Node.js does not follow redirects automatically - you need to handle them.\nReuse connections: Use a custom Agent with keepAlive for multiple requests to the same server.",
      "examples": [
        "const http = require('http');\n\n// Create a client request\nconst req = http.request({\nhostname: 'example.com',\nport: 80,\npath: '/',\nmethod: 'GET'\n}, (res) => {\n// Handle response (IncomingMessage)\nconsole.log(`Status: ${res.statusCode}`);\n});\n\n// End the request\nreq.end();",
        "const http = require('http');\n\n// Create HTTP server\nconst server = http.createServer((req, res) => {\n// 'req' is an IncomingMessage object\nconsole.log(`Received ${req.method} request for ${req.url}`);\nres.end('Hello World');\n});\n\nserver.listen(8080);",
        "const http = require('http');\n\n// Make a simple GET request\nhttp.get('http://example.com', (res) => {\nconst { statusCode } = res;\nconst contentType = res.headers['content-type'];\n\nconsole.log(`Status Code: ${statusCode}`);\nconsole.log(`Content-Type: ${contentType}`);\n\nlet error;\nif (statusCode !== 200) {\nerror = new Error(`Request Failed. Status Code: ${statusCode}`);\n} else if (!/^text\\/html/.test(contentType)) {\nerror = new Error(`Invalid content-type. Expected text/html but received ${contentType}`);\n}\n\nif (error) {\nconsole.error(error.message);\n// Consume response data to free up memory\nres.resume();\nreturn;\n}\n\nres.setEncoding('utf8');\nlet rawData = '';\n\n// Collect response data as it arrives\nres.on('data', (chunk) => { rawData += chunk; });\n\n// Process the complete response\nres.on('end', () => {\ntry {\nconsole.log(`Response length: ${rawData.length} characters`);\nconsole.log('First 100 characters:');\nconsole.log(rawData.substring(0, 100) + '...');\n} catch (e) {\nconsole.error(e.message);\n}\n});\n}).on('error', (e) => {\nconsole.error(`Got error: ${e.message}`);\n});",
        "const http = require('http');\n\n// Data to send in the POST request\nconst postData = JSON.stringify({\n'name': 'John Doe',\n'email': 'john@example.com',\n'message': 'Hello from Node.js HTTP client!'\n});\n\n// Request options\nconst options = {\nhostname: 'postman-echo.com',\nport: 80,\npath: '/post',\nmethod: 'POST',\nheaders: {\n'Content-Type': 'application/json',\n'Content-Length': Buffer.byteLength(postData)\n}\n};\n\n// Create the request\nconst req = http.request(options, (res) => {\nconsole.log(`STATUS: ${res.statusCode}`);\nconsole.log(`HEADERS: ${JSON.stringify(res.headers)}`);\n\nres.setEncoding('utf8');\nlet responseData = '';\n\nres.on('data', (chunk) => {\nresponseData += chunk;\n});\n\nres.on('end', () => {\nconsole.log('Response body:');\n\ntry {\n// Try to parse as JSON\nconst parsedData = JSON.parse(responseData);\nconsole.log(JSON.stringify(parsedData, null, 2));\n} catch (e) {\n// If not JSON, show as text\nconsole.log(responseData);\n}\n});\n});\n\nreq.on('error', (e) => {\nconsole.error(`Problem with request: ${e.message}`);\n});\n\n// Write data to request body\nreq.write(postData);\n\n// End the request\nreq.end();",
        "const http = require('http');\n\n// Create a server to demonstrate request headers\nconst server = http.createServer((req, res) => {\n// Display request information\nconsole.log(`Request received: ${req.method} ${req.url}`);\nconsole.log(`HTTP Version: ${req.httpVersion}`);\n\n// Display standard headers\nconsole.log('\\nStandard Headers:');\nconst stdHeaders = ['host', 'user-agent', 'accept', 'accept-language', 'content-type', 'content-length'];\nstdHeaders.forEach(header => {\nif (req.headers[header]) {\nconsole.log(`${header}: ${req.headers[header]}`);\n}\n});\n\n// Display raw headers (name-value pairs)\nconsole.log('\\nRaw Headers:');\nfor (let i = 0; i < req.rawHeaders.length; i += 2) {\nconsole.log(`${req.rawHeaders[i]}: ${req.rawHeaders[i+1]}`);\n}\n\n// Create response\nres.writeHead(200, {'Content-Type': 'text/html'});\n\n// Send response with headers information\nres.end(`\n<!DOCTYPE html>\n<html>\n<head>\n<title>Request Headers</title>\n</head>\n<body>\n<h1>Your Request Headers</h1>\n<pre>${JSON.stringify(req.headers, null, 2)}</pre>\n</body>\n</html>\n`);\n});\n\n// Start server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n\n// Make a request to demonstrate headers\nconst req = http.request({\nhostname: 'localhost',\nport: PORT,\npath: '/headers-demo',\nmethod: 'GET',\nheaders: {\n'User-Agent': 'Node.js HTTP Client',\n'X-Custom-Header': 'Custom Value',\n'Accept': 'text/html,application/json'\n}\n}, (res) => {\nres.resume(); // Consume response data\n});\n\nreq.on('error', (e) => {\nconsole.error(`Demo request error: ${e.message}`);\n});\n\nreq.end();\n});",
        "const http = require('http');\nconst fs = require('fs');\nconst path = require('path');\n\n// Create a sample file for upload\nconst sampleFile = path.join(__dirname, 'upload-sample.txt');\nfs.writeFileSync(sampleFile, 'This is a sample file for upload demonstration.\\n'.repeat(10));\n\n// Function to create multipart form-data boundary and body\nfunction createMultipartFormData(fields, files) {\nconst boundary = `----NodeJSUploadExample${Math.random().toString(16).substr(2)}`;\nlet body = '';\n\n// Add regular fields\nObject.keys(fields).forEach(field => {\nbody += `--${boundary}\\r\\n`;\nbody += `Content-Disposition: form-data; name=\"${field}\"\\r\\n\\r\\n`;\nbody += `${fields[field]}\\r\\n`;\n});\n\n// Add files\nObject.keys(files).forEach(fileField => {\nconst filePath = files[fileField];\nconst filename = path.basename(filePath);\nconst fileContent = fs.readFileSync(filePath);\n\nbody += `--${boundary}\\r\\n`;\nbody += `Content-Disposition: form-data; name=\"${fileField}\"; filename=\"${filename}\"\\r\\n`;\nbody += `Content-Type: application/octet-stream\\r\\n\\r\\n`;\nbody += fileContent.toString() + '\\r\\n';\n});\n\n// Add final boundary\nbody += `--${boundary}--\\r\\n`;\n\nreturn {\nboundary,\nbody\n};\n}\n\n// Prepare form data\nconst formData = createMultipartFormData(\n{\nname: 'Node.js Upload Example',\ndescription: 'Uploading a file using HTTP client request'\n},\n{\nfile: sampleFile\n}\n);\n\n// Request options\nconst options = {\nhostname: 'httpbin.org',\nport: 80,\npath: '/post',\nmethod: 'POST',\nheaders: {\n'Content-Type': `multipart/form-data; boundary=${formData.boundary}`,\n'Content-Length': Buffer.byteLength(formData.body)\n}\n};\n\n// Create the request\nconst req = http.request(options, (res) => {\nconsole.log(`Upload Status: ${res.statusCode}`);\n\nlet responseData = '';\nres.setEncoding('utf8');\n\nres.on('data', (chunk) => {\nresponseData += chunk;\n});\n\nres.on('end', () => {\nconsole.log('Upload Response:');\ntry {\nconst response = JSON.stringify(JSON.parse(responseData), null, 2);\nconsole.log(response);\n} catch (e) {\nconsole.log(responseData);\n}\n\n// Clean up sample file\nfs.unlinkSync(sampleFile);\nconsole.log('Sample file removed');\n});\n});\n\nreq.on('error', (e) => {\nconsole.error(`Upload error: ${e.message}`);\n});\n\n// Send the form data\nreq.write(formData.body);\nreq.end();\n\nconsole.log('Uploading file...');",
        "const http = require('http');\n\n// Create a request with timeout\nconst req = http.request({\nhostname: 'example.com',\nport: 80,\npath: '/',\nmethod: 'GET',\ntimeout: 8080 // 3 second timeout\n}, (res) => {\nconsole.log(`STATUS: ${res.statusCode}`);\nres.resume(); // Consume response data\n});\n\n// Handle timeout event\nreq.on('timeout', () => {\nconsole.log('Request timed out after 3 seconds');\nreq.abort(); // Abort the request\n});\n\n// Handle errors, including those caused by abort()\nreq.on('error', (err) => {\nconsole.error(`Request error: ${err.message}`);\n});\n\n// End the request\nreq.end();",
        "http.ClientRequest",
        "http.IncomingMessage",
        "Writable Stream",
        "http.request()",
        "http.get()",
        "request.connection",
        "noDelay",
        "keepAlive",
        "net.Socket",
        "request.end()"
      ]
    },
    {
      "title": "Node.js Response Reference",
      "summary": "HTTP Response Object\nThe HTTP Response object in Node.js (http.ServerResponse) is created internally by an HTTP server, not by the user. It's passed as the second parameter to the 'request' event callback function.\nThis object is used to return data to the client and implements the Writable Stream interface. The response object is how the server sends data back to the client that made the request.\nUsing the Response Object\nResponse Properties\nResponse Methods\nBasic Response Example\nA basic example of using various response methods:\nSetting Response Headers\nDifferent ways to set response headers:\nHTTP Status Codes\nSetting different HTTP status codes:\nStreaming Responses\nUsing the response object to stream data:\nCompression\nCompressing responses with gzip or deflate:\nBest Practices\nAlways set Content-Type: Always set the appropriate Content-Type header for your responses.\nUse proper status codes: Use appropriate HTTP status codes to indicate the result of the request.\nSet proper headers: Set appropriate headers like Cache-Control, Content-Length, etc.\nHandle errors properly: Return appropriate status codes (4xx, 5xx) with meaningful error messages.\nStream large responses: For large responses, use streaming instead of loading everything into memory.\nImplement compression: Use compression for text-based responses to reduce bandwidth usage.\nSecurity headers: Include security headers like Content-Security-Policy, X-Content-Type-Options, etc.\nAlways end the response: Always call response.end() to finalize the response.",
      "examples": [
        "const http = require('http');\n\n// Create an HTTP server\nconst server = http.createServer((req, res) => {\n// 'res' is the ServerResponse object\nres.statusCode = 200;\nres.setHeader('Content-Type', 'text/plain');\nres.end('Hello World\\n');\n});\n\nserver.listen(8080, () => {\nconsole.log('Server running at http://localhost:8080/');\n});",
        "const http = require('http');\n\n// Create an HTTP server\nconst server = http.createServer((req, res) => {\n// Set status code and message\nres.statusCode = 200;\nres.statusMessage = 'OK';\n\n// Set headers\nres.setHeader('Content-Type', 'text/html');\nres.setHeader('X-Powered-By', 'Node.js');\n\n// Log response information\nconsole.log(`Response status: ${res.statusCode} ${res.statusMessage}`);\nconsole.log(`Headers sent: ${res.headersSent}`);\n\n// Send additional headers using writeHead (overwrites previously set ones)\nres.writeHead(200, {\n'Content-Type': 'text/html',\n'X-Custom-Header': 'Custom Value'\n});\n\n// Check headers sent now\nconsole.log(`Headers sent after writeHead: ${res.headersSent}`);\n\n// Write response body in chunks\nres.write('<!DOCTYPE html>\\n');\nres.write('<html>\\n');\nres.write('<head><title>Node.js Response Example</title></head>\\n');\nres.write('<body>\\n');\nres.write('  <h1>Hello from Node.js!</h1>\\n');\nres.write('  <p>This response was sent using the ServerResponse object.</p>\\n');\nres.write('</body>\\n');\nres.write('</html>');\n\n// End the response\nres.end();\n\n// Log completion status\nconsole.log(`Response finished: ${res.finished}`);\nconsole.log(`Response writableEnded: ${res.writableEnded}`);\nconsole.log(`Response writableFinished: ${res.writableFinished}`);\n});\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n});",
        "const http = require('http');\n\n// Create HTTP server\nconst server = http.createServer((req, res) => {\n// Method 1: Set individual headers with setHeader\nres.setHeader('Content-Type', 'application/json');\nres.setHeader('Cache-Control', 'max-age=3600');\nres.setHeader('X-Custom-Header', 'Method 1');\n\n// Get a header value\nconst contentType = res.getHeader('Content-Type');\nconsole.log(`Content-Type header: ${contentType}`);\n\n// Check if a header exists\nconsole.log(`Has Cache-Control header: ${res.hasHeader('Cache-Control')}`);\n\n// Get all header names\nconsole.log('Header names:', res.getHeaderNames());\n\n// Get all headers as an object\nconsole.log('All headers:', res.getHeaders());\n\n// Remove a header\nres.removeHeader('X-Custom-Header');\nconsole.log(`After removal, has X-Custom-Header: ${res.hasHeader('X-Custom-Header')}`);\n\n// Method 2: Set multiple headers with writeHead\nres.writeHead(200, {\n'Content-Type': 'application/json',\n'X-Custom-Header': 'Method 2',\n'X-Powered-By': 'Node.js'\n});\n\n// Send JSON response\nconst responseObject = {\nmessage: 'Headers demonstration',\nheaders: Object.fromEntries(\nObject.entries(res.getHeaders())\n),\nheadersSent: res.headersSent\n};\n\nres.end(JSON.stringify(responseObject, null, 2));\n});\n\n// Start server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n});",
        "const http = require('http');\nconst url = require('url');\n\n// Create an HTTP server that demonstrates different status codes\nconst server = http.createServer((req, res) => {\n// Parse the request URL\nconst parsedUrl = url.parse(req.url, true);\nconst path = parsedUrl.pathname;\n\n// Set Content-Type header\nres.setHeader('Content-Type', 'text/html');\n\n// Handle different paths with different status codes\nif (path === '/') {\n// 200 OK\nres.writeHead(200, 'OK');\nres.end(`\n<h1>HTTP Status Codes Demo</h1>\n<p>This page demonstrates different HTTP status codes.</p>\n<ul>\n<li><a href=\"/\">200 OK (this page)</a></li>\n<li><a href=\"/redirect\">301 Moved Permanently</a></li>\n<li><a href=\"/not-modified\">304 Not Modified</a></li>\n<li><a href=\"/bad-request\">400 Bad Request</a></li>\n<li><a href=\"/unauthorized\">401 Unauthorized</a></li>\n<li><a href=\"/forbidden\">403 Forbidden</a></li>\n<li><a href=\"/not-found\">404 Not Found</a></li>\n<li><a href=\"/server-error\">500 Internal Server Error</a></li>\n</ul>\n`);\n}\nelse if (path === '/redirect') {\n// 301 Moved Permanently\nres.writeHead(301, {\n'Location': '/'\n});\nres.end();\n}\nelse if (path === '/not-modified') {\n// 304 Not Modified\nres.writeHead(304);\nres.end();\n}\nelse if (path === '/bad-request') {\n// 400 Bad Request\nres.writeHead(400, 'Bad Request');\nres.end(`\n<h1>400 Bad Request</h1>\n<p>The server could not understand the request due to invalid syntax.</p>\n<p><a href=\"/\">Go back to home</a></p>\n`);\n}\nelse if (path === '/unauthorized') {\n// 401 Unauthorized\nres.writeHead(401, {\n'WWW-Authenticate': 'Basic realm=\"Access to the site\"'\n});\nres.end(`\n<h1>401 Unauthorized</h1>\n<p>Authentication is required but was not provided.</p>\n<p><a href=\"/\">Go back to home</a></p>\n`);\n}\nelse if (path === '/forbidden') {\n// 403 Forbidden\nres.writeHead(403, 'Forbidden');\nres.end(`\n<h1>403 Forbidden</h1>\n<p>The server understood the request but refuses to authorize it.</p>\n<p><a href=\"/\">Go back to home</a></p>\n`);\n}\nelse if (path === '/not-found') {\n// 404 Not Found\nres.writeHead(404, 'Not Found');\nres.end(`\n<h1>404 Not Found</h1>\n<p>The requested resource could not be found on this server.</p>\n<p><a href=\"/\">Go back to home</a></p>\n`);\n}\nelse if (path === '/server-error') {\n// 500 Internal Server Error\nres.writeHead(500, 'Internal Server Error');\nres.end(`\n<h1>500 Internal Server Error</h1>\n<p>The server has encountered a situation it doesn't know how to handle.</p>\n<p><a href=\"/\">Go back to home</a></p>\n`);\n}\nelse {\n// Default: 404 Not Found\nres.writeHead(404, 'Not Found');\nres.end(`\n<h1>404 Not Found</h1>\n<p>The requested resource could not be found on this server.</p>\n<p><a href=\"/\">Go back to home</a></p>\n`);\n}\n});\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n});",
        "const http = require('http');\nconst fs = require('fs');\nconst path = require('path');\n\n// Create an HTTP server\nconst server = http.createServer((req, res) => {\nconst parsedUrl = new URL(req.url, 'http://localhost');\nconst pathname = parsedUrl.pathname;\n\n// Handle different paths\nif (pathname === '/') {\n// Send a regular response\nres.writeHead(200, {'Content-Type': 'text/html'});\nres.end(`\n<h1>Streaming Examples</h1>\n<ul>\n<li><a href=\"/stream-text\">Stream a large text response</a></li>\n<li><a href=\"/stream-file\">Stream a file</a></li>\n<li><a href=\"/stream-json\">Stream a JSON response</a></li>\n</ul>\n`);\n}\nelse if (pathname === '/stream-text') {\n// Stream a large text response\nres.writeHead(200, {'Content-Type': 'text/plain'});\n\nlet count = 1;\nconst max = 10;\n\n// Write response in chunks with delay\nconst interval = setInterval(() => {\nres.write(`Chunk ${count} of data\\n`.repeat(20));\n\nif (count >= max) {\nclearInterval(interval);\nres.end('\\nStreaming complete!');\n}\ncount++;\n}, 500);\n\n// Handle client disconnect\nreq.on('close', () => {\nclearInterval(interval);\nconsole.log('Client closed connection');\n});\n}\nelse if (pathname === '/stream-file') {\n// Create a sample file\nconst filePath = path.join(__dirname, 'sample-large-file.txt');\nif (!fs.existsSync(filePath)) {\nconst writeStream = fs.createWriteStream(filePath);\nfor (let i = 0; i < 10000; i++) {\nwriteStream.write(`Line ${i}: This is a sample line of text for streaming demonstration.\\n`);\n}\nwriteStream.end();\n}\n\n// Get file stats\nconst stat = fs.statSync(filePath);\n\n// Set headers\nres.writeHead(200, {\n'Content-Type': 'text/plain',\n'Content-Length': stat.size\n});\n\n// Create read stream and pipe to response\nconst fileStream = fs.createReadStream(filePath);\nfileStream.pipe(res);\n\n// Handle file stream errors\nfileStream.on('error', (err) => {\nconsole.error(`Error streaming file: ${err.message}`);\nres.end('Error streaming file');\n});\n\n// Clean up after response is sent\nres.on('finish', () => {\nfs.unlink(filePath, (err) => {\nif (err) console.error(`Error deleting sample file: ${err.message}`);\n});\n});\n}\nelse if (pathname === '/stream-json') {\n// Stream a large JSON response\nres.writeHead(200, {'Content-Type': 'application/json'});\n\n// Start JSON array\nres.write('[\\n');\n\nlet count = 0;\nconst max = 100;\nlet isFirst = true;\n\n// Write JSON objects with delay\nconst interval = setInterval(() => {\n// Add comma for all but first item\nif (!isFirst) {\nres.write(',\\n');\n} else {\nisFirst = false;\n}\n\n// Create a JSON object\nconst obj = {\nid: count,\nname: `Item ${count}`,\ntimestamp: new Date().toISOString(),\ndata: `Sample data for item ${count}`\n};\n\n// Write the object as JSON\nres.write(JSON.stringify(obj, null, 2));\n\nif (count >= max) {\nclearInterval(interval);\n// End JSON array\nres.write('\\n]');\nres.end();\n}\ncount++;\n}, 100);\n\n// Handle client disconnect\nreq.on('close', () => {\nclearInterval(interval);\nconsole.log('Client closed connection during JSON streaming');\n});\n}\nelse {\n// Handle unknown paths\nres.writeHead(404, {'Content-Type': 'text/plain'});\nres.end('Not Found');\n}\n});\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Streaming server running at http://localhost:${PORT}/`);\n});",
        "const http = require('http');\nconst zlib = require('zlib');\n\n// Create an HTTP server with compression\nconst server = http.createServer((req, res) => {\n// Get the Accept-Encoding header\nconst acceptEncoding = req.headers['accept-encoding'] || '';\n\n// Create a sample response (large string)\nconst sampleData = 'This is a sample text that will be compressed. '.repeat(1000);\n\n// Function to send the response with appropriate headers\nfunction sendResponse(data, encoding) {\n// Set Content-Encoding header if compression is used\nif (encoding) {\nres.setHeader('Content-Encoding', encoding);\n}\n\nres.setHeader('Content-Type', 'text/plain');\nres.setHeader('Vary', 'Accept-Encoding');\nres.writeHead(200);\nres.end(data);\n}\n\n// Check what encodings the client supports\nif (/\\bgzip\\b/.test(acceptEncoding)) {\n// Client supports gzip\nconsole.log('Using gzip compression');\nzlib.gzip(sampleData, (err, compressed) => {\nif (err) {\nconsole.error('Gzip compression failed:', err);\nsendResponse(sampleData); // Fall back to uncompressed\n} else {\nsendResponse(compressed, 'gzip');\nconsole.log(`Original size: ${sampleData.length}, Compressed size: ${compressed.length}`);\nconsole.log(`Compression ratio: ${(compressed.length / sampleData.length * 100).toFixed(2)}%`);\n}\n});\n} else if (/\\bdeflate\\b/.test(acceptEncoding)) {\n// Client supports deflate\nconsole.log('Using deflate compression');\nzlib.deflate(sampleData, (err, compressed) => {\nif (err) {\nconsole.error('Deflate compression failed:', err);\nsendResponse(sampleData); // Fall back to uncompressed\n} else {\nsendResponse(compressed, 'deflate');\nconsole.log(`Original size: ${sampleData.length}, Compressed size: ${compressed.length}`);\nconsole.log(`Compression ratio: ${(compressed.length / sampleData.length * 100).toFixed(2)}%`);\n}\n});\n} else if (/\\bbr\\b/.test(acceptEncoding)) {\n// Client supports Brotli (if Node.js version supports it)\nif (typeof zlib.brotliCompress === 'function') {\nconsole.log('Using Brotli compression');\nzlib.brotliCompress(sampleData, (err, compressed) => {\nif (err) {\nconsole.error('Brotli compression failed:', err);\nsendResponse(sampleData); // Fall back to uncompressed\n} else {\nsendResponse(compressed, 'br');\nconsole.log(`Original size: ${sampleData.length}, Compressed size: ${compressed.length}`);\nconsole.log(`Compression ratio: ${(compressed.length / sampleData.length * 100).toFixed(2)}%`);\n}\n});\n} else {\nconsole.log('Brotli not supported in this Node.js version');\nsendResponse(sampleData); // Fall back to uncompressed\n}\n} else {\n// No compression supported by client\nconsole.log('No compression used');\nsendResponse(sampleData);\n}\n});\n\n// Start the server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Compression server running at http://localhost:${PORT}/`);\n});",
        "http.ServerResponse",
        "Writable Stream",
        "response.end()",
        "true",
        "name",
        "cork()"
      ]
    },
    {
      "title": "Node.js Message Reference",
      "summary": "HTTP Message Object\nThe http.IncomingMessage object is created by the http.Server or http.ClientRequest and passed as the first argument to the 'request' and 'response' event respectively. It is used to access response status, headers, and data.\nThis message object represents both:\nThe HTTP request received by the server (passed to the 'request' event)\nThe HTTP response received by the client (passed to the 'response' event)\nIt implements the Readable Stream interface, allowing you to consume the message body.\nMessage Properties\nMessage Methods\nMessage as a Readable Stream\nBecause http.IncomingMessage implements the Readable Stream interface, it includes all stream methods like read(), pipe(), and events like 'data', 'end', and 'error'.\nExamples\nServer-side Message (Request)\nThis example demonstrates handling the IncomingMessage object on the server side:\nClient-side Message (Response)\nThis example demonstrates handling the IncomingMessage object on the client side:\nHandling Message Body with Streams\nThis example demonstrates using stream methods to handle a message body:\nHandling Message Trailers\nThis example demonstrates handling HTTP trailers (headers that come after the message body):\nHandling Large Messages with Flow Control\nThis example demonstrates handling large message bodies with flow control:\nBest Practices\nCheck for complete messages: Use message.complete to ensure the entire message has been received.\nHandle errors: Always listen for the 'error' event on message objects.\nFlow control: For large messages, use pause() and resume() to control data flow.\nStream processing: Use stream methods like pipe() for efficient processing of message bodies.\nMemory management: For large messages, process data in chunks rather than loading the entire message into memory.\nURL parsing: Use the url module to parse URL strings from request.url.\nHeader handling: Be aware that HTTP headers are case-insensitive, but Node.js converts them to lowercase.",
      "examples": [
        "const http = require('http');\nconst url = require('url');\n\n// Create an HTTP server\nconst server = http.createServer((req, res) => {\n// 'req' is the IncomingMessage object\n\n// Basic message properties\nconsole.log('HTTP Version:', req.httpVersion);\nconsole.log('Method:', req.method);\nconsole.log('URL:', req.url);\n\n// Parse the URL\nconst parsedUrl = url.parse(req.url, true);\nconsole.log('Pathname:', parsedUrl.pathname);\nconsole.log('Query:', parsedUrl.query);\n\n// Headers\nconsole.log('Headers:', req.headers);\nconsole.log('User-Agent:', req.headers['user-agent']);\n\n// Raw headers with keys and values as separate array elements\nconsole.log('Raw Headers:', req.rawHeaders);\n\n// Socket information\nconsole.log('Remote Address:', req.socket.remoteAddress);\nconsole.log('Remote Port:', req.socket.remotePort);\n\n// Reading the message body (if any)\nlet body = [];\nreq.on('data', (chunk) => {\nbody.push(chunk);\n});\n\nreq.on('end', () => {\nbody = Buffer.concat(body).toString();\nconsole.log('Request body:', body);\n\n// Now that we have the body, send a response\nres.writeHead(200, { 'Content-Type': 'application/json' });\nres.end(JSON.stringify({\nhttpVersion: req.httpVersion,\nmethod: req.method,\nurl: req.url,\nheaders: req.headers,\nbody: body || null\n}));\n});\n\n// Handle errors\nreq.on('error', (err) => {\nconsole.error('Request error:', err);\nres.statusCode = 400;\nres.end('Error: ' + err.message);\n});\n});\n\n// Start server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n\n// Make a test request\nhttp.request({\nhostname: 'localhost',\nport: PORT,\npath: '/test?param1=value1¶m2=value2',\nmethod: 'POST',\nheaders: {\n'Content-Type': 'application/json',\n'Custom-Header': 'Custom Value'\n}\n}, (res) => {\nres.resume(); // Consume response data\n}).end('{\"message\":\"Hello from the client!\"}');\n});",
        "const http = require('http');\n\n// Make an HTTP request\nconst req = http.request('http://example.com', (res) => {\n// 'res' is the IncomingMessage object (response)\n\n// Basic message properties\nconsole.log('Status Code:', res.statusCode);\nconsole.log('Status Message:', res.statusMessage);\nconsole.log('HTTP Version:', res.httpVersion);\n\n// Headers\nconsole.log('Headers:', res.headers);\nconsole.log('Content-Type:', res.headers['content-type']);\nconsole.log('Raw Headers:', res.rawHeaders);\n\n// Socket information\nconsole.log('Remote Address:', res.socket.remoteAddress);\nconsole.log('Remote Port:', res.socket.remotePort);\n\n// Reading the message body\nlet body = [];\n\n// Data events emit when chunks of the body are received\nres.on('data', (chunk) => {\nbody.push(chunk);\nconsole.log('Received chunk of', chunk.length, 'bytes');\n});\n\n// End event is emitted when the entire body has been received\nres.on('end', () => {\nbody = Buffer.concat(body).toString();\nconsole.log('Body length:', body.length);\nconsole.log('Body preview:', body.substring(0, 100) + '...');\n\n// Check trailers (if any)\nconsole.log('Trailers:', res.trailers);\nconsole.log('Raw Trailers:', res.rawTrailers);\n\n// Check if message is complete\nconsole.log('Message complete:', res.complete);\n});\n\n// Handle message errors\nres.on('error', (err) => {\nconsole.error('Response error:', err);\n});\n});\n\n// Handle request errors\nreq.on('error', (err) => {\nconsole.error('Request error:', err);\n});\n\n// End the request\nreq.end();",
        "const http = require('http');\nconst fs = require('fs');\nconst path = require('path');\n\n// Create a server to handle file uploads\nconst server = http.createServer((req, res) => {\nif (req.method === 'POST' && req.url === '/upload') {\n// Create a write stream to a file\nconst filePath = path.join(__dirname, 'uploaded-file.txt');\nconst fileStream = fs.createWriteStream(filePath);\n\n// Pipe the request body directly to the file\nreq.pipe(fileStream);\n\n// Handle completion\nfileStream.on('finish', () => {\n// Get file stats to check size\nfs.stat(filePath, (err, stats) => {\nif (err) {\nconsole.error('Error getting file stats:', err);\nres.writeHead(500, {'Content-Type': 'text/plain'});\nres.end('Error processing upload');\nreturn;\n}\n\n// Send response\nres.writeHead(200, {'Content-Type': 'application/json'});\nres.end(JSON.stringify({\nsuccess: true,\nmessage: 'File uploaded successfully',\nsize: stats.size,\npath: filePath\n}));\n\nconsole.log(`File uploaded to ${filePath}`);\nconsole.log(`File size: ${stats.size} bytes`);\n\n// Clean up the file after a delay\nsetTimeout(() => {\nfs.unlink(filePath, (err) => {\nif (err) console.error('Error removing uploaded file:', err);\nelse console.log('Uploaded file removed');\n});\n}, 5000);\n});\n});\n\n// Handle errors\nfileStream.on('error', (err) => {\nconsole.error('File write error:', err);\nres.writeHead(500, {'Content-Type': 'text/plain'});\nres.end('Error saving file');\n});\n\nreq.on('error', (err) => {\nconsole.error('Request error:', err);\nfileStream.destroy(err);\n});\n}\nelse if (req.method === 'GET' && req.url === '/') {\n// Provide a simple HTML form for uploading\nres.writeHead(200, {'Content-Type': 'text/html'});\nres.end(`\n<!DOCTYPE html>\n<html>\n<head>\n<title>File Upload Example</title>\n</head>\n<body>\n<h1>Upload a Text File</h1>\n<form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n<input type=\"file\" name=\"file\" accept=\".txt\">\n<button type=\"submit\">Upload</button>\n</form>\n<p>Note: This is a simple example. A real implementation would need to parse multipart form data.</p>\n</body>\n</html>\n`);\n}\nelse {\n// Handle all other requests\nres.writeHead(404, {'Content-Type': 'text/plain'});\nres.end('Not Found');\n}\n});\n\n// Start server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n\n// Make a test upload\nsetTimeout(() => {\nconst req = http.request({\nhostname: 'localhost',\nport: PORT,\npath: '/upload',\nmethod: 'POST',\nheaders: {\n'Content-Type': 'text/plain'\n}\n}, (res) => {\nlet data = '';\nres.on('data', (chunk) => { data += chunk; });\nres.on('end', () => {\nconsole.log('Upload response:', data);\n});\n});\n\nreq.on('error', (e) => {\nconsole.error('Test request error:', e.message);\n});\n\n// Write some content to upload\nreq.write('This is a test file content uploaded using http.request.\\n');\nreq.write('It demonstrates streaming data to the server.\\n');\nreq.end();\n}, 1000);\n});",
        "const http = require('http');\nconst zlib = require('zlib');\n\n// Create an HTTP server that sends trailers\nconst server = http.createServer((req, res) => {\n// Inform the client we'll be sending trailers\nres.writeHead(200, {\n'Content-Type': 'text/plain',\n'Transfer-Encoding': 'chunked', // Required for trailers\n'Trailer': 'Content-MD5, X-Response-Time' // Declare which trailers will be sent\n});\n\n// Write some response data\nres.write('Beginning of the response\\n');\n\n// Simulate processing time\nsetTimeout(() => {\nres.write('Middle of the response\\n');\n\nsetTimeout(() => {\n// Final part of the body\nres.write('End of the response\\n');\n\n// Add trailers\nres.addTrailers({\n'Content-MD5': 'e4e68fb7bd0e697a0ae8f1bb342846d3', // Would normally be the hash of the body\n'X-Response-Time': `${Date.now() - req.start}ms` // Processing time\n});\n\n// End the response\nres.end();\n}, 500);\n}, 500);\n});\n\n// Track request start time\nserver.on('request', (req) => {\nreq.start = Date.now();\n});\n\n// Start server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n\n// Make a request to test trailers\nhttp.get(`http://localhost:${PORT}`, (res) => {\nconsole.log('Response status:', res.statusCode);\nconsole.log('Response headers:', res.headers);\n\n// Check if trailers are declared\nif (res.headers.trailer) {\nconsole.log('Trailer headers declared:', res.headers.trailer);\n}\n\n// Read the response body\nlet body = '';\n\nres.on('data', (chunk) => {\nbody += chunk;\nconsole.log('Received chunk:', chunk.toString());\n});\n\n// The 'end' event is emitted when the entire body has been received\nres.on('end', () => {\nconsole.log('Complete response body:', body);\nconsole.log('Trailers received:', res.trailers);\n\n// Server should close after test is complete\nserver.close();\n});\n}).on('error', (err) => {\nconsole.error('Request error:', err);\n});\n});",
        "const http = require('http');\n\n// Create a server to handle large uploads with flow control\nconst server = http.createServer((req, res) => {\nif (req.method === 'POST' && req.url === '/large-upload') {\n// Set up variables to track data\nlet dataSize = 0;\nlet chunks = 0;\n\n// Switch to pause mode (by default it's in flowing mode)\nreq.pause();\n\nconsole.log('Incoming large upload - using flow control');\n\n// Process data in chunks\nfunction processNextChunk() {\n// Resume the stream to get more data\nreq.resume();\n\n// Set a timeout to pause after a bit\nsetTimeout(() => {\n// Pause the stream again\nreq.pause();\n\nconsole.log(`Processed chunk ${++chunks}, total ${dataSize} bytes so far`);\n\n// If there's more data to process, schedule the next chunk\n// Otherwise, wait for 'end' event to finish\nif (!req.complete) {\n// Schedule next chunk processing\nsetTimeout(processNextChunk, 100);\n}\n}, 100); // Process for 100ms, then pause\n}\n\n// Listen for data events\nreq.on('data', (chunk) => {\ndataSize += chunk.length;\n});\n\n// Handle request end\nreq.on('end', () => {\nconsole.log(`Upload complete: ${dataSize} bytes received in ${chunks} chunks`);\n\n// Send a response\nres.writeHead(200, {'Content-Type': 'application/json'});\nres.end(JSON.stringify({\nsuccess: true,\nbytesReceived: dataSize,\nchunks: chunks\n}));\n});\n\n// Handle errors\nreq.on('error', (err) => {\nconsole.error('Request error:', err);\n\nres.writeHead(500, {'Content-Type': 'text/plain'});\nres.end('Error processing upload: ' + err.message);\n});\n\n// Start processing\nprocessNextChunk();\n}\nelse {\n// Handle other requests\nres.writeHead(404, {'Content-Type': 'text/plain'});\nres.end('Not Found');\n}\n});\n\n// Start server\nconst PORT = 8080;\nserver.listen(PORT, () => {\nconsole.log(`Server running at http://localhost:${PORT}/`);\n\n// Create a test client to simulate large upload\nconsole.log('Simulating large upload...');\n\nconst req = http.request({\nhostname: 'localhost',\nport: PORT,\npath: '/large-upload',\nmethod: 'POST',\nheaders: {\n'Content-Type': 'application/octet-stream'\n}\n}, (res) => {\n// Handle response\nlet responseData = '';\n\nres.on('data', (chunk) => {\nresponseData += chunk;\n});\n\nres.on('end', () => {\nconsole.log('Server response:', responseData);\n\n// Close the server after the test\nserver.close();\n});\n});\n\nreq.on('error', (err) => {\nconsole.error('Upload request error:', err);\n});\n\n// Generate and send a large body in chunks\nfunction sendChunk(i, total) {\nif (i >= total) {\n// All chunks sent, end the request\nreq.end();\nreturn;\n}\n\n// Create a 10KB chunk\nconst chunk = Buffer.alloc(10240);\nchunk.fill(65 + (i % 26)); // Fill with repeating letters\n\n// Write the chunk\nconst canContinue = req.write(chunk);\n\n// Log progress\nif (i % 10 === 0) {\nconsole.log(`Sent chunk ${i}/${total} (${i * 10240} bytes)`);\n}\n\n// If we can continue writing, schedule next chunk\nif (canContinue) {\n// Schedule next chunk\nsetImmediate(() => sendChunk(i + 1, total));\n} else {\n// If backpressure is applied, wait for drain event\nconsole.log('Backpressure applied, waiting for drain');\nreq.once('drain', () => {\nconsole.log('Drained, continuing upload');\nsendChunk(i + 1, total);\n});\n}\n}\n\n// Start sending chunks (50 chunks = ~500KB)\nsendChunk(0, 50);\n});",
        "http.IncomingMessage",
        "http.Server",
        "http.ClientRequest",
        "Readable Stream",
        "net.Socket",
        "destroy()",
        "error",
        "socket.setTimeout(msecs, callback)",
        "read()",
        "pipe()",
        "message.complete",
        "pause()",
        "resume()",
        "url",
        "request.url"
      ]
    },
    {
      "title": "Node.js Interface Reference",
      "summary": "Interface Object\nThe Interface class is part of the readline module in Node.js. It provides a way to read data from a Readable stream (such as process.stdin) one line at a time. It's commonly used for creating command-line interfaces (CLIs) and interactive prompts.\nImporting the readline Module\nInterface Properties\nInterface Methods\nInterface Events\nBasic Usage Example\nThis example demonstrates the basic usage of the Interface object to create a simple command-line prompt:\nPromise-based API Example\nNode.js v17+ provides a promise-based API for readline:\nCommand Line Interface Example\nBuilding a simple command-line interface with history support:\nInteractive Password Input\nCreating a password input that masks the entered characters:\nInteractive Menu Example\nCreating an interactive menu with options:\nBest Practices\nAlways close the interface: Be sure to call rl.close() when you're done to free up resources.\nHandle Ctrl+C: Listen for the 'SIGINT' event to handle program termination gracefully.\nUse promise-based API: For Node.js v17 and above, consider using the promise-based API for cleaner async code.\nSave history: For CLI applications, save and restore command history to provide a better user experience.\nHandle errors: Always handle potential errors when interacting with the user.\nProvide clear prompts: Make sure your prompts clearly indicate what type of input is expected.\nValidate input: Always validate user input before processing it.",
      "examples": [
        "// Import the readline module\nconst readline = require('readline');\n\n// Create an Interface instance\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});",
        "const readline = require('readline');\n\n// Create interface for reading from stdin and writing to stdout\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\n// Ask a question and get the user's input\nrl.question('What is your name? ', (name) => {\nconsole.log(`Hello, ${name}!`);\n\n// Ask another question\nrl.question('How are you today? ', (response) => {\nconsole.log(`Glad to hear: ${response}`);\n\n// Close the interface\nrl.close();\n});\n});\n\n// Handle the close event\nrl.on('close', () => {\nconsole.log('Interface closed. Goodbye!');\n});",
        "// For Node.js v17 and above:\nconst readline = require('readline/promises');\nconst { stdin: input, stdout: output } = require('process');\n\nasync function askQuestions() {\nconst rl = readline.createInterface({ input, output });\n\ntry {\n// Ask questions sequentially\nconst name = await rl.question('What is your name? ');\nconsole.log(`Hello, ${name}!`);\n\nconst age = await rl.question('How old are you? ');\nconsole.log(`You are ${age} years old.`);\n\nconst location = await rl.question('Where do you live? ');\nconsole.log(`${location} is a nice place!`);\n\n// Summary\nconsole.log('\\nSummary:');\nconsole.log(`Name: ${name}`);\nconsole.log(`Age: ${age}`);\nconsole.log(`Location: ${location}`);\n} finally {\n// Make sure to close the interface\nrl.close();\n}\n}\n\n// Run the async function\naskQuestions()\n.then(() => console.log('Questions completed!'))\n.catch(err => console.error('Error:', err));",
        "const readline = require('readline');\nconst fs = require('fs');\nconst path = require('path');\n\n// History file path\nconst historyFile = path.join(__dirname, '.command_history');\n\n// Load command history if it exists\nlet commandHistory = [];\ntry {\nif (fs.existsSync(historyFile)) {\ncommandHistory = fs.readFileSync(historyFile, 'utf8')\n.split('\\n')\n.filter(cmd => cmd.trim());\n}\n} catch (err) {\nconsole.error('Error loading history:', err.message);\n}\n\n// Create the interface with custom configuration\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout,\nprompt: 'cli> ',\nhistorySize: 100,\nhistory: commandHistory\n});\n\n// Available commands\nconst commands = {\nhelp: () => {\nconsole.log('\\nAvailable commands:');\nconsole.log('  help     - Show this help message');\nconsole.log('  hello    - Say hello');\nconsole.log('  date     - Show current date and time');\nconsole.log('  clear    - Clear the console');\nconsole.log('  exit     - Exit the CLI');\nrl.prompt();\n},\nhello: () => {\nconsole.log('Hello, world!');\nrl.prompt();\n},\ndate: () => {\nconsole.log(new Date().toLocaleString());\nrl.prompt();\n},\nclear: () => {\nprocess.stdout.write('\\x1Bc');\nrl.prompt();\n},\nexit: () => {\n// Save command history to file\ntry {\nfs.writeFileSync(historyFile, rl.history.join('\\n'));\nconsole.log(`Command history saved to ${historyFile}`);\n} catch (err) {\nconsole.error('Error saving history:', err.message);\n}\n\nconsole.log('Goodbye!');\nrl.close();\n}\n};\n\n// Display welcome message\nconsole.log('Simple CLI Example');\nconsole.log('Type \"help\" for available commands');\n\n// Display the prompt\nrl.prompt();\n\n// Handle input\nrl.on('line', (line) => {\nconst input = line.trim();\n\nif (input === '') {\nrl.prompt();\nreturn;\n}\n\nconst command = input.toLowerCase();\n\nif (commands[command]) {\ncommands[command]();\n} else {\nconsole.log(`Command not found: ${input}`);\nconsole.log('Type \"help\" for available commands');\nrl.prompt();\n}\n}).on('close', () => {\nprocess.exit(0);\n});\n\n// Handle Ctrl+C (SIGINT)\nrl.on('SIGINT', () => {\nrl.question('Are you sure you want to exit? (y/n) ', (answer) => {\nif (answer.toLowerCase() === 'y') {\ncommands.exit();\n} else {\nconsole.log('Operation cancelled');\nrl.prompt();\n}\n});\n});",
        "const readline = require('readline');\n\n// Create the interface\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\n// Function to prompt for masked input\nfunction promptPassword(query) {\nreturn new Promise((resolve) => {\n// Create a hidden readline instance to control input/output\nconst stdin = process.stdin;\n\n// Save the original configuration\nconst originalStdinIsTTY = stdin.isTTY;\nif (originalStdinIsTTY) {\nstdin.setRawMode(true);\n}\n\nlet password = '';\n\n// Write the query\nprocess.stdout.write(query);\n\n// Handle keypress events\nconst onData = (key) => {\n// Ctrl+C\nif (key.toString() === '\\u0003') {\nprocess.stdout.write('\\n');\nprocess.exit();\n}\n\n// Enter key\nif (key.toString() === '\\r' || key.toString() === '\\n') {\nif (originalStdinIsTTY) {\nstdin.setRawMode(false);\n}\nstdin.removeListener('data', onData);\nprocess.stdout.write('\\n');\nresolve(password);\nreturn;\n}\n\n// Backspace\nif (key.toString() === '\\u0008' || key.toString() === '\\u007f') {\nif (password.length > 0) {\npassword = password.slice(0, -1);\nprocess.stdout.write('\\b \\b'); // Erase last character\n}\nreturn;\n}\n\n// Regular character\npassword += key.toString();\nprocess.stdout.write('*'); // Show asterisk for each character\n};\n\nstdin.on('data', onData);\n});\n}\n\n// Example usage\nasync function login() {\nconst username = await new Promise((resolve) => {\nrl.question('Username: ', (answer) => {\nresolve(answer);\n});\n});\n\nconst password = await promptPassword('Password: ');\n\nconsole.log(`\\nAttempting login for user: ${username}`);\n\n// Simulate authentication check\nif (username === 'admin' && password === 'password') {\nconsole.log('Login successful!');\n} else {\nconsole.log('Invalid username or password');\n}\n\nrl.close();\n}\n\n// Start the login process\nlogin();",
        "const readline = require('readline');\n\n// Create the interface\nconst rl = readline.createInterface({\ninput: process.stdin,\noutput: process.stdout\n});\n\n// Menu options\nconst menuOptions = [\n{ id: 1, name: 'View Profile' },\n{ id: 2, name: 'Edit Settings' },\n{ id: 3, name: 'Check Messages' },\n{ id: 4, name: 'Log Out' },\n{ id: 5, name: 'Exit' }\n];\n\n// Display the menu\nfunction displayMenu() {\nconsole.log('\\n===== MAIN MENU =====');\nmenuOptions.forEach(option => {\nconsole.log(`${option.id}. ${option.name}`);\n});\nconsole.log('====================');\n}\n\n// Process the selected option\nfunction processOption(option) {\nconst selectedOption = menuOptions.find(item => item.id === parseInt(option));\n\nif (!selectedOption) {\nconsole.log('Invalid option. Please try again.');\nreturn promptUser();\n}\n\nconsole.log(`\\nYou selected: ${selectedOption.name}`);\n\n// Handle each option\nswitch (selectedOption.id) {\ncase 1:\nconsole.log('Displaying user profile...');\nconsole.log('Name: John Doe');\nconsole.log('Email: john@example.com');\nconsole.log('Role: Administrator');\nbreak;\ncase 2:\nconsole.log('Opening settings menu...');\nconsole.log('(Settings options would be displayed here)');\nbreak;\ncase 3:\nconsole.log('Checking messages...');\nconsole.log('You have no new messages.');\nbreak;\ncase 4:\nconsole.log('Logging out...');\nconsole.log('You have been logged out successfully.');\nreturn rl.close();\ncase 5:\nconsole.log('Exiting the application...');\nreturn rl.close();\n}\n\n// Return to the menu after a short delay\nsetTimeout(() => {\npromptUser();\n}, 1500);\n}\n\n// Prompt the user to select an option\nfunction promptUser() {\ndisplayMenu();\nrl.question('Select an option: ', (answer) => {\nprocessOption(answer);\n});\n}\n\n// Start the menu\nconsole.log('Welcome to the Interactive Menu Example');\npromptUser();\n\n// Handle close event\nrl.on('close', () => {\nconsole.log('\\nThank you for using the application!');\nprocess.exit(0);\n});",
        "Interface",
        "readline",
        "process.stdin",
        "query",
        "callback",
        "data",
        "key",
        "ctrl",
        "meta",
        "preserveCursor",
        "true",
        "rl.prompt()",
        "rl.close()"
      ]
    },
    {
      "title": "Node.js Online Compiler",
      "summary": "Node.js Compiler (Editor)\nBuild and host your own website with W3Schools Spaces with a Node.js environment.\nW3Schools Spaces is a website-building tool that enables you to create and share your own website and you can get a Node.js environment to run your web applications.\nYou have full control over the website's appearance and functionality by editing the code directly in your web browser.\nThe tool is user-friendly and requires no setup, making it easy to use.\nThe code editor is packed with features to help you achieve more:\nTemplates: Start from scratch or use a template\nCloud-based: no installations required. You only need your browser\nTerminal & Log: debug and troubleshoot your code easily\nFile Navigator: switch between files inside the code editor\nAnd much more!\nLearn Faster\nPractice is key to mastering coding, and the best way to put your Node.js knowledge into practice is by getting practical with code.\nUse W3Schools Spaces to build, test and deploy code.\nThe code editor lets you write and practice different types of computer languages. It includes Node.js, but you can use it for other languages too.\nNew languages are added all the time:\nIf you don't know Node.js, we suggest that you read our Node.js Tutorial from scratch.\nEasy Package Management\nGet an overview of your packages and easily add or delete frameworks and libraries. Then, with just one click, you can make changes to your packages without manual installation.\nBuild Powerful Websites\nYou can use the code editor in W3School Spaces to build frontend or full-stack websites from scratch.\nOr you can use the 60+ templates available and save time:\nCreate your Spaces account today and explore them all!\nShare Your Website With The World\nHost and publish your websites in no time with W3School Spaces.\nW3Schools subdomain and SSL certificate are included for free with W3School Spaces. An SSL certificate makes your website safe and secure. It also helps people trust your website and makes it easier to find it online.\nWant a custom domain for your website?\nYou can buy a domain or transfer an existing one and connect it to your space.\nHow Does It Work?\nGet started in a few clicks with W3School Spaces.",
      "examples": []
    },
    {
      "title": "Node.js Server Create Node.js Server Powerful Code Editor Practice Makes Perfect kAI",
      "summary": "Coding Skills\nAI Tutor\nProjects\nSecurely\nChoose your Plan\nBy subscribing to a plan you support the W3Schools mission to make\nlearning available to everyone - no matter their background.\n$0 /Forever\nThis is for you that are beginning to explore coding and web development\nTrack your progress\nSet your goals\nBuild and host 1 static website\n100 credits/month\nAccess various AI features like W3Schools kAI coding tutor and interview preparation.\nNo support\n$14.99 /Month\nThis is for you that want to learn and reach your goals faster. Build fullstack projects, ad free experience.\nAd-free experience\nUnlimited challenges\nUnlimited practice tests\nBuild and host 15 static websites\nBuild and host 1 full stack server\nChoose from 75+ templates\n10000 credits/month\nAccess various AI features like W3Schools kAI coding tutor and interview preparation.\nCancel anytime\nFor teachers\nSpend less time on admin tasks while engaging your students. Help them learn, practice and collaborate. All in one place.\nAd-free for focused learning\nDashboard to manage your classroom\nStudy plans for structured learning\nTrack progress with insights\nInteractive code challenges and projects\nAccess to all courses and certification exams\nSpaces for building and publishing projects\n25% OFF\nYou can also buy a domain or connect an existing one.\nSave Time with Templates\nJust landed in Spaces\nLearn to code more effectively\nand intelligently with kAI - AI tutor\nHi! I'm kAI, W3Schools AI Tutor...\nFeel free to ask me any coding-related questions, and I'll do my best to assist you.\nI can help you checking your code for errors, improving your code's structure, explaining coding concepts in a clear and understandable way, and more...\nI can even create complete websites for you based on your input, so what are you waiting for?\nSuper Simple to Share\nIncluded for free in all plans\nWant custom domains?\nHow it works\nCoding Made Easy\nCloud-based\nTerminal & Log\nHow To Libraries\nDatabase\nFile Navigator\nPackage Manager\nAnalytics\nEnvironment Manager\nSave Time & Money.\nAll Your Files in One Place.\nFix Your Code Faster.\nGet Full Data Visibility.\nIncreased Control and Security.\nFind What You Need Quicker.\nGet Traffic Insights.\nGet Inspired\nFrequently Asked Questions\nWith Basic Spaces, you can build frontend websites. Whereas with Fullstack Spaces, you can build frontend and backend websites.\nBasic Spaces include HTML, CSS, and Javascript. Full Stack Spaces include everything in Basic Spaces plus PHP, Python, React.js, Vue.js, Node.js, Handlebars, and Django.\nYour subscription will be automatically renewed every month.\nYour access to all the benefits for the paid period of time will continue. However, the subscription will not be renewed automatically.\nTo subscribe W3Schools accounts for multiple users, you can contact sales@w3schools.com",
      "examples": []
    },
    {
      "title": "Node.js Quiz",
      "summary": "You can test your Node.js skills with W3Schools' Quiz.\nThe Test\nThe test contains 25 questions and there is no time limit.\nThe test is not official, it's just a nice way to see how much you know, or don't know, about Node.js.\nCount Your Score\nYou will get 1 point for each correct answer. At the end of the Quiz, your total score will be displayed. Maximum score is 25 points.\nStart the Quiz\nGood luck!\nStart the Node.js Quiz ❯\nIf you don't know Node.js, we suggest that you read our Node.js Tutorial from scratch.\nKickstart your career\nGet certified by completing the NODEJS course",
      "examples": []
    },
    {
      "title": "Node.js Exercises",
      "summary": "Exercises\nTest your Node.js skills with exercises from all categories:\nIntroduction\nGet Started\nJS Requirements\nvs Browser\nCommand Line\nV8 Engine\nArchitecture\nEvent Loop\nAsync\nPromise\nAsync/Await\nError Handling\nModules\nES Modules\nNPM\npackage.json\nScripts\nDependencies\nPublish Package\nHTTP\nHTTPS\nFile System\nPath\nOS\nURL\nEvents\nStreams\nBuffer\nCrypto\nTimers\nDNS\nAssert\nUtil\nReadline\nES6\nProcess Management\nTypeScript\nLint & Formatting\nFrameworks\nExpress.js\nMiddleware\nREST API\nAPI Authentication\nFrontend\nMySQL\nMySQL Create DB\nMySQL Create Table\nMySQL Insert\nMySQL Select\nMySQL Where\nMySQL Order By\nMySQL Delete\nMySQL Drop Table\nMySQL Update\nMySQL Limit\nMySQL Join\nMongoDB\nMongoDB Create DB\nMongoDB Create Collection\nMongoDB Insert\nMongoDB Find\nMongoDB Query\nMongoDB Sort\nMongoDB Delete\nMongoDB Drop Collection\nMongoDB Update\nMongoDB Limit\nMongoDB Join\nGraphQL\nSocket.IO\nWebSockets\nAdvanced Debugging\nTesting\nTesting Frameworks\nTest Runner\nEnvironment Variables\nDev vs Prod\nCI/CD\nSecurity\nDeployment\nLogging\nMonitoring & Observability\nPerformance\nChild Process\nCluster\nWorker Threads\nMicroservices\nWebAssembly\nHTTP/2\nPerformance Hooks\nVM\nTLS/SSL\nNetwork\nCompression\nLog in to track your progress\nIf you haven't already, sign up to become a W3Schooler, and get points for every exercise you complete.\nAs a logged on W3Schools user you will have access to many features like having your own web page, track your learning progress, receive personal guided paths, and more.\nThe Exercise\nThe exercises are a mix of \"multiple choice\" and \"fill in the blanks\" questions. There are between 3 and 9 questions in each catergory. The answer can be found in the corresponding tutorial chapter. If you're stuck, or answer wrong, you can try again or hit the \"Show Answer\" button to see the correct answer.",
      "examples": []
    },
    {
      "title": "Node.js Syllabus",
      "summary": "Introduction\nThe W3Schools Node.js Tutorial is comprehensive and beginner-friendly.\nIt will give you a fundamental knowledge of Node.js.\nIt is designed for beginners and requires only basic JavaScript knowledge.\nThe content has been carefully made to be bite-sized, simple, and easy to understand.\nThe content has been proven by millions of users over the years. It is updated and improved frequently.\nThe syllabus outline and its sequence are structured so you can learn Node.js step by step, from the introduction to creating server-side applications.\nGet Started With Node.js »\nLearning Outcomes\nLearn what Node.js is and set up your environment\nCreate web servers with the HTTP module\nWork with built-in modules (File System, URL, Events)\nUse Node Package Manager (NPM) to manage packages\nHandle files (upload, read, create, update, delete)\nSend emails using Node.js\nConnect and work with MySQL database\nCreate and manage MongoDB databases\nBuild real-world applications with Node.js\nNote: Are you a teacher teaching Node.js? W3Schools Academy is a toolbox of features that can help you teach. It offers classroom features such as pre-built study plans, classroom administration and much more. Read more about Academy here.\nWhich Subjects Are Node.js Relevant For?\nBack-end Development:\nNode.js is essential for server-side application development.\nWeb Development:\nNode.js enables full-stack JavaScript development.\nAPI Development:\nNode.js is perfect for building RESTful APIs and microservices.\nReal-time Applications:\nNode.js excels at handling real-time data and WebSocket connections.\nDevOps:\nNode.js is widely used for build tools and automation.\nCloud Computing:\nNode.js is popular for cloud-native application development.\nEnterprise Applications:\nNode.js supports building scalable enterprise solutions.\nGet Started\nSign in to Track Progress\nYou can also create a free account to track your progress.\nAs a signed-in user, you get access to features such as:\nLearning paths\nSandbox and lab environments\nAchievements\nAnd much more!\nSign Up - It's free\nOverview of the Modules\nNode.js HOME\nNode.js Intro\nNode.js Get Started\nNode.js Modules\nNode.js HTTP Module\nNode.js File System\nNode.js URL Module\nNode.js NPM\nNode.js Events\nNode.js Upload Files\nNode.js Email\nMySQL Get Started\nMySQL Create Database\nMySQL Create Table\nMySQL Insert Into\nMySQL Select From\nMySQL Where\nMySQL Order By\nMySQL Delete\nMySQL Drop Table\nMySQL Update\nMySQL Limit\nMySQL Join\nMongoDB Get Started\nMongoDB Create DB\nMongoDB Collection\nMongoDB Insert\nMongoDB Find\nMongoDB Query\nMongoDB Sort\nMongoDB Delete\nMongoDB Drop Collection\nMongoDB Update\nMongoDB Limit\nMongoDB Join\nRasPi Get Started\nRasPi GPIO Introduction\nRasPi Blinking LED\nRasPi LED & Pushbutton\nRasPi Flowing LEDs\nRasPi WebSocket\nRasPi RGB LED WebSocket\nRasPi Components\nNode.js Certificate\nGet Started\nSandbox and Lab Environment\nNode.js, like any other platform, is best learned through hands-on practice.\nTry this example using our editor:\nExampleGet your own Node.js Server\nIf you want to explore more and host your project, we have a feature called Spaces that allows you to build, test and deploy Node.js applications for free.\nHere you get a secure sandbox environment called Spaces, where you can practice Node.js code and test projects in real-time.\nSpaces allow you to test, build, and deploy code. This includes a W3Schools subdomain, hosting, and secure SSL certificates.\nSpaces require no installation and run directly in the browser.\nFeatures include:\nCollaboration\nFile navigator\nTerminal & log\nPackage manager\nDatabase\nEnvironment manager\nAnalytics\nCreate a Spaces Account\nNode.js Certification\nW3Schools offers an end-of-pathway certification program.\nHere you can take exams to get certified.\nThe Node.js exam is a test that summarizes the W3Schools Node.js syllabus.\nAfter passing the exam you get the \"Certified Node.js Developer\" Certification.\nThe certification exam is adaptive and graded; students will get a grade from intermediate, advanced to professional.\nBuy Certificate »\nAre You a Teacher?\nAre you interested in learning how you can use W3Schools Academy to Teach Node.js?\nWatch a demo of W3Schools Academy. You'll see how it works, and discover how it can make teaching programming easier and more engaging.\nWatch Demo »",
      "examples": [
        "let http = require('http');\n\nhttp.createServer(function (req, res) {\nres.writeHead(200, {'Content-Type': 'text/plain'});\nres.end('Hello World!');\n}).listen(8080);"
      ]
    },
    {
      "title": "Node.js Study Plan",
      "summary": "Introduction\nThe Node.js study plan helps you teach your students Node.js step-by-step.\nCreating a study plan for Node.js is easy.\nYou can use a pre-built study plan or customize it.\nStudents have different skill levels. The study plans can be customized to ensure that everyone is challenged.\nSave time with pre-built teacher materials and study plans. Easily organize your class with a timeline from the introduction of Node.js to the final exam.\nW3Schools Academy\nThis study plan is a feature of W3Schools Academy.\nW3Schools Academy is a platform that has everything you need to teach coding, all in one place.\nIt offers you as a teacher a toolbox of features that helps you succeed with teaching in your classroom.\nYou need to have an active subscription to access the study plan feature. There are two different subscription tiers:\nEssentials ($1.99 / month per student)\nFull Access ($5.99 / month per student)\nCalculate your price and order here.\nLearn More »\nAcademy also offer other features such as:\nManaging your classroom\nTracking of student progress and reports\nLabs, assignments, and code challenges (prebuilt challenges or create your own ones)\nAuto-grading\nTeaching materials\nCertification exams\nGet a free demo »\nTeacher Materials\nW3Schools has everything you need to teach Node.js.\nThe Node.js training materials is available for you to include and use in your study plan:\nW3Schools Node.js Tutorial\nNode.js Challenges (Coding challenges)\nNode.js Certification Exam (End of Pathway Exam)\nNode.js Syllabus\nWith the Node.js Syllabus, your students will start with the basics, like setting up a Node.js environment and running simple scripts, and move to more advanced topics, like building servers, handling asynchronous events, and creating dynamic applications. Each chapter includes examples, try-it-yourself sections, exercises, and quizzes to make learning easy, interactive, and fun.\nRead more about Node.js Syllabus.\nStudy Plan Overview\nThe study plan features are made to help teachers and students. They make learning easy, flexible, and fun. These features work for different types of classes, learning styles and student level.\nLearning Paths\nYou can add ready-made learning paths.\nThe learning paths are by default ordered by our recommended order.\nYou can change the order.\nYou can add custom activities with text, links, or multi-media files.\nDrag and drop or click to make changes to the path.\nYou can add ready-made learning paths.\nThe learning paths are by default ordered by our recommended order.\nYou can change the order.\nYou can add custom activities with text, links, or multi-media files.\nDrag and drop or click to make changes to the path.\nInteractive Content\nTutorials\nTry-its (test code snippets)\nExercises\nQuiz\nChallenges\nLabs\nTutorials\nTry-its (test code snippets)\nExercises\nQuiz\nChallenges\nLabs\nTimeline and Pace\nYou can set a timeline of your study plan (e.g., 4-week, 8-week, 12-week, 24-week plans).\nYou can decide the learning pace for your class.\nDifferent study plans can be assigned to different students in the same class.\nThe flexibility can help to make sure that everyone is challenged.\nYou can set a timeline of your study plan (e.g., 4-week, 8-week, 12-week, 24-week plans).\nYou can decide the learning pace for your class.\nDifferent study plans can be assigned to different students in the same class.\nThe flexibility can help to make sure that everyone is challenged.\nTrack Student Progress\nThere are tools to track student progress.\nThe analytic tools include: chapter progress, exercises results, quiz results, exam results, and much more.\nThe challenges can be auto-graded or manually graded. The results are available to you as a teacher.\nThere are tools to track student progress.\nThe analytic tools include: chapter progress, exercises results, quiz results, exam results, and much more.\nThe challenges can be auto-graded or manually graded. The results are available to you as a teacher.\nEnd of Pathway Exam\nThe Node.js study plan aligns with the Node.js Certification Exam.\nThe exam can be taken at the end of the study plan, at your selected date.\nThe exam summarizes the Node.js Tutorial.\nYou get reports of the students' results.\nThe Node.js study plan aligns with the Node.js Certification Exam.\nThe exam can be taken at the end of the study plan, at your selected date.\nThe exam summarizes the Node.js Tutorial.\nYou get reports of the students' results.\nAccessibility\nStudy plans and learning materials are accessible on desktops, tablets, and smartphones.\nThis ensures students can learn anytime, anywhere.\nStudy plans and learning materials are accessible on desktops, tablets, and smartphones.\nThis ensures students can learn anytime, anywhere.\nLearn More »\nSample Study Plan\nYou choose the timeline and pace of your study plans.\nSchools have different preferences.\nSome would like more intensive pace, e.g. 5 weeks, others 12 or more weeks.\nIt is completely up to you.\nFor example, this is how a 5-week Node.js study plan could look like:\nWeek 1: Essentials\nWeek 2: Modules, HTTP Modules, File System, URL Module, NPM, Events, Upload Files, Email\nWeek 3: Working with MySQL, Working with MongoDB, Node.js Certification Exam\nImage of Sample Node.js study plan:\nReady to get started?\nStart with Node.js Study Plans today.\nGet Started »\nAre You a Teacher?\nAre you interested in learning how you can use W3Schools Academy to Teach Node.js programming?\nWatch a demo of W3Schools Academy. You'll see how it works, and discover how it can make teaching programming easier and more engaging.\nWatch Demo »",
      "examples": []
    },
    {
      "title": "W3Schools Node.JS Certificate",
      "summary": "W3Schools offers an Online Certification Program.\nThe perfect solution for busy professionals who need to balance work, family, and career building.\nMore than 50 000 certificates already issued!\nGet Your Certificate »\nW3Schools offers an Online Certification Program.\nThe perfect solution for busy professionals who need to balance work, family, and career building.\nMore than 50 000 certificates already issued!\nGet Your Certificate »\nWho Should Consider Getting Certified?\nAny student or professional within the digital industry.\nCertifications are valuable assets to gain trust and demonstrate knowledge to your clients, current or future employers on a ever increasing competitive market.\nW3Schools is Trusted by Top Companies\nW3Schools has over two decades of experience with teaching coding online.\nOur certificates are recognized and valued by companies looking to employ skilled developers.\nSave Time and Money\nShow the world your coding skills by getting a certification.\nThe prices is a small fraction compared to the price of traditional education.\nDocument and validate your competence by getting certified!\nExam overview\nFee: 95 USD\nAchievable certification levels:\nIntermediate (40%)\nAdvanced (75%)\nProfessional (90%)\nNumber of questions:\nAdaptive, 60 on average\nRequirement to pass:\nMinimum 40% - Intermediate level\nTime limit: 60 minutes\nNumber of attempts to pass: 3\nExam deadline: None\nCertification Expiration: None\nFormat: Online, multiple choice\nRegister now »\nAdvance Faster in Your Career\nGetting a certificate proves your commitment to upgrading your skills.\nThe certificate can be added as credentials to your CV, Resume, LinkedIn profile, and so on.\nIt gives you the credibility needed for more responsibilities, larger projects, and a higher salary.\nKnowledge is power, especially in the current job market.\nDocumentation of your skills enables you to advance your career or helps you to start a new one.\nHow Does It Work?\nStudy for free at W3Schools.com\nStudy at your own speed\nTest your skills with W3Schools online quizzes\nApply for your certificate by paying an exam fee\nTake your exam online, at any time, and from any location\nGet Your Certificate and Share It With The World\nExample certificate:\nEach certificate gets a unique link that can be shared with others.\nValidate your certification with the link or QR code.\nCheck how it looks like in this Example.\nShare your certificate on Linked in the Certifications section in just one click!\nDocument Your Skills\nGetting a certificate proves your commitment to upgrade your skills, gives you the credibility needed for more responsibilities, larger projects, and a higher salary.\nGet Your Certificate »\nLooking to add multiple users?\nAre you an educator, manager or business owner looking for courses or certifications?\nWe are working with schools, companies and organizations from all over the world.\nGet courses and/or certifications for your team here.",
      "examples": []
    }
  ],
  "glossary": [
    "2 hostname",
    "advanced communication",
    "api authentication",
    "assert module",
    "asynchronous",
    "backend",
    "buffer module",
    "building applications",
    "built-in modules",
    "cipher crypto",
    "cluster module",
    "core modules",
    "crypto module",
    "ctrl+x",
    "database integration",
    "decipher crypto",
    "diffiehellman crypto",
    "dns module",
    "ecdh crypto",
    "enter",
    "eventemitter events",
    "events module",
    "exercises",
    "express.js",
    "finish",
    "free",
    "graphql",
    "hardware iot",
    "hash crypto",
    "hmac crypto",
    "http module",
    "http2 module",
    "https module",
    "interface readline",
    "javascript",
    "message http",
    "microservices",
    "middleware concept",
    "module basics",
    "mongodb collection",
    "mongodb delete",
    "mongodb find",
    "mongodb insert",
    "mongodb join",
    "mongodb limit",
    "mongodb query",
    "mongodb sort",
    "mongodb update",
    "mysql delete",
    "mysql join",
    "mysql limit",
    "mysql update",
    "mysql where",
    "net module",
    "node architecture",
    "node async",
    "node deployment",
    "node es6+",
    "node frameworks",
    "node home",
    "node intro",
    "node logging",
    "node modules",
    "node monitoring",
    "node npm",
    "node package.json",
    "node performance",
    "node process",
    "node promises",
    "node security",
    "node typescript",
    "node webassembly",
    "node.js advanced",
    "node.js compiler",
    "node.js deployment",
    "node.js exercises",
    "node.js quiz",
    "node.js reference",
    "node.js server",
    "node.js syllabus",
    "open",
    "os module",
    "p2 ssh",
    "path module",
    "perfomance scaling",
    "pi",
    "programs",
    "raspberry",
    "raspi components",
    "raspi websocket",
    "readline module",
    "report error",
    "request http",
    "resources tools",
    "response http",
    "sign crypto",
    "socket.io",
    "stream module",
    "testing debugging",
    "timers module",
    "url module",
    "util module",
    "verify crypto",
    "vm module",
    "w3.css",
    "w3schools spaces",
    "websockets",
    "wifiname",
    "wifipassword",
    "worker cluster",
    "worker threads",
    "yes",
    "zlib module"
  ],
  "objectives": [
    "Web servers and websites",
    "REST APIs",
    "Real-time apps (like chat)",
    "Command-line tools",
    "Working with files and databases",
    "IoT and hardware control"
  ]
}